<html>
<head>
<title>P14-1029.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We extend RNTN to directly consider the sentiment information of arguments</a>
<a name="1">[1]</a> <a href="#1" id=1>By examining sentiment compositions of negators and arguments, we model the quantitative behavior of negators in changing sentiment</a>
<a name="2">[2]</a> <a href="#2" id=2>Figure 1 shows the distribution of the effect of negators on sentiment without considering further semantics of the arguments</a>
<a name="3">[3]</a> <a href="#3" id=3>Note that the two neural network based models incorporate the syntax and semantics by representing each node with a vector</a>
<a name="4">[4]</a> <a href="#4" id=4>Each node of the parse tree is a fixed-length vector that encodes compositional semantics and syntax, which can be used to predict the sentiment of this node</a>
<a name="5">[5]</a> <a href="#5" id=5>A recursive neural tensor network (RNTN) is a specific form of feed-forward neural network based on syntactic (phrasal-structure) parse tree to conduct compositional sentiment analysis</a>
<a name="6">[6]</a> <a href="#6" id=6>In the backpropogation process of the training, each node (except the root node) in the tree carries two kinds of errors the local softmax error and the error passing down from its parent node</a>
<a name="7">[7]</a> <a href="#7" id=7>Note that depending on different purposes, p 1 s u'\u2062' e u'\u2062' n can take the value of the automatically predicted sentiment distribution obtained in forward propagation, the gold sentiment annotation of node p 1 , or even other normalized prior sentiment value or confidence score from external sources (e.g.,, sentiment lexicons or external training data</a>
<a name="8">[8]</a> <a href="#8" id=8>The incoming</a>
</body>
</html>