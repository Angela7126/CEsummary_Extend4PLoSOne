(lp0
VOur contributions to the field are as follows we present a novel and efficient method for tackling the challenge of content selection using a ML classification approach; we applied this method to the domain of feedback summarisation; we present a comparison with an optimisation technique (Reinforcement Learning), and we discuss the similarities and differences between the two methods
p1
aVContent selection decisions based on trends in time-series data determine the selection of the useful and important variables, which we refer to here as factors , that should be conveyed in a summary
p2
aVWe frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not
p3
aVHere, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously []
p4
aVContent is regarded as labels (each template represents a label) and thus the task can be thought of as a classification problem
p5
aVThe decisions of factor selection can be influenced by other factors that their values are correlated with; can be based on the appearance or absence of other factors in the summary; and can be based on the factors u'\u005cu2019' behaviour over time
p6
aVEnsemble methods [] are algorithms that use ensembles to perform ML learning and they are based on problem transformation or algorithm adaptation methods
p7
aVThe difference between the two methods lies in that the collective content selection requires the consideration of an individual preference score (which is defined as the preference of the entity to be selected or omitted, and it is
p8
a.