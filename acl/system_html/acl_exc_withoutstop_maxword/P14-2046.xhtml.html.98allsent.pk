(lp0
VWe create English, Pinyin training pairs from our phrasebook simply by pronouncing the Chinglish with FST D
p1
aVTo do this, we first take our phrasebook triples and construct sample string pairs Epron, Pinyin-split by pronouncing the phrasebook English with FST A, and by pronouncing the phrasebook Chinglish with FSTs D and C
p2
aVHere, we start with reference English and measure the accuracy of Pinyin syllable production, since the choice of Chinglish character does not affect the Chinglish pronunciation
p3
aVThe word-based model can only decode 29 of the 65 test utterances, because wFST E fails if an utterance contains a new English word type, previously unseen in training
p4
aVAs Table 6 shows, the ratio of unseen English word tokens is small, thus large portion of tokens are transformed using word-based method
p5
aVIf the Franglish is well designed, an English speaker can pronounce it and be understood by a French listener
p6
aVFirst, because Chinglish and Chinese are written with the same characters, they render the same inventory of 416 distinct syllables
p7
aVFollowing phrase-based methods in statistical machine translation [ 4 ] and machine transliteration [ 1 ] , we model substitution of longer sequences
p8
aVWe seek to imitate phonetic transformations found in phrasebooks, so phrasebooks themselves are a good source of training data
p9
aVwhere as the reference Pinyin-split sequence is
p10
aVIt is reasonable for u'\u005cu2018' u'\u005cu2018' can I u'\u005cu2019' u'\u005cu2019' to be rendered as u'\u005cu2018' u'\u005cu2018' kan nai u'\u005cu2019' u'\u005cu2019' , with u'\u005cu2018' u'\u005cu2018' nai u'\u005cu2019' u'\u005cu2019' spanning both English words, but this is rare
p11
aVSyllables u'\u005cu2018' u'\u005cu2018' si u'\u005cu2019' u'\u005cu2019' and u'\u005cu2018' u'\u005cu2018' te u'\u005cu2019' u'\u005cu2019' are very popular, because while consonant clusters like English u'\u005cu2018' u'\u005cu2018' st u'\u005cu2019' u'\u005cu2019' are impossible to reproduce exactly, the particular vowels in u'\u005cu2018' u'\u005cu2018' si u'\u005cu2019' u'\u005cu2019' and u'\u005cu2018' u'\u005cu2018' te u'\u005cu2019' u'\u005cu2019' are fortunately very weak
p12
aVSince the speaker may not be able to pronounce the foreign-language orthography, phrasebooks additionally provide phonetic spellings that approximate the sounds of the foreign phrase
p13
aVIf a Chinese speaker wants to say u'\u005cu2018' u'\u005cu2018' {CJK} UTF8gkai u'\u005cu975e' u'\u005cu5e38' u'\u005cu611f' u'\u005cu8c22' u'\u005cu4f60' u'\u005cu8fd9' u'\u005cu987f' u'\u005cu7f8e' u'\u005cu9910' u'\u005cu2019' u'\u005cu2019' , she need only read off the Chinglish u'\u005cu201c' {CJK} UTF8gkai u'\u005cu4e09' u'\u005cu53ef' u'\u005cu6cb9' u'\u005cu5426' u'\u005cu70ed' u'\u005cu65af' u'\u005cu5f2f' u'\u005cu5fb7' u'\u005cu5426' u'\u005cu7c73' u'\u005cu6b27' u'\u005cu201d' , which approximates the sounds of u'\u005cu201c' Thank you for this wonderful meal u'\u005cu201d' using Chinese characters
p14
aVNotice that this model makes alignment errors due to sparser data (e.g.,, the word u'\u005cu2018' u'\u005cu2018' tips u'\u005cu2019' u'\u005cu2019' and u'\u005cu2018' u'\u005cu2018' ti pu si u'\u005cu2019' u'\u005cu2019' only appear once each in the training data
p15
aVFor example, when we decode English u'\u005cu2018' u'\u005cu2018' grandmother u'\u005cu2019' u'\u005cu2019' , we get
p16
aVWe must now estimate the values of FST B parameters, such as P( s i
p17
aVFSTs A, C, and D are unweighted, and remain so throughout this paper
p18
aVIn this paper, we lift this restriction by designing and evaluating a software program with the following
p19
aVOur first evaluation (Table 4 ) is intrinsic, measuring our Chinglish output against references from the test portion of our phrasebook, using edit distance
p20
aVThe output is a string of Chinese characters that approximate English sounds, which we call Chinglish
p21
aVWe find that multiple occurrences of an English word type are generally associated with the same Chinglish sequence
p22
aVTo improve the accuracy of word-based EM alignment, we use the phoneme based model to decode each English word in the training data to Pinyin
p23
aVAlso, Chinglish characters do not generally span multiple English words
p24
aVHowever, the distribution of Chinglish syllables differs a great deal from Chinese (Table 2
p25
aVFinally, FST C converts Pinyin-split into Pinyin, and FST D chooses Chinglish characters
p26
aVTable 5 shows a few examples of the Chinglish generated by the hybrid training and decoding method, as well as the recognized English from the dictation and ASR tasks
p27
aVWe measure the normalized edit distance against an English reference
p28
aVThe average edit distance of phoneme-phrase model and that of hybrid training/decoding model are close, indicating that long phoneme-phrase pairs can emulate word-pinyin mappings
p29
aVActually, we use a Chinese synthesizer to remove bias.) Then we measure edit distance between the human transcription and the reference English from our phrasebook
p30
aVWe compute the normalized edit distance between the system u'\u005cu2019' s output and a human-generated Chinglish reference
p31
aVWe use an online MT system to convert Chinese to an English word sequence (Eword), which is then passed through FST A to generate an English sound sequence (Epron
p32
aVThe phoneme-based models are more robust, able to decode 63 of the 65 utterances, failing only when some English word type falls outside the CMU pronouncing dictionary (FST A
p33
aVWe see that the Word-based method has very high accuracy, but low coverage
p34
aVHere is a sample entry from a French phrasebook for English speakers
p35
aVThen we run the EM algorithm to learn FST B parameters (Table 3 ) and Viterbi alignments, such as
p36
aVWe obtained a collection of 1312 Chinese, English, Chinglish phrasebook tuples 1 1 Dataset can be found at http://www.isi.edu/natural-language/mt/chinglish-data.txt (see Table 1
p37
aVWe speak our Chinglish character sequence output aloud and ask an English monolingual person to transcribe it
p38
aVFigure 1 shows a sample entry from another book u'\u005cu2014' an English phrasebook for Chinese speakers
p39
aVWe initially allow each English word type to map to any sequence of Pinyin, up to length 7, with uniform probability
p40
aVWe also experiment with an additional wFST E that translates English words directly into Chinglish
p41
aVOur final model combines these two, using the word-based model for known English words, and the phoneme-based models for unknown English words
p42
aVWe now turn to WFST E, which short-cuts directly from English words to Pinyin
p43
aVA Chinese speaker pronounces the system u'\u005cu2019' s output out loud, and an English listener takes dictation
p44
aVThe other is respelling generation [ 2 ] , where an English speaker is given a phonetic hint about how to pronounce a rare or foreign word to another English speaker
p45
aVNext, wFST B translates English sounds into Chinese sounds (Pinyin-split
p46
aVFST A is constructed from the CMU Pronouncing Dictionary [ 6 ]
p47
aVOur Chinglish has interesting gross empirical properties
p48
aVOur best system uses the Hybrid training/decoding method
p49
aVWe add these phrase pairs to FST B, and call this the phoneme-phrase-based model
p50
aVPinyin is an official syllable-based romanization of Mandarin Chinese characters, and Pinyin-split is a standard separation of Pinyin syllables into initial and final parts
p51
aVThe current paper describes a single system that lets a Chinese person speak English
p52
aVThese spellings employ the familiar writing system and sounds of the speaker u'\u005cu2019' s language
p53
aVFrom the 100-best list of decodings, we collect combinations of start/end Pinyin syllables for the word
p54
aVThe user ignores the French and goes straight to the Franglish
p55
aVEM learns values for parameters like P ( nai te n i g h t ) , plus Viterbi alignments such as
p56
aVFirst, we obtain Viterbi alignments using the phoneme-based model, e.g
p57
aVOur wFST allows one English sound token to map to one or two Pinyin-split tokens, and it also allows two English sounds to map to one Pinyin-split token
p58
aV1) a Chinese speech synthesizer, and (2) a English speech recognizer
p59
aVWe use 1182 utterances for training, 65 for development, and 65 for test
p60
aVOur system u'\u005cu2019' s input is Chinese
p61
aVPhrasebooks permit a form of accurate, personal, oral communication that speech-to-speech translation devices lack
p62
aVWe model Chinese-to-Chinglish translation with a cascade of weighted finite-state transducers (wFST), shown in Figure 2
p63
aVHowever, the user is limited to a small set of fixed phrases
p64
aVWe take a statistical modeling approach to this problem, as is done in two lines of research that are most related
p65
aVFinally, we repeat the last experiment, but removing the human from the loop, using both automatic Chinese speech synthesis and English speech recognition
p66
aVSecond, we extract phoneme phrase pairs consistent with these alignments
p67
aVResults are shown in Table 7
p68
aVDespite this, the system u'\u005cu2019' s output should be both unambiguously pronounceable by the speaker and readily understood by the listener
p69
aVResults are shown in Table 8
p70
aVPhonetic rendering of a foreign-language translation of that text, which, when pronounced by the speaker, can be understood by the listener
p71
aVWhen we run EM, we find that alignment errors for u'\u005cu2018' u'\u005cu2018' tips u'\u005cu2019' u'\u005cu2019' in section 5.3 are fixed
p72
aVWe then modify the initial, uniform English-to-Pinyin mapping probabilities by giving higher initial weight to mappings that respect observed start/end pairs
p73
aVOutput
p74
aVFrom the example above, we pull out phrase pairs like
p75
aVTravel phrasebooks contain phrases in the speaker u'\u005cu2019' s language (e.g.,, u'\u005cu2018' u'\u005cu2018' thank you u'\u005cu2019' u'\u005cu2019' ) paired with foreign-language translations (e.g.,, u'\u005cu2018' u'\u005cu2018' u'\u005cu0421' u'\u005cu041f' u'\u005cu0410' u'\u005cu0421' u'\u005cu0418' u'\u005cu0411' u'\u005cu041e' u'\u005cu2019' u'\u005cu2019'
p76
aVWe use no phrase-size limit, but we do not cross word boundaries
p77
aVOur goal is to build an application that covers many language pairs and directions
p78
aVText entered by the speaker, in her own language
p79
aVThe first is machine transliteration [ 3 ] , in which names and technical terms are translated across languages with different sound systems
p80
aVBy contrast, we aim to help people issue full utterances that cross language barriers
p81
aVCan people speak a language they don u'\u005cu2019' t know
p82
aVWe know of no other computational work on this type of corpus
p83
aVSpeech recognition is more fragile than human transcription, so edit distances are greater
p84
aVMappings between phonemes are context-sensitive
p85
aVOur second evaluation is a dictation task
p86
aVHere, u'\u005cu2018' u'\u005cu2018' ae n u'\u005cu2019' u'\u005cu2019' should be decoded as u'\u005cu2018' u'\u005cu2018' uan u'\u005cu2019' u'\u005cu2019' when preceded by u'\u005cu2018' u'\u005cu2018' r u'\u005cu2019' u'\u005cu2019'
p87
aVWe automate the previous evaluation by replace the two humans with
p88
aVInput
p89
aVThe main challenge is that different languages have different orthographies, different phoneme inventories, and different phonotactic constraints, so mismatches are inevitable
p90
aVWe build several candidate Chinese-to-Chinglish systems and evaluate them as follows
p91
aVActually, it happens frequently
p92
aVS
p93
a.