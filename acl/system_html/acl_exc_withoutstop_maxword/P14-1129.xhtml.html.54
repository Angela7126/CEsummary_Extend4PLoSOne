<html>
<head>
<title>P14-1129.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We chose these values for the hidden layer size, vocabulary size, and source window size because they seemed to work best on our data sets u'\u2013' larger sizes did not improve results, while smaller sizes degraded results</a>
<a name="1">[1]</a> <a href="#1" id=1>Additionally, on top of a simpler decoder equivalent to Chiang u'\u2019' s [ 5 ] original Hiero implementation, our NNJM features are able to produce an improvement of +6.3 BLEU u'\u2013' as much as all of the other features in our strong baseline system combined</a>
<a name="2">[2]</a> <a href="#2" id=2>When used as MT decoding features, these models are able to produce a gain of +3.0 BLEU on top of a very strong and feature-rich baseline, as well as a +6.3 BLEU gain on top of a simpler system</a>
<a name="3">[3]</a> <a href="#3" id=3>Specifically, if unaligned target word t is on the right edge of an arc that covers source span [ s i , s j ] , we simply say that t is affiliated with source word s j</a>
<a name="4">[4]</a> <a href="#4" id=4>One issue with the S2T NNJM is that the probability is</a>
</body>
</html>