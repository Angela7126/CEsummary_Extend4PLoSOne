(lp0
VRAkEL tackles this problem by constructing an ensemble of LP classifiers and training each one on a different random subset of the set of labels []
p1
aVML classification achieved significantly higher accuracy, which was expected as it is a supervised learning method
p2
aVRAkEL is based on Label Powerset (LP), a problem transformation method []
p3
aVRAkEL overcomes this limitation by constructing a set of LP classifiers, which are trained with different random subsets of the set of labels []
p4
aVWe compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with student users
p5
aVHere, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously []
p6
aVContent is regarded as labels (each template represents a label) and thus the task can be thought of as a classification problem
p7
aVEnsemble methods [] are algorithms that use ensembles to perform ML learning and they are based on problem transformation or algorithm adaptation methods
p8
aVWe frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not
p9
aVRL is trained to optimise for this function, and therefore it achieves higher reward, whereas ML is trained to learn by examples, therefore it produces output closer to the gold standard (lecturer u'\u005cu2019' s produced summaries
p10
aVThe reduced accuracy of the classification with predicted history is due to the error in
p11
a.