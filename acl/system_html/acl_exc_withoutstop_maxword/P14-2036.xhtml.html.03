<html>
<head>
<title>P14-2036.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In LDA, each document has a distribution over all topics P ( z k d j ) , and each topic has a distribution over all words P ( w i z k ) , where z k , d j and w i represent the topic, document and word respectively</a>
<a name="1">[1]</a> <a href="#1" id=1>To enrich the content of every microblog, we select relevant words from external knowledge in this section</a>
<a name="2">[2]</a> <a href="#2" id=2>With the above two distributions, we then add a number of words from news as additional information to microblogs by evaluating the relatedness of between each word and microblog, since words not appearing in the microblog may still be highly relevant</a>
<a name="3">[3]</a> <a href="#3" id=3>Differing from step (a), the method used for topic inference for microblogs is not</a>
</body>
</html>