<html>
<head>
<title>P14-1056.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>This paper introduces a novel method for imposing soft constraints via dual decomposition</a>
<a name="1">[1]</a> <a href="#1" id=1>The algorithms we present in later sections for handling soft global constraints and for learning the penalties of these constraints can be applied to general structured linear models, not just CRFs, provided we have an available algorithm for performing MAP inference</a>
<a name="2">[2]</a> <a href="#2" id=2>When hard constraints can be encoded as linear equations on the output variables, and the underlying model u'\u2019' s inference task can be posed as linear optimization, one can formulate this constrained inference problem as an integer linear program (ILP) [ 15 ]</a>
<a name="3">[3]</a> <a href="#3" id=3>We also propose a method for learning the penalties the prediction problem incurs for violating these soft constraints</a>
<a name="4">[4]</a> <a href="#4" id=4>This is necessary because u'\u039b' is a vector of dual variables for inequality constraints</a>
<a name="5">[5]</a> <a href="#5" id=5>Note that when performing MAP subject to soft constraints, optimal solutions might not satisfy some constraints, since doing so would reduce the model u'\u2019' s score by too much</a>
<a name="6">[6]</a> <a href="#6" id=6>Using our new method, we are able to incorporate not only all the soft global constraints of Chang et al</a>
<a name="7">[7]</a> <a href="#7" id=7>In other words, the dual problem can not penalize the violation of a constraint more than the soft constraint model in the primal would penalize you if you violated it</a>
<a name="8">[8]</a> <a href="#8" id=8>Dual Decomposition is a popular method for performing MAP inference in this scenario, since it leverages known algorithms for MAP</a>
</body>
</html>