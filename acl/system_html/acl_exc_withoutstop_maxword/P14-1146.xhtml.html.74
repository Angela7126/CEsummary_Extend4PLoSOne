<html>
<head>
<title>P14-1146.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We compare sentiment-specific word embedding (SSWE h , SSWE r , SSWE u ) with baseline embedding learning algorithms by only using word embedding as features for Twitter sentiment classification</a>
<a name="1">[1]</a> <a href="#1" id=1>A typical case in sentiment analysis is that the composed phrase and multiword expression may have a different sentiment polarity than the individual words it contains, such as not [bad] and [great] deal of (the word in the bracket has different sentiment polarity with the ngram</a>
<a name="2">[2]</a> <a href="#2" id=2>Following the traditional C W model [ 9 ] , we incorporate the sentiment information into the neural network to learn sentiment-specific word embedding</a>
<a name="3">[3]</a> <a href="#3" id=3>These automatically collected tweets contain noises so they cannot be directly used as gold training data to build sentiment classifiers, but they are effective enough to provide weakly supervised signals for training the sentiment-specific word embedding</a>
<a name="4">[4]</a> <a href="#4" id=4>Many studies on Twitter sentiment classification [ 32 , 10 , 1 , 22 , 48 ] leverage massive noisy-labeled tweets selected by positive and negative emoticons as training set and build sentiment classifiers directly, which is called distant supervision [ 17 ]</a>
<a name="5">[5]</a> <a href="#5" id=5>The objective is to classify the sentiment polarity of a tweet as positive, negative or neutral</a>
<a name="6">[6]</a> <a href="#6" id=6>The quality of SSWE is also directly evaluated by measuring the word similarity in the embedding space for sentiment lexicons</a>
<a name="7">[7]</a> <a href="#7" id=7>When such word embeddings</a>
</body>
</html>