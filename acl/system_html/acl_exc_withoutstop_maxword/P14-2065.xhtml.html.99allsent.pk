(lp0
VWe next investigated whether our results support the Semantic Consistency Hypothesis
p1
aVThus, calculating consistency of a class must take differing frames into account
p2
aVThe Semantic Consistency Hypothesis would be supported if, within that database, predicates with the same syntactic properties were systematically related semantically
p3
aVThe consistency for the class as a whole is the average across frames
p4
aVAs noted above, the question is not whether all verbs in the same syntactic class share the same semantic entailments
p5
aVThere are many sophisticated rubrics for calculating consistency
p6
aVEven a single verb may have different semantic entailments when placed in different syntactic frames
p7
aVThe consistency for this class/frame combination is 60%
p8
aVPrevious work suggests that it is the semantic entailments that matter, particularly for explaining the syntactic behavior of verbs [ 10 ]
p9
aVMean consistency averaged across classes is shown for each task in Table 2
p10
aVIn Phase 1 of the project, we focused on 11 verb classes (Table 3) comprising 641 verbs and seven different semantic entailments (Table 2
p11
aVAs expected, consistency was lowest for Evaluation , which is not expected to necessarily correlate with syntax
p12
aVOne significant challenge for any such project is first classifying verbs according to the syntactic frames they can appear in
p13
aVVerbNet (Kipper et al., 2008; based on Levin, 1993) lists over 6,000 verbs, categorized into 280 classes according to the syntactic frames they can appear in
p14
aVThus, we investigate the semantics of each verb in each syntactic frame available to it (as described by VerbNet
p15
aVWe selected semantic features of interest based on those most commonly cited in the linguistics literature, with a particular focus on those that u'\u005cu2013' according to VerbNet u'\u005cu2013' apply to many predicates
p16
aVThe exact semantics associated with a verb may depend on its syntactic frame
p17
aVBelow, we summarize the main findings thus far
p18
aVThus, at least initially, we are focusing on the 6,000+ verbs already cataloged in VerbNet
p19
aVVerbNet will be edited as necessary based on the empirical results
p20
aVAs such, the VerbCorner Project is also verifying and validating the semantics currently encoded in VerbNet
p21
aVIntegration with VerbNet has additional benefits, since VerbNet itself is integrated with a variety of linguistic resources, such as PropBank and Penn TreeBank
p22
aVVerbs such as hit and like do not describe a change of state and so cannot appear in both forms
p23
aVCollecting data from naive subjects is even more laborious, particularly since the average Man on the Street is not necessarily equipped with metalinguistic concepts like caused change of state and propositional attitude
p24
aVIn fact, annotators frequently flagged these items as ungrammatical, which is a valuable result in itself for improving VerbNet
p25
aVThus Sally rolled the ball entails that somebody applied force to the ball (namely
p26
aVSally), whereas The ball rolled does not
p27
aVPrevious research has shown that humans find it easier to reason about real-world scenarios than make abstract judgments [ 3 ]
p28
aVThus, for each feature (e.g.,, movement ), we converted the metalinguistic judgment ( u'\u005cu201c' Does this verb entail movement on the part of some entity u'\u005cu201d' ) into a real-world problem
p29
aVIn principle, these judgments would come from naive annotators, since researchers u'\u005cu2019' intuitions about subtle judgments may be unconsciously clouded by theoretical commitments [ 4 ]
p30
aVEach task had been iteratively piloted and redesigned until inter-annotator reliability was acceptable, as described in a previous publication
p31
aVGiven the sheer scale of the project, data-collection is expected to take several years at least
p32
aVHowever, these pilot studies involved a small number of items which were coded by all annotators
p33
aVBecause we recruited large numbers of annotators, most of whom annotated only a few items, typical measures of inter-annotator agreement such as Cohen u'\u005cu2019' s kappa are not easily calculated
p34
aVSince there were typically 4 or more possible answers per item, inter-annotator agreement was well above chance
p35
aVThus, data-collection has been broken up into a series of phases
p36
aVThat is, ideally there would be some database of semantic judgments for a comprehensive set of verbs from each syntactic class
p37
aVThe limiting factor is scale with many thousands of verbs and over a hundred commonly-discussed semantic features and syntactic frames, it is not feasible for a single researcher, or even team of researchers, to check which verbs appear in which syntactic frames and carry which semantic entailments
p38
aVImportantly, the semantics listed here is not just for the verb spray but applies to all verbs from the Spray Class whenever they appear in that syntactic frame u'\u005cu2013' that is, VerbNet assumes the Semantic Consistency Hypothesis
p39
aVHowever, the relevant verbs make up a tiny fraction of all English verbs, and even for these verbs, the syntactic frames in question represent only a fraction of the syntactic frames available to those verbs
p40
aVThe VerbCorner Project 3 3 http://gameswithwords.org/VerbCorner/ is devoted to collecting semantic judgments for a comprehensive set of verbs along a comprehensive set of theoretically-relevant semantic dimension
p41
aVThese data can be used to test the Semantic Consistency Hypothesis
p42
aVThere is some set of semantic features such that verbs that share the same syntactic behavior are identical along those semantic features
p43
aVThat is, all verbs in the same class appear in the same set of syntactic frames
p44
aVThis account has a natural consequence, which we dub the Semantic Consistency Hypothesis
p45
aVImportantly, in addition to characterizing the syntactic frames associated with each class, VerbNet also characterizes the semantics of each class
p46
aVAs such, this task provides a lower bound for how much semantic consistency one might expect within a syntactic verb class
p47
aVIn computational linguistics and natural language processing, some form of the Semantic Consistency Hypothesis is often included in linguistic resources and utilized in applications
p48
aVWe then considered how many verbs in each class had the same annotation in any given syntactic frame
p49
aVIn the second frame, 6 verbs received the same annotation and 4 verbs received others
p50
aVIndependent of the validity of that hypothesis, the semantic judgments themselves should prove useful for any study of linguistic meaning or related application
p51
aVGiven the prominence of the Semantic Consistency Hypothesis in both theory and practice, one might expect that it was on firm empirical footing
p52
aVThe semantic annotation depended on syntactic frame nearly 1/4 of the time
p53
aVFor instance, class 9.7, which comprises a couple dozen verbs, allows 7 different syntactic frames
p54
aVVerbNet suggests two syntactic frames for class 63, one of which ( NP V that S ) appears to be marginal
p55
aVFor each syntactic frame in each class, we determined the most common annotation
p56
aVFor example, suppose a class had 10 verbs and 2 frames
p57
aVVerbs vary in terms of which syntactic frames they can appear in (Table 1
p58
aVIn the first frame, 8 verbs received the same annotation and 2 received others
p59
aVFor instance, annotators judged that class 18.1 verbs in the NP V NP PP.instrument entailed movement on the part of the instrument ( Sally hit the ball with the stick ) u'\u005cu2013' something not reflected in VerbNet
p60
aVHowever, most theorists posit that there is a systematic relationship between the semantics of a verb and the syntactic frames in which it can appear [ 9 ]
p61
aVVerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling [ 18 ] , inferencing [ 20 ] , verb classification [ 8 ] , and information extraction [ 11 ]
p62
aVHere, there does appear to be a systematic semantic distinction between the two syntactic frames in each alternation, at least most of the time
p63
aVSeveral previous projects have successfully crowd-sourced linguistic annotations, such as Phrase Detectives, where volunteers have contributed 2.5 million judgments on anaphoric relations [ 16 ]
p64
aVEach phase focuses on a small number of classes and/or semantic entailments
p65
aVBelow, the term item is the unit of annotation a verb in a frame
p66
aVIn any case, to our knowledge, of the 280 syntactic verb classes listed by VerbNet, only a handful have been studied in any detail
p67
aVThe consistency for this class/frame combination is 80%
p68
aVThe VerbCorner Project is aimed at filling that empirical gap
p69
aVNo such database exists, whether consisting of the judgments of linguists or naive annotators
p70
aVSyntactic Frame NP V NP PP destination Example Jessica sprayed the wall
p71
aVIn fact, both researchers argue that a principled relationship between syntax and semantics is necessary for language to be learnable at all
p72
aVFor instance, it is argued that verbs like break , which describe a caused change of state, can appear in both the NP V NP form ( Sally broke the vase ) and the NP V form ( The vase broke
p73
aVFor instance, inter-annotator agreement was typically low for class 63
p74
aV1 1 Note that this is a simplification in that there are non-causal verbs that appear in both the NP V NP frame and the NP V frame
p75
aVIn general, there has been interest in the NLP literature in using these syntactially-relevant semantic features for shallow semantic parsing (e.g.,, Giuglea and Moschitti, 2006)
p76
aVWe address the issue of scale through crowd-sourcing
p77
aVWe describe in detail one such resource, VerbNet, which is highly relevant to our investigation
p78
aVIt is widely recognized that a principled relationship between syntax and semantics would have broad implications
p79
aVMost theoretical studies report researcher judgments for only a handful of examples; how many additional examples were considered by the researcher goes unreported
p80
aVRecruiting large numbers of volunteers, each of whom may provide only a few annotations
p81
aVConversely, Gleitman (1990) has shown such a syntax-semantics relationship could solve significant problems in vocabulary acquisition
p82
aVInterestingly, consistency for Evaluation was nonetheless well above floor
p83
aVIt is frequently invoked in theories of language acquisition
p84
aVThis has been tested with a reasonable sample of the relevant verbs and also in both children and adults [ 1 , 15 ]
p85
aV4 4 Note that this table was calculated based on whether the semantic feature was present or not
p86
aVFirst, we determined the annotation for each item (i.e.,, each verb/frame combination) by majority vote
p87
aVThese frequently matched VerbNet u'\u005cu2019' s semantics, though not always
p88
aVSimilarly, only verbs that describe propositional attitudes, such as like , can take a that complement ( John liked that Sally broke the vase
p89
aVIn all, we collected 162,564 judgments from 1,983 volunteers (Table 2
p90
aVWhile six of these entailments were chosen from among those features widely believed to be relevant for syntax, one was not
p91
aVA Good World, which investigated evaluation ( Is the event described by the verb positive or negative
p92
aVThe entry for one frame is shown below
p93
aVHow good was the reliability in the crowd-sourcing context
p94
aVWe then considered what proportion of all annotations were accounted for by the modal response a mean of 100% would indicate that there was no disagreement among annotators for any item
p95
aVThis is perhaps not surprising two sentences that have the same values for Physical Change, Application of Force, Physical Contact, Change of Mental State, Mental State , and Location Change are, on average, also likely to be both good or both bad
p96
aVFor instance, for Application of Force , annotators determined which participant in the event was applying the force
p97
aVIn many cases, annotator disagreement seems to be driven by syntactic constructions that are only marginally grammatical
p98
aVIn principle, this could be an unpredictable fact about the verb that must be acquired, much like the phonological form of the verb
p99
aVNote that each task is designed to elicit judgments about entailments u'\u005cu2013' things that must be true rather than are merely likely to be true
p100
aVThis amplifies the impact of any VerbCorner-inspired changes to VerbNet
p101
aVFor instance, Pinker (1984, 1989) has described how this correspondence could solve long-standing puzzles about how children learn syntax in the first place
p102
aVAlthough evaluation of events is an important component of human psychology, to our knowledge no researcher has suggested that it is relevant for syntax
p103
aVInstead, for each item, we calculated the most common (modal) response
p104
aVThe full data and annotations will be released in the near future and may be available now by request
p105
aVAs can be seen in Table 2, for every task, the modal response covered the bulk responses, ranging from a low of 72% for Evaluation to a high of 93% for Physical Contact
p106
aVThis ensures that there are meaningful intermediate results that can be disseminated prior to the completion of the entire project
p107
aVConsistency was much higher for the other tasks, and in fact was close to ceiling for most of them
p108
aV2 2 There is a long tradition of partitioning semantics into those aspects of meaning which are u'\u005cu201c' grammatically relevant u'\u005cu201d' and those which are not
p109
aVThe strongest evidence comes from experimental work on several so-called alternations (the passive, causative, locative, and dative alternations
p110
aVSyntax Agent V Theme {+ loc
p111
aVOne way of addressing this question is to collect additional annotations for those items that deviate from the mode
p112
aVWe refer the interested reader to Pinker (1989), Jackendoff (1990), and Levin Rappaport Hovav (2005
p113
aVThis represents good performance given that the annotators were entirely untrained
p114
aVThis manuscript reports the results of Phase 1
p115
aVIn u'\u005cu201c' Explode on Contact, u'\u005cu201d' designed to elicit judgments about physical contact, objects and people explode when they touch one another
p116
aVIt has also been employed in models of language acquisition [ 12 , 2 ]
p117
aVIn many cases, the data was significantly richer
p118
aVIn order to minimize unwanted effects of world knowledge, the verb u'\u005cu2019' s arguments are replaced with nonsense words or randomly chosen proper names ( Sally sprayed the dax onto the blicket
p119
aVThis is not an accidental oversight
p120
aVIt remains to be seen whether the items that deviate from the mode represent true differences in semantics or reflect merely noise
p121
aVNote that on certain accounts, this is a strong tendency rather than a strict necessity (e.g.,, Goldberg, 1995)
p122
aV+ dest_conf } Destination Semantics motion ( during (E), Theme ) Not ( Prep ( start (E), Theme , Destination )) Prep ( end (E), Theme , Destination ) Cause ( Agent , E
p123
aVHowever, for expository purposes here, we use one that is intuitive and easy to interpret
p124
aVFor example, in u'\u005cu201c' Simon Says Freeze, u'\u005cu201d' a task designed to elicit judgments about movement, the Galactic Overlord (Simon) decrees u'\u005cu201c' Galactic Stay Where You Are Day, u'\u005cu201d' during which nobody is allowed to move from their current location
p125
aVI control that Mary eats
p126
aVThis is summarized in Table 3
p127
aVThe use of novel words is explained by the story for each task
p128
aVThe participant reads descriptions of events and decides whether anything has exploded
p129
aVParticipants read descriptions of events and decide whether anyone violated the rule
p130
aVIf John greeted Bill, they might have come into contact (e.g.,, by shaking hands), but perhaps they did not
p131
aVAny opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation
p132
aVFor details, see [ 10 ]
p133
aVWe gratefully acknowledge the support of the National Science Foundation Grant NSF-IIS-1116782, DARPA Machine Reading FA8750-09-C-0179, and funding from the Ruth L
p134
aVKirschstein National Research Service Award
p135
aV70%
p136
a.