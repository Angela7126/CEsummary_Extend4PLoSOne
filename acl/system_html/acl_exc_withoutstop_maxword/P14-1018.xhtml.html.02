<html>
<head>
<title>P14-1018.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Sharing restrictions and rate limits on Twitter data collection only allowed us to recreate a semblance of ZLR data 6 6 This inability to perfectly replicate prior work based on Twitter is a recognized problem throughout the community of computational social science, arising from the data policies of Twitter itself, it is not specific to this work u'\u2013' 193 Democratic and 178 Republican users with 1K tweets per user, and 20 neighbors of four types including follower, friends, user mention and retweet with 200 tweets per neighbor for each user of interest</a>
<a name="1">[1]</a> <a href="#1" id=1>Other works suggested to process text streams for a variety of NLP tasks e.g.,, real-time opinion mining and sentiment analysis in social media [ 25 ] , named entity disambiguation [ 32 ] , statistical machine translation [ 16 ] , first story detection [ 28 ] , and unsupervised dependency parsing [ 14 ]</a>
<a name="2">[2]</a> <a href="#2" id=2>Supervised Batch Approaches The vast majority of work on predicting latent user attributes in social media apply supervised static SVM models for discrete categorical e.g.,, gender and regression models for continuous attributes e.g.,, age with lexical bag-of-word features for classifying user gender [ 11 , 31 , 5 , 38 ] , age [ 31 , 22 , 21 ] or political orientation</a>
<a name="3">[3]</a> <a href="#3" id=3>[ 7 ] rely on identifying strong partisan clusters of Democratic and Republican users in a Twitter network based on retweet and user mention degree of connectivity, and then combine this clustering information with the follower and friend neighborhood size features</a>
<a name="4">[4]</a> <a href="#4" id=4>Inferring latent user attributes such as gender, age, and political preferences [ 30 , 42 , 6 ] automatically from personal communications and social media including emails, blog posts or public discussions has become increasingly popular with the web getting more social and volume of data available</a>
<a name="5">[5]</a> <a href="#5" id=5>experiments are performed across multiple datasets supporting the prediction of political preference in Twitter, to highlight the significant differences in performance that arise from the underlying collection and annotation strategies</a>
<a name="6">[6]</a> <a href="#6" id=6>To investigate all types of social relationships between Twitter users and construct Twitter social graphs we collect lists of followers and friends, and extract user mentions, hashtags, replies and retweets from communications</a>
<a name="7">[7]</a> <a href="#7" id=7>Such extreme divergences in the amount of time required for classification across all graphs should be of strong interest to researchers concerned with latent attribute prediction tasks because Twitter users produce messages with extremely different frequencies</a>
<a name="8">[8]</a> <a href="#8" id=8>Figure 3 demonstrates that more tweets during prediction time lead to higher accuracy by showing that more users with 100 tweets are correctly classified e.g.,, filled green markers in the right upper quadrant are true Republicans and in the left lower quadrant are true Democrats</a>
<a name="9">[9]</a> <a href="#9" id=9>In addition, we propose streaming models for personal analytics that dynamically update user labels based on their stream of communications which has been</a>
</body>
</html>