<html>
<head>
<title>P14-1031.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Specifically, we use the Conditional Random Field (CRF) model as the learner for sentence-level sentiment classification, and incorporate rich discourse and lexical knowledge as soft constraints into the learning of CRF parameters via Posterior Regularization (PR) [ 7 ]</a>
<a name="1">[1]</a> <a href="#1" id=1>The second example in Table 5 shows that the PR model learned with discourse constraints correctly predicts the sentiment of two sentences where no lexical constraints apply</a>
<a name="2">[2]</a> <a href="#2" id=2>We can incorporate the proposed constraints (constraints derived from lexical patterns and discourse connectives) as hard constraints into CRF during inference by manually setting u'\u039b' in equation 4 to a large value, 9 9 We set u'\u039b' to 1000 for the lexical constraints and -1000 to the discourse connective constraints in the experiments</a>
<a name="3">[3]</a> <a href="#3" id=3>In contrast, both PR l u'\u2062' e u'\u2062' x and PR significantly outperform CRF , which implies that incorporating lexical and discourse constraints as posterior constraints is much more effective</a>
<a name="4">[4]</a> <a href="#4" id=4>CRF augmented with inference constraints</a>
</body>
</html>