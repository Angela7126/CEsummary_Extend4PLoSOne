(lp0
VWe show that for both domains, patents and Wikipedia, jointly learning bilingual sparse word associations and dense knowledge-based similarities directly on relevance ranked data improves significantly over approaches that use either only sparse or only dense features, and over approaches that combine query translation by SMT with standard retrieval in the target language
p1
aVVW denotes a sparse model using word-based features trained with SGD
p2
aVLinLearn denotes model combination by overloading the vector representation of queries u'\u005cud835' u'\u005cudc2a' and documents u'\u005cud835' u'\u005cudc1d' in the VW linear learner by incorporating arbitrary ranking models as dense features
p3
aVSokolov et al
p4
aV2010 ) show that for the domain of Wikipedia, learning a sparse
p5
a.