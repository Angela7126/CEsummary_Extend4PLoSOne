(lp0
VNote that the Asiya metrics are combinations of several metrics, and these combinations (which exclude DR and DR- lex ) can be also tuned; this yields sizable improvements over the untuned versions as column three in the table shows
p1
aVAs an example, consider the three discourse trees (DTs) shown in Figure 4 a ) for a reference (human) translation, and ( b ) and ( c ) for translations of two different systems on the WMT12 test dataset
p2
aVIn this paper, rather than proposing yet another MT evaluation metric, we show that discourse information is complementary to many existing evaluation metrics, and thus should not be ignored
p3
aVAgain, DR- lex is better than DR; with a positive Tau of +.133, yet as an individual metric, it ranks poorly compared to other metrics in group II
p4
aVFurthermore, when combined with individual metrics in group II, DR- lex is able to improve consistently over each one of them
p5
aVThis suggests that both DR and DR- lex contain information that is complementary to that of the individual metrics that we experimented with
p6
aVHowever, over all metrics and all language pairs, DR- lex is able to obtain an average improvement in correlation of +.035, which is remarkably higher than that of DR
p7
aVOur working hypothesis is that the similarity between the discourse structures of an automatic and of a reference translation provides additional information that can be valuable for evaluating MT systems
p8
aVIndividually, DR- lex outperforms most of the metrics from group II, and ranks as the second best metric in that group
p9
aVTo do so, we
p10
a.