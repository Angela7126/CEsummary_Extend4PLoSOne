(lp0
VWhen combining discourse constraints with features from different sentences, the PR model becomes more powerful in disambiguating sentiment
p1
aVThe second example in Table 5 shows that the PR model learned with discourse constraints correctly predicts the sentiment of two sentences where no lexical constraints apply
p2
aVWe develop a rich set of context-aware posterior constraints for sentence-level sentiment analysis by exploiting lexical and discourse knowledge
p3
aVSpecifically, we use the Conditional Random Field (CRF) model as the learner for sentence-level sentiment classification, and incorporate rich discourse and lexical knowledge as soft constraints into the learning of CRF parameters via Posterior Regularization (PR) [ 7 ]
p4
aVSpecifically, we construct the lexical constraints by extracting sentiment-bearing patterns within sentences and construct the discourse-level constraints by extracting discourse relations that indicate sentiment coherence or sentiment changes both within and across sentences
p5
aVThis confirms that encoding lexical and discourse knowledge as posterior constraints allows the feature-based model to gain additional
p6
a.