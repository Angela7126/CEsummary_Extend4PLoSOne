<html>
<head>
<title>P14-2007.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We ensure the quality of our dataset in different ways a) Our annotators are instructed to avoid unnecessary head movements and eye-movements outside the experiment environment b) To minimize noise due to head movements further, they are also asked to state the annotation verbally, which was then manually recorded, (c) Our annotators are students between the ages 20-24 with English as the primary language of academic instruction and have secured a TOEFL iBT score of 110 or above</a>
<a name="1">[1]</a> <a href="#1" id=1>The novelty of our work is three-fold a) The proposition of a metric to measure complexity of sentiment annotation, (b) The adaptation of past work that uses eye-tracking for NLP in the context of sentiment annotation, (c) The learning of regressors that automatically predict SAC using linguistic features</a>
<a name="2">[2]</a> <a href="#2" id=2>The correlation values are positive and indicate that even if the predicted scores are not as accurate as desired, the system is capable of ranking sentences in the correct order based on their sentiment complexity</a>
<a name="3">[3]</a> <a href="#3" id=3>The underlying idea is if we monitor annotation of two textual units of equal length, the more complex unit will take longer to annotate, and hence, should have a higher SAC</a>
</body>
</html>