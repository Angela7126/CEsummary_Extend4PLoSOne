<html>
<head>
<title>P14-1116.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>RAkEL tackles this problem by constructing an ensemble of LP classifiers and training each one on a different random subset of the set of labels []</a>
<a name="1">[1]</a> <a href="#1" id=1>ML classification achieved significantly higher accuracy, which was expected as it is a supervised learning method</a>
<a name="2">[2]</a> <a href="#2" id=2>RAkEL is based on Label Powerset (LP), a problem transformation method []</a>
<a name="3">[3]</a> <a href="#3" id=3>RAkEL overcomes this limitation by constructing a set of LP classifiers, which are trained with different random subsets of the set of labels []</a>
<a name="4">[4]</a> <a href="#4" id=4>We compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with student users</a>
<a name="5">[5]</a> <a href="#5" id=5>Here, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously []</a>
<a name="6">[6]</a> <a href="#6" id=6>Content is regarded as labels (each template represents a label) and thus the task can be thought of as a classification problem</a>
<a name="7">[7]</a> <a href="#7" id=7>Ensemble methods [] are algorithms that use ensembles to perform ML learning and they are based on problem transformation or algorithm adaptation methods</a>
<a name="8">[8]</a> <a href="#8" id=8>We frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not</a>
<a name="9">[9]</a> <a href="#9" id=9>RL is trained to optimise for this function, and therefore it achieves higher reward, whereas ML is trained to learn by examples, therefore it produces output closer to the gold standard (lecturer u'\u2019' s produced summaries</a>
<a name="10">[10]</a> <a href="#10" id=10>The reduced accuracy of the classification with predicted history is due to the error in</a>
</body>
</html>