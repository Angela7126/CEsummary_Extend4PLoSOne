<html>
<head>
<title>P14-1132.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We show that the induced cross-modal semantic space is powerful enough that sensible guesses about the correct word denoting an object can be made, even when the linguistic context vector representing the word has been created from as little as 1 sentence containing it</a>
<a name="1">[1]</a> <a href="#1" id=1>During training, this cross-modal vocabulary is used to induce a projection function (Section 4.4 ), which u'\u2013' intuitively u'\u2013' represents a mapping between visual and linguistic dimensions</a>
<a name="2">[2]</a> <a href="#2" id=2>The process of learning to map objects to the their word label is implemented by training a projection function f proj v u'\u2192' w from the visual onto the linguistic semantic space</a>
<a name="3">[3]</a> <a href="#3" id=3>Thus, this function, given a visual vector, returns its corresponding linguistic representation</a>
<a name="4">[4]</a> <a href="#4" id=4>Moreover, if this is also the first linguistic encounter of that concept, then we refer to the task as fast mapping</a>
<a name="5">[5]</a> <a href="#5" id=5>In our setup, after applying CCA on the two spaces u'\ud835' u'\udc15' s and u'\ud835' u'\udc16' s , we obtain the two projection mappings onto the common space and thus our projection function can be derived as</a>
<a name="6">[6]</a> <a href="#6" id=6>2013 ) , however, our objective function yielded consistently better results in all experimental settings</a>
<a name="7">[7]</a> <a href="#7" id=7>Whereas for the latter our system assumes that all concepts have rich linguistic representations (i.e.,, representations estimated from a large corpus), in the case of the former, new concepts are assumed to be encounted in a limited linguistic context and therefore lacking rich linguistic representations</a>
<a name="8">[8]</a> <a href="#8" id=8>This is achieved by means of a simple neural network trained to project image-extracted feature vectors to text-based vectors through a hidden layer that can be interpreted as a cross-modal semantic space</a>
<a name="9">[9]</a> <a href="#9" id=9>For ESP, given the size and amount of noise in this dataset, we build vectors for visual concepts , by normalizing and summing the BoVW vectors of</a>
</body>
</html>