(lp0
Vstate
p1
aVIn all experiments, the contextual variable is the observed US state (including DC), so that u'\u005cud835' u'\u005cudc9e'
p2
aVWe evaluate our model by confirming its face validity in a qualitative analysis and estimating its accuracy at the quantitative task of judging geographically-informed semantic similarity
p3
aVFor comparison, we also partition the data among all 51 states, and train a single model for each state using only data from that state
p4
aVAs a preprocessing step, we identify a set of target multiword expressions in this corpus as the maximal sequence of adjectives + nouns with the highest pointwise mutual information; in all experiments described below, we define the vocabulary V as the most frequent 100,000 terms (either unigrams or multiword expressions) in the total data, and set the dimensionality of the embedding k = 100
p5
aVWhile the two models that include geographical information naturally outperform the model that does not, the Joint model generally far outperforms the Individual models trained on state-specific subsets of the data
p6
aVThis model defines a joint parameterization over all variable values in the data, where information from data originating in California, for instance, can influence the representations
p7
a.