<html>
<head>
<title>P14-1092.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The second baseline (CR + LS) trains a reranking model without discourse, using just the CR and LS features</a>
<a name="1">[1]</a> <a href="#1" id=1>So far, we have treated LS and discourse as distinct features in the reranking model, However, given that LS features greatly improve the CR baseline, we hypothesize that a natural extension to the discourse models would be to make use of LS similarity (in addition to the traditional information retrieval similarity) to label discourse segments</a>
<a name="2">[2]</a> <a href="#2" id=2>For the Bio corpus where answer candidates consist of entire paragraphs of a biology text, overall performance is dominated by inter-sentence discourse features</a>
<a name="3">[3]</a> <a href="#3" id=3>Similarly, line 9, the top-performing model that combines discourse with LS has a +5.69 absolute P@1 improvement over the CR + LS baseline</a>
<a name="4">[4]</a> <a href="#4" id=4>For the YA corpus, where lexical semantics showed the most benefit, simply adding LS features to the CR baseline increases baseline P@1 performance from 19.57 to 26.57, a +36% relative improvement</a>
<a name="5">[5]</a> <a href="#5" id=5>We propose a novel answer reranking (AR) model that combines lexical semantics (LS) with discourse information, driven by two representations of discourse a shallow representation centered around discourse markers and surface text information, and</a>
</body>
</html>