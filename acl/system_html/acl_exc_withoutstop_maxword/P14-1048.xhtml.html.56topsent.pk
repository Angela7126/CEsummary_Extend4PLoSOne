(lp0
VTherefore, our model incorporates the strengths of both HILDA and Joty et al u'\u005cu2019' s model, i.e.,, the efficiency of a greedy parsing algorithm, and the ability to incorporate sequential information with CRFs
p1
aVFirst, with a greedy bottom-up strategy, we develop a discourse parser with a time complexity linear in the total number of sentences in the document
p2
aVAs shown by Feng and Hirst ( 2012 ) , for a pair of discourse constituents of interest, the sequential information from contextual constituents is crucial for determining structures
p3
aVFirst, as shown in Table 2 , the average number of sentences in a document is 26.11, which is already too large for optimal parsing models, e.g.,, the CKY-like parsing algorithm in j CRF, let alone the fact that the largest document contains several hundred of EDUs and sentences
p4
aVBecause the structure model is the first component in our pipeline of local models, its accuracy is crucial
p5
aVDue to the O u'\u005cu2062' ( n 3 ) time complexity, where n is the number of input discourse units, for large documents, the parsing simply takes too long 1 1 The largest document in the RST-DT contains over 180 sentences, i.e.,, n 180 for their multi-sentential CKY parsing
p6
aVWhile research in discourse parsing can be partitioned into several directions according to different theories and frameworks, Rhetorical Structure Theory (RST) [ 12 ] is probably the most ambitious one, because it aims to
p7
a.