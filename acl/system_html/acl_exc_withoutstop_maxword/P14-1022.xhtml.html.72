<html>
<head>
<title>P14-1022.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Our parser can be easily adapted to this task by replacing the X-bar grammar over treebank symbols with a grammar over the sentiment values to encode the output variables and then adding n-gram indicators to our feature set to capture the bulk of the lexical effects</a>
<a name="1">[1]</a> <a href="#1" id=1>The open question is whether surface features are adequate for key effects like subcategorization, which have deep definitions but regular surface reflexes (e.g., the preposition selected by a verb will often linearly follow it</a>
<a name="2">[2]</a> <a href="#2" id=2>The u'\u201c' Replaced u'\u201d' system modifies the Berkeley parser by replacing rare words with morphological descriptors of those words computed using language-specific modules, which have been hand-crafted for individual languages or are trained with additional annotation layers in the treebanks that we do not exploit</a>
<a name="3">[3]</a> <a href="#3" id=3>Their model has high capacity to model complex interactions of words through a combinatory tensor, but it appears that our simpler, feature-driven model is just as effective at capturing the key effects of compositionality for sentiment analysis</a>
<a name="4">[4]</a> <a href="#4" id=4>By annotating grammar nonterminals with their headwords, the idea is to better model phenomena that depend heavily on the semantics of the words involved, such as coordination and PP attachment</a>
<a name="5">[5]</a> <a href="#5" id=5>Figure 3 shows an example of one instance of this feature template impact is a noun that is more likely to take a PP than other</a>
</body>
</html>