(lp0
VWe compare sentiment-specific word embedding (SSWE h , SSWE r , SSWE u ) with baseline embedding learning algorithms by only using word embedding as features for Twitter sentiment classification
p1
aVIn this section, we present the details of learning sentiment-specific word embedding ( SSWE ) for Twitter sentiment classification
p2
aVWe conduct experiments to evaluate SSWE by incorporating it into a supervised learning framework for Twitter sentiment classification
p3
aVIn the accuracy of polarity consistency between each sentiment word and its top N closest words, SSWE outperforms existing word embedding learning algorithms
p4
aVWe then describe the use of SSWE in a supervised learning framework for Twitter sentiment classification
p5
aVWe apply SSWE as features in a supervised learning framework for Twitter sentiment classification, and evaluate it on the benchmark dataset in SemEval 2013
p6
aVIn this paper, we propose learning sentiment-specific word embedding ( SSWE ) for sentiment analysis
p7
aVWe extend the existing word embedding learning algorithm [ 9 ] and develop three neural networks to learn SSWE
p8
aVWe also directly evaluate the effectiveness of the SSWE by measuring the word similarity in the embedding space for sentiment lexicons
p9
aVWe apply sentiment-specific word embedding for Twitter sentiment classification under a supervised learning framework as in previous work [ 33 ]
p10
aVBy contrast, SSWE h and SSWE r learn sentiment-specific word embedding by integrating
p11
a.