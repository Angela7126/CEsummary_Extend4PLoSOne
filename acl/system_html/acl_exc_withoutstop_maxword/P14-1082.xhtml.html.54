<html>
<head>
<title>P14-1082.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The main research question in this research is how to disambiguate an L1 word or phrase to its L2 translation based on an L2 context, and whether such cross-lingual contextual approaches provide added value compared to baseline models that are not context informed or compared to standard language models</a>
<a name="1">[1]</a> <a href="#1" id=1>We do so by normalising the class probability from the classifier ( s u'\u2062' c u'\u2062' o u'\u2062' r u'\u2062' e T u'\u2062' ( H ) ), which is our translation model, and the language model ( s u'\u2062' c u'\u2062' o u'\u2062' r u'\u2062' e l u'\u2062' m u'\u2062' ( H ) ), in such a way that the highest classifier score for the alternatives under consideration is always 1.0 , and the highest language model score of the sentence is always 1.0</a>
<a name="2">[2]</a> <a href="#2" id=2>Preparing the data to build training and test data for our intended translation assistance system is not trivial, as the type of interactive translation assistant we aim to develop does not exist yet</a>
<a name="3">[3]</a> <a href="#3" id=3>The language model is a trigram-based back-off language model with Kneser-Ney smoothing, computed using SRILM [] and trained on the same training data as the translation model</a>
<a name="4">[4]</a> <a href="#4" id=4>The fact that a phrase-translation table needs to be constructed for the test data is also the reason that the parallel corpus split from which the test data is derived has to be large enough, ensuring better quality</a>
<a name="5">[5]</a> <a href="#5" id=5>If not, we check for the presence of a classifier expert for the offered L1 fragment; only then we can proceed by extracting the desired number of L2 local context words to the immediate left and right of this fragment and adding those to the feature vector</a>
<a name="6">[6]</a> <a href="#6" id=6>We see that the language model baseline for English u'\u2192' French shows the same substantial improvement over the baseline as our English u'\u2192' Spanish results</a>
<a name="7">[7]</a> <a href="#7" id=7>Automatic configuration selection was done by performing leave-one-out testing (for small number of instances) or 10-fold-cross validation (for larger number of instances, n u'\u2265' 20 ) on the training data per classifier expert</a>
<a name="8">[8]</a> <a href="#8" id=8>A second baseline was constructed by weighing the probabilities from the translation table directly with the L2 language model described earlier</a>
<a name="9">[9]</a> <a href="#9" id=9>The word accuracy for the entire set is then computed by taking the sum of the word accuracies per sentence pair, divided by the total number of sentence pairs</a>
<a name="10">[10]</a> <a href="#10" id=10>Third, we observe that adding the language model to our classifier leads to another significant gain (configuration l1r1 + LM in the results in Table 2</a>
<a name="11">[11]</a> <a href="#11" id=11>A second parameter u'\u039b' 2 further limits the considered phrase pairs ( f s , f t ) to have the product of their conditional probabilities not not deviate more than a fraction u'\u039b' 2 from the joint probability for the strongest possible pairing for f s , the</a>
</body>
</html>