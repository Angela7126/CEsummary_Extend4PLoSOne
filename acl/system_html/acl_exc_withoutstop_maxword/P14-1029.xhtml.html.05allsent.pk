(lp0
VBy examining sentiment compositions of negators and arguments, we model the quantitative behavior of negators in changing sentiment
p1
aVFigure 1 illustrates the effect of a common list of negators on sentiment as observed on the Stanford Sentiment Treebank
p2
aVFigure 1 shows the distribution of the effect of negators on sentiment without considering further semantics of the arguments
p3
aVMaking the basic shifting model to be dependent on the negators (model 4) reduces the prediction error significantly as compared with the error of the basic shifting (model 3
p4
aVThe shifting hypothesis [] , however, assumes that negators change sentiment values by a constant amount
p5
aVA different hypothesis, called the shifting hypothesis in this paper, assumes that negators change the sentiment values by a constant amount []
p6
aVTo understand this further, we plot in Figure 3 the behavior of different negators the x-axis is a subset of our negators and the y-axis denotes absolute shifting in sentiment values
p7
aVThis model learns the syntax and semantics of the negator u'\u005cu2019' s argument with a recursive neural network
p8
aVData As described earlier, the Stanford Sentiment Treebank [] has manually annotated, real-valued sentiment values for all phrases in parse trees
p9
aVFour of them have significantly different shifting power when composed with positive or negative phrases, which can explain why the polarity-based shifting model achieves improvement over the basic shifting model
p10
aVUnderstanding the impact of negation on sentiment is essential in automatic analysis of sentiment
p11
aVThe recently available Stanford Sentiment Treebank [] renders manually annotated, real-valued sentiment scores for all phrases in parse trees
p12
aVThis paper describes a quantitative study of the effect of a list of frequent negators on sentiment
p13
aVWe calculated their shifting power in the same manner as for the negators and found three diminishers having shifting capability in the shifting range of these negators
p14
aVIn previous research, some influential, widely adopted assumptions posit the effect of negators to be independent of both the specific negators and the semantics and syntax of the arguments
p15
aVThat is, the model parameters are only based on the sentiment value of the arguments
p16
aVFurthermore, modeling the syntax and semantics with the state-of-the-art recursive neural network (model 7 and 8) can dramatically improve the performance over model 6
p17
aVNote that the two neural network based models incorporate the syntax and semantics by representing each node with a vector
p18
aVFigure 4 shows the shifting capacity of negators when they modify positive (blue boxes) or negative phrases (red boxes
p19
aVThe figure includes five most frequently used negators found in the sentiment treebank
p20
aVThis corpus provides us with the data to further understand the quantitative behavior of negators, as the effect of negators can now be studied with arguments of rich syntactic and semantic variety
p21
aVWe extend RNTN to directly consider the sentiment information of arguments
p22
aVA recursive neural tensor network (RNTN) is a specific form of feed-forward neural network based on syntactic (phrasal-structure) parse tree to conduct compositional sentiment analysis
p23
aVWe then extend the models to be dependent on the negators and demonstrate that such a simple extension can significantly improve the performance of fitting to the human annotated data
p24
aVThe same is true for the polarity-based shifting (model 5), reflecting that the roles of negators are different when modifying positive and negative phrases
p25
aVNote that this is a special case of what the neural network based models can model
p26
aVThe PSTN model, which takes into account the human-annotated prior sentiment of arguments, performs the best
p27
aVThis shifting model is based on negators and the polarity of the text they modify constants can be different for each negator-polarity pair
p28
aVThe table shows that the basic reversing and shifting heuristics do capture negators u'\u005cu2019' behavior to some degree, as their MAE scores are higher than that of the baseline
p29
aVNegation modeling Negation is a general grammatical category pertaining to the changing of the truth values of propositions; negation modeling is not limited to sentiment
p30
aVPSTN outperforms RNTN at greater depths, where the syntax and semantics are more complicated and harder to model
p31
aVPolarity-based shifting As will be shown in our experiments, negators can have different shifting power when modifying a positive or a negative phrase
p32
aVThe original RNTN and the PSTN predict 5-class sentiment for each negated phrase; we map the output to real-valued scores based on the scale that used to map real-valued sentiment scores to sentiment categories
p33
aVNegation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text [] , e.g.,, from +0.5 to -0.5, or vice versa
p34
aVThis model further improves the fitting performance on the test data
p35
aVIn this paper, we call a model based on such assumptions a non-lexicalized model
p36
aVWhen the depths are within 4, the RNTN performs very well and the (human annotated) prior sentiment of arguments used in PSTN does not bring additional improvement over RNTN
p37
aVAutomatic sentiment analysis The expression of sentiment is an integral component of human language
p38
aVNote that depending on different purposes, p 1 s u'\u005cu2062' e u'\u005cu2062' n can take the value of the automatically predicted sentiment distribution obtained in forward propagation, the gold sentiment annotation of node p 1 , or even other normalized prior sentiment value or confidence score from external sources (e.g.,, sentiment lexicons or external training data
p39
aVFor example, if a phrase very good modified by a negator not appears in the training and test data, the system can simply memorize the sentiment score of not very good in training and use this score at testing
p40
aVBasic shifting Similarly, a shifting based model depends on s u'\u005cu2062' ( w u'\u005cu2192' ) only, which can be written as
p41
aVIn the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify
p42
aVModeling syntax and semantics We have seen above that modeling syntax and semantics through the-state-of-the-art neural networks help improve the fitting performance
p43
aVIn general, we argue that one should always consider modeling negators individually in a sentiment analysis system
p44
aVWe begin with previously proposed methods that leverage heuristics to model the behavior of negators
p45
aVThe errors made by model 6 is bumpy, as the model considers no semantics and hence its errors are not dependent on the depths
p46
aVWe call this model negator-based shifting
p47
aVFor the former, we adopt the recursive neural tensor network (RNTN) proposed recently by , which has showed to achieve the state-of-the-art performance in sentiment analysis
p48
aVFor example, a simple yet influential hypothesis posits that a negator reverses the sign of the sentiment value of the modified text []
p49
aVWe regard the negators u'\u005cu2019' behavior as an underlying function embedded in annotated data; we aim to model this function from different aspects
p50
aV1 1 The sentiment values have been linearly rescaled from the original range [0, 1] to [-0.5, 0.5]; in the figure a negative or positive value corresponds to a negative or a positive sentiment respectively; zero means neutral
p51
aVThe figure shows that both RNTN and PSTN perform much better at all depths than the model 6 in Table 1
p52
aVFollowing the idea of , we regard the sentiment of p 1 as a prior sentiment as it has not been affected by the specific context (negators), so we denote our method as prior sentiment-enriched tensor network (PSTN
p53
aVAs we have discussed above, we will use the human annotated sentiment for the arguments, same as in the models discussed in Section 3
p54
aVEach dot in the figure corresponds to a negated phrase in the treebank
p55
aVThe phrases at all tree nodes were manually annotated with one of 25 sentiment values that uniformly span between the positive and negative poles
p56
aVThe x-axis is the sentiment score of its argument s u'\u005cu2062' ( w u'\u005cu2192' ) and y-axis the sentiment score of the entire negated phrase s u'\u005cu2062' ( w n , w u'\u005cu2192' )
p57
aVThis provides us with the training and evaluation data to study the effect of negators with syntax and semantics of different complexity in a natural setting
p58
aVEach node of the parse tree is a fixed-length vector that encodes compositional semantics and syntax, which can be used to predict the sentiment of this node
p59
aVIn addition, we explicitly incorporate the prior sentiment of the argument and observe that this information helps reduce fitting errors
p60
aVThe number of parameters in this model is the multiplication of number of negators by two (the number of sentiment polarities
p61
aVMuch recent work considers sentiment analysis from a semantic-composition perspective [] , which achieved the state-of-the-art performance used a collection of hand-written compositional rules to assign sentiment values to different granularities of text spans proposed a learning-based framework
p62
aVAbove, we have considered the semantics of the negators
p63
aVIn this paper, we refer to a negation word as the negator (e.g.,, isn u'\u005cu2019' t ), a text span being modified by and composed with a negator as the argument (e.g.,, very good ), and entire phrase (e.g.,, isn u'\u005cu2019' t very good ) as the negated phrase
p64
aVNegation is often expressed through the use of negative signals or negators u'\u005cu2013' words like isn u'\u005cu2019' t and never , and it can significantly affect the sentiment of its scope
p65
aVIn principle neural network is able to fit very complicated functions [] , and in this paper, we adapt the state-of-the-art approach described in [] to help understand the behavior of negators specifically
p66
aVSuch models work in a bottom-up fashion over the parse tree of a sentence to infer the sentiment label of the sentence as a composition of the sentiment expressed by its constituting parts
p67
aVDiscriminating negators The results in Table 1 has demonstrated the benefit of discriminating negators
p68
aVNext, we evaluate a recently proposed composition model (Socher, 2013) that relies on both the negator and the argument
p69
aVFor example, we can see that the negator u'\u005cu201c' is_never u'\u005cu201d' on average shifts the sentiment of the arguments by 0.26, which is a significant change considering the range of sentiment value is [0, 1]
p70
aVNegators appearing at deeper levels of the tree tend to have more complicated syntax and semantics
p71
aVThe literature contains interesting research attempting to model and understand the behavior (reviewed in Section 2
p72
aVMerging these two models yields additional improvement (model 6
p73
aVWe first evaluate the modeling capabilities of two influential heuristics and show that they capture only very limited regularity of negators u'\u005cu2019' effect
p74
aVWe will show that this model also statistically significantly outperforms the basic shifting without overfitting, although the number of parameters have increased
p75
aVNegators can interact with arguments in complex ways
p76
aVAfter the models are trained, they are applied to predict the sentiment of the test data
p77
aVTo train the model, one first needs to calculate the predicted sentiment distribution for each node
p78
aVFor the latter, we propose a prior sentiment-enriched tensor network (PSTN) to take into account the prior sentiment of the argument s u'\u005cu2062' ( w u'\u005cu2192' )
p79
aVThe first row of the table is a random baseline, which simply guesses the sentiment value for each test case randomly in the range [0,1]
p80
aVBelow, we take a closer look at the fitting errors made at different depths of the sentiment treebank
p81
aVEarly work on automatic sentiment analysis includes the widely cited work of [] , among others
p82
aVSince then, there has been an explosion of research addressing various aspects of the problem, including detecting subjectivity, rating and classifying sentiment, labeling sentiment-related semantic roles (e.g.,, target of sentiment), and visualizing sentiment (see surveys by and
p83
aVWhen incorporating this memorizing strategy into model (6), we observed a MAE score of 0.1222
p84
aVThis shows that the boundary between negators and diminishers can by fuzzy
p85
aVEvaluation metrics We use the mean absolute error (MAE) to evaluate the models, which measures the averaged absolute offsets between the predicted sentiment values and the gold standard
p86
aVThe negator list will be discussed later in the paper
p87
aVThe more recent work of [] proposed models based on recursive neural networks that do not rely on any heuristic rules
p88
aVA typical model falling into this category is the reversing hypothesis discussed in Section 2 , where a negator simply reverses the sentiment score s u'\u005cu2062' ( w u'\u005cu2192' ) to be - s u'\u005cu2062' ( w u'\u005cu2192' ) ; i.e.,, f u'\u005cu2062' ( s u'\u005cu2062' ( w u'\u005cu2192' ) ) = - s u'\u005cu2062' ( w u'\u005cu2192' )
p89
aVThe non-uniform distribution in Figure 1 has showed certain correlations between the sentiment values of s u'\u005cu2062' ( w n , w u'\u005cu2192' ) and s u'\u005cu2062' ( w u'\u005cu2192' ) , and such information has been leveraged in the models discussed in Section 3
p90
aVFurther semantic or syntactic information from either the negators or the phrases they modify could be helpful
p91
aVOverall regression performance Table 1 shows the overall fitting performance of all models
p92
aVHowever, in our current study, we focus on exploring the behavior of negators
p93
aVThe most straightforward way of expanding the non-lexicalized heuristics is probably to make the models to be dependent on the negators
p94
aVBelow, we further make the models to be dependent on the arguments
p95
aVIn general, we can simply define this category of models in Equation 1
p96
aVIn Figure 5 , the x-axis corresponds to different depths and y-axis is the mean absolute errors (MAE
p97
aVIn Figure 2 , the red portion shows the added components of PSTN
p98
aVWhen calculating its vector, we aim to directly engage the sentiment information of its right child, i.e.,, the argument
p99
aVThe question then is that whether and how much incorporating further syntax and semantic information can help better fit or predict the negation effect
p100
aVEach occurrence of a negator and the phrase it is directly composed with in the treebank, i.e.,, u'\u005cu27e8' w n , w u'\u005cu2192' u'\u005cu27e9' , is considered a data point in our study
p101
aVOne may consider that a straightforward way of considering the semantics of the modified phrases is simply memorizing them
p102
aVMoreover, the figure shows that same or similar s u'\u005cu2062' ( w u'\u005cu2192' ) scores (x-axis) can correspond to very different s u'\u005cu2062' ( w n , w u'\u005cu2192' ) scores (y-axis), which, to some degree, suggests the potentially complicated behavior of negators
p103
aVIn the formula, r u'\u005cu2062' ( w u'\u005cu2192' ) is a certain type of representation for the argument w u'\u005cu2192' and it models the semantics or/and syntax of the argument
p104
aVNegator-based shifting We can simply extend the basic shifting model above to consider the lexical information of negators f u'\u005cu2062' ( s u'\u005cu2062' ( w u'\u005cu2192' ) ) = s u'\u005cu2062' ( w u'\u005cu2192' ) - s u'\u005cu2062' i u'\u005cu2062' g u'\u005cu2062' n u'\u005cu2062' ( s u'\u005cu2062' ( w u'\u005cu2192' ) ) * C u'\u005cu2062' ( w n
p105
aVAs shown in the black portion of Figure 2 , each instance of RNTN corresponds to a binary parse tree of a given sentence
p106
aVWe will show that this simple modification improves the fitting performance statistically significantly
p107
aVFor each negator, a 95% confidence interval is shown by the boxes in the figure, which is calculated with the bootstrapping resampling method
p108
aVAlternatively, if the modeling has to be done in groups, one should consider clustering valence shifters by their shifting abilities in training or external data
p109
aVWe search these negators in the Stanford Sentiment Treebank and normalize the same negators to a single form; e.g.,, u'\u005cu201c' is n u'\u005cu2019' t u'\u005cu201d' , u'\u005cu201c' isn u'\u005cu2019' t u'\u005cu201d' , and u'\u005cu201c' is not u'\u005cu201d' are all normalized to u'\u005cu201c' is_not u'\u005cu201d'
p110
aVNote also that instead of determining these constants by human intuition, we use the training data to find the constants in all shifting-based models as well as for the parameters in other models
p111
aVThis could suggest that additional external knowledge, e.g.,, that from human-built resources or automatically learned from other data (e.g.,, as in [] ), including sentiment that cannot be inferred from its constituent expressions, might be incorporated to benefit the current neural-network-based models as prior knowledge
p112
aVOther approaches to negation modeling have been discussed in []
p113
aVOn the other hand, the errors of RNTN and PSTN monotonically increase with depths, indicating the increase in the task difficulty
p114
aVIn written text, sentiment is conveyed with word senses and their composition, and in speech also via prosody such as pitch []
p115
aVIn this paper, we use a list of most frequent negators that include the words not , no , never , and their combinations with auxiliaries (e.g.,, didn u'\u005cu2019' t
p116
aVThis is actually an interesting place to extend the current recursive neural network to consider extrinsic knowledge
p117
aVWe then propose to extend them to consider lexical information of the negators themselves
p118
aVHere, we assume the sentiment task has m classes
p119
aVThe approaches of modeling this include bag-of-word-based models
p120
aVThere exist different ways of incorporating more complicated syntactic and semantic information
p121
aVIt u'\u005cu2019' s not surprising that memorizing the phrases has some benefit, but such matching relies on the exact reoccurrences of phrases
p122
aVThe approach leverages a principled method, the forward and backward propagation, to learn a vector representation to optimize the system performance
p123
aVThat is, the non-uniform information shown in Figure 1 is not directly modeled
p124
aVdefine negation to be u'\u005cu201c' a grammatical category that allows the changing of the truth value of a proposition u'\u005cu201d'
p125
aVThe split of training and test data is same as specified in []
p126
aVDuring learning, following the method used by the RNTN model in [] , PSTN also aims to minimize the cross-entropy error between the predicted distribution y i u'\u005cu2208' u'\u005cu211d' m × 1 at node i and the target distribution t i u'\u005cu2208' u'\u005cu211d' m × 1 at that node
p127
aVAs intuitively shown in Figure 1 , the capability of the non-lexicalized heuristics might be limited
p128
aVIn the backpropogation process of the training, each node (except the root node) in the tree carries two kinds of errors the local softmax error and the error passing down from its parent node
p129
aVWe intend to devise a model that implements Equation 4
p130
aVTo this end, we make use of the sentiment class information of p 1 , noted as p 1 s u'\u005cu2062' e u'\u005cu2062' n
p131
aVFigure 3 also includes three diminishers (the white bars), i.e.,, barely , unlikely , and superficial
p132
aVThat is, given a negated phrase (e.g.,, isn u'\u005cu2019' t very good ) and the sentiment score of its argument (e.g.,, s u'\u005cu2062' ( ` u'\u005cu2062' ` u'\u005cu2062' v u'\u005cu2062' e u'\u005cu2062' r u'\u005cu2062' y u'\u005cu2062' g u'\u005cu2062' o u'\u005cu2062' o u'\u005cu2062' d u'\u005cu2032' u'\u005cu2032' ) = 0.5 ), we focus on understanding the negator u'\u005cu2019' s quantitative behavior in yielding the sentiment score of the negated phrase s u'\u005cu2062' ( ` u'\u005cu2062' ` u'\u005cu2062' i u'\u005cu2062' s u'\u005cu2062' n u'\u005cu2032' u'\u005cu2062' t u'\u005cu2062' v u'\u005cu2062' e u'\u005cu2062' r u'\u005cu2062' y u'\u005cu2062' g u'\u005cu2062' o u'\u005cu2062' o u'\u005cu2062' d u'\u005cu2032' u'\u005cu2032' )
p133
aVConsider the node p 2 in Figure 2
p134
aVThe values are normalized to the range of [0, 1]
p135
aVFor example, in the work of [] , a feature not_good will be created if the word good is encountered within a predefined range after a negator
p136
aVWe consider two models in this study one drops s u'\u005cu2062' ( w u'\u005cu2192' ) in Equation 4 and directly models f u'\u005cu2062' ( w n , r u'\u005cu2062' ( w u'\u005cu2192' )
p137
aVA major difference of RNTN from the conventional recursive neural network (RRN) [] is the use of the tensor V in order to directly capture the multiplicative interaction of two input vectors, although the matrix W implicitly captures the nonlinear interaction between the input vectors
p138
aVThe training of RNTN uses conventional forward-backward propagation
p139
aVThe incoming error message of node a can be calculated similarly
p140
aVMore specifically, MAE is calculated as
p141
aV2 2 Similar distribution is observed in other data such as Tweets []
p142
aVIn total, we collected 2,261 pairs, including 1,845 training and 416 test cases
p143
aVSpecifically, we first compute the prediction errors in all tree nodes bottom-up
p144
aVThe above negation hypotheses rely on s u'\u005cu2062' ( w u'\u005cu2192'
p145
aVThat is, the error for a sentence is calculated as
p146
aVThis approach performs significantly better than those mentioned above
p147
aVwhere s i g n is the standard sign function which determines if the constant C should be added to or deducted from s u'\u005cu2062' ( w n the constant is added to a negative s u'\u005cu2062' ( w u'\u005cu2192' ) but deducted from a positive one
p148
aVThe sentences were parsed with the Stanford parser []
p149
aVBy following [] , we extracted 319 diminishers (also called understatement or downtoners ) from General Inquirer 3 3 http://www.wjh.harvard.edu/ inquirer/
p150
aVSome automatic methods to detect opposites were proposed by and
p151
aVDuring the derivative computation, the two errors will be summed up as the complement incoming error for the node
p152
aVThe data contain around 11,800 sentences from movie reviews that were originally collected by
p153
aVWe can observe statistically significant differences of shifting abilities between many negator pairs such as that between u'\u005cu201c' is_never u'\u005cu201d' and u'\u005cu201c' do_not u'\u005cu201d' as well as between u'\u005cu201c' does_not u'\u005cu201d' and u'\u005cu201c' can_not u'\u005cu201d'
p154
aVThe constant C now can take one of two possible values
p155
aVIt bridges between the models we have discussed above that use either s u'\u005cu2062' ( w u'\u005cu2192' ) or r u'\u005cu2062' ( w u'\u005cu2192' )
p156
aVThat is, each negator has its own C
p157
aVAs shown in Equation 6 , for the node vector p 1 u'\u005cu2208' u'\u005cu211d' d × 1 , we employ a matrix, namely W s u'\u005cu2062' e u'\u005cu2062' n u'\u005cu2208' u'\u005cu211d' d × ( d + m ) and a tensor, V s u'\u005cu2062' e u'\u005cu2062' n u'\u005cu2208' u'\u005cu211d' ( d + m ) × ( d + m ) × d , aiming at explicitly capturing the interplays between the sentiment class of p 1 , denoted as p 1 s u'\u005cu2062' e u'\u005cu2062' n ( u'\u005cu2208' u'\u005cu211d' m × 1 ), and the negator a
p158
aVThe vector of a node, say p 2 in Figure 2 , is computed from the d -dimensional vectors of its two children, namely a and p 1 ( a , p 1 u'\u005cu2208' u'\u005cu211d' d × 1 ) , with a non-linear function
p159
aVWe can see that the reversing assumption (the red diagonal line) does capture some regularity of human perception, but rather roughly
p160
aVIn general, a negated expression and the opposite of the expression may or may not convey the same meaning
p161
aVFor example, paraphrase and contradiction detection systems rely on detecting negated expressions and opposites []
p162
aVAfter this forward process, we then calculate the derivatives of the softmax classifiers at each node in the tree in a top-down fashion
p163
aVFor example, if y i = [ 0.5 u'\u005cu2004' 0.5 u'\u005cu2004' 0 u'\u005cu2004' 0 u'\u005cu2004' 0 ] , meaning this phrase has a 0.5 probability to be in the first category (strong negative) and 0.5 for the second category (weak negative), the resulting p i r u'\u005cu2062' e u'\u005cu2062' a u'\u005cu2062' l will be 0.2 (0.5*0.1+0.5*0.3
p164
aVCombined shifting We further combine the negator-based shifting and polarity-based shifting above f u'\u005cu2062' ( s u'\u005cu2062' ( w u'\u005cu2192' ) ) = s u'\u005cu2062' ( w u'\u005cu2192' ) - s u'\u005cu2062' i u'\u005cu2062' g u'\u005cu2062' n u'\u005cu2062' ( s u'\u005cu2062' ( w u'\u005cu2192' ) ) * C u'\u005cu2062' ( w n , s u'\u005cu2062' i u'\u005cu2062' g u'\u005cu2062' n u'\u005cu2062' ( s u'\u005cu2062' ( w u'\u005cu2192' ) )
p165
aVNote that mean square error (MSE) is another widely used measure for regression, but it is less intuitive for out task here
p166
aVWith the new matrix and tensor, we then have u'\u005cu0398' = ( V , V s u'\u005cu2062' e u'\u005cu2062' n , W , W s u'\u005cu2062' e u'\u005cu2062' n , W l u'\u005cu2062' a u'\u005cu2062' b u'\u005cu2062' e u'\u005cu2062' l , L ) as the PSTN model u'\u005cu2019' s parameters
p167
aVAs a result, the vector of p 2 is calculated as follows
p168
aVWith this notation, the error for the root node p 2 can be formulated as follows
p169
aVTo minimize E u'\u005cu2062' ( u'\u005cu0398' ) , the gradient of the objective function with respect to each of the parameters in u'\u005cu0398' is calculated efficiently via backpropagation through structure, as proposed by
p170
aVInference and learning in PSTN follow a forward-backward propagation process similar to that in [] , and for completeness, we depict the details as follows
p171
aVHere, L denotes the vector representations of the word dictionary
p172
aVWe denote the complete incoming error and the softmax error vector for node i as u'\u005cu0394' i , c u'\u005cu2062' o u'\u005cu2062' m u'\u005cu2208' u'\u005cu211d' d × 1 and u'\u005cu0394' i , s u'\u005cu2208' u'\u005cu211d' d × 1 , respectively
p173
aVThis can be written as
p174
aVNow, let u'\u005cu2019' s form the equations for computing the error for the two children of the p 2 node
p175
aVWith the results from Equation 4.2.1 , we then can calculate the derivatives for the W s u'\u005cu2062' e u'\u005cu2062' n at node p 2 using the following equation
p176
aVM u'\u005cu2062' A u'\u005cu2062' E = 1 N u'\u005cu2062' u'\u005cu2211' u'\u005cu27e8' w n , w u'\u005cu2192' u'\u005cu27e9' s ^ u'\u005cu2062' ( w n , w u'\u005cu2192' ) - s u'\u005cu2062' ( w n , w u'\u005cu2192' ) where s ^ u'\u005cu2062' ( w n , w u'\u005cu2192' ) denotes the gold sentiment value and s u'\u005cu2062' ( w n , w u'\u005cu2192' ) the predicted one for the pair u'\u005cu27e8' w n , w u'\u005cu2192' u'\u005cu27e9' , and N is the total number of test instances
p177
aVThe difference for the error at p 2 and its two children is that the error for the latter will need to compute the error message passing down from p 2
p178
aVThere exist different ways of implementing r u'\u005cu2062' ( w u'\u005cu2192'
p179
aVSpecifically, we conduct the mapping with the formula p i r u'\u005cu2062' e u'\u005cu2062' a u'\u005cu2062' l = y i u'\u005cu22c5' [ 0.1 u'\u005cu2004' 0.3 u'\u005cu2004' 0.5 u'\u005cu2004' 0.7 u'\u005cu2004' 0.9 ] ; i.e.,, we calculate the dot product of the posterior probability y i and the scaling vector
p180
aVThe depth here is defined as the longest distance between the root of a negator-phrase pair u'\u005cu27e8' w n , w u'\u005cu2192' u'\u005cu27e9' and their descendant leafs
p181
aVMore details can be found in []
p182
aVThe other takes into account s u'\u005cu2062' ( w u'\u005cu2192' ) too
p183
aVFollowing this notation, we have the error message for the two children of p 2 , provided that we have the u'\u005cu0394' p 2 , d u'\u005cu2062' o u'\u005cu2062' w u'\u005cu2062' n
p184
aVwhere, W u'\u005cu2208' u'\u005cu211d' d × ( d + d ) and V u'\u005cu2208' u'\u005cu211d' ( d + d ) × ( d + d ) × d are the matrix and tensor for the composition function
p185
aVwhere, u'\u005cu039b' represents the regularization hyperparameters, and j u'\u005cu2208' m denotes the j -th element of the multinomial target distribution
p186
aVNote that the gradient calculations for the V , W , W l u'\u005cu2062' a u'\u005cu2062' b u'\u005cu2062' e u'\u005cu2062' l , L are the same as that of presented in []
p187
aVWe denote the error passing down as u'\u005cu0394' p 2 , d u'\u005cu2062' o u'\u005cu2062' w u'\u005cu2062' n , where the left child and the right child of p 2 take the 1 s u'\u005cu2062' t and 2 n u'\u005cu2062' d half of the error u'\u005cu0394' p 2 , d u'\u005cu2062' o u'\u005cu2062' w u'\u005cu2062' n , namely u'\u005cu0394' p 2 , d u'\u005cu2062' o u'\u005cu2062' w u'\u005cu2062' n [ 1 d ] and u'\u005cu0394' p 2 , d u'\u005cu2062' o u'\u005cu2062' w u'\u005cu2062' n [ d + 1
p188
aVSimilarly, for the derivative of each slice k ( k = 1 , u'\u005cu2026' , d ) of the V s u'\u005cu2062' e u'\u005cu2062' n tensor, we have the following
p189
aVFor example, not alive has the same meaning as dead , however, not tall does not always mean short
p190
aVFor completeness, we briefly review it here
p191
aVand then compute the posterior probability over the m labels
p192
aVWe will discuss the gradient computation for the V s u'\u005cu2062' e u'\u005cu2062' n and W s u'\u005cu2062' e u'\u005cu2062' n in detail next
p193
aVFinally, we can finish the above equations with the following formula for computing u'\u005cu0394' p 2 , d u'\u005cu2062' o u'\u005cu2062' w u'\u005cu2062' n
p194
aVwhere u'\u005cu2297' is the Hadamard product between the two vectors and f u'\u005cu2032' is the element-wise derivative of f = t u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' h
p195
aVThus, we explore the use of two different constants for these two situations, i.e.,, f u'\u005cu2062' ( s u'\u005cu2062' ( w u'\u005cu2192' ) ) = s u'\u005cu2062' ( w u'\u005cu2192' ) - s u'\u005cu2062' i u'\u005cu2062' g u'\u005cu2062' n u'\u005cu2062' ( s u'\u005cu2062' ( w u'\u005cu2192' ) ) * C u'\u005cu2062' ( s u'\u005cu2062' i u'\u005cu2062' g u'\u005cu2062' n u'\u005cu2062' ( s u'\u005cu2062' ( w u'\u005cu2192' ) )
p196
aVwhere
p197
aV2 d ] , respectively
p198
a.