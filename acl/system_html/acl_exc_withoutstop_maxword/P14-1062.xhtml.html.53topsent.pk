(lp0
VIn the network the width of a feature map at an intermediate layer varies depending on the length of the input sentence; the resulting architecture is the Dynamic Convolutional Neural Network
p1
aVBy adding a max pooling layer to the network, the TDNN can be adopted as a sentence model []
p2
aVFor example, the second layer is obtained by applying a convolution to the sentence matrix u'\u005cud835' u'\u005cudc2c' itself
p3
aVConcretely, we think of u'\u005cud835' u'\u005cudc2c' as the input sentence and u'\u005cud835' u'\u005cudc2c' i u'\u005cu2208' u'\u005cu211d' is a single feature value associated with the i -th word in the sentence
p4
aVA sentence model based on a recurrent neural network is sensitive to word order, but it has a bias towards the latest words that it takes as input []
p5
aVA convolutional layer in the
p6
a.