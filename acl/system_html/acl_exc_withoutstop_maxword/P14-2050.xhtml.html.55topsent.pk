(lp0
VWe thus expect the syntactic contexts to yield more focused embeddings, capturing more functional and less topical similarity
p1
aVSyntactic contexts capture different information than bag-of-word contexts, as we demonstrate using the sentence u'\u005cu201c' Australian scientist discovers star with telescope u'\u005cu201d'
p2
aVA very common paradigm for acquiring such representations is based on the distributional hypothesis of Harris [ 16 ] , stating that words in similar contexts have similar meanings
p3
aVIf we keep the context embeddings, we can query the model for the contexts that are most activated by (have the highest dot product with) a given target word
p4
aVWe thus seek a representation that captures semantic and syntactic similarities between words
p5
aVThey capture relations to words that are far apart and thus u'\u005cu201c' out-of-reach u'\u005cu201d' with small window bag-of-words (e.g.,
p6
a.