(lp0
VA set of candidate labels is generated from Wikipedia article titles by querying using topic terms
p1
aVThe 10 terms with the highest marginal probabilities in the topic are used to query Wikipedia and the titles of the articles retrieved used as candidate labels
p2
aVThe results obtained by applying PageRank over the unweighted graph (2.05, 1.98, 2.04 and 1.88) are consistently better than the supervised and unsupervised methods reported by Lau et al
p3
aVThe most important keywords can be used to generate keyphrases for labelling the topic or weight pre-existing candidate labels
p4
aVFurther candidate labels are generated by processing the titles of these articles to identify noun chunks and n-grams within the noun chunks that are themselves the titles of Wikipedia articles
p5
aVWe would like to thank Jey Han Lau for providing us with the labels selected by Lau et al
p6
aVConsequently, it is not necessary to measure semantic similarity between topic keywords and candidate labels as previous approaches have done
p7
aVIn Figure 6 , we show the scores of Top-1 average rating obtained in the different domains by experimenting with the number of search results used to generate the text graph
p8
aVResults from the nDCG metric imply that our methods provide better rankings of the candidate labels in the majority of the cases
p9
aV2009 ) introduced an approach for labelling topics that relied on two hierarchical knowledge resources labelled by humans, while Lau et al
p10
aVAn interesting finding is that, although limited in length, the textual information in the search result u'\u005cu2019' s metadata contain enough salient terms relevant to the topic to provide reliable estimates of term importance
p11
aVA common way to represent topics is as set of keywords generated from the n terms with the highest marginal probabilities
p12
aVThey reported that the supervised version achieves better performance than a previously reported approach [ 17 ]
p13
aVIn addition, performance improvement gained from using the weighted graph is modest, suggesting that the computation of association scores over a large reference corpus could be omitted if resources are limited
p14
aVThis is expected since the weighted graph contains additional information about word relatedness
p15
aVWord co-occurrences are computed using Wikipedia as a a reference corpus
p16
aVHowever, this has a negative effect on performance since it favoured short labels of one or two words which were not sufficiently descriptive of the topics
p17
aVIn addition, we weight the edges of the graph by computing the relatedness between two nodes, v i and v j , as their normalised Pointwise Mutual Information (NPMI) [ 3 ]
p18
aVFor example, a topic which has keywords school, student, university, college, teacher, class, education, learn, high, program , could be labelled as Education and a suitable label for the topic shown above would be Global Financial Crisis
p19
aVEach node is connected to its neighbouring words in a context window of ± n words
p20
aVWe consider any remaining words in the search result metadata as nodes, v u'\u005cu2208' V , in a graph G = ( V , E
p21
aV2011 ) report two versions of their approach, one unsupervised (which is used as a baseline) and another which is supervised
p22
aVFor example, the word hardware is more related and, therefore, closer in the graph to the word virtualization than to the word investments
p23
aVImportant terms are identified by applying the PageRank algorithm [ 19 ] in a similar way to the approach used by Mihalcea and Tarau ( 2004 ) for document keyphrase extraction
p24
aVPairs of words are connected with edges only if NPMI u'\u005cu2062' ( w i , w j ) 0.2 avoiding connections between words co-occurring by chance and hence introducing noise
p25
aVBut interpreting such lists is not always straightforward, particularly since background knowledge may be required [ 5 ]
p26
a.