<html>
<head>
<title>P14-2135.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>To evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u'\u222a' C introduced in Section 2</a>
<a name="1">[1]</a> <a href="#1" id=1>Multi-modal models in which perceptual input is filtered according to our algorithm learn higher-quality semantic representations than previous approaches, resulting in a significant performance improvement of up to 17% in capturing the semantic similarity of concepts</a>
<a name="2">[2]</a> <a href="#2" id=2>Formally, we propose a measure, image dispersion d of a concept word w , defined as the average pairwise cosine distance between all the image representations { w 1 u'\u2192' u'\u2062' u'\u2026' u'\u2062' w n u'\u2192' } in the set of images for that concept</a>
<a name="3">[3]</a> <a href="#3" id=3>The Turney et al algorithm quantifies the concreteness of concepts that lack such a rating based on their proximity to rated concepts in a semantic vector space</a>
<a name="4">[4]</a> <a href="#4" id=4>This model learns high quality lexical semantic representations based on the distributional properties of words in text, and has been shown to outperform simple distributional models on applications such as semantic composition and analogical mapping [ 19 ]</a>
<a name="5">[5]</a> <a href="#5" id=5>The filtering approach described thus far improves multi-modal representations because image dispersion provides</a>
</body>
</html>