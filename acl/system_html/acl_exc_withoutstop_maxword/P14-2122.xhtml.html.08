<html>
<head>
<title>P14-2122.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The bilingual model is</a>
<a name="1">[1]</a> <a href="#1" id=1>The proposed method with monolingual bigram model performed poorly on the Chinese monolingual segmentation task; thus, it was not tested</a>
<a name="2">[2]</a> <a href="#2" id=2>It was set to 3 for the monolingual unigram model, and 2 for the bilingual unigram model, which provided slightly higher BLEU scores on the development set than the other settings</a>
<a name="3">[3]</a> <a href="#3" id=3>the first bilingual UWS method practical for large corpora;</a>
<a name="4">[4]</a> <a href="#4" id=4>However, bilingual approaches that model word probabilities suffer from computational complexity</a>
<a name="5">[5]</a> <a href="#5" id=5>The first bilingual corpus</a>
<a name="6">[6]</a> <a href="#6" id=6>The computational complexity of our method is linear in the number of iterations, the size of the corpus, and the complexity of calculating the expectations on each sentence or sentence pair</a>
<a name="7">[7]</a> <a href="#7" id=7>In monolingual segmentation, the proposed methods with both unigram and bigram models were tested</a>
<a name="8">[8]</a> <a href="#8" id=8>Table 5 presents the run times of the proposed methods on the bilingual corpora</a>
<a name="9">[9]</a> <a href="#9" id=9>To this end, we model bilingual UWS under a similar framework with monolingual UWS in order to improve efficiency, and replace Gibbs sampling with expectation maximization (EM) in training</a>
<a name="10">[10]</a> <a href="#10" id=10>This section describes our unified monolingual and bilingual UWS scheme</a>
<a name="11">[11]</a> <a href="#11" id=11>The monolingual model u'\u2133' is</a>
<a name="12">[12]</a> <a href="#12" id=12>The time cost of the bilingual models is about 5 times</a>
</body>
</html>