<html>
<head>
<title>P14-1045.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Smote synthetizes and adds new instances similar to the minority class instances and is more efficient than a mere resampling</a>
<a name="1">[1]</a> <a href="#1" id=1>We tested the two strategies, by applying the classical Smote method of [] as a kind of resampling, and the ensemble method MetaCost of [] as a cost-aware learning method</a>
<a name="2">[2]</a> <a href="#2" id=2>For cost-aware learning, a sensible choice is to invert the class ratio for the cost ratio, i.e., here the cost of a mistake on a relevant link (false negative) is exactly 8.5 times higher than the cost on a non-relevant link (false positive), as non-relevant instances are 8.5 times more present than relevant ones</a>
<a name="3">[3]</a> <a href="#3" id=3>The method we propose here has been designed as an intrinsic evaluation with a view to validate semantic proximity links in a broad perspective, to cover what [] call u'\u201c' non classical lexical semantic relations u'\u201d'</a>
<a name="4">[4]</a> <a href="#4" id=4>The random forest model is significantly improved by the balancing techniques the overall best F-score of 46.3% is reached with Random Forests and the cost-aware learning method</a>
<a name="5">[5]</a> <a href="#5" id=5>One advantage of distributional similarities is to exhibit a lot of different semantic relations, not necessarily standard lexical relations</a>
<a name="6">[6]</a> <a href="#6" id=6>We analysed the learning curve by doing a cross-validation on reduced set of instances (from 10% to 90%); F1-scores range from 37.3% with 10% of instances and stabilize at 80%, with small increment in every case</a>
<a name="7">[7]</a> <a href="#7" id=7>They are not suitable for the evaluation of the whole range of semantic relatedness that is exhibited by distributional similarities, which exceeds the limits of classical lexical relations, even though researchers have tried to collect equivalent resources manually, to be used as a gold standard []</a>
<a name="8">[8]</a> <a href="#8" id=8>MetaCost is an interesting meta-learner that can use any classifier as a base classifier</a>
<a name="9">[9]</a> <a href="#9" id=9>If we take the best simple classifier (random forests), the precision and</a>
</body>
</html>