<html>
<head>
<title>P14-1079.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Suppose that we have built a training corpus for relation classification with n items (entity pairs), d -dimensional textual features, and t labels (relations), based on the basic alignment assumption proposed by Mintz et al</a>
<a name="1">[1]</a> <a href="#1" id=1>As we are stepping into the big data era, the explosion of unstructured Web texts simulates us to build more powerful models that can automatically extract relation instances from large-scale online natural language corpora without hand-labeled annotation</a>
<a name="2">[2]</a> <a href="#2" id=2>More specifically, as shown in Figure 2, we model the task with a sparse matrix whose rows present items (entity pairs) and columns contain noisy textual features and incomplete relation labels</a>
<a name="3">[3]</a> <a href="#3" id=3>As the ranks decline before approaching the optimum, the performance gradually improves, implying that our approaches filter the noise in data and keep the principal information for classification via recovering the underlying low-rank data matrix</a>
<a name="4">[4]</a> <a href="#4" id=4>In such a way, relation classification is transformed into a problem of completing the unknown labels for testing items in the sparse matrix that concatenates training and testing textual features with training labels, based on the assumption that the item-by-feature and item-by-label joint matrix is of low rank</a>
<a name="5">[5]</a> <a href="#5" id=5>An example accounting for the basic but practical assumption is illustrated in Figure 1, in which we know that the two entities ( Barack Obama, U.S are not only involved in the relation</a>
</body>
</html>