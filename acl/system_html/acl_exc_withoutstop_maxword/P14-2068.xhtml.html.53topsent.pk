(lp0
VThis dataset was annotated by Mechanical Turk workers who gave ratings for the factuality of the scoped claims in each Twitter message
p1
aVThis enables us to build a predictive model of the factuality annotations, with the goal of determining the full set of relevant factors, including the predicate, the source, the journalist, and the content of the claim itself
p2
aVOur interest in this text is specifically in quoted content u'\u005cu2014' including u'\u005cu201c' indirect u'\u005cu201d' quotes, which may include paraphrased quotations, as in the examples in Figure 1
p3
aVHaving obtained a corpus of factuality ratings, we now model the factors that drive these ratings
p4
aVThe cues that give the highest factuality coefficients are learn and admit , which are labeled as predicates of knowledge
p5
aVWe also allowed for u'\u005cu201c' Not Applicable u'\u005cu201d' option to capture ratings where the Turkers did not have sufficient knowledge about the statement or if the statement was not really a claim
p6
aVWe throw out tweets that were rated as u'\u005cu201c' not applicable u'\u005cu201d' by a majority of raters, but otherwise ignore u'\u005cu201c' not applicable u'\u005cu201d' ratings
p7
a.