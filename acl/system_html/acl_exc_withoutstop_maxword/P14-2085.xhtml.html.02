<html>
<head>
<title>P14-2085.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We aim to leverage existing, possibly noisy sets of representative stative, dynamic or mixed verb types extracted from LCS (see section 3 ), making up for unseen verbs and noise by averaging over distributional similarities</a>
<a name="1">[1]</a> <a href="#1" id=1>Using an existing large distributional model [ 31 ] estimated over the set of Gigaword documents marked as stories, for each verb type, we build a syntactically informed vector representing the contexts in which the verb occurs</a>
<a name="2">[2]</a> <a href="#2" id=2>The experiments presented in this section aim to evaluate the effectiveness of the feature sets described in the previous section, focusing on the challenging cases of verb types unseen in the training data and highly ambiguous verbs</a>
<a name="3">[3]</a> <a href="#3" id=3>For predicting the aspectual class of verbs in context ( stative , dynamic , both ), we assume a supervised learning setting and explore features mined from a large background corpus, distributional features, and instance-based features</a>
<a name="4">[4]</a> <a href="#4" id=4>Their model fails to outperform a baseline of memorizing the most frequent class of a verb type, and they present an experiment testing on unseen verb types only for the related task of classifying completedness of events</a>
<a name="5">[5]</a> <a href="#5" id=5>We replicate their method using publicly available software, create a similar but larger</a>
</body>
</html>