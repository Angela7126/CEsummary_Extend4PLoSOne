(lp0
VWe thus expect the syntactic contexts to yield more focused embeddings, capturing more functional and less topical similarity
p1
aVIn this paper we experiment with dependency-based syntactic contexts
p2
aVThe pairs are ranked according to cosine similarities between the embedded words
p3
aVTurney [ 31 ] described this distinction as domain similarity versus functional similarity
p4
aVThe next two examples demonstrate that similarities induced from Deps share a syntactic function (adjectives and gerunds), while similarities based on BoW are more diverse
p5
aVOptimizing this objective makes observed word-context pairs have similar embeddings, while scattering unobserved pairs
p6
aVSince word2vec removes the subsampled words from the corpus before creating the window contexts, this option effectively increases the window size, resulting in greater topicality
p7
aVA very common paradigm for acquiring such representations is based on the distributional hypothesis
p8
a.