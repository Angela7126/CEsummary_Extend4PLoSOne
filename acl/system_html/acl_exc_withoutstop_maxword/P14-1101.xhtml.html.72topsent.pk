(lp0
V6 6 Other clustering measures, such as 1-1 matching and pairwise precision and recall (accuracy and completeness) showed the same trends, but VM has been demonstrated to be the most stable measure when comparing solutions with varying numbers of clusters ( 7
p1
aVThe other topics are less frequent but capture stronger semantic meaning (e.g., yummy, peach, cookie, daddy, bib in one topic, shoe, let, put, hat, pants in another
p2
aVIn the individual components of VM, TLD and LD have similar VC ( u'\u005cu201c' recall u'\u005cu201d' ), but TLD has higher VH ( u'\u005cu201c' precision u'\u005cu201d' ), demonstrating that the semantic information given by the topics can separate potentially ambiguous words, as hypothesized
p3
aVThe TLD model retains the IGMM vowel phone component, but extends the lexicon of the LD model by adding topic-specific lexicons, which capture the notion that lexeme probabilities are topic-dependent
p4
aVThe modeled situations consist of combinations of categories of salient activities or objects, similar to the activity contexts explored by Roy et al
p5
aVHowever, due to a widespread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see 42 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information ( 8 ; 9 ; 11 ; 26 ; 50 )
p6
aVThe TLD model includes additional observations, described below.) A single vowel token, w i u'\u005cu2062' j , is a two dimensional vector representing the first two formants (peaks in the frequency spectrum, ordered from lowest to highest
p7
aVWe therefore obtain the topic distributions used as input to the TLD model by training an LDA topic model ( 5 ) on a superset of the child-directed transcript data we use for lexical-phonetic learning, dividing the transcripts into small sections (the u'\u005cu2018' documents u'\u005cu2019' in LDA) that serve as our distinct situations u'\u005cud835' u'\u005cudc89'
p8
aVEach word in the dataset is converted to a phonemic representation using the
p9
a.