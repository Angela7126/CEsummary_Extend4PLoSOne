(lp0
VMansur et al
p1
aVMansur et al
p2
aVTo incorporate features into the neural network, Mansur et al
p3
aVIn Mansur et al
p4
aVZheng et al
p5
aVZheng et al
p6
aV[ 15 ] , the bigram embeddings are pre-trained on unlabeled data with character embeddings, which significantly improves the model performance
p7
aVMikolov et al
p8
aVMikolov et al
p9
aVCollobert et al
p10
aVCompared with Mansur et al
p11
aVA very common feature in Chinese word segmentation is the character bigram feature
p12
aVIn our model, the bigram features are extracted in the window context and then the corresponding bigram embeddings are concatenated with character embeddings in Layer 1 and fed into Layer 2
p13
aVFollowing Mansur et al
p14
aV[ 35 ] followed the model proposed by Collobert et al
p15
aV[ 15 ] used the model proposed by Bengio et al
p16
aVPrevious work found that the performance can be improved by pre-training the character embeddings on large unlabeled
p17
a.