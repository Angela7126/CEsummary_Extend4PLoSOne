<html>
<head>
<title>P14-1124.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We consider term detection rather than the transcription task in considering how to exploit topic context, because in evaluating the retrieval of certain key terms we need not focus on improving the entire word sequence</a>
<a name="1">[1]</a> <a href="#1" id=1>The BABEL task is modeled on the 2006 NIST Spoken Term Detection evaluation [] but focuses on limited resource conditions</a>
<a name="2">[2]</a> <a href="#2" id=2>The x -coordinate of each point in Figure 1 is the frequency of k in the training data, and the y -coordinate is the correlation coefficient u'\u03a1' k between T u'\u2062' ( k , w ) and D u'\u2062' ( k , w</a>
<a name="3">[3]</a> <a href="#3" id=3>Lastly, the reductions in P u'\u2062' ( Miss ) suggests that we are improving the term detection metric, which is sensitive to threshold changes, by doing what we set out to do, which is to boost lower confidence repeated words and correctly asserting them as true hits</a>
<a name="4">[4]</a> <a href="#4" id=4>For each keyword k , we count how often it co-occurs in the same conversation as a vocabulary word w in the ASR training data and the development data, and designate the counts T u'\u2062' ( k , w</a>
</body>
</html>