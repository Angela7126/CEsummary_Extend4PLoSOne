(lp0
VThen, we induce verb classes by clustering these verb-specific semantic frames across verbs
p1
aVOur method consists of two clustering steps verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames
p2
aVinduce verb classes by clustering the induced semantic frames across verbs as shown in the upper part of Figure 1
p3
aVIn this paper, we propose a two-step approach for inducing semantic frames and verb classes
p4
aVWe induce verb-specific semantic frames from verb uses based on the method of Kawahara et al
p5
aVTo do that, we induce verb-specific semantic frames by clustering verb uses
p6
aVTo output a single class for each verb by using our proposed method, we skip the induction of verb-specific semantic frames and instead create a single frame for each verb by merging all predicate-argument structures of the verb
p7
aVWe first evaluate our induced verb classes on the test set created by Korhonen et al
p8
aVBased on the best results in the above evaluations, we induced semantic frames using slot-word pair features, and then induced verb classes using slot-only features
p9
aVWe evaluate the single-class output for each verb based on the predominant gold-standard classes, which are defined for each verb in the test set of Korhonen et al
p10
aVIn this paper, we propose an unsupervised method for inducing verb classes that is aware of verb polysemy
p11
aV2006 ) ) model to jointly learn argument structures (subcategorization frames) and verb classes by using syntactic features
p12
aVWe can use exactly the same clustering method as described in Section 3.2.3 by using semantic frames for multiple verbs as an input instead of initial frames for a single verb
p13
aVapply clustering to the initial frames based on the Chinese Restaurant Process [ 1 ] to produce verb-specific semantic frames
p14
aVBy taking this step-wise approach, we can not only induce verb classes with frequency information from a massive amount of verb uses in a scalable manner, but also deal with verb polysemy
p15
aV2003 ) evaluated hard clusterings based on a gold standard with multiple classes per verb
p16
aVWe regard each output cluster as a semantic frame, by merging the initial frames in a cluster into a semantic frame
p17
aVFirst, we make multiple data points for each verb to deal with verb polysemy (cf polysemy-aware previous studies still represented a verb as one data point [ 14 , 23 ]
p18
aVSince we focus on the handling of verb polysemy, predominant class induction for each verb is not our main objective
p19
aVThis result is consistent with expectations, given a gold standard based on Levin u'\u005cu2019' s verb classes, which are organized according to the syntactic behavior of verbs
p20
aV2012 ) extended the model of Titov and Klementiev ( 2012 ) , which is an unsupervised model for inducing semantic roles, to jointly induce semantic roles and frames across verbs using the Chinese Restaurant Process [ 1 ]
p21
aV2008 ) also applied probabilistic soft clustering to verbs by incorporating subcategorization frames and selectional preferences based on WordNet
p22
aVinduce verb-specific semantic frames by clustering predicate-argument structures for each verb extracted from automatic parses as shown in the lower part of Figure 1 , and
p23
aVAlthough Bayesian approaches are a possible solution to simultaneously induce frames and verb classes from a corpus as used in previous studies, it has prohibitive computational cost
p24
aVAfter performing soft clustering, they noted that most verbs fell into a single class, and they decided to assign a single class to each verb by hardening the clustering
p25
aV2003 ) , prepositional phrases (pp) are parameterized for two frequent subcategorization frames (NP and NP_PP), and the unfiltered raw frequencies of subcategorization frames are used as features to represent a verb
p26
aVFrom the result, we can see that the induced verb classes based on slot-only features did not achieve a higher F 1 than those based on slot-word pair features in many cases
p27
aVInterestingly, this result indicates that slot distributions are more effective than lexical information in slot-word pairs for inducing verb classes similar to the gold standard
p28
aVWe regard each output cluster as a verb class this time
p29
aV9 9 Since FrameNet frames are not assigned to all verbs of SemLink, the number of verbs is different from the evaluations against VerbNet classes
p30
aVVerb classes are one such lexical resource
p31
aVLapata and Brew ( 2004 ) and Li and Brew ( 2007 ) proposed probabilistic models for calculating prior probabilities of verb classes for a verb
p32
aVWhen we evaluate against the multiple classes in the gold standard, we do normalize the inverse purity
p33
aVThis is because an initial frame has the same structure as a semantic frame, which is produced by merging initial frames
p34
aVWe speculate that slot distributions are not so different among verbs when all uses of a verb are merged into one frame, and thus their discrimination power is lower than that in the intermediate construction of semantic frames
p35
aVIn particular, they tried to consider verb polysemy by using the IB method, which is a soft clustering method [ 43 ]
p36
aVHowever, since these measures are only applicable to a hard clustering, it is necessary to extend them to be applicable to a soft clustering, because in our task a verb can belong to multiple clusters or classes
p37
aVSince they focused on the incorporation of selectional preferences, they did not evaluate verb classes but evaluated only selectional preferences using a language model-based measure
p38
aV2003 ) (Table 1 of their paper) which was created by considering verb polysemy on the basis of Levin u'\u005cu2019' s classes and the LCS database [ 6 ]
p39
aV2003 ) , using the gold standard with multiple classes, which we also use for our multi-class evaluations
p40
aVFor instance, u'\u005cu201c' Class 2 u'\u005cu201d' consists of the semantic frames u'\u005cu201c' need:2 u'\u005cu201d' and u'\u005cu201c' say:2 u'\u005cu201d' These frames were merged due to the high syntactic similarity of constituting slot distributions, which are comprised of a subject and a sentential complement
p41
aVParisien and Stevenson ( 2011 ) extended their model by adding semantic features
p42
aV2009 ) proposed a Dirichlet process mixture model (DPMM; Neal ( 2000 ) ) to cluster verbs based on subcategorization frame distributions
p43
aVAs we did with the multi-class evaluations, we adopt modified purity (mPU), inverse purity (iPU) and their harmonic mean (F 1 ) as the metrics for the evaluation with predominant classes
p44
aVHowever, the verb itself is still represented as a single data point
p45
aVWe can see that u'\u005cu201c' web/SW-S u'\u005cu201d' achieved the best performance and obtained a higher F 1 than the baselines by more than nine points u'\u005cu201c' Web/SW-S u'\u005cu201d' uses the combination of slot-word pair features for clustering verb-specific frames and slot-only features for clustering across verbs
p46
aVThese models are approximated to condition not on verbs but on subcategorization frames
p47
aVHe applied this method to the BNC and acquired 1,200 frames and 400 roles [ 21 ]
p48
aVWe select an argument in the following order by considering the degree of effect on the verb sense
p49
aVIt is not necessary to normalize these metrics when we treat verbs as monosemous, and evaluate against the predominant sense
p50
aVIt is not necessary to normalize these metrics because the clustering of these instances is hard
p51
aVThe original method in Kawahara et al
p52
aVThe other representation using the slot-word pairs means that semantic similarity based on word overlap is naturally considered by looking at lexical information
p53
aVmerge the predicate-argument structures that have presumably the same meaning based on the assumption of one sense per collocation [ 46 ] to get a set of initial frames, and
p54
aVFinally, we use the harmonic mean (F 1 ) of nmPU and niPU as a single measure of clustering quality
p55
aVHe used a model based on latent Dirichlet allocation (LDA; Blei et al
p56
aVAs usual, the following normalized inverse purity (niPU) is used to measure the recall of a clustering
p57
aVCapturing the sense of a verb is essential for natural language processing (NLP), and thus lexical resources for verbs play an important role in NLP
p58
aVIn addition, to penalize clusters that consist of only one verb, such singleton clusters in K are considered as errors, as is usual with modified purity
p59
aVThese two levels of evaluations are performed by considering the work of Reichart et al
p60
aVAs mentioned in Li and Brew ( 2007 ) , it is desirable to extend the model to depend on verbs to further improve accuracy
p61
aVFor the features, w , in equation ( 2 ), we try the two representations again slot-only features and slot-word pair features
p62
aVThis model is based on the Expectation-Maximization algorithm and the Minimum Description Length principle
p63
aVBoth of these are represented as a probabilistic distribution of words across verbs
p64
aVTo prepare a web corpus, we extracted sentences from crawled web pages that are judged to be written in English based on the encoding information
p65
aVIt is necessary to specify the number of clusters, k , for the IB method beforehand, and we adopt 35 and 42 clusters according to their reported high accuracies
p66
aVThis monosemous assumption, however, is not realistic because many frequent verbs actually have multiple senses
p67
aV3 3 If a predicate-argument structure has multiple prepositional phrases, one of them is randomly selected
p68
aVP ( f i c j ) is defined based on the Dirichlet-Multinomial distribution as follows
p69
aVAn excerpt from this data is shown in Table 1
p70
aVThe clusterings with the NN and IB methods are obtained by using the VALEX subcategorization lexicon
p71
aVThe normalized modified purity (nmPU) can then be written as follows
p72
aV2014 ) defined w as pairs of slots and words, e.g.,, u'\u005cu201c' nsubj:child u'\u005cu201d' and u'\u005cu201c' dobj:bird, u'\u005cu201d' but does not consider slot-only features, e.g.,, u'\u005cu201c' nsubj u'\u005cu201d' and u'\u005cu201c' dobj, u'\u005cu201d' which ignore lexical information
p73
aVNote that our results of the NN and IB methods are different from those reported in their paper since the data source is different
p74
aVK i denotes the number of positive components in K i , and c i u'\u005cu2062' v denotes the v -th component of K i u'\u005cu0394' K i u'\u005cu2062' ( K i u'\u005cu2229' G j ) means the total mass of the set of verbs in K i u'\u005cu2229' G j , given by summing up the values in K i
p75
aVAs our baselines, we adopt two previously proposed methods
p76
aVK i u'\u005cu2229' G j because all the values of c i u'\u005cu2062' v are equal to 1
p77
aVThe results of the IB baseline and our methods are obtained by averaging five runs
p78
aVThe results of these methods are obtained by averaging five runs
p79
aVTo induce verb classes across verbs, we apply clustering to the induced verb-specific semantic frames
p80
aVinduce both semantic frames and verb classes from a massive amount of verb uses by a scalable method
p81
aVWe first implemented a soft clustering method for verb class induction proposed by Korhonen et al
p82
aVWe ended with 38,481 semantic frames and 699 verb classes from the Gigaword corpus, and 61,903 semantic frames and 840 verb classes from the web corpus
p83
aVMaterna applied an LDA-based method to the BNC, which contains 1.4M verb uses, to induce semantic frames across verbs that can be considered to be verb classes [ 21 , 22 ]
p84
aV2003 ) ) and the Dirichlet process to cluster verb instances of a triple (subject, verb, object) to produce semantic frames and roles
p85
aVOur objective is to automatically learn semantic frames and verb classes from a massive amount of verb uses following usage-based approaches
p86
aVTo output multiple classes for each verb, we set a threshold, t , for class attribute probabilities
p87
aVThey conducted several evaluations including predominant class induction and token-level verb sense disambiguation, but did not evaluate multiple classes output by their models
p88
aVHe did not evaluate the resulting frames as verb classes
p89
aVExamples of verb classes and semantic frames induced from the web corpus are shown in Table 5 and Table 6
p90
aVFor a baseline, we use verb-specific semantic frames without clustering across verbs ( u'\u005cu201c' S-NIL u'\u005cu201d' and u'\u005cu201c' SW-NIL u'\u005cu201d' ), where these frames are considered to be verb classes but not shared across verbs
p91
aVFor instance, Parisien and Stevenson applied HDP only to a small-scale child speech corpus that contains 170K verb uses to jointly induce subcategorization frames and verb classes [ 26 , 27 ]
p92
aVThen, we compare the induced verb classes of the SemLink instances with their gold-standard VerbNet classes
p93
aVWe finally induce verb classes from the semantic frames of 1,667 verbs, which appear at least once in sections 02-21 of the WSJ corpus
p94
aVWe cluster initial frames for each verb to produce semantic frames using the Chinese Restaurant Process [ 1 ] , regarding each initial frame as an instance
p95
aVThen, we apply clustering to these frames across verbs
p96
aVquantitatively evaluate a soft clustering of verbs
p97
aVThe average number of verb classes per verb is 2.24
p98
aVOur procedure to automatically induce verb classes from verb uses is summarized as follows
p99
aVThey used the information bottleneck (IB) method for assigning probabilities of classes to each verb
p100
aVWe also evaluate our induced verb classes on this gold-standard data, which was created on the basis of Levin u'\u005cu2019' s classes [ 16 ]
p101
aVIn this way, semantic frames for each verb are acquired
p102
aVTo measure the precision and recall of a clustering, modified purity and inverse purity (also called collocation or weighted class accuracy) are commonly used in previous studies on verb clustering (e.g.,, Sun and Korhonen ( 2009 )
p103
aVManually-crafted verb classes have been developed, such as Levin u'\u005cu2019' s classes [ 16 ] and their extension, VerbNet [ 12 ] , in which verbs are organized into classes on the basis of their syntactic and semantic behavior
p104
aVLDA-frames are probabilistic semantic frames automatically induced from a raw corpus
p105
aVThat is, classes that have a higher class attribute probability than the threshold are output for each verb
p106
aVAll of the above methods considered verbs to be monosemous and did not deal with verb polysemy
p107
aVAmong these studies on monosemous verb clustering (i.e.,, predominant class induction), there have been several Bayesian methods
p108
aVThey tried to account for verb learning by children and did not evaluate the resultant verb classes
p109
aVWe first describe our experimental settings and define evaluation metrics to evaluate induced soft clusterings of verb classes
p110
aVThe use of slot-word pairs for verb class induction generally merged too many frames into each class, apparently due to accidental word overlaps across verbs
p111
aVIn sum, there have been no studies that quantitatively evaluate polysemous verb classes automatically induced by unsupervised methods
p112
aV2003 ) , who used distributions of subcategorization frames to cluster verbs
p113
aVAs stated in Section 1 , most of the previous studies on verb clustering assume that verbs are monosemous
p114
aVMore sophisticated methods for predominant class induction, such as the method of Sun and Korhonen ( 2009 ) using selectional preferences, could produce better single-class outputs, but have difficulty in producing polysemy-aware verb classes
p115
aVFor baselines, we once more adopt the Nearest Neighbor (NN) and Information Bottleneck (IB) methods proposed by Korhonen et al
p116
aVHowever, we wish to compare our method with previous work on the induction of a predominant (monosemous) class for each verb
p117
aVTheir method represents a verb u'\u005cu2019' s syntactic and semantic features, and learns a log-linear model from the SemLink corpus [ 20 ]
p118
aV2012 ) induced semantic frames across verbs using the monosemous assumption and reported an F 1 of 44.7% (77.9% PU and 31.4% iPU) for the assignment of FrameNet frames to the FrameNet corpus
p119
aVA typical method in these studies is to represent each verb as a single data point and apply classification (e.g.,, Joanis et al
p120
aVThe verb classes induced from the web corpus achieved a higher F 1 than those from the Gigaword corpus
p121
aVThere have also been many attempts to automatically acquire verb classes with the goal of either adding frequency information to an existing resource or of inducing similar verb classes for other languages
p122
aVAs a representation for a data point, distributions of subcategorization frames are often used, and other semantic features (e.g.,, selectional preferences) are sometimes added to improve the performance
p123
aVThese initial frames are the input of the subsequent clustering process
p124
aVOur proposed method using the web corpus achieved comparable performance with the baseline methods on the predominant class evaluation and outperformed them on the multiple class evaluation
p125
aVTo improve the quality of verb classes, it is necessary to develop a clustering model that can consider syntactic and lexical similarity in a balanced way
p126
aVThe most closely related work to our polysemy-aware task of unsupervised verb class induction is the work of Korhonen et al
p127
aV2003 ) reported that the highest modified purity was 49% against predominant classes and 60% against multiple classes
p128
aVThey considered multiple classes only in the gold-standard data used for their evaluations
p129
aVMaterna proposed LDA-frames, which are defined across verbs and can be considered to be a kind of verb class [ 21 , 22 ]
p130
aVThey adopted the Nearest Neighbor (NN) and Information Bottleneck (IB) methods for clustering
p131
aVTo harden the clusterings of the IB method and the LDA-frames, the class with the highest probability is selected for each verb
p132
aVIt consists of 62 classes and 110 verbs, out of which 35 verbs are monosemous and 75 verbs are polysemous
p133
aV2012 ) , but our induced verb classes seem to have higher F 1 accuracy
p134
aVThis data contains 110 verbs and 33 classes
p135
aVOur approach also uses Bayesian methods, but is designed to capture verb polysemy
p136
aVThe procedure for inducing these semantic frames is as follows
p137
aVexplicitly deal with verb polysemy
p138
aVThey evaluated their result with a gold-standard test set, where a single class is assigned to a verb
p139
aVIt took two days to induce verb classes from the Gigaword corpus and three days from the web corpus
p140
aVWhere there is no frequency information available for class distribution, such as the gold-standard data described in Section 4.3 , we use a uniform distribution across the verb u'\u005cu2019' s classes
p141
aVFor each predicate-argument structure of a verb, we couple the verb and an argument to make a unit for sense disambiguation
p142
aVParisien and Stevenson ( 2010 ) proposed a hierarchical Dirichlet process (HDP; Teh et al
p143
aV6 6 http://nlp.fi.muni.cz/projekty/lda-frames/ This frame data was induced from the BNC and consists of 1,200 frames and 400 semantic roles
p144
aVSuppose K is the set of automatically induced clusters and G is the set of gold classes
p145
aVMoreover, to the best of our knowledge, none of the following approaches attempt to quantitatively evaluate soft clusterings of verb classes induced by polysemy-aware unsupervised approaches [ 14 , 15 , 17 , 31 ]
p146
aVMiyao and Tsujii ( 2009 ) proposed a supervised method that can handle verb polysemy
p147
aVTo measure the precision of a clustering, a normalized version of modified purity is defined as follows
p148
aVModi et al
p149
aVModi et al
p150
aVWe propose a normalized version of modified purity and inverse purity
p151
aVNote that Korhonen et al
p152
aVEach instance of these 119 verbs in this corpus belongs to one of 102 VerbNet classes
p153
aVWe also conducted the above evaluation against FrameNet frames for 75 verbs
p154
aVFor clustering features, we again compare two representations slot-only features (S) and slot-word pair features (SW
p155
aVOur semantic frames consist of case slots, each of which consists of word instances that can be filled
p156
aVThese 119 verbs cover 102 VerbNet classes, and 48 of them are polysemous in the sense of being in more than one VerbNet class
p157
aVThey reported only precision measures including modified purity, and avoided extending the evaluation metrics for soft clusterings
p158
aVwhere N is the number of initial frames for the target verb and n u'\u005cu2062' ( c j ) is the current number of initial frames assigned to the cluster c j u'\u005cu0391' is a hyper-parameter that determines how likely it is for a new cluster to be created
p159
aVPredicate-argument structures are collected for each verb and the subsequent processes are applied to the predicate-argument structures of each verb
p160
aVWe evaluate these single-class outputs in the same manner as Korhonen et al
p161
aVdiscover effective features for each of the clustering steps, and
p162
aVThis hardening process is exactly the same as Korhonen et al
p163
aV2008 ) ) or clustering (e.g.,, Sun and Korhonen ( 2009 ) ) to these data points
p164
aVLet K i be the verb vector of the i -th cluster and G j be the verb vector of the j -th gold class
p165
aVWe report the values of modified purity (mPU), inverse purity (iPU) and their harmonic mean (F 1
p166
aVWhile there are many classes with consistent meanings, such as u'\u005cu201c' Class 4 u'\u005cu201d' and u'\u005cu201c' Class 16, u'\u005cu201d' some classes have mixed meanings
p167
aVSuch verb classes have been used in many NLP applications that need to consider semantics in particular, such as word sense disambiguation [ 4 ] , semantic parsing [ 41 , 33 ] and discourse parsing [ 37 ]
p168
aVThen, the predicate-argument structures that have the same verb and argument pair (slot and word, e.g.,, u'\u005cu201c' dobj:effect u'\u005cu201d' ) are merged into an initial frame
p169
aVVlachos et al
p170
aVapply dependency parsing to a raw corpus and extract predicate-argument structures for each verb from the automatic parses
p171
aVAn interesting point here is that we can use exactly the same method for these two clustering steps
p172
aVThis kind of normalization for soft clusterings was performed for other evaluation metrics as in Springorum et al
p173
aV2010 ) on clustering evaluation
p174
aVTable 2 lists evaluation results for the baseline methods and our methods
p175
aVWe report results using our methods with four feature combinations (slot-only (S) and slot-word pair (SW) features each used for both the frame-generation and verb-class clustering steps) for both the Gigaword and web corpora
p176
aV5 5 http://ilexir.co.uk/applications/valex/ By following the method of Korhonen et al
p177
aVWe first add these instances to the instances from a raw corpus and apply the two-step clustering to these merged instances
p178
aVEach component of these vectors is a normalized frequency, which equals a cluster/class attribute probability given a verb
p179
aVAgain, we set a threshold for frame attribute probabilities
p180
aVSchulte im Walde et al
p181
aVThere were 7,356 verbs after applying the same frequency threshold as the web corpus
p182
aVThe core idea of purity is that each cluster K i is associated with its most prevalent gold class
p183
aVWe summarize a few studies that consider polysemy of verbs in the rest of this section
p184
aVThere were 19,649 verbs, including phrasal verbs, and separating passive and active constructions
p185
aVFor clustering features, we compare two feature combinations u'\u005cu201c' S-S u'\u005cu201d' and u'\u005cu201c' SW-S, u'\u005cu201d' which achieved high performance in the type-level multi-class evaluations (Section 4.3
p186
aVBoleda et al
p187
aV4 4 Korhonen et al
p188
aVWe focused on verbs whose frequency in the web corpus was more than 1,000
p189
aVTable 3 lists accuracies of baseline methods and our methods
p190
aVIn case of evaluating a hard clustering, this is equal to
p191
aV2003 ) actually hardened the clusterings and left the evaluations of soft clusterings for their future work
p192
aVwhere N denotes the total number of verbs
p193
aVWe conduct token-level multi-class evaluations using 119 verbs, which appear 100 or more times in sections 02-21 of the SemLink WSJ corpus
p194
aV8 8 Korhonen et al
p195
aVFor input data, we employ VALEX [ 13 ] , which is a publicly-available large-scale subcategorization lexicon
p196
aVTo make the computation feasible, we merge the predicate-argument structures that have the same or similar meaning to get initial frames
p197
aVAfter this process, we discard minor initial frames that occur fewer than 10 times
p198
aVIn this process, the verb and arguments are lemmatized, and only the head of an argument is preserved for compound nouns
p199
aV2007 ) also proposed a supervised method for Catalan adjectives considering the polysemy of adjectives
p200
aVWe report the results of the following threshold values
p201
aVA verb plays a primary role in conveying the meaning of a sentence
p202
aVWe can see that u'\u005cu201c' SW-S u'\u005cu201d' achieved a higher F 1 than u'\u005cu201c' S-S u'\u005cu201d' and the baselines without verb class induction ( u'\u005cu201c' S-NIL u'\u005cu201d' and u'\u005cu201c' SW-NIL u'\u005cu201d'
p203
aVWe will compare in our experiments four possible combinations two feature representations for each of the two clustering steps
p204
aVDependents that have the following dependency relations to a verb are extracted as arguments
p205
aVThe employment of this kind of huge corpus is enabled by our scalable method
p206
aVWe achieved an F 1 of 62.79% (66.97% mPU and 59.09% iPU) for u'\u005cu201c' web/SW-S, u'\u005cu201d' and an F 1 of 60.06% (65.58% mPU and 55.39% iPU) for u'\u005cu201c' Gigaword/SW-S u'\u005cu201d' It is difficult to directly compare these results with Modi et al
p207
aVFrom this process, we obtained a corpus of one billion sentences, totaling approximately 20 billion words
p208
aVTable 4 lists accuracies of these methods for the two corpora
p209
aVWe took 100 samples for each input frame and selected the cluster assignment that has the highest probability
p210
aVWe use Gibbs sampling to realize this clustering
p211
aVThis result is different from that of multi-class evaluations in Section 4.3
p212
aVWe use two kinds of large-scale corpora a web corpus and the English Gigaword corpus
p213
aVWe apply dependency parsing to a large raw corpus
p214
aVWe calculate the posterior probability of a cluster c j given an initial frame f i as follows
p215
aVThen, we conduct type-level multi-class evaluations, type-level single-class evaluations and token-level multi-class evaluations
p216
aV7 7 Although we do not think that the classes with very small attribute probabilities are meaningful, the F 1 scores for lower thresholds than 0.01 converged to about 66 in the case of LDA-frames
p217
aV2003 ) , and LDA-frames proposed by Materna ( 2012
p218
aVThis corpus consists of approximately 180 million sentences, which totaling four billion words
p219
aVwhere V is the vocabulary in all case slots cooccurring with the verb and c u'\u005cu2062' o u'\u005cu2062' u u'\u005cu2062' n u'\u005cu2062' t u'\u005cu2062' ( f i , w ) is the number of w in the initial frame f i
p220
aVMost of these approaches assume that all target verbs are monosemous [ 36 , 32 , 9 , 18 , 38 , 39 , 45 , 26 , 27 , 7 , 19 , 29 , 40 ]
p221
aVWe extracted 423,778,278 predicate-argument structures from this corpus
p222
aVWe use the induced LDA-frames that are available on the web site
p223
aVHere we experiment with both representations and compare the results
p224
aVFor a new cluster, this probability is uniform ( 1 /
p225
aVThe representation using only slots corresponds to the consideration of only syntactic argument patterns
p226
aVAlthough it is best to use the largest possible corpus for this kind of knowledge acquisition tasks [ 30 ] , it is infeasible to scale to giga-word corpora using such joint models
p227
aVHowever, it would take three months for this experiment using this 100 million word corpus
p228
aVWe also gratefully acknowledge the support of the National Science Foundation Grant NSF-IIS-1116782, A Bayesian Approach to Dynamic Lexical Resources for Flexible Language Processing
p229
aVFor this merge, we assume one sense per collocation [ 46 ] for predicate-argument structures
p230
aVThis can be attributed to the larger size of the web corpus
p231
aVIn this equation, the first term is the Dirichlet process prior and the second term is the likelihood of f i
p232
aVFinally, we discuss the results of our full experiments
p233
aVThen, we selected sentences that consist of at most 40 words, and removed duplicated sentences
p234
aVWe also used the English Gigaword corpus (LDC2011T07; English Gigaword Fifth Edition
p235
aVwhere c u'\u005cu2062' o u'\u005cu2062' u u'\u005cu2062' n u'\u005cu2062' t u'\u005cu2062' ( c j , w ) is the current number of w in the cluster c j , and u'\u005cu0392' is a hyper-parameter of Dirichlet distribution
p236
aVTo reach 1,000 iterations, which are reported to be optimum, it would take three months
p237
aVThe cluster assignments for all the components were initialized randomly
p238
aV1 1 In our replication experiment, it took a week to perform 70 iterations using Materna u'\u005cu2019' s code and an Intel Xeon E5-2680 (2.7GHz) CPU
p239
aVWe extracted 2,032,774,982 predicate-argument structures
p240
aVWe set the hyper-parameters u'\u005cu0391' in ( 1 ) and u'\u005cu0392' in ( 3 ) to 1.0
p241
aV2 2 http://nlp.stanford.edu/software/lex-parser.shtml Collapsed dependencies are adopted to directly extract prepositional phrases
p242
aVThen, we extract predicate-argument structures from the dependency parses
p243
aVEach of these two steps is described in the following sections in detail
p244
aVThese three steps are briefly described below
p245
aVP ( w c j ) is defined as follows
p246
aVThis work was supported by Kyoto University John Mung Program and JST CREST
p247
aVThe other baseline is LDA-frames [ 21 ]
p248
aVdobj, ccomp, nsubj, prep_ * , iobj
p249
aVnsubj, xsubj, dobj, iobj, ccomp, xcomp, prep_ *
p250
aVOur novel contributions are summarized as follows
p251
aVAny opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation
p252
aVWe use the Stanford parser with Stanford dependencies [ 5 ]
p253
aV2014
p254
aVV
p255
aV2003
p256
aV2003
p257
aV2013 )
p258
aV2003
p259
aV0.01, 0.02, 0.05 and 0.10
p260
a.