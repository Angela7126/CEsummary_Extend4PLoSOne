(lp0
VGiven the distribution w u'\u005cu2192' \u005ccS of a word w in a source domain \u005ccS , we propose a method for learning its distribution w u'\u005cu2192' \u005ccT in a target domain \u005ccT
p1
aVAt test time, for each word w that appears in a target domain test sentence, we measure the similarity, sim u'\u005cu2062' ( \u005cmat u'\u005cu2062' M u'\u005cu2062' u u'\u005cu2192' \u005ccS ( i ) , w u'\u005cu2192' \u005ccT ) , and select the most similar r words u ( i ) in the source domain labeled sentences as the distributional features for w , with their values set to sim u'\u005cu2062' ( \u005cmat u'\u005cu2062' M u'\u005cu2062' u u'\u005cu2192' \u005ccS ( i ) , w u'\u005cu2192' \u005ccT
p2
aVIn this paper, given the distribution w u'\u005cu2192' \u005ccS of a word w in the source domain \u005ccS , we propose an unsupervised method for predicting its distribution w u'\u005cu2192' \u005ccT in a different target domain \u005ccT
p3
aVRecall that the \u005ccT p u'\u005cu2062' r
p4
a.