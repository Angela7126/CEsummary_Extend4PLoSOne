<html>
<head>
<title>P14-2080.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We show that for both domains, patents and Wikipedia, jointly learning bilingual sparse word associations and dense knowledge-based similarities directly on relevance ranked data improves significantly over approaches that use either only sparse or only dense features, and over approaches that combine query translation by SMT with standard retrieval in the target language</a>
<a name="1">[1]</a> <a href="#1" id=1>Since patent applicants and lawyers are required to list relevant prior work explicitly in the patent application, patent citations can be used to automatically extract large amounts of relevance judgments across languages [ 12 ]</a>
<a name="2">[2]</a> <a href="#2" id=2>Borda denotes model combination by Borda Count voting where the linear interpolation parameter is adjusted for MAP on the respective development</a>
</body>
</html>