(lp0
VThe batch model is built by learning only from the training data and is evaluated on the test set without exploiting information from the test instances
p1
aVFocusing on the adaptability to user and domain changes, we report the results of comparative experiments with two online algorithms and the standard batch approach
p2
aVLarge values indicate a low similarity between training and test data and a more challenging scenario for the learning algorithms
p3
aVQE is generally cast as a supervised machine learning task, where a model trained from a collection of ( source, target, label ) instances is used to predict labels 1 1 Possible label types include post-editing effort scores ( e.g., 1-5 Likert scores indicating the estimated percentage of MT output that has to be corrected), HTER values [ 28 ] , and post-editing time ( e.g., seconds per word for new, unseen test items [ 31 ]
p4
aVAt each step of the process, the goal of the learner is to exploit user post-editions to reduce the difference between the predicted HTER values and the true labels for the following ( source, target ) pairs
p5
aVOn the other side, online learning techniques are designed to learn in a stepwise manner (either from scratch, or by refining an existing model) from new, unseen test instances by taking advantage of external feedback
p6
aVThis demonstrates that, as expected, the online algorithms do not take advantage of test data with a label distribution similar to the training set
p7
aVEvaluation is carried out by measuring the performance of the batch (learning only from the training set), the adaptive (learning from the training
p8
a.