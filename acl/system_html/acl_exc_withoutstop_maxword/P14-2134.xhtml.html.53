<html>
<head>
<title>P14-2134.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>A joint model has three a priori advantages over independent models i) sharing data across variable values encourages representations across those values to be similar; e.g.,, while city may be closer to Boston in Massachusetts and Chicago in Illinois, in both places it still generally connotes a municipality ; (ii) such sharing can mitigate data sparseness for less-witnessed areas; and (iii) with a joint model, all representations are guaranteed to be in the same vector space and can therefore be compared to each other; with individual models (each with different initializations), word vectors across different states may not be directly compared</a>
<a name="1">[1]</a> <a href="#1" id=1>The model we introduce is grounded in the distributional hypothesis [] , that two words are similar by appearing in the same kinds of contexts (where u'\u201c' context u'\u201d' itself can be variously defined as the bag or sequence of tokens around a target word, either by linear distance or dependency path</a>
<a name="2">[2]</a> <a href="#2" id=2>In all experiments, the contextual variable is the observed US state (including DC), so that u'\ud835' u'\udc9e'</a>
<a name="3">[3]</a> <a href="#3" id=3>As a quantitative measure of our model u'\u2019' s performance, we consider the task of judging semantic similarity among words</a>
</body>
</html>