<html>
<head>
<title>P14-1020.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>As expected, binary rules account for the vast majority of the time in the unpruned Viterbi case, but much less time in the pruned case, with the total time taken for binary rules in the coarse and fine passes taking about 1/5 of the time taken by binaries in the unpruned version</a>
<a name="1">[1]</a> <a href="#1" id=1>Their system uses a grammar based on the Berkeley parser [ 9 ] (which is particularly amenable to GPU processing), u'\u201c' compiling u'\u201d' the grammar into a sequence of GPU kernels that are applied densely to every item in the parse chart</a>
<a name="2">[2]</a> <a href="#2" id=2>Figure 1 shows an overview of the approach we first parse densely with a coarse grammar and then parse sparsely with the fine grammar, skipping symbols that the coarse pass deemed sufficiently unlikely</a>
<a name="3">[3]</a> <a href="#3" id=3>Because the grammar used in the coarse pass is a projection of the grammar used in the fine pass, these coarse scores correlate reasonably closely with the probabilities computed in the fine pass</a>
<a name="4">[4]</a> <a href="#4" id=4>The coarse to fine pruning approach of Petrov and Klein ( 2007 ) employs an X-bar grammar as its first pruning phase, but there is no reason why we cannot begin with a more complex grammar for our</a>
</body>
</html>