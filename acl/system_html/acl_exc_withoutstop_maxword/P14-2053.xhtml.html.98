<html>
<head>
<title>P14-2053.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>From each system, 100 questions were randomly selected, making sure that the LPN W questions did not include questions generated from domain-specific templates such as</a>
<a name="1">[1]</a> <a href="#1" id=1>The file has 93 sentences and our system generated 184 questions; the LPN W system generated roughly 4 times as many questions</a>
<a name="2">[2]</a> <a href="#2" id=2>The Heilman and Smith system, as they describe it, takes an over-generate and rank approach</a>
<a name="3">[3]</a> <a href="#3" id=3>Since current state-of-the-art systems do not deal well with relative and possessive pronouns, this will continue to be a limitation of natural language generation systems for the time being</a>
<a name="4">[4]</a> <a href="#4" id=4>Some patterns look for modals and so can handle future tense</a>
<a name="5">[5]</a> <a href="#5" id=5>Not having coreference resolution leads to vague questions, some of which can be filtered as discussed previously</a>
<a name="6">[6]</a> <a href="#6" id=6>This task utilized a file (Biology the body) with 56 source sentences from which our system generated 102 questions</a>
<a name="7">[7]</a> <a href="#7" id=7>We compared our system to the H S and LPN W systems because they produce questions that are the most similar to ours, and for the same purpose reading comprehension reinforcement</a>
<a name="8">[8]</a> <a href="#8" id=8>Interestingly, our system again achieved a 44% reduction in the</a>
</body>
</html>