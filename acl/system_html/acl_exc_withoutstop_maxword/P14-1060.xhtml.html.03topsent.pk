(lp0
VThe above table shows some of the top results for the unary token u'\u005cu2018' elephant u'\u005cu2019' by frequency, and frequent unary and non-unary motifs for the motif u'\u005cu2018' white elephant u'\u005cu2019' retrieved by the segmentation model
p1
aVConsider the following sentences tagged by the segmentation model, that would correspond to different representations of the token u'\u005cu2018' remains u'\u005cu2019' once as a standalone motif, and once as part of an encompassing bigram motif ( u'\u005cu2018' remains classified u'\u005cu2019'
p2
aVWe describe learning of the model parameters with fully annotated training data, as well as an approach for learning motif segmentation that requires only partial supervision
p3
aVWe present a framework for extending distributional semantics to learn semantic representations of both words and phrases in terms of recurrent motifs, rather than arbitrary word tokens
p4
aVIn particular, consider the second example, where the model picks u'\u005cu2018' white elephant u'\u005cu2019' as a motif
p5
aVWe first quantitatively and qualitatively analyze the performance of the segmentation model, and then evaluate the distributional motif representations learnt by the model through two downstream applications
p6
aVOur hypothesis is that a model that can even weakly identify recurrent motifs such as u'\u005cu2018' water table u'\u005cu2019' or u'\u005cu2018' breaking a fall u'\u005cu2019' would be helpful in building more effective semantic representations
p7
aVWe observe that this model has a very high precision (since many token sequences marked as motifs would recur in similar contexts, and would thus have the same motif boundaries
p8
aVFor this task, the motif based distributional embeddings vastly outperform a conventional distributional model (DSM) based on token distributions, as well as additive (AVM) and multiplicative (MVM) models of vector compositionality, as proposed by Lapata et al
p9
aVWith such neighbourhood contexts, the distributional paradigm posits that semantic similarity between a pair of motifs can be given by
p10
a.