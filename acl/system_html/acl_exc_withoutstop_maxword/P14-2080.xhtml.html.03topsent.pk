(lp0
VLinLearn denotes model combination by overloading the vector representation of queries u'\u005cud835' u'\u005cudc2a' and documents u'\u005cud835' u'\u005cudc1d' in the VW linear learner by incorporating arbitrary ranking models as dense features
p1
aV2013 ) by presenting an alternative learning-to-rank approach that can be used for supervised model combination to integrate dense and sparse features, and by evaluating both approaches on cross-lingual retrieval for patents and Wikipedia
p2
aVDK denotes VW training of a model that represents queries u'\u005cud835' u'\u005cudc2a' and documents u'\u005cud835' u'\u005cudc1d' by dense domain-knowledge features instead of by sparse word-based vectors
p3
aVWe show that for both domains, patents and Wikipedia, jointly learning bilingual sparse word associations and dense knowledge-based similarities
p4
a.