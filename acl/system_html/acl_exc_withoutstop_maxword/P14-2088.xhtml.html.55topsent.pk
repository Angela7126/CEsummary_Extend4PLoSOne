(lp0
VAs we will show, substantial efficiency improvements can be obtained by designing domain adaptation methods for learning in structured feature spaces
p1
aVIn structural correspondence learning (SCL), the induced representation is based on the task of predicting the presence of pivot features
p2
aVFor each feature template, there are thousands of binary features
p3
aVThen we present three versions of marginalized denoising autoencoders (mDA) by incorporating different types of noise, including two new noising processes that are designed for structured features
p4
aVBoth structure-aware domain adaptation algorithms perform as well as standard dropout u'\u005cu2014' and better than the well-known structural correspondence learning (SCL) algorithm [ 1 ] u'\u005cu2014' but structured dropout is more than an order-of-magnitude faster
p5
aVConsequently, many approaches rely on
p6
a.