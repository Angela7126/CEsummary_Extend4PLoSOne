(lp0
VAs strength is inherently relative, it is natural to look at revisions that change statement strength, which we refer to as u'\u005cu201c' strength changes u'\u005cu201d'
p1
aVMany differences between these versions constitute a source of valid and motivated strength differences, as can be seen from the sentential revisions in Table 1
p2
aVFor pair 1, while one turker pointed out the decline in number of experiments, most turkers simply labeled it as stronger because it was more specific u'\u005cu201c' Specific u'\u005cu201d' turned out to be a common reason used in the comments, even though we said in the instructions that only additional justification and evidence matter
p3
aVParticipants were then asked to choose labels and write mandatory comments for 50 pairs
p4
aVThe main contribution of this work is to provide the first large-scale corpus of sentence-level revisions for studying a broad range of variations in statement strength
p5
aV2 2 http://sinosphere.blogs.nytimes.com/2014/03/03/u-n-security-council-condemns-terrorist-attack-in-kunming/ In particular, regarding the statement by the US embassy that referred to this incident as the u'\u005cu201c' terrible and senseless act of violence in Kunming u'\u005cu201d' , a Weibo user posted u'\u005cu201c' If you say that the Kunming attack is a u'\u005cu2018' terrible and senseless act of violence u'\u005cu2019' , then the 9/11 attack can be called a u'\u005cu2018' regrettable traffic incident u'\u005cu201d' u'\u005cu2019'
p6
aVPublic datasets of science communication are available, such as the ACL Anthology, 5 5 http://aclweb.org/anthology/ collections of NIPS papers, 6 6 http://nips.djvuzone.org/txt.html and so on
p7
aVIt may initially seem surprising to have annotations of technical statements not done by domain experts; we did this intentionally because it is common to communicate unfamiliar topics to the public in political and science communication (we comment on non-expert rationales later
p8
aVBut it is clear that the majority of changes are rewrites; thus revisions on the arXiv indeed provide a great source for potential strength differences
p9
aVBut the lack of edit histories or revisions makes them not immediately suitable for studying strength differences
p10
aVFor instance, the majority labeled pair 2 as u'\u005cu201c' stronger u'\u005cu201d'
p11
aVIn order to align the first version and the final version of the same paper, we first did macro alignment of paper sections based on section titles
p12
aVTo create the pool of pairs for labeling, we randomly sampled 1000 pairs and then removed pairs that we thought were processing errors
p13
aVSince the strength and scope of an argument can be a crucial factor in its success, it is important to understand the effects of statement strength in communication
p14
aVPair 1 makes the contribution seem more impressive by replacing u'\u005cu201c' studied u'\u005cu201d' with u'\u005cu201c' proposed u'\u005cu201d'
p15
aVOne might initially think that typo fixes represent a large proportion of revisions, but this is not correct, as shown in Figure 4
p16
aV1 1 http://en.wikipedia.org/wiki/2014_Kunming_attack In the aftermath, Chinese media accused Western media of u'\u005cu201c' soft-pedaling the attack and failing to state clearly that it was an act of terrorism u'\u005cu201d'
p17
aVAccording to the comments written by participants, we believe that they did the labeling in good faith
p18
aVThe instructions included 8 pairs as examples and 10 pairs to label as a training exercise
p19
aV9 9 This differs from the number in Section 1 because articles may not have the tex source available, or the differences between versions may be in non-textual content
p20
aVThis could be because a single author enjoys greater freedom and has stronger motivation to make changes, or because multiple authors tend to submit a more polished initial version
p21
aVSince it is likely that a new version adds or deletes a large sequence of sentences, we did not impose a skip penalty
p22
aVDeletions represent a substantial fraction, especially in the middle section of a paper
p23
aV8 8 We did not allow cross matching (i.e.,, i u'\u005cu2192' j - 1 , i - 1 u'\u005cu2192' j ), since we thought matching this case as ( i - 1 , i ) u'\u005cu2192' j or i u'\u005cu2192' ( j , j - 1 ) can provide context for annotation purposes
p24
aV10 10 These decisions were made based on the results and feedback that we got from graduate students in an initial labeling
p25
aVFirst, participants tend to take details as evidence even when these details are not germane to the statement
p26
aVThese datasets are useful for understanding the progress of disciplines or the evolution of topics
p27
aVThe comments indicate features that humans think salient
p28
aVSince the arXiv started in 1991, it has become u'\u005cu201c' the standard repository for new papers in mathematics, physics, statistics, computer science, biology, and other disciplines u'\u005cu201d' []
p29
aVBut in S2 for that pair, the result holds for strictly fewer possible worlds
p30
aVThough careful and repeated revisions are presumably ubiquitous in politics, legal systems, and journalism, it is not clear how to collect them; on the other hand, revisions to research papers may be more accessible, and many researchers spend significant time on editing to convey the right message regarding the strength of a project u'\u005cu2019' s contributions, novelty, and limitations
p31
aVIndeed, statement strength in science communication matters to writers understating contributions can affect whether people recognize the true importance of the work; at the same time, overclaiming can cause papers to be rejected
p32
aVWe believe that this corpus of sentence-level revisions, together with the labels and comments from participants, can provide insights into better ways to approach this problem and help further understand strength of statements
p33
aVThe participants u'\u005cu2019' comments may further shed light on science communication and point to better ways to define and understand strength differences
p34
aVBut in some cases, the labels differed from our expectations, indicating that the general public can interpret the strength of scientific statements differently from researchers
p35
aVOur observations regarding the annotation results raise questions regarding what is a generalizable way to define strength differences, how to use the labels that we collected, and how to collect labels in the future
p36
aVWe focused on matched sentences from abstracts and introductions to maximize the proportion of strength differences (as opposed to factual/no strength changes
p37
aVPair 5 is an interesting case that shows the complexity of this problem on the one hand, S2 claims that something is u'\u005cu201c' inefficient u'\u005cu201d' , which is an absolute statement, compared to u'\u005cu201c' efficiency loss u'\u005cu201d' in S1, where the possibility of efficiency still exists; on the other hand, S1 employs an active tone that emphasizes a causal relationship
p38
aVThe ultimate goal of our study is to understand the effects of statement strength on the public, which can lead to various applications in public communication
p39
aVInstead of cosine similarity, we used an idf-weighted longest-common-subsequence algorithm to define the similarity between two sentences, because changes in word ordering can also be interesting
p40
aVWe required pairs to have similarity score larger than 0.5 in our labeling task to make pairs more comparable
p41
aVA first step towards addressing this question is to be able to distinguish between strong and weak statements
p42
aVIn this section, we describe how we tried to define strength differences, compiled labeling instructions, and gathered labels using Amazon Mechanical Turk
p43
aVBut none of the categories of Wikipedia revisions previously examined [] relate to statement strength
p44
aVWe were excited about the labels from these participants despite the apparent difficulty of the task, we found that many labels for the 386 pairs were reasonable
p45
aVFor pair 3, the majority thought that u'\u005cu201c' vectors u'\u005cu201d' sounds more impressive than u'\u005cu201c' images u'\u005cu201d' ; for pair 4, the majority considered u'\u005cu201c' adapt u'\u005cu201d' stronger than u'\u005cu201c' discover u'\u005cu201d'
p46
aVHedging, which can lead to strength differences, has received some attention in the study of science communication []
p47
aVRevisions on Wikipedia have been shown useful for various applications, including spelling correction [] , sentence compression [] , text simplification [] , paraphrasing [] , and textual entailment []
p48
aVWe took a conservative approach and only considered pairs with an absolute majority label, i.e.,, at least 5 of 9 labelers chose the same label
p49
aVOn this subset of pairs, Fleiss u'\u005cu2019' Kappa is 0.322, and 74.4% of pairs were strength changes
p50
aVWith the increasing popularity of e-print services such as the arXiv 4 4 http://arxiv.org/ , strength changes in scientific papers are becoming more readily available
p51
aVPair 4 shows an insertion of hedging, a relatively well-known type of strength reduction
p52
aVTypo all sequences in a pair of matched sentences are typos, where a sequence-level typo is one where the edit distance between the matched sequences is less than three
p53
aVThis issue is common when communicating new topics to the public not only in science communication but also in politics and other scenarios
p54
aVPair 2 downgrades u'\u005cu201c' human communication activity u'\u005cu201d' to u'\u005cu201c' mobile phone communication u'\u005cu201d'
p55
aVFigure 4 shows that the Math subarchive makes the largest number of changes
p56
aVIndeed, sometimes heated debates can arise around the choice of statement strength
p57
aVBut it should be said that there are cases that labelers interpreted logically, e.g.,, u'\u005cu201c' compelling evidence u'\u005cu201d' subsumes u'\u005cu201c' compelling experimental evidence u'\u005cu201d'
p58
aV7 7 http://openreview.net Records from open reviewing can provide additional insights into the revision process once enough data is collected
p59
aVWe collected 9 labels each for 500 pairs
p60
aVWe first extracted the textual content from papers that have multiple versions of tex source files
p61
aVHedge detection was also used to understand scientific framing in debates over genetically-modified organisms in food []
p62
aVIn order to study statement strength, reliable strength-difference labels are needed
p63
aVAn intriguing observation is that many researchers submit multiple versions of the same paper on arXiv
p64
aVThis echoes the finding in that the collaborative writing process differs considerably from individual writing
p65
aVBut in the end, we focused on labeling very similar pairs
p66
aVBoth of the above cases share the property that they seem to be correlated with a tendency to judge lengthier statements as stronger
p67
aVIt is important for authors and speakers to find the appropriate u'\u005cu201c' pitch u'\u005cu201d' to convey a desired message to the public
p68
aVWe collected labels for a subset of these revisions
p69
aVFurther, Figure 7 shows the effect of the number of authors
p70
aVNumber of changes vs sections u'\u005cu201c' middle u'\u005cu201d' refers to the sections between introduction and conclusion
p71
aVTop 5 categories in number of changes over the number of sentences
p72
aVThis work was supported in part by NSF grant IIS-0910664 and a Google Research Grant
p73
aVIt may partly explain miscommunications and misinterpretations of scientific studies in journalism
p74
aVThere are 386 pairs that satisfy this requirement (93 weaker, 194 stronger, 99 no change
p75
aVAfter all, the objective of editing on Wikipedia is to present neutral and objective articles
p76
aVFor instance, on March 1, 2014, an attack at Kunming u'\u005cu2019' s railway station left 29 people dead and more than 140 others injured
p77
aVAlso, more than 25% of the first versions are changed, which again shows that substantive edits are being made in these resubmissions
p78
aVThen, for micro alignment of sentences, we employed a dynamic programming algorithm similar to that of
p79
aVWe obtained 108K pairs that satisfy the above conditions, available at http://chenhaot.com/pages/statement-strength.html
p80
aVThis echoes the finding in that even unrelated details influenced judgments of guilt
p81
aVAnother interesting case that does not share this characteristic is that participants can have a different understanding of domain-specific terms
p82
aVIt is interesting that both in terms of sheer number and percentage, single-authored papers have the most changes
p83
aVIn terms of changes per sentence (Figure 4 ), statistics and quantitative studies are the top subareas
p84
aVDeletion we cannot find a match in the final version
p85
aVStronger, Weaker, No Strength Change, I can u'\u005cu2019' t tell
p86
aVGiven the possibility of all kinds of disagreement, the fair level of agreement (Fleiss u'\u005cu2019' Kappa) among our annotators was decent
p87
aVTable 3 shows some representative examples
p88
aVSection titles were not included in the final texts but are used in alignment
p89
aVOur main dataset was constructed from all papers submitted in 2011 on the arXiv
p90
aVThis example is striking but not an isolated case, for settings in which one party is trying to convince another are pervasive; scenarios range from court trials to conference submissions
p91
aVPair 3 removes u'\u005cu201c' significantly u'\u005cu201d' and the emphasis on u'\u005cu201c' same privacy guarantees u'\u005cu201d'
p92
aVThe CoNLL 2010 Shared Task was devoted to hedge detection []
p93
aVSecond, participants interpret constraints/conditions not in strictly logical ways, seeming to care little about scope at times
p94
aVOne interesting direction that this enables is a potentially new kind of learning problem
p95
aVWe categorize sentential revisions into the following three types
p96
aVFormally, the similarity score between sentence i and sentence j is defined as
p97
aVThis is consistent with the mathematics community u'\u005cu2019' s custom of using the arXiv to get findings out early
p98
aVWe use the following set of labels
p99
aVIs it possible to automatically learn new features from the comments
p100
aVFor instance, among the 70K papers submitted in 2011, almost 40% (27.7K) have multiple versions
p101
aVIn the end, there are 23K papers where the first version was different from the last version
p102
aVTop 5 categories in number of changes
p103
aVRecently, there have been experiments with open peer review
p104
aVYang and the anonymous annotators for all their labeling help
p105
aVHowever, in some cases, the labels were counter-intuitive
p106
aVAmong the 500 pairs, Fleiss u'\u005cu2019' Kappa was 0.242, which indicates fair agreement []
p107
aVRewrite matched sentences that are not typos
p108
aVwhere S i and S j refer to sentence i and sentence j
p109
aVWe also replaced all math environments with u'\u005cu201c' [MATH] u'\u005cu201d'
p110
aVWe used Amazon Mechanical Turk
p111
aVWe set the mismatch penalty to 0.1
p112
aVGinsparg for providing data; and S
p113
aVCallison-Burch, and the reviewers for helpful comments; P
p114
aVConsidering all the possible disagreement, this result was acceptable
p115
aVAll mathematical environments were ignored
p116
aVThis type is the focus of this study
p117
aVTable 2 gives our definitions
p118
aVThis decision had little effect
p119
aVBaldridge, J
p120
aVXie, B
p121
aVWang, W
p122
aVSwaminathan, L
p123
aVSipos, A
p124
aVSharma, R
p125
aVRoy, A
p126
aVReitblatt, S
p127
aVRaman, M
p128
aVPark, K
p129
aVOtt, J
p130
aVLenz, M
p131
aVLee, I
p132
aVKozyri, M
p133
aVChen, E
p134
aV11 11 http://www.phdcomics.com/comics/archive.php?comicid=1174
p135
aVBoyd-Graber, C
p136
aV3 3 http://www.huffingtonpost.co.uk/2014/03/03/china-kunming-911_n_4888748.html
p137
aVWe thank J
p138
a.