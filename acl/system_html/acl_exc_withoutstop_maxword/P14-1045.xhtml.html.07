<html>
<head>
<title>P14-1045.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We used this dataset to set up a supervised classification experiment in order to automatically predict the relevance of a semantic link in a given discourse</a>
<a name="1">[1]</a> <a href="#1" id=1>We present the experiments we set up to automatically filter semantic relations in context, with various groups of features that take into account information from the corpus used to build the thesaurus and contextual information related to occurrences of semantic neighbours 3</a>
<a name="2">[2]</a> <a href="#2" id=2>The outcome of the contextual annotation presented above is a rather sizeable dataset of validated semantic links, and we showed these linguistic judgments to be reliable</a>
<a name="3">[3]</a> <a href="#3" id=3>A distributional thesaurus is a lexical network that lists semantic neighbours, computed from a corpus and a similarity measure between lexical items, which generally captures the similarity of contexts in which the items occur</a>
<a name="4">[4]</a> <a href="#4" id=4>For each pair neighbour a / neighbour b , we computed a set of features from Wikipedia (the corpus used to derive the distributional similarity</a>
<a name="5">[5]</a> <a href="#5" id=5>A distributional thesaurus includes a lot of u'\u201c' noise u'\u201d' from a semantic point of view, but also lists relevant lexical pairs that escape classical lexical relations such as synonymy or hypernymy</a>
<a name="6">[6]</a> <a href="#6" id=6>We hypothetize that evaluating and filtering semantic relations in texts where lexical items occur would help tasks that naturally make use of semantic similarity relations, but assessing this goes beyond the present work</a>
<a name="7">[7]</a> <a href="#7" id=7>To address class imbalance, two broad types of methods can be applied to help the model focus on the minority class</a>
<a name="8">[8]</a> <a href="#8" id=8>They can be divided in three groups, according to their origin they are computed from the whole corpus, gathered from the distributional resource, or extracted from the considered text which contains the semantic pair to be evaluated</a>
<a name="9">[9]</a> <a href="#9" id=9>Our task is to identify relevant similarities between lexical items, between all possible related pairs, and we want</a>
</body>
</html>