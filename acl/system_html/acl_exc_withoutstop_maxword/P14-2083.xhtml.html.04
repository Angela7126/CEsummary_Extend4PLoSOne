<html>
<head>
<title>P14-2083.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Lastly, we compare the disagreements of annotators on a French social media data set [] , which we mapped to the universal POS tag set</a>
<a name="1">[1]</a> <a href="#1" id=1>presents work on detecting linguistically hard cases in the context of word sense annotations, e.g.,, cases where expert annotators will disagree, as well as differentiating between underspecified, overspecified and metaphoric cases</a>
<a name="2">[2]</a> <a href="#2" id=2>Finally, use small samples of doubly-annotated POS data to estimate annotator reliability and show how those metrics can be implemented in the loss function when inducing POS taggers to reflect confidence we can put in annotations</a>
<a name="3">[3]</a> <a href="#3" id=3>In this study, we had between 2-10 individual annotators with degrees in linguistics annotate different kinds of English text with POS tags, e.g.,, newswire text (PTB WSJ Section 00), transcripts of spoken</a>
</body>
</html>