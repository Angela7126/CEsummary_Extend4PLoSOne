<html>
<head>
<title>P14-1124.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The spoken term detection task arises as a key subtask in applying NLP applications to spoken content</a>
<a name="1">[1]</a> <a href="#1" id=1>The BABEL task is modeled on the 2006 NIST Spoken Term Detection evaluation [] but focuses on limited resource conditions</a>
<a name="2">[2]</a> <a href="#2" id=2>If we had perfectly accurate ASR in the language of the corpus, term detection is reduced to an exact string matching task</a>
<a name="3">[3]</a> <a href="#3" id=3>In applying the burstiness quantity to term detection, we recall that the task requires us to locate a particular instance of a term, not estimate a count, hence the utility of N-gram language models predicting words in sequence</a>
<a name="4">[4]</a> <a href="#4" id=4>Although spoken term detection does not require the use of word-based automatic speech recognition (ASR), it is closely related</a>
<a name="5">[5]</a> <a href="#5" id=5>Spoken term detection converts the raw acoustics into time-marked keyword occurrences, which may subsequently be fed (e.g., as a bag-of-terms) to standard NLP algorithms</a>
<a name="6">[6]</a> <a href="#6" id=6>In general, we can think of using word repetitions to re-score term detection as applying a limited form of adaptive or cache language model []</a>
<a name="7">[7]</a> <a href="#7" id=7>Tasks like topic identification and named-entity detection require transforming a continuous acoustic signal into a stream of discrete tokens</a>
</body>
</html>