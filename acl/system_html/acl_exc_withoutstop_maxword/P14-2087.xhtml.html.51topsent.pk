(lp0
VSpecifically, highly similar, fine-grained sense candidates apparently share more hypernyms in the fine-grained case than in the coarse-grained case; adding to the generality of hypernyms (both semantic and distributional), we postulate that their probability in the NBM is uniformly inflated among many sense candidates, and hence they decrease in distinguishability
p1
aVBy using only glosses, the proposed model already shows statistically significant improvement over the basic Lesk algorithm (92.4% and 140.5% relative improvement in Senseval-2 coarse- and fine-grained tracks, respectively
p2
aVThese systems compared favourably to existing methods in WSD performance, although by using sense frequency information, they are essentially supervised methods
p3
aVModel performance is evaluated in terms of WSD accuracy using Equation ( 2 ) as the scoring function
p4
aVWe further hypothesize that, beyond sheer numbers, synonyms and hyponyms offer stronger semantic specification that helps distinguish the senses of
p5
a.