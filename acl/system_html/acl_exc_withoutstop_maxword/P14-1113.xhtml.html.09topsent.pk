(lp0
VThat is, all word pairs ( x , y ) in the training data are first clustered into several groups, where word pairs in each group are expected to exhibit similar hypernym u'\u005cu2013' hyponym relations
p1
aVTo verify this hypothesis, we compute the embedding offsets over all hypernym u'\u005cu2013' hyponym word pairs in our training data and visualize them
p2
aVWe obtain 15,247 word pairs of hypernym u'\u005cu2013' hyponym relations (9,288 for direct relations and 5,959 for indirect relations
p3
aVFurthermore, we propose a piecewise linear projection method based on relation clustering to better model hypernym u'\u005cu2013' hyponym relations (Section 3.3.2
p4
aVOur method based on word embeddings can discover more hypernym u'\u005cu2013' hyponym relations than the previous methods can
p5
aVAs a preliminary experiment, we compute the embedding offsets between some randomly sampled hypernym u'\u005cu2013' hyponym word pairs and measure their similarities
p6
aVA uniform linear projection may still be under-representative for fitting all of the hypernym u'\u005cu2013' hyponym word pairs, because the relations are rather diverse, as shown in Figure 2
p7
aVThen we elaborate on our proposed method composed of three major steps, namely, word embedding training, projection learning, and hypernym u'\u005cu2013' hyponym
p8
a.