<html>
<head>
<title>P14-2084.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We show that the misclassifications (with respect to whether comments contain irony or not) made by a standard text classification model significantly correlate with those comments for which human annotators requested additional context</a>
<a name="1">[1]</a> <a href="#1" id=1>Reddit is a good corpus for the irony detection task in part because it provides a natural practical realization of the otherwise ill-defined context for comments</a>
<a name="2">[2]</a> <a href="#2" id=2>We also introduce a new annotated corpus that will allow researchers to build models that augment existing approaches to irony detection with contextual information regarding the text (utterance) to be classified and its author</a>
<a name="3">[3]</a> <a href="#3" id=3>In these works, verbal irony detection has mostly been treated as a standard text classification task, though with some innovative approaches specific to detecting irony</a>
<a name="4">[4]</a> <a href="#4" id=4>Our principal argument is that simple bag-of-words based text classification models u'\u2013' which, when coupled with sufficient data, have proven to be extremely successful for many natural language processing tasks [] u'\u2013' are inadequate for irony detection</a>
<a name="5">[5]</a> <a href="#5" id=5>Put another way, the model makes mistakes on those comments for which annotators requested</a>
</body>
</html>