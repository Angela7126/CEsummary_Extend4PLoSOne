(lp0
VAttempts on topic-based translation modeling include topic-specific lexicon translation models [ 37 , 38 ] , topic similarity models for synchronous rules [ 34 ] , and document-level translation with topic coherence [ 36 ]
p1
aVBy measuring the similarity between the source texts and bilingual translation rules, the SMT decoder is able to encourage topic relevant translation candidates and penalize topic irrelevant candidates
p2
aVTo incorporate topic representations as translation knowledge into SMT, our neural network based approach directly optimizes similarities between the source language and target language in a compact topic space
p3
aVIn this section, we explain our neural network based topic similarity model in detail, as well as how to incorporate the topic similarity features into SMT decoding procedure
p4
aVIn this way, the topic of a sentence can be inferred with document-level information using off-the-shelf topic modeling toolkits such as Latent Dirichlet Allocation (LDA) [ 3 ] or Hidden Topic Markov Model (HTMM) [ 14 ]
p5
aVThe learned neural networks are used to obtain sentence topic representations, which will be further leveraged to infer topic representations of bilingual translation rules
p6
aVSince the vectors from DAE are trained using information from monolingual training data independently, these vectors may be inadequate to measure bilingual topic similarity due to their different topic spaces
p7
aVFollowing this work,
p8
a.