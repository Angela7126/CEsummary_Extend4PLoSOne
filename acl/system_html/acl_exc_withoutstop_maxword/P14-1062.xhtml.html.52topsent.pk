(lp0
VIncreasing m or stacking multiple convolutional layers of the narrow type makes the range of the feature detectors larger; at the same time it also exacerbates the neglect of the margins of the sentence and increases the minimum size s of the input sentence required by the convolution
p1
aVIn the network the width of a feature map at an intermediate layer varies depending on the length of the input sentence; the resulting architecture is the Dynamic Convolutional Neural Network
p2
aVThe difference in performance between the DCNN and the NBoW further suggests that the ability of the DCNN to both capture features based on long n -grams and to hierarchically combine these features is highly beneficial
p3
aVBesides comprising powerful classifiers as part of their architecture, neural sentence models can be used to condition
p4
a.