<html>
<head>
<title>P14-2044.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The simplest model, ddCRP uniform , uses a uniform prior that sets the distance between any two words equal to one</a>
<a name="1">[1]</a> <a href="#1" id=1>1) the distributional similarity between all words in the proposed partition containing w 1 and w 2 , which is encoded using a Gaussian likelihood function over the word embeddings; and 2) the morphological similarity between w 1 and w 2 , which acts as a prior distribution on the induced clustering</a>
<a name="2">[2]</a> <a href="#2" id=2>We can create an infinite mixture model by combining the ddCRP prior with a likelihood function defining the probability of the data given the cluster assignments</a>
<a name="3">[3]</a> <a href="#3" id=3>The final model, ddCRP exp , adds the prior exponentiation</a>
<a name="4">[4]</a> <a href="#4" id=4>In contrast, we use pairwise morphological similarity as a prior in a non-parametric clustering model</a>
<a name="5">[5]</a> <a href="#5" id=5>Exponentiating the prior reduces the number of induced clusters and</a>
</body>
</html>