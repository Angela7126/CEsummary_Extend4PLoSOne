(lp0
VWe train two CNN semantic models from sets of pattern u'\u005cu2013' relation and mention u'\u005cu2013' entity pairs, respectively
p1
aVFollowing [ 8 ] , for every pattern, the corresponding relation is treated as a positive example and 100 randomly selected other relations are used as negative examples
p2
aV2013 ) , we train two semantic similarity models one links a mention from the question to an entity in the KB and the other maps a relation pattern to a relation
p3
aVAn early example of this research is the semantic parser for answering geography-related questions, learned using inductive logic programming [ 18 ]
p4
aVModel training is done by maximizing the log-posteriori using stochastic gradient descent
p5
aVThe posterior probability of the positive relation given the pattern is computed based on the cosine scores using softmax
p6
aVData were tokenized by replacing hyphens with blank spaces
p7
aVThe semantic relevance score between a pattern Q and a relation R is defined as the cosine score of their semantic vectors y Q and y R
p8
aVGiven a pattern and a relation, we compute their relevance score by measuring the cosine similarity between their semantic vectors
p9
aVIf the mapping of the relation and entity in the question
p10
a.