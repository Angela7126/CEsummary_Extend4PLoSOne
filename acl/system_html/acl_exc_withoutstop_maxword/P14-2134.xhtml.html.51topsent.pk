(lp0
VThe final prediction over the output vocabulary is then found by passing this resulting vector through the softmax function u'\u005cud835' u'\u005cudc90' = softmax u'\u005cu2062' ( X u'\u005cu2062' u'\u005cud835' u'\u005cudc89' ) , giving a vector in the
p1
aVA joint model has three a priori advantages over independent models i) sharing data across variable values encourages representations across those values to be similar; e.g.,, while city may be closer to Boston in Massachusetts and Chicago in Illinois, in both places it still generally connotes a municipality ; (ii) such sharing can mitigate data sparseness for less-witnessed areas; and (iii) with a joint model, all representations are guaranteed to be in the same vector space and can therefore be compared to each other; with individual models (each with different initializations), word vectors across different states may not be directly compared
p2
aVThe model we introduce is grounded in the distributional hypothesis [] , that two words are similar by appearing in the same kinds of contexts (where u'\u005cu201c' context u'\u005cu201d' itself can be variously defined as the bag or sequence of tokens around a target word, either by linear distance or dependency path
p3
aVIn
p4
a.