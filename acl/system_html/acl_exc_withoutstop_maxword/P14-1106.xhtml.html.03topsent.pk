(lp0
VTable 1 shows the features used in syntactic leftmost and rightmost reordering models
p1
aVFor the semantic reordering models, we also add two new features into the log-linear translation model
p2
aVGiven the two adjacent roles u'\u005cud835' u'\u005cudc45' i and u'\u005cud835' u'\u005cudc45' i + 1 in a PAS pas , Table 2 shows the features that are used in the semantic leftmost and rightmost reordering models
p3
aVTo train the syntactic and semantic reordering models, we use a gold alignment dataset
p4
aVThe syntactic reordering models outperform the semantic reordering models on both the baseline and MR08 systems
p5
aVFor models with syntactic reordering, we add two new features (i.e.,, one for the leftmost reordering model and the other for the rightmost reordering model) into the log-linear translation model in Eq
p6
aVAnd we again see that the improvement achieved by semantic reordering models is limited in the presence of the syntactic reordering models
p7
aVFinally, we integrate both the syntactic and semantic reordering models into the final system
p8
aVThe syntactic reordering models outperform the semantic reordering models, and the gain achieved by the semantic reordering models is limited in the presence of the MR08 syntactic features
p9
aVFor the
p10
a.