<html>
<head>
<title>P14-1124.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We consider term detection rather than the transcription task in considering how to exploit topic context, because in evaluating the retrieval of certain key terms we need not focus on improving the entire word sequence</a>
<a name="1">[1]</a> <a href="#1" id=1>In applying the burstiness quantity to term detection, we recall that the task requires us to locate a particular instance of a term, not estimate a count, hence the utility of N-gram language models predicting words in sequence</a>
<a name="2">[2]</a> <a href="#2" id=2>The BABEL task is modeled on the 2006 NIST Spoken Term Detection evaluation [] but focuses on limited resource conditions</a>
<a name="3">[3]</a> <a href="#3" id=3>In general, we can think of using word repetitions to re-score term detection as applying a limited form of adaptive or cache language model []</a>
<a name="4">[4]</a> <a href="#4" id=4>The spoken term detection task arises as a key subtask in applying NLP applications to spoken content</a>
<a name="5">[5]</a> <a href="#5" id=5>As it turns out this u'\u2018' burstiness u'\u2019' of words within documents, as the term is defined by Church and Gale in their work on Poisson mixtures (1995), provides a more reliable framework for successfully exploiting document context</a>
<a name="6">[6]</a> <a href="#6" id=6>We illustrate this variability by looking at how consistent word co-occurrences</a>
</body>
</html>