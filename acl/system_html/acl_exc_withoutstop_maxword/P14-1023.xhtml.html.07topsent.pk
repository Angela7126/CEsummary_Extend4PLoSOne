(lp0
VThe selected predict model is the fourth best model in Table 4
p1
aVThe count model performance is severely affected by this unlucky choice (2-word window, Local Mutual Information, NMF, 400 dimensions, mean performance rank
p2
aVThe second block reports results obtained with single count and predict models that are best in terms of average performance rank across tasks (these are the models on the top rows of tables 3 and 4 , respectively
p3
aVWe see that, for both approaches, performance is not seriously affected by using the single best setup rather than task-specific settings, except for a considerable drop in performance for the best predict model on esslli (due to the small size of this data set?), and an even more dramatic drop of the count model on ansem
p4
aVTop accuracy on the entire data set (an) and on the semantic subset (ansem) was reached by Mikolov et al
p5
aVSpecifically, we pick the models that work best on the small rg set, and report their performance on all tasks (we obtained similar results by picking other tuning sets
p6
aVThe first block of the table reports the maximum per-task performance (across all considered parameter settings) for count and predict vectors
p7
aVInstead, in a word-similarity-in-context task (Table 5), the best predict model outperforms the count model, albeit not by a large margin
p8
aVMikolov et al
p9
aVMikolov et al
p10
aVThe selected count model is the third best overall model of its class as reported in Table 3
p11
aVWhile all the previous data sets are relatively standard in the DSM field to test traditional count models, our last benchmark was introduced in Mikolov et al
p12
aV2013d ) compare their predict models to u'\u005cu201c' Latent Semantic Analysis u'\u005cu201d' (LSA) count vectors on syntactic and semantic analogy tasks, finding that the predict models are highly superior
p13
aVThe success of the predict models cannot be blamed on poor performance of the count models
p14
aVInterestingly, count vectors achieve performance comparable to that of predict vectors only on the selectional preference tasks
p15
aVFinally, Mikolov et al
p16
aV51) into perspective, its performance is more than 10% below the best count model only for the an and ansem tasks, and actually higher than it in 3 cases (note how on esslli the worst predict models performs much better than the best one, confirming our suspicion about the brittleness of this small data set
p17
aV2013a ) specifically to test predict models
p18
aVCurrent state of the art was reached by the window-based count model of Baroni and Lenci ( 2010 )
p19
aVThe mcrae set [ 31 ] consists of 100 noun u'\u005cu2013' verb pairs, with top performance reached by the DepDM system of Baroni and Lenci ( 2010 ) , a count DSM relying on syntactic information
p20
aV2013a ) pick the nearest neighbour among vectors for 1M words, Mikolov et al
p21
aVBesides the fact that this would not explain the near-state-of-the-art performance of the predict vectors, the count model results are actually quite good in absolute terms
p22
aVThe
p23
a.