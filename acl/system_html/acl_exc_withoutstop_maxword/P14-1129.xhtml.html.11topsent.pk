(lp0
VAdditionally, on top of a simpler decoder equivalent to Chiang u'\u005cu2019' s [ 5 ] original Hiero implementation, our NNJM features are able to produce an improvement of +6.3 BLEU u'\u005cu2013' as much as all of the other features in our strong baseline system combined
p1
aVWe also present a novel technique for training the neural network to be self-normalized , which avoids the costly step of posteriorizing over the entire vocabulary in decoding
p2
aVHowever, we have demonstrated that we can obtain 50%-80% of the total improvement with only one model (S2T/L2R NNJM), and 70%-90% with only two models (S2T/L2R NNJM + S2T NNLTM
p3
aVSpecifically, if unaligned target word t is on the right edge of an arc that covers source span [ s i , s j ] , we simply say that t is affiliated with source word s j
p4
aVThe decoding cost is based on a measurement of u'\u005cu223c' 1200 unique NNJM lookups per source word for our Arabic-English system
p5
aVTo do this, we first say that each
p6
a.