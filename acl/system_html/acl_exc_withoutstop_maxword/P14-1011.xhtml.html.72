<html>
<head>
<title>P14-1011.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In addition to the cross-lingual applications, we believe the BRAE model can be applied in many monolingual NLP tasks which depend on good phrase representations or semantic similarity between phrases, such as named entity recognition, parsing, textual entailment, question answering and paraphrase detection</a>
<a name="1">[1]</a> <a href="#1" id=1>Therefore, in order to successfully apply DNN to model the whole translation process, such as modelling the decoding process, learning compact vector representations for the basic phrasal translation units is the essential and fundamental work</a>
<a name="2">[2]</a> <a href="#2" id=2>Several researchers extend the original RAEs to a semi-supervised setting so that the induced phrase embedding can predict a target label, such as polarity in sentiment analysis [ 23 ] , syntactic category in parsing [ 21 ] and phrase reordering pattern in SMT [ 16 ]</a>
<a name="3">[3]</a> <a href="#3" id=3>Recently, statistical machine translation (SMT) community has seen a strong interest in adapting and applying DNN to many tasks, such as word alignment [ 29 ] , translation confidence estimation [ 19 , 18 , 31 ] , phrase reordering prediction [ 16 ] , translation modelling [ 1 , 12 ] and language modelling [ 7 , 26 ]</a>
<a name="4">[4]</a> <a href="#4" id=4>Due to the powerful capacity of feature learning and representation, Deep (multi-layer) Neural Networks (DNN) have achieved a great success in speech and image processing [ 13</a>
</body>
</html>