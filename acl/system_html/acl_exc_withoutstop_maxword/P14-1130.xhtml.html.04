<html>
<head>
<title>P14-1130.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In this way, our model is able to capture a wide range of information including the auxiliary features without having uncontrolled feature explosion, while still having the full accessibility to the manually engineered features that are proven useful</a>
<a name="1">[1]</a> <a href="#1" id=1>These feature selection methods are particularly promising in parsing scenarios where the optimal feature set is likely to be a small subset of the original set of candidate features</a>
<a name="2">[2]</a> <a href="#2" id=2>Our parameters are divided into a sparse set corresponding to manually chosen MST or Turbo parser features and a larger set governed by a low-rank tensor</a>
<a name="3">[3]</a> <a href="#3" id=3>Our parsing model aims to combine the strengths of both traditional features from the MST/Turbo parser as well as the new low-rank tensor features</a>
<a name="4">[4]</a> <a href="#4" id=4>Indeed, in the full English training set of CoNLL-2008, the tensor involves around 8 10 11 entries while the MST feature vector has approximately 1.5 10 7 features</a>
<a name="5">[5]</a> <a href="#5" id=5>Based on this feature representation, we define the score of each arc as s u'\u0398' ( h u'\u2192' m ) = u'\u27e8' u'\u0398' , u'\u03a6' h u'\u2192' m u'\u27e9' where u'\u0398' u'\u2208' u'\u211d'</a>
</body>
</html>