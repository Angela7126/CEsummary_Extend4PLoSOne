(lp0
VSpecifically, we construct the lexical constraints by extracting sentiment-bearing patterns within sentences and construct the discourse-level constraints by extracting discourse relations that indicate sentiment coherence or sentiment changes both within and across sentences
p1
aVWe can incorporate the proposed constraints (constraints derived from lexical patterns and discourse connectives) as hard constraints into CRF during inference by manually setting u'\u005cu039b' in equation 4 to a large value, 9 9 We set u'\u005cu039b' to 1000 for the lexical constraints and -1000 to the discourse connective constraints in the experiments
p2
aVSpecifically, we use the Conditional Random Field (CRF) model as the learner for sentence-level sentiment classification, and incorporate rich discourse and lexical knowledge as soft constraints into the learning of CRF parameters via Posterior Regularization (PR) [ 7 ]
p3
aVIn this paper, we propose a sentence-level sentiment classification method that can (1) incorporate rich discourse information at both local and global levels; (2) encode discourse knowledge as soft constraints during learning; (3) make use of unlabeled data to enhance learning
p4
aV1) we encode the coreference relations as soft constraints during learning instead of applying them as hard constraints during inference time; (2) our constraints can apply to both polar and non-polar sentences; (3) our identification of coreference relations is automatic without any fine-grained annotations for opinion targets
p5
aVThis confirms that encoding lexical and discourse knowledge as posterior constraints allows the feature-based model to gain additional learning power for sentence-level sentiment prediction
p6
aVIntuitively, discourse connectives with the senses of Expansion (e.g., also, for example, furthermore) and Contingency (e.g., as a result, hence, because) are likely to indicate sentiment coherence; discourse connectives with the sense of Comparison (e.g., but, however, nevertheless) are likely to indicate sentiment changes
p7
aVWe extract lexical patterns that consist of polar words and negators 3 3 The polar words are identified using the MPQA lexicon and the negators are identified using a handful of seed words extended by the General Inquirer dictionary and WordNet as described in [ 2 ] and apply the heuristics based on compositional semantics [ 2 ] to assign a sentiment value to each pattern
p8
aVHowever, if we examine these sentences within the discourse context, we can see that the second sentence expresses sentiment towards the same aspect u'\u005cu2013' the music u'\u005cu2013' as the first sentence; the third sentence expands the second sentence with the discourse connective In fact
p9
aVTo better understand the different effects of lexical and discourse constraints, we report results for applying only the lexical constraints ( CRF-inf l u'\u005cu2062' e u'\u005cu2062' x ) as well as results for applying only the discourse constraints ( CRF-inf d u'\u005cu2062' i u'\u005cu2062' s u'\u005cu2062' c
p10
aVTherefore we allow the lexical patterns to be assigned a neutral sentiment with a prior probability r 0 (we compute this value as the empirical probability of neutral sentiment in the training documents
p11
aVExisting feature-based classifiers may be effective in identifying the positive sentiment of the first sentence due to the use of the word revelation , but they could be less effective in the last two sentences due to the lack of explicit sentiment signals
p12
aVWe develop a rich set of context-aware posterior constraints for sentence-level sentiment analysis by exploiting lexical and discourse knowledge
p13
aVIn contrast, both PR l u'\u005cu2062' e u'\u005cu2062' x and PR significantly outperform CRF , which implies that incorporating lexical and discourse constraints as posterior constraints is much more effective
p14
aVThe first idea is to exploit sentiment signals at the sentence level by learning the relevance of sentiment and words while taking into account the context in which they occur
p15
aVThe lexical constraints alone are often not sufficient since their coverage is limited by the sentiment lexicon and they can only constrain sentiment locally
p16
aVThis demonstrates that our modeling of discourse information is effective and that taking into account the discourse context is important for improving sentence-level sentiment analysis
p17
aVBased on an analysis of the Amazon review data, we observe that sentence-level sentiment usually doesn u'\u005cu2019' t conflict with the document-level sentiment in terms of polarity
p18
aVTo capture context at the clause or sentence level, we consider discourse connectives, which are cue phrases or words that indicate discourse relations between adjacent sentences or clauses
p19
aVIn the MD dataset, a neutral label may be given because the sentence contains mixed sentiment or no sentiment or it is off-topic
p20
aVFor the CRF baseline and its invariants, we observe a similar performance trend as in the two-way classification task there is nearly no performance improvement from applying the lexical and discourse-connective-based constraints during CRF inference
p21
aVThe ability to extract sentiment from text is crucial for many opinion-mining applications such as opinion summarization, opinion question answering and opinion retrieval
p22
aVPR makes the assumption that the labeled data we have is not enough for learning good model parameters, but we have a set of constraints on the posterior distribution of the labels
p23
aVWe also show that constraints derived from the discourse context can be highly useful for disambiguating sentence-level sentiment
p24
aVIn addition, we include the discourse connectives as local or transition features and the document-level sentiment labels as features (only available in the MD dataset
p25
aVWe set the CRF regularization parameter u'\u005cu03a3' = 1 and set the posterior regularization parameter u'\u005cu0392' and u'\u005cu0393' (a trade-off parameter we introduce to balance the supervised objective and the posterior regularizer in 2 ) by using grid search 8 8 We conducted 10-fold cross-validation on each training fold with the parameter space u'\u005cu0392'
p26
aVIn contrast, the PR model is able to associate stronger sentiment signals to these features by leveraging unlabeled data for indirect supervision
p27
aVTo identify discourse connectives, we apply a discourse tagger trained on the Penn Discourse Treebank [ 20 ] 4 4 http://www.cis.upenn.edu/~epitler/discourse.html to our data
p28
aVThus it is hard to directly constrain the posterior expectation for each type of sentiment transitions using inter-sentential discourse connectives
p29
aVAs these opinion targets are coreferential (referring to the same entity u'\u005cu201c' the speaker phone u'\u005cu201d' ), they are linked by the opinion coreference relation 5 5 In general, the opinion-related entities include both the opinion targets and the opinion holders
p30
aVTherefore we only consider lexical patterns that are strongly discriminative (many opinion words in the lexicon only indicate sentiment with weak strength
p31
aVThis indicates that the document-level sentiment is a very strong indicator of the sentence-level sentiment label
p32
aVWe encode the extracted lexical patterns along with their sentiment values as feature-label constraints
p33
aVThe poor performance of CRF-inf l u'\u005cu2062' e u'\u005cu2062' x indicates that directly applying lexical constraints as hard constraints during inference could only hurt the performance
p34
aVAccordingly, extracting sentiment at the fine-grained level (e.g., at the sentence- or phrase-level) has received increasing attention recently due to its challenging nature and its importance in supporting these opinion analysis tasks [ 18 ]
p35
aV2013 ) explored the use of explanatory discourse relations as soft constraints in a Markov Logic Network framework for extracting subjective text segments
p36
aVUsing the polarity indicated by lexical patterns to constrain the sentiment of sentences is quite aggressive
p37
aVNote that these constraints are not necessary for our model and can be applied when the document-level sentiment labels are naturally available
p38
aVIt has the advantages of utilizing rich discourse knowledge at different levels of context and encoding it as soft constraints during learning
p39
aVNote that sentences with neutral sentiment can also contain such lexical patterns
p40
aVThe PR objective can be written as the original model objective penalized with a regularization term, which minimizes the KL-divergence between the desired model posteriors and the learned model posteriors with an L2 penalty 2 2 Other convex functions can be used for the penalty
p41
aVWe also show that discourse knowledge is highly useful for improving sentence-level sentiment classification
p42
aVStill, their methods can encounter difficulty when the sentence on its own does not contain strong enough sentiment signals (due to the lack of statistical evidence or the requirement for background knowledge
p43
aVThen we introduce the context-aware constraints derived based on intuitive discourse and lexical knowledge
p44
aV2010 ) uses tree-CRF to model word interactions based on dependency tree structures; Choi and Cardie ( 2008 ) applies compositional inference rules to handle polarity reversal; Socher et al
p45
aVHowever, the discourse relations were obtained from fine-grained annotations and implemented as hard constraints on polarity
p46
aVIn particular, incorporating discourse constraints leads to consistent improvements to our model
p47
aVDenote u'\u005cud835' u'\u005cudc31' as a sequence of sentences within a document and u'\u005cud835' u'\u005cudc32' as a vector of sentiment labels associated with u'\u005cud835' u'\u005cudc31'
p48
aVIn this work, we apply PR in the context of CRFs for sentence-level sentiment classification
p49
aVWe consider a discourse connective to be intra-sentential if it has the Comparison sense and connects two polar clauses with opposite polarities (determined by the lexical patterns
p50
aVThis is because it over-predicts the polar sentences in the polar documents, and predicts no polar sentences in the neutral documents
p51
aVMost of our constraints can be factorized in the same way as factorizing the model features in the first-order CRF model, and we can compute the expectations under q very efficiently using the forward-backward algorithm
p52
aVBy introducing the u'\u005cu201c' neutral u'\u005cu201d' category, the sentiment classification problem becomes harder
p53
aVWe consider a set of polar sentences to be linked by the opinion coreference relation if they contain coreferring opinion-related entities
p54
aVAs a result they could not help disambiguate neutral sentiment from polar sentiment, such as the third example in Table 5
p55
aVThe rule-based baseline VoteFlip gave the weakest performance because it has no prediction power on sentences with no opinion words
p56
aVLeveraging both ideas, our approach exploits sentiment signals from both intra-sentential and inter-sentential context
p57
aVOne reason is that they do not constrain the neutral sentiment
p58
aVA plausible explanation is that most of our constraints focus on discriminating polar sentences
p59
aVInstead, we impose constraints on the model posteriors by reducing constraint violations
p60
aVListing Patterns Another type of coherence relations we observe in online reviews is listing, where a reviewer expresses his/her opinions by listing a series of statements followed by a sequence of numbers
p61
aVObtaining sentiment labels at the fine-grained level is costly
p62
aVSince the possible label assignments only differ at position i , we can make the computation efficient by maintaining the structure of the coreference clusters and precomputing the constraint function for different types of violations
p63
aVThe desired value for the constraint expectation is set to 0 so that the model is encouraged to have less constraint violations
p64
aVIn the supervised setting, we treated the test data as unlabeled data and performed transductive learning
p65
aVTherefore all the constraints are applied as soft constraints
p66
aVEach constraint can be formulated as equality between the expectation of a constraint function value and a desired value set by prior knowledge
p67
aVWe focus on the equality constraints since we found them to express the sentiment-relevant constraints well
p68
aVLexical Patterns The existence of a polarity-carrying word alone may not correctly indicate the polarity of the sentence, as the polarity can be reversed by other polarity-reversing words
p69
aVIn general, discourse connectives can also be used to connect non-polar (neutral) sentences
p70
aVIn this work, we also take into account this information and encode it as posterior constraints
p71
aVLexical patterns can be limited in capturing contextual information since they only look at interactions between words within an expression
p72
aVHowever, hard-constraint baselines can hardly improve the performance in general because the contributions of different constraints are not learned and their combination may not lead to better predictions
p73
aVAs a framework for structured learning with constraints, PR has been successfully applied to many structural NLP tasks [ 6 , 7 , 5 ]
p74
aVFor documents where the higher-order constraints apply, we use the same Gibbs sampler as described above to infer the most likely label assignment, otherwise, we use the Viterbi algorithm
p75
aVWhen u'\u005cu039b' is large enough, it is equivalent to adding hard constraints to the viterbi inference
p76
aVThe opinion holders can be included in a similar way as the opinion targets
p77
aVIn the semi-supervised setting, our unlabeled data consists of both the available unlabeled data and the test data
p78
aVIn our tables, boldface numbers are statistically significant by paired t-test for p 0.05 against the best baseline developed in this paper 7 7 Significance test was not conducted over the previous methods as we do not have their results for each fold
p79
aVExisting machine learning approaches for the task can be classified based on the use of two ideas
p80
aVFor example, the following sentences express opinions towards u'\u005cu201c' the speaker phone u'\u005cu201d' , u'\u005cu201c' The speaker phone u'\u005cu201d' and u'\u005cu201c' it u'\u005cu201d' respectively
p81
aVThe equality is not strictly enforced (due to the regularization in the PR objective 2
p82
aVSolving the minimization problem is equivalent to solving its dual since the objective is convex
p83
aVDocOracle performs much better than VoteFlip and performs especially well on the Music domain
p84
aVWe use L2 norm because it works well in practice u'\u005cu0392' is a regularization constant for the constraint violations
p85
aVWe use accuracy as the performance measure
p86
aVThe constraint function can be written as
p87
aVHowever, the improvement on the neutral category is modest
p88
aVMy favorite features are the speaker phone and the radio
p89
aVWe can derive q by solving the dual problem in 3
p90
aVIn this work, we only consider the targets since we experiment with single-author product reviews
p91
aVOur approach is also semi-supervised
p92
a.