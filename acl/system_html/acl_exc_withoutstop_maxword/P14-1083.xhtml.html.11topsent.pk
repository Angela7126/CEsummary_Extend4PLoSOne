(lp0
VThe structured perceptron algorithm [ Collins2002 ] learns an optimal weight vector w by updating w on input x ( i ) by the following rule, in case the predicted translation y ^ is different from and scored higher than the reference translation y ( i )
p1
aVIn case of positive feedback, the predicted translation can be treated as reference translation for a structured learning update
p2
aVIn case of negative feedback, a structural update can be performed against translations that have been approved previously by positive task feedback
p3
aVWe show in an error analysis that this improvement can be attributed to using structural and lexical variants of reference translations as positive examples in response-based learning
p4
aVBuilding on prior work in grounded semantic parsing, we generate translations of queries, and receive feedback by executing semantic parses of translated queries against the database
p5
aVUpon predicting translation y ^ , in case of positive feedback from the task, we treat the prediction as surrogate reference by
p6
a.