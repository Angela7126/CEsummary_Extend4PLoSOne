(lp0
VSince this is a stochastic process, we average results over 100 runs
p1
aVWe also show that these annotations lead to better POS tagging models than previous models learned from crowdsourced lexica []
p2
aVNote that while we report agreement between the crowdsourced annotations and the crowdsourced annotations, our main evaluations are based on models learned from expert vs. crowdsourced annotations and downstream applications thereof (chunking and NER
p3
aVIn chunking, we see that using the crowdsourced annotations leads to worse performance than using the professional annotations
p4
aVIt is therefore common to aggregate over multiple annotations for the same item to get more robust annotations
p5
aVSince the only difference between models are the respective
p6
a.