(lp0
VWhen the induced projection function maps an object onto the linguistic space, the derived text vector will inherit a mixture of textual features from the concepts that activated the same hidden unit as the object
p1
aVThe process of learning to map objects to the their word label is implemented by training a projection function f proj v u'\u005cu2192' w from the visual onto the linguistic semantic space
p2
aVThe zero-shot framework leads us to frame fast mapping as the task of projecting visual representations of new objects onto language space for retrieving their word labels ( v u'\u005cu2192' w
p3
aVConcretely, we assume that concepts, denoted for convenience by word labels, are represented in linguistic terms by vectors in a text-based distributional semantic space (see Section 4.3
p4
aVWhereas for the latter our system assumes that all concepts have rich linguistic representations (i.e.,, representations estimated from a large corpus), in the case of the former, new concepts are assumed to be encounted in a limited linguistic context and therefore lacking rich linguistic representations
p5
aVIn this section, we aim at simulating a fast mapping scenario in which the learner has been just exposed to a new concept, and thus has limited linguistic evidence for that concept
p6
aVDuring training, this cross-modal vocabulary is used to induce a projection function (Section 4.4 ), which u'\u005cu2013' intuitively u'\u005cu2013' represents a mapping between visual and linguistic dimensions
p7
aVMoreover, if this is also the first linguistic encounter of that concept, then we refer to the task as fast mapping
p8
aVThus, this function, given a visual vector, returns its corresponding linguistic representation
p9
aVThe fast mapping setting can be seen as a special case of the zero-shot task
p10
aVFurthermore, since not all new concepts in the linguistic environment refer to new objects (they
p11
a.