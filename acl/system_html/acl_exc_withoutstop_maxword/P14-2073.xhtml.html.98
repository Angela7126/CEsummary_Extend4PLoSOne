<html>
<head>
<title>P14-2073.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>With this in mind, we consider whether we can reduce variance in the initialization by tuning the initial model</a>
<a name="1">[1]</a> <a href="#1" id=1>The results, shown in Figure 3 , show that we can ameliorate the variance due to initialization by tuning the initial model to NMI or perplexity</a>
<a name="2">[2]</a> <a href="#2" id=2>We observed previously that variance in the Gibbs initialization of the model contributes significantly to variance of the overall algorithm, as measured by NMI</a>
<a name="3">[3]</a> <a href="#3" id=3>Thus we perform a set of experiments in which we perform Gibbs initialization 20 times on the initialization set, setting the particle filter u'\u2019' s initial model to the model out of these 20 with the highest in-sample NMI</a>
<a name="4">[4]</a> <a href="#4" id=4>Thus, if initialization continues to be crucial to performance, at least we may have the flexibility of initializing without gold-standard labels</a>
<a name="5">[5]</a> <a href="#5" id=5>We may not always have labeled data for initialization, so we</a>
</body>
</html>