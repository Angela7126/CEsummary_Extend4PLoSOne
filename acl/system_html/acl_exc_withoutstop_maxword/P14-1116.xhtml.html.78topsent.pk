(lp0
VWe frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not
p1
aVContent selection decisions based on trends in time-series data determine the selection of the useful and important variables, which we refer to here as factors , that should be conveyed in a summary
p2
aVHere, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously []
p3
aVContent is regarded as labels (each template represents a label) and thus the task can be thought of as a classification problem
p4
aVEnsemble methods [] are algorithms that use ensembles to perform ML learning and they are based on problem transformation or algorithm adaptation methods
p5
aVML classification achieved significantly higher accuracy, which was expected as it is a supervised learning method
p6
aVRAkEL is based on Label Powerset (LP), a problem transformation method []
p7
aVWe compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with student users
p8
aVOur contributions to the field are as follows we present a novel and efficient method for tackling the challenge of content selection using a ML classification approach; we applied this method to the domain of feedback summarisation; we present a comparison with an optimisation technique (Reinforcement Learning), and we discuss the similarities and differences between the two methods
p9
aVRL is trained to optimise for this function, and therefore
p10
a.