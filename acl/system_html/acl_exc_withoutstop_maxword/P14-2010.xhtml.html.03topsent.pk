(lp0
VC number of topics on the sprinkled dataset using collapsed Gibbs sampling, where C is the set of class labels of the training documents
p1
aVIn this approach, a topic model on a given set of unlabeled training documents is constructed using LDA, then an annotator assigns a class label to some topics based on their most probable words
p2
aVAs in ClassifyLDA, we ask an annotator to assign class labels to a set of topics inferred on the unlabeled training documents
p3
aV[] used LDA topics as features in text classification, but they use labeled documents while learning a classifier sLDA [] , DiscLDA [] and MedLDA [] are few extensions of LDA which model both class labels and words in the documents
p4
aVWe use the labeled topics to find probability distribution of each training document over the class labels
p5
aVThese labeled topics are used to create a new topic model such that in the new model topics are better aligned to class labels
p6
aVAs the most probable words of topics are representative of the dataset, there is no need for the annotator to search for the right set of features for each class
p7
aVWe then infer a set of
p8
a.