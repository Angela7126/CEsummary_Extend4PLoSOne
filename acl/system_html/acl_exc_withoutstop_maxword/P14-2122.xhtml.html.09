<html>
<head>
<title>P14-2122.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The proposed method with monolingual bigram model performed poorly on the Chinese monolingual segmentation task; thus, it was not tested</a>
<a name="1">[1]</a> <a href="#1" id=1>Table 5 presents the run times of the proposed methods on the bilingual corpora</a>
<a name="2">[2]</a> <a href="#2" id=2>The bilingual model is</a>
<a name="3">[3]</a> <a href="#3" id=3>In monolingual segmentation, the proposed methods with both unigram and bigram models were tested</a>
<a name="4">[4]</a> <a href="#4" id=4>The time cost of the bilingual models is about 5 times that of the monolingual model, which is consistent with the complexity analysis in Section 3</a>
<a name="5">[5]</a> <a href="#5" id=5>It was set to 3 for the monolingual unigram model, and 2 for the bilingual unigram model, which provided slightly higher BLEU scores on the development set than the other settings</a>
<a name="6">[6]</a> <a href="#6" id=6>The monolingual model u'\u2133' is</a>
<a name="7">[7]</a> <a href="#7" id=7>The computational complexity of our method is linear in the number of iterations, the size of the corpus, and the complexity of calculating the expectations on each sentence or sentence pair</a>
<a name="8">[8]</a> <a href="#8" id=8>Thus its complexity is U 2 times the unigram model u'\u2019' s complexity</a>
<a name="9">[9]</a> <a href="#9" id=9>The experimental results show that the proposed UWS methods are comparable to the Stanford segmenters on the OpenMT06 corpus, while achieves a 0.96 BLEU increase on the PatentMT9 corpus</a>
<a name="10">[10]</a> <a href="#10" id=10>However, bilingual approaches that model word</a>
</body>
</html>