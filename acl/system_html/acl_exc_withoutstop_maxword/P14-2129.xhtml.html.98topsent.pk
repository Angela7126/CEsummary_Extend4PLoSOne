(lp0
VWe ran timing tests on an Intel 2.66GHz processor with 3MB of cache and 2GB of memory
p1
aVKeep in mind that the number of reference constituents increases as L increases, hence both precision and recall can decrease as the parameter grows
p2
aVSegmentation accuracy is better for the model with labels, although overall that accuracy is rather low
p3
aVNote that segmentation time is negligible compared to the parsing time, hence is omitted in reported time
p4
aVThe final two rows show performance with automatic segmentation, using a model that includes either unlabeled or labeled segmentation tags, as described in the last section
p5
aVThis method should yield a ceiling on hedge-parsing accuracy, as it has access to rich contextual information (as compared to grammars trained on transformed trees
p6
aVWe use hedge segmentation as a finite-state pre-processing step for hedge context-free parsing
p7
aVThe results show the same patterns as on the development set
p8
aVFinally, Figure 3 shows the speed of inference, labeled precision and labeled recall of annotating hedge constituents on the test set as a function of the maximum span parameter L , versus the baseline parser
p9
aVEfficiency results are reported as number of words parsed per second (w/s
p10
aVIf we apply this transform to an entire treebank, we can use the transformed trees to induce a PCFG for parsing
p11
aVThus, we train a grammar in a matched condition, which we call it a hedgebank grammar
p12
aVA
p13
a.