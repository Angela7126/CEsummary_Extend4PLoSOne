<html>
<head>
<title>P14-1031.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>When combining discourse constraints with features from different sentences, the PR model becomes more powerful in disambiguating sentiment</a>
<a name="1">[1]</a> <a href="#1" id=1>The second example in Table 5 shows that the PR model learned with discourse constraints correctly predicts the sentiment of two sentences where no lexical constraints apply</a>
<a name="2">[2]</a> <a href="#2" id=2>We develop a rich set of context-aware posterior constraints for sentence-level sentiment analysis by exploiting lexical and discourse knowledge</a>
<a name="3">[3]</a> <a href="#3" id=3>Specifically, we use the Conditional Random Field (CRF) model as the learner for sentence-level sentiment classification, and incorporate rich discourse and lexical knowledge as soft constraints into the learning of CRF parameters via Posterior Regularization (PR) [ 7 ]</a>
<a name="4">[4]</a> <a href="#4" id=4>Specifically, we construct the lexical constraints by extracting sentiment-bearing patterns within sentences and construct the discourse-level constraints by extracting discourse relations that indicate sentiment coherence or sentiment changes both within and across sentences</a>
<a name="5">[5]</a> <a href="#5" id=5>This confirms that encoding lexical and discourse knowledge as posterior constraints allows the feature-based model to gain additional</a>
</body>
</html>