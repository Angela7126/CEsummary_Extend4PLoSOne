(lp0
VRAkEL is based on Label Powerset (LP), a problem transformation method []
p1
aVWe frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not
p2
aVHere, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously []
p3
aVContent is regarded as labels (each template represents a label) and thus the task can be thought of as a classification problem
p4
aVRAkEL overcomes this limitation by constructing a set of LP classifiers, which are trained with different random subsets of the set of labels []
p5
aVContent selection decisions based on trends in time-series data determine the selection of the useful and important variables, which we refer to here as factors , that should be conveyed in a summary
p6
aVRAkEL tackles this problem by constructing an ensemble of LP classifiers and training each one on a different random subset of the set of labels []
p7
aVEnsemble methods [] are algorithms that use ensembles to perform ML learning and they are based on problem transformation or algorithm adaptation methods
p8
aVML classification achieved significantly higher accuracy, which was expected as it is a supervised learning method
p9
aVWe compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with student users
p10
aVThe reduced accuracy of the classification with predicted history is due to the error in the predicted values
p11
aVOur contributions to the field are as follows we present a novel and efficient method for tackling the challenge of content selection using a ML classification approach; we applied this method to the domain of feedback summarisation; we present a comparison with an optimisation technique (Reinforcement Learning), and we discuss the similarities and differences between the two methods
p12
aVThe classification method reduces the generation steps, by making the decision of the factor selection and the template selection jointly
p13
aVFor the corpus creation, 11 lecturers selected the content to be conveyed in a summary, given the set of raw data []
p14
aVRL is trained to optimise for this function, and therefore it achieves higher reward, whereas ML is trained to learn by examples, therefore it produces output closer to the gold standard (lecturer u'\u005cu2019' s produced summaries
p15
aVTraditional single-label classification is the task of identifying which label one new observation is associated with, by choosing from a set of labels L []
p16
aVIt was found out that Decision Trees achieved on average 3% higher accuracy
p17
aVRule-based System generates summaries based on Content Selection rules derived by working with a L T expert and a student []
p18
aVConsequently, a single poor decision in the ML classification can result in much less reward
p19
aVThe decisions of factor selection can be influenced by other factors that their values are correlated with; can be based on the appearance or absence of other factors in the summary; and can be based on the factors u'\u005cu2019' behaviour over time
p20
aVThis algorithm does not perform well when considering a large number of labels, due to the fact that the label space grows exponentially []
p21
aVThis result is indicative of the significance of the relations between the factors showing that the predicted decisions are dependent due to existing correlations as discussed in Section 1 , therefore the system should not take these decisions independently
p22
aVML classification performs better because it does take into account these correlations and dependencies in the data
p23
aVThis method did not take into account other selected templates u'\u005cu2013' it was only based on the time-series data
p24
aVIf the agent decides to refer to a factor, the template is selected in a deterministic way, i.e., from the available templates it selects the template that results in higher expected cumulative future reward
p25
aVOn the contrary, the RL is trained to optimise the selected content and not to replicate the existing lecturer summaries, hence there is a difference in accuracy
p26
aVDuring run time, RAkEL estimates the average decision for each label in L and if the average is greater than a threshold t (determined by the developer) it includes the label in the predicted labelset
p27
aVLP benefits from taking into consideration label correlations, but does not perform well when trained with few examples as in our case []
p28
aVHowever, simple classification assumes that the templates are independent of each other, thus the decision for each template is taken in isolation from the others, which is not appropriate for our domain
p29
aVIn order to have a more objective view on the results, the score achieved by each algorithm using the reward function was also calculated
p30
aVMoreover, we plan to utilise the results from this student evaluation in order to train an optimisation algorithm to perform summarisation according to students u'\u005cu2019' preferences
p31
aVInstead of dealing with this task in a hierarchical way, where the algorithm will first learn whether to talk about a factor and then to decide how to refer to it, we transformed the task in order to reduce the learning steps
p32
aVThe upper-bound accuracy is 78.09% calculated by using the expert previous decisions and not the potentially erroneous predicted decisions
p33
aVContent selection is seen as a Markov Decision problem and the goal of the agent is to learn to take the sequence of actions that leads to optimal content selection
p34
aVML classification requires no history, i.e., does not keep track of previous decisions, and thus has a smaller feature space
p35
aVTherefore, classification can reduce the decision workload by deciding either in which way to talk about it, or not to talk about a factor at all
p36
aVThe difference between the two methods lies in that the collective content selection requires the consideration of an individual preference score (which is defined as the preference of the entity to be selected or omitted, and it is based on the values of entity attributes and is computed using a boosting algorithm) and the identification of links between the entities with similar labels
p37
aVFinally, our domain for feedback generation is motivated by previous studies [] who show that text summaries are more effective in decision making than graphs therefore it is advantageous to provide a summary over showing users the raw data graphically
p38
aVThere is evidently a mismatch between the rules and the test-set; the content selection rules are based on heuristics provided by a L T Expert rather than by the same pool of lecturers that created the test-set
p39
aV1) the numbers of iterations m (which is developer specified and denotes the number of models that the algorithm will produce), (2) the size of labelset k (which is also developer specified), (3) the set of labels L , and (4) the training set D
p40
aVIn this case, optimisation would be the preferred method as it would not be appropriate to collect gold standard data from students
p41
aVMoreover, each decision is rewarded with a different value as some combinations of factors and templates have greater or negative regression coefficients
p42
aVTherefore, when generating feedback, we need to take into account all variables simultaneously in order to capture potential dependencies and provide more effective and useful feedback that is relevant to the students
p43
aVWe, therefore, went on to use Decision Trees that use generation history in three ways
p44
aVAccuracy was estimated as the proportion of the correctly classified templates to the population of templates
p45
aVIn order to reduce the confounding variables, we kept the ordering of content in all systems the same, by adopting the ordering of the rule-based system
p46
aVOn the other hand, when mentioning the average difficulty the summary is u'\u005cu201c' punished u'\u005cu201d' with -81 (see description of the reward function in Section 5.2
p47
aVAs we will discuss further in Section 5.1 , content decisions are influenced by the previously generated content, for example, if the lecturer has previously mentioned health_issues, mentioning hours_studied has a high probability of also being mentioned
p48
aVMoreover, some factors may have to be discussed together in order to achieve some communicative goal, for instance, a teacher might want to refer to student u'\u005cu2019' s marks as a motivation for increasing the number of hours studied
p49
aVOverall, for all factors there are 29 different templates 1 1 There are fewer than 36 templates, because for some factors there are less than 4 possible ways of referring to them
p50
aVAs mentioned, there are 4 ways to refer to a factor
p51
aVRAkEL takes as input the following parameters
p52
aVFor this initial experiment, we evaluated with students and not with lecturers, since the students are the recipients of feedback
p53
aVThe RAndom k-labELsets (RAkEL) [] was applied in order to perform ML classification
p54
aVThe algorithm was implemented using the MULAN Open Source Java library [] , which is based on WEKA []
p55
aVOur analysis of the dataset showed that there are significant correlations between the factors, for example, the number of lectures attended (LA) correlates with the student u'\u005cu2019' s understanding of the material (Und), see Table 5
p56
aVReinforcement Learning (RL) is a machine learning technique that defines how an agent learns to take optimal actions so as to maximise a cumulative reward []
p57
aVAs a result, for the same student there are various summaries provided by the different experts
p58
aVIn future, we could perform parameter optimisation by using a technique similar to []
p59
aVThe summaries generated by the ML classification system are then compared with the output of a RL system and two baseline systems in simulation and with real students
p60
aVML-kNN identifies for each new instance its k nearest neighbours in the training set and then it predicts the label set by utilising the maximum a posteriori principle according to statistical information derived from the label sets of the k neighbours
p61
aVWe compared the RAkEL algorithm with single-label (SL) classification
p62
aVSecondly, for Decision Tree (with predicted history) , 29 classifiers were also trained, but this time the input included the previous decisions made by the previous classifiers (i.e., the history) as well as the set of time-series data in order to emulate the dependencies in the dataset
p63
aVThe LP method transforms the ML task, into one single-label multi-class classification task, where the possible set of predicted variables for the transformed class is the powerset of labels present in the original dataset
p64
aVML system, RL system, Rule-based and Random system
p65
aVThe rule-based system and the RL system have lower accuracy compared to the ML system
p66
aVAlgorithm adaptation approaches [] extend simple classification methods to handle ML data
p67
aVFirstly, we performed a preliminary evaluation on classification methods, comparing our proposed ML classification with multiple iterated classification approaches
p68
aVProblem transformation approaches [] transform the ML classification task into one or more simple classification tasks
p69
aVThe average accuracy of the single-label classifiers is 75.95% (10-fold validation), compared to 73.43% of classification with history
p70
aVThe RL system differs from the classification system in the way it performs content selection
p71
aVIn this paper, we applied RAkEL (Random k-labelsets) [] an ensemble problem transformation method, which constructs an ensemble of simple-label classifiers, where each one deals with a random subset of the labels
p72
aVML classification algorithms have been divided into three categories algorithm adaptation methods, problem transformation and ensemble methods []
p73
aVThe difference in ratings between the ML classification system, the RL system and the Rule-based system is not significant (see Mode (mean) in Table 7 , p 0.05
p74
aVCollective content selection [] is similar to our proposed method in that it is a classification task that predicts the templates from the same instance simultaneously
p75
aVThe ML classification system performed worse than this gold standard in terms of reward, which is expected given the error in predictions (supervised methods learn to reproduce the gold standard
p76
aVIn this section, the content selection task and the suggested multi-label classification approach are presented
p77
aVDuring the combination phase, the algorithm takes as input the results of the production phase, i.e., the ensemble of LPs with the corresponding k -labelsets, the set of labels L , and the new instance x and it outputs the result vector of predicted labels for instance x
p78
aVFirstly, for Decision Tree (no history) , 29 decision-tree classifiers were trained, one for each template
p79
aVThe above-mentioned classifiers are compared with, the Majority-class (single label) baseline, which labels each instance with the most frequent template
p80
aVMulti-label classification is the task of associating an observation with a set of labels Y u'\u005cu2286' L []
p81
aVThirdly, for Decision Tree (with real history) , the real, expert values were used rather than the predicted ones in the history
p82
aVThe input of these classifiers were the 9 factors and each classifier was trained in order to decide whether to include a specific template or not
p83
aVA ML classifier is able to make decisions for all templates simultaneously and capture these differences
p84
aVFor instance, classifier n was trained using the data from the 9 factors and the template decisions for templates 0 to n - 1
p85
aVIn contrast, ML classification does not need the computation of links between the data and the templates
p86
aVTable 7 presents the accuracy, reward, and mode of student rating of each algorithm when used to generate the 26 summaries
p87
aVDuring the initial phase it outputs an ensemble of LP classifiers and the corresponding k-labelsets
p88
aVThe reward for the lecturers u'\u005cu2019' produced summaries is 124.62 and for the ML method is 107.77
p89
aVSection 5 ) - Offline evaluation (Accuracy and Reward) - Online evaluation (Subjective Ratings
p90
aVThe reward function reflects the lecturers u'\u005cu2019' preferences on summaries and is derived through linear regression analysis of a dataset containing lecturer constructed summaries and ratings of randomly generated summaries
p91
aVIn order to capture the dependencies in the context, multiple simple classifiers can make the decisions for each template iteratively
p92
aVReward Function
p93
aVFirstly, they change over time, and secondly they can be dependent on or independent of each other
p94
aVFeedback summaries constructed by lecturers; random summaries rated by lecturers
p95
aVOne set of factor values can result in various sets of templates as interpreted by the different experts
p96
aVThe reward represents predicted ratings that lecturers would give to the summary
p97
aVDifferent SL classifiers were trained using WEKA
p98
aVthe production of an ensemble of LP algorithms, and
p99
aVIn this method, at every step, the predicted outcome was used including the incorrect decisions that the classifier made
p100
aVRL uses exploration and exploitation to discover combinations of content that result in higher reward
p101
aVPrevious methods for content selection include Reinforcement Learning [] ; multi-objective optimisation [] ; Gricean Maxims [] ; Integer Linear Programming [] ; collective content selection [] ; interest scores assigned to content [] ; a combination of statistical and template-based approaches to NLG [] ; statistical acquisition of rules [] and the Hidden Markov model approach for Content Selection and ordering []
p102
aVRandom System initially, selects a factor randomly and then selects a template randomly, until it makes decisions for all factors
p103
aVEach instance includes time-series information about the student u'\u005cu2019' s learning habits and the selected templates that lecturers used to provide feedback to this student
p104
aVThe state consists of the time-series data and the selected templates
p105
aVThe accuracy, the weighted precision, the weighted recall, and the weighted F-score of the classifiers are shown in Table 6
p106
aV[H] RAkEL production phase
p107
aVThe development and evaluation of the time-series generation system follows the following pipeline []
p108
aVAccuracy measures how similar the generated output is to the gold standard, whereas the reward function calculates a score regarding how good the output is, given an objective function
p109
aVIt was found that in 10-fold cross validation RAkEL performs significantly better in all these automatic measures (accuracy = 76.95%, F-score = 85.50%
p110
aVMoreover, the training time for the classification method is faster (a couple of seconds compared to over an hour
p111
aVOur learning task is formed as follows given a set of 9 time-series factors, select the content that is most appropriate to be included in a summary
p112
aVML classification can also apply to other problems whose features are correlated, such as text classification [] , when an aligned dataset is provided
p113
aVRemarkably, ML achieves more than 10% higher F-score than the other methods (Table 6
p114
aVThe Temporal Difference learning method was used to train an agent for content selection
p115
aVAfter each iteration, the feature space grows by 1 feature, in order to include the history of the previous template decisions
p116
aVthe combination of the LP algorithms
p117
aVIn the next section, we refer to the related work on Natural Language Generation from time-series data and on Content Selection
p118
aVTime-Series data collection from students
p119
aVThese summaries were evaluated in simulation and with real student users
p120
aVDevelopment of time-series generation systems (Section 4.2 , Section 5.3
p121
aVEach participant was shown a graphical representation of the time-series data of one student and four different summaries generated by the four systems (see Figure 1
p122
aVFinally, the student significantly prefer all the systems over the random
p123
aVJRip, Decision Trees, Naive Bayes, k-nearest neighbour, logistic regression, multi-layer perceptron and support vector machines
p124
aVSummarisation of time-series data refers to the task of automatically generating text from variables whose values change over time
p125
aVAn example of the input data is shown in Table 4
p126
aVIn addition, feedback summarisation from time-series data can be applied to the field of Intelligent Tutoring Systems []
p127
aVThe order of the presented summaries was randomised
p128
aVIn Section 4.2 , we describe our approach and we carry out a comparison with simple classification methods
p129
aVHowever, there is a trend towards the RL system
p130
aVThe important tasks of time-series data summarisation systems are content selection (what to say), surface realisation (how to say it) and information presentation (Document Planning, Ordering, etc
p131
aVFor instance, the combination of the factors u'\u005cu201c' deadlines u'\u005cu201d' and the template that corresponds to weeks is rewarded with 57
p132
aVIn Section 5 , we present the evaluation setup and in Section 6 we discuss the results, obtained in simulation and with real students
p133
aVIn the training phase, the agent selects a factor and then decides whether to talk about it or not
p134
aVEvaluation
p135
aVThis characteristic of the dataset, that each instance is associated with more than one solution, additionally motivates the use of multi-label classification, which is concerned with learning from examples, where each example is associated with multiple labels
p136
aVIn future, we plan to evaluate with students u'\u005cu2019' own data under real circumstances as well as with ratings from lecturers
p137
aVNatural Language Generation from time-series data has been investigated for various tasks such as weather forecast generation [] , report generation from clinical data [] , narrative to assist children with communication needs [] and audiovisual debrief generation from sensor data from Autonomous Underwater Vehicles missions []
p138
aVThe templates describe these factors in four different ways
p139
aVTemplate construction by Learning and Teaching (L T) expert
p140
aVIn order to explore the state space the agent selects a factor (e.g., marks, deadlines etc.) and then decides whether to talk about it or not
p141
aVA pseudocode for the production phase is shown below
p142
aVEach of the four systems described above generated 26 feedback summaries corresponding to the 26 student profiles
p143
aVIn this work, we concentrate on content selection
p144
aVIn this paper, with the term u'\u005cu2018' template u'\u005cu2019' we refer to a quadruple consisting of an id , a factor (bottom left of Table 4 ), a reference type (trend, weeks, average, other) and surface text
p145
aVWe consider the task of automatically generating feedback summaries for students describing their performance during the lab of a Computer Science module over the semester
p146
aVIn this work, we concentrate on content selection which is the task of choosing what to say, i.e., what information is to be included in a report []
p147
aVThe algorithm works in two phases
p148
aVFor example, the k-nearest neighbour algorithm is extended to ML-kNN by Zhang and Zhou \u005cshortcite Zhang:2007
p149
aVThere are two decisions that need to be made
p150
aVIn fact, it would be of interest to investigate multi-objective optimisation techniques that can balance the needs of the lecturers to convey important content to the satisfaction of students
p151
aVaverage considering the average of a factor value (e.g.,  u'\u005cu201c' You dedicated 1.5 hours studying on average u'\u005cu2026' u'\u005cu201d' ), and
p152
aVAn example of one such instance is presented in Table 4
p153
aV1) describing the trend, (2) describing what happened in every time stamp, (3) mentioning the average and (4) making another general statement
p154
aVSpecifically, it is the following cumulative multivariate function
p155
aVFinally, in Section 8 , directions for future work are discussed
p156
aVWe used the standard parameter values of t , k and m ( t = 0.5, k = 3 and m equals to 58 (2*29 templates
p157
aV1) the marks achieved at the lab; (2) the hours that the student spent studying; (3) the understandability of the material; (4) the difficulty of the lab exercises as assessed by the student; (5) the number of other deadlines that the student had that week; (6) health issues; (7) personal issues; (8) the number of lectures attended; and (9) the amount of revision that the student had performed
p158
aVHow would you evaluate the following feedback summaries from 1 to 10 u'\u005cu201d' , where 10 corresponds to the most preferred summary and 1 to the least preferred
p159
aVThe time-series information includes for each week of the semester
p160
aV1) whether to talk about a factor and (2) in which way to refer to it
p161
aVThey were asked to rate each feedback summary on a 10-point rating scale in response to the following statement u'\u005cu201c' Imagine you are the following student
p162
aVStudents u'\u005cu2019' learning can be influenced by many variables, such as difficulty of the material [] , other deadlines [] , attendance in lectures [] , etc
p163
aVFor a few students there is more than 1 instance
p164
aVThe dataset consists of 37 instances referring to the activities of 26 students
p165
aV37 first year computer science students participated in the study
p166
aVtrend referring to the trend of a factor over the semester (e.g.,  u'\u005cu201c' Your performance was increasing u'\u005cu2026' u'\u005cu201d'
p167
aVweeks explicitly describing the factor value at specific weeks (e.g., u'\u005cu201c' In weeks 2, 3 and 9 u'\u005cu2026' u'\u005cu201d'
p168
aVActions and States
p169
aVR u'\u005cu2062' e u'\u005cu2062' w u'\u005cu2062' a u'\u005cu2062' r u'\u005cu2062' d = a + u'\u005cu2211' i = 1 n b i * x i + c * l u'\u005cu2062' e u'\u005cu2062' n u'\u005cu2062' g u'\u005cu2062' t u'\u005cu2062' h where X = { x 1 , x 2 , u'\u005cu2026' , x n } describes the combinations of the data trends observed in the time-series data and a particular template a , b and c are the regression coefficients, and their values vary from -99 to 221
p170
aVThe value of x i is given by the function
p171
aVThese variables have two important qualities
p172
aVother mentioning other relevant information (e.g.,  u'\u005cu201c' Revising material will improve your performance u'\u005cu201d'
p173
aVFor instance, the set of labels L = { t u'\u005cu2062' e u'\u005cu2062' m u'\u005cu2062' p 0 , t u'\u005cu2062' e u'\u005cu2062' m u'\u005cu2062' p 1 , u'\u005cu2026' u'\u005cu2062' t u'\u005cu2062' e u'\u005cu2062' m u'\u005cu2062' p 28 } could be transformed to { t u'\u005cu2062' e u'\u005cu2062' m u'\u005cu2062' p 0 , 1 , 2 , t u'\u005cu2062' e u'\u005cu2062' m u'\u005cu2062' p 28 , 3 , 17 , u'\u005cu2062' u'\u005cu2026' }
p174
aVThe baselines are as follows
p175
aVThe research leading to this work has received funding from the EC u'\u005cu2019' s FP7 programme
p176
aVFP7/2011-14) under grant agreement no. 248765 (Help4Mood
p177
aV2
p178
aV1
p179
a.