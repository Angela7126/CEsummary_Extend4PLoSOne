(lp0
VImportantly, the semantics listed here is not just for the verb spray but applies to all verbs from the Spray Class whenever they appear in that syntactic frame u'\u005cu2013' that is, VerbNet assumes the Semantic Consistency Hypothesis
p1
aVThat is, all verbs in the same class appear in the same set of syntactic frames
p2
aVWe then considered how many verbs in each class had the same annotation in any given syntactic frame
p3
aVThat is, ideally there would be some database of semantic judgments for a comprehensive set of verbs from each syntactic class
p4
aVAs such, this task provides a lower bound for how much semantic consistency one might expect within a syntactic verb class
p5
aVAs noted above, the question is not whether all verbs in the same syntactic class share the same semantic entailments
p6
aVThus, we investigate the semantics of each verb in each syntactic frame available to it (as described by VerbNet
p7
aVEven a single verb may have different semantic entailments when placed in different syntactic frames
p8
aVImportantly, in addition to characterizing the syntactic frames associated with each class, VerbNet also characterizes the semantics of each class
p9
aVPrevious work suggests that it is the semantic entailments that matter, particularly for explaining the syntactic behavior of verbs [ 10 ]
p10
aVVerbs vary in terms of which syntactic frames they can appear in (Table 1
p11
aVThere is some set of semantic features such that verbs that share the same syntactic behavior are identical along those semantic features
p12
aVOne significant challenge for any such project is first classifying verbs according to the syntactic frames they can appear in
p13
aVIn Phase 1 of the project, we focused on 11 verb classes (Table 3) comprising 641 verbs and seven different semantic entailments (Table 2
p14
aVFor each syntactic frame in each class, we determined the most common annotation
p15
aVFor example, suppose a class had 10 verbs and 2 frames
p16
aVFor instance, class 9.7, which comprises a couple dozen verbs, allows 7 different syntactic frames
p17
aVThe exact semantics associated with a verb may depend on its syntactic frame
p18
aVThe semantic annotation depended on syntactic frame nearly 1/4 of the time
p19
aVVerbNet suggests two syntactic frames for class 63, one of which ( NP V that S ) appears to be marginal
p20
aVThese data can be used to test the Semantic Consistency Hypothesis
p21
aVThe consistency for the class as a whole is the average across frames
p22
aVWe next investigated whether our results support the Semantic Consistency Hypothesis
p23
aVHowever, most theorists posit that there is a systematic relationship between the semantics of a verb and the syntactic frames in which it can appear [ 9 ]
p24
aVHere, there does appear to be a systematic semantic distinction between the two syntactic frames in each alternation, at least most of the time
p25
aVHowever, the relevant verbs make up a tiny fraction of all English verbs, and even for these verbs, the syntactic frames in question represent only a fraction of the syntactic frames available to those verbs
p26
aVThe Semantic Consistency Hypothesis would be supported if, within that database, predicates with the same syntactic properties were systematically related semantically
p27
aVThe limiting factor is scale with many thousands of verbs and over a hundred commonly-discussed semantic features and syntactic frames, it is not feasible for a single researcher, or even team of researchers, to check which verbs appear in which syntactic frames and carry which semantic entailments
p28
aVIn the first frame, 8 verbs received the same annotation and 2 received others
p29
aVVerbNet (Kipper et al., 2008; based on Levin, 1993) lists over 6,000 verbs, categorized into 280 classes according to the syntactic frames they can appear in
p30
aVThus, calculating consistency of a class must take differing frames into account
p31
aVThe VerbCorner Project 3 3 http://gameswithwords.org/VerbCorner/ is devoted to collecting semantic judgments for a comprehensive set of verbs along a comprehensive set of theoretically-relevant semantic dimension
p32
aVIn the second frame, 6 verbs received the same annotation and 4 verbs received others
p33
aVFor instance, annotators judged that class 18.1 verbs in the NP V NP PP.instrument entailed movement on the part of the instrument ( Sally hit the ball with the stick ) u'\u005cu2013' something not reflected in VerbNet
p34
aVMean consistency averaged across classes is shown for each task in Table 2
p35
aVThis account has a natural consequence, which we dub the Semantic Consistency Hypothesis
p36
aVIn any case, to our knowledge, of the 280 syntactic verb classes listed by VerbNet, only a handful have been studied in any detail
p37
aV1 1 Note that this is a simplification in that there are non-causal verbs that appear in both the NP V NP frame and the NP V frame
p38
aVGiven the prominence of the Semantic Consistency Hypothesis in both theory and practice, one might expect that it was on firm empirical footing
p39
aVIn computational linguistics and natural language processing, some form of the Semantic Consistency Hypothesis is often included in linguistic resources and utilized in applications
p40
aVBelow, the term item is the unit of annotation a verb in a frame
p41
aVAs expected, consistency was lowest for Evaluation , which is not expected to necessarily correlate with syntax
p42
aVThese frequently matched VerbNet u'\u005cu2019' s semantics, though not always
p43
aVAs such, the VerbCorner Project is also verifying and validating the semantics currently encoded in VerbNet
p44
aVFor instance, it is argued that verbs like break , which describe a caused change of state, can appear in both the NP V NP form ( Sally broke the vase ) and the NP V form ( The vase broke
p45
aVThus, at least initially, we are focusing on the 6,000+ verbs already cataloged in VerbNet
p46
aV4 4 Note that this table was calculated based on whether the semantic feature was present or not
p47
aVSyntactic Frame NP V NP PP destination Example Jessica sprayed the wall
p48
aVIndependent of the validity of that hypothesis, the semantic judgments themselves should prove useful for any study of linguistic meaning or related application
p49
aVVerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling [ 18 ] , inferencing [ 20 ] , verb classification [ 8 ] , and information extraction [ 11 ]
p50
aVNote that each task is designed to elicit judgments about entailments u'\u005cu2013' things that must be true rather than are merely likely to be true
p51
aVWe selected semantic features of interest based on those most commonly cited in the linguistics literature, with a particular focus on those that u'\u005cu2013' according to VerbNet u'\u005cu2013' apply to many predicates
p52
aVIn fact, annotators frequently flagged these items as ungrammatical, which is a valuable result in itself for improving VerbNet
p53
aVEach phase focuses on a small number of classes and/or semantic entailments
p54
aVVerbs such as hit and like do not describe a change of state and so cannot appear in both forms
p55
aVIn fact, both researchers argue that a principled relationship between syntax and semantics is necessary for language to be learnable at all
p56
aVThe consistency for this class/frame combination is 80%
p57
aVThe consistency for this class/frame combination is 60%
p58
aVIn all, we collected 162,564 judgments from 1,983 volunteers (Table 2
p59
aVSimilarly, only verbs that describe propositional attitudes, such as like , can take a that complement ( John liked that Sally broke the vase
p60
aVVerbNet will be edited as necessary based on the empirical results
p61
aVFor instance, inter-annotator agreement was typically low for class 63
p62
aVThis has been tested with a reasonable sample of the relevant verbs and also in both children and adults [ 1 , 15 ]
p63
aVWe then considered what proportion of all annotations were accounted for by the modal response a mean of 100% would indicate that there was no disagreement among annotators for any item
p64
aVAs can be seen in Table 2, for every task, the modal response covered the bulk responses, ranging from a low of 72% for Evaluation to a high of 93% for Physical Contact
p65
aVIn principle, these judgments would come from naive annotators, since researchers u'\u005cu2019' intuitions about subtle judgments may be unconsciously clouded by theoretical commitments [ 4 ]
p66
aVInterestingly, consistency for Evaluation was nonetheless well above floor
p67
aVFor instance, for Application of Force , annotators determined which participant in the event was applying the force
p68
aVIt is widely recognized that a principled relationship between syntax and semantics would have broad implications
p69
aVNo such database exists, whether consisting of the judgments of linguists or naive annotators
p70
aVWhile six of these entailments were chosen from among those features widely believed to be relevant for syntax, one was not
p71
aV2 2 There is a long tradition of partitioning semantics into those aspects of meaning which are u'\u005cu201c' grammatically relevant u'\u005cu201d' and those which are not
p72
aVAny opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation
p73
aVA Good World, which investigated evaluation ( Is the event described by the verb positive or negative
p74
aVAlthough evaluation of events is an important component of human psychology, to our knowledge no researcher has suggested that it is relevant for syntax
p75
aVThere are many sophisticated rubrics for calculating consistency
p76
aVWe describe in detail one such resource, VerbNet, which is highly relevant to our investigation
p77
aVIn many cases, annotator disagreement seems to be driven by syntactic constructions that are only marginally grammatical
p78
aVIn u'\u005cu201c' Explode on Contact, u'\u005cu201d' designed to elicit judgments about physical contact, objects and people explode when they touch one another
p79
aVConsistency was much higher for the other tasks, and in fact was close to ceiling for most of them
p80
aVBecause we recruited large numbers of annotators, most of whom annotated only a few items, typical measures of inter-annotator agreement such as Cohen u'\u005cu2019' s kappa are not easily calculated
p81
aVPrevious research has shown that humans find it easier to reason about real-world scenarios than make abstract judgments [ 3 ]
p82
aVIn general, there has been interest in the NLP literature in using these syntactially-relevant semantic features for shallow semantic parsing (e.g.,, Giuglea and Moschitti, 2006)
p83
aVIt remains to be seen whether the items that deviate from the mode represent true differences in semantics or reflect merely noise
p84
aVGiven the sheer scale of the project, data-collection is expected to take several years at least
p85
aVFor example, in u'\u005cu201c' Simon Says Freeze, u'\u005cu201d' a task designed to elicit judgments about movement, the Galactic Overlord (Simon) decrees u'\u005cu201c' Galactic Stay Where You Are Day, u'\u005cu201d' during which nobody is allowed to move from their current location
p86
aVThe entry for one frame is shown below
p87
aVThus, for each feature (e.g.,, movement ), we converted the metalinguistic judgment ( u'\u005cu201c' Does this verb entail movement on the part of some entity u'\u005cu201d' ) into a real-world problem
p88
aVThis is perhaps not surprising two sentences that have the same values for Physical Change, Application of Force, Physical Contact, Change of Mental State, Mental State , and Location Change are, on average, also likely to be both good or both bad
p89
aVSeveral previous projects have successfully crowd-sourced linguistic annotations, such as Phrase Detectives, where volunteers have contributed 2.5 million judgments on anaphoric relations [ 16 ]
p90
aVThus Sally rolled the ball entails that somebody applied force to the ball (namely
p91
aVThis amplifies the impact of any VerbCorner-inspired changes to VerbNet
p92
aVMost theoretical studies report researcher judgments for only a handful of examples; how many additional examples were considered by the researcher goes unreported
p93
aVThis represents good performance given that the annotators were entirely untrained
p94
aVOne way of addressing this question is to collect additional annotations for those items that deviate from the mode
p95
aVHowever, these pilot studies involved a small number of items which were coded by all annotators
p96
aVIntegration with VerbNet has additional benefits, since VerbNet itself is integrated with a variety of linguistic resources, such as PropBank and Penn TreeBank
p97
aVIn principle, this could be an unpredictable fact about the verb that must be acquired, much like the phonological form of the verb
p98
aVSince there were typically 4 or more possible answers per item, inter-annotator agreement was well above chance
p99
aVIt has also been employed in models of language acquisition [ 12 , 2 ]
p100
aVSally), whereas The ball rolled does not
p101
aVFor instance, Pinker (1984, 1989) has described how this correspondence could solve long-standing puzzles about how children learn syntax in the first place
p102
aVFirst, we determined the annotation for each item (i.e.,, each verb/frame combination) by majority vote
p103
aVCollecting data from naive subjects is even more laborious, particularly since the average Man on the Street is not necessarily equipped with metalinguistic concepts like caused change of state and propositional attitude
p104
aVIn order to minimize unwanted effects of world knowledge, the verb u'\u005cu2019' s arguments are replaced with nonsense words or randomly chosen proper names ( Sally sprayed the dax onto the blicket
p105
aVInstead, for each item, we calculated the most common (modal) response
p106
aVEach task had been iteratively piloted and redesigned until inter-annotator reliability was acceptable, as described in a previous publication
p107
aV+ dest_conf } Destination Semantics motion ( during (E), Theme ) Not ( Prep ( start (E), Theme , Destination )) Prep ( end (E), Theme , Destination ) Cause ( Agent , E
p108
aVHow good was the reliability in the crowd-sourcing context
p109
aVThe participant reads descriptions of events and decides whether anything has exploded
p110
aVWe gratefully acknowledge the support of the National Science Foundation Grant NSF-IIS-1116782, DARPA Machine Reading FA8750-09-C-0179, and funding from the Ruth L
p111
aVSyntax Agent V Theme {+ loc
p112
aVThe VerbCorner Project is aimed at filling that empirical gap
p113
aVThe full data and annotations will be released in the near future and may be available now by request
p114
aVConversely, Gleitman (1990) has shown such a syntax-semantics relationship could solve significant problems in vocabulary acquisition
p115
aVRecruiting large numbers of volunteers, each of whom may provide only a few annotations
p116
aVThis is summarized in Table 3
p117
aVIt is frequently invoked in theories of language acquisition
p118
aVParticipants read descriptions of events and decide whether anyone violated the rule
p119
aVThis manuscript reports the results of Phase 1
p120
aVThis ensures that there are meaningful intermediate results that can be disseminated prior to the completion of the entire project
p121
aVKirschstein National Research Service Award
p122
aVWe address the issue of scale through crowd-sourcing
p123
aVThe use of novel words is explained by the story for each task
p124
aVIf John greeted Bill, they might have come into contact (e.g.,, by shaking hands), but perhaps they did not
p125
aVIn many cases, the data was significantly richer
p126
aVNote that on certain accounts, this is a strong tendency rather than a strict necessity (e.g.,, Goldberg, 1995)
p127
aVBelow, we summarize the main findings thus far
p128
aVWe refer the interested reader to Pinker (1989), Jackendoff (1990), and Levin Rappaport Hovav (2005
p129
aVThus, data-collection has been broken up into a series of phases
p130
aVFor details, see [ 10 ]
p131
aVThe strongest evidence comes from experimental work on several so-called alternations (the passive, causative, locative, and dative alternations
p132
aVThis is not an accidental oversight
p133
aVHowever, for expository purposes here, we use one that is intuitive and easy to interpret
p134
aVI control that Mary eats
p135
aV70%
p136
a.