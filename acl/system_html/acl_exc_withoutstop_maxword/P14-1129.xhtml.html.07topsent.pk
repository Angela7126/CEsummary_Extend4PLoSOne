(lp0
VThis notion of affiliation is derived from the word alignment, but unlike word alignment, each target word must be affiliated with exactly one non-NULL source word
p1
aVFormally, our model approximates the probability of target hypothesis T conditioned on source sentence S
p2
aVSpecifically, we introduce a novel formulation for a neural network joint model (NNJM), which augments an n -gram target language model with an m -word source window
p3
aVWe follow the standard n -gram LM decomposition of the target, where each target word t i is conditioned on the previous n - 1 target words
p4
aVWe treat NULL as a normal target word, and if a source word aligns to multiple target words, it is treated as a single concatenated token
p5
aVThe probability is computed over every source word in the input sentence
p6
aVOne issue with the S2T NNJM is that the probability is computed over every target word, so it does not explicitly model NULL-aligned source words
p7
aVThe input vector is a 14-word context vector (3 target words, 11
p8
a.