(lp0
VTo do so, we contrast different MT evaluation metrics with and without discourse information
p1
aVIn this paper, rather than proposing yet another MT evaluation metric, we show that discourse information is complementary to many existing evaluation metrics, and thus should not be ignored
p2
aVFurthermore, when combined with individual metrics in group II, DR- lex is able to improve consistently over each one of them
p3
aVThis suggests that both DR and DR- lex contain information that is complementary to that of the individual metrics that we experimented with
p4
aVIndividually, DR- lex outperforms most of the metrics from group II, and ranks as the second best metric in that group
p5
aVAgain, DR- lex is better than DR; with a positive Tau of +.133, yet as an individual metric, it ranks poorly compared to other metrics in group II
p6
aVThus, we can conclude that at the system-level, adding discourse information to a metric, even using the simplest of the combination schemes, is a good idea for most of the metrics, and can help to significantly improve the correlation with human judgments
p7
aVFor example, at WMT12, 12 metrics were compared [] , most of them new
p8
aVThese metrics tasks are based on sentence-level evaluation, which arguably can limit the benefits of using global discourse properties
p9
aVNote that the Asiya metrics are combinations of several metrics, and these combinations (which exclude DR and DR- lex ) can be also tuned; this yields sizable improvements over the untuned versions as column three in the table shows
p10
aV6 6 In Asiya the metrics from this family are referred to as
p11
a.