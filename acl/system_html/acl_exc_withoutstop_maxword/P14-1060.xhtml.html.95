<html>
<head>
<title>P14-1060.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>For composing the motifs representations to get judgments on semantic similarity of sentences, we use our recent Vector Tree Kernel approach The VTK approach defines a convolutional kernel over graphs defined by the dependency parses of sentences, using a vector representation at each graph node that representing a single lexical token</a>
<a name="1">[1]</a> <a href="#1" id=1>We present a framework for extending distributional semantics to learn semantic representations of both words and phrases in terms of recurrent motifs, rather than arbitrary word tokens</a>
<a name="2">[2]</a> <a href="#2" id=2>For this task, the motif based distributional embeddings vastly outperform a conventional distributional model (DSM) based on token distributions, as well as additive (AVM) and multiplicative (MVM) models of vector compositionality, as proposed by Lapata et al</a>
<a name="3">[3]</a> <a href="#3" id=3>For sentence polarity, we consider the Cornell Sentence Polarity corpus by Pang and Lee ( 2005 ) , where the task is to classify the polarity of a sentence as positive or negative</a>
<a name="4">[4]</a> <a href="#4" id=4>Section 3 describes our methodology, which consists of a frequency-driven segmentation model to partition text into semantically meaningful recurring lineal-subunits, a representation learning framework for learning new semantic embeddings based on this segmentation, and an approach to use such embeddings in downstream applications</a>
<a name="5">[5]</a> <a href="#5" id=5>Given constituent motifs of each sentence in the data, we can now define neighbourhood distributions for unary or phrasal motifs in terms of other motifs (as envisioned in Table 1</a>
<a name="6">[6]</a> <a href="#6" id=6>This is the overarching theme of this work we present a frequency driven paradigm for extending distributional semantics to phrasal and sentential levels in terms of such semantically cohesive, recurrent lexical units or motifs</a>
<a name="7">[7]</a> <a href="#7" id=7>For this task, the motif based model is expected to perform well as common metaphorical usage is generally through idiosyncratic MWEs, which the motif based models is specially geared to capture through the features of the segmentation model</a>
<a name="8">[8]</a> <a href="#8" id=8>We describe</a>
</body>
</html>