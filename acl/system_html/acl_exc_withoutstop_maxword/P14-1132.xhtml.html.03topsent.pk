(lp0
VThe process of learning to map objects to the their word label is implemented by training a projection function f proj v u'\u005cu2192' w from the visual onto the linguistic semantic space
p1
aVFor the learning, we use a set of N s seen concepts for which we have both image-based visual representations u'\u005cud835' u'\u005cudc15' s u'\u005cu2208' u'\u005cu211d' N s × d v and text-based linguistic representations u'\u005cud835' u'\u005cudc16' s u'\u005cu2208' u'\u005cu211d' N s × d w
p2
aV2013 ) use linear regression to transform vector-based image representations onto vectors representing the same concepts in linguistic semantic space
p3
aVIn this setting, we assume that our system possesses linguistic and visual information for a set of concepts in the form of text-based representations of words and image-based vectors of the corresponding objects, used for vision-to-language-mapping training
p4
aVObjects corresponding to concepts are represented in visual terms by vectors in an image-based semantic space (Section 4.2
p5
aVWe implement this second setup ( w u'\u005cu2192' v ) by training the projection function f proj w u'\u005cu2192' v which maps linguistic vectors to visual ones
p6
aVWe use a set of approximately 9,500 concepts, the intersection of the ESP-based visual semantic space with the linguistic space
p7
aVThe zero-shot framework leads us to frame fast mapping as the task of projecting visual representations of new objects onto language space for retrieving their word labels ( v u'\u005cu2192' w
p8
aVWhen the induced projection function maps an object onto the linguistic space, the derived text vector will inherit a mixture of textual features from the concepts that activated the same hidden unit as the object
p9
aVThe system is then provided with visual information for a previously unseen object, and the task is to associate it with a word by cross-modal mapping
p10
aVThe 71
p11
a.