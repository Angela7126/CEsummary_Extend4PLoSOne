<html>
<head>
<title>P14-1045.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Smote synthetizes and adds new instances similar to the minority class instances and is more efficient than a mere resampling</a>
<a name="1">[1]</a> <a href="#1" id=1>We tested the two strategies, by applying the classical Smote method of [] as a kind of resampling, and the ensemble method MetaCost of [] as a cost-aware learning method</a>
<a name="2">[2]</a> <a href="#2" id=2>For cost-aware learning, a sensible choice is to invert the class ratio for the cost ratio, i.e., here the cost of a mistake on a relevant link (false negative) is exactly 8.5 times higher than the cost on a non-relevant link (false positive), as non-relevant instances are 8.5 times more present than relevant ones</a>
<a name="3">[3]</a> <a href="#3" id=3>The random forest model is significantly improved by the balancing techniques the overall best F-score of 46.3% is reached with Random Forests and the cost-aware learning method</a>
<a name="4">[4]</a> <a href="#4" id=4>We analysed the learning curve by doing a cross-validation on reduced set of instances (from 10% to 90%); F1-scores range from 37.3% with 10% of instances and stabilize at 80%, with small increment in every case</a>
<a name="5">[5]</a> <a href="#5" id=5>MetaCost is an interesting meta-learner that can use any classifier as a base classifier</a>
<a name="6">[6]</a> <a href="#6" id=6>The method we propose here has been designed as an intrinsic evaluation with a view to validate semantic proximity links in a broad perspective, to cover what [] call u'\u201c' non classical lexical semantic relations u'\u201d'</a>
<a name="7">[7]</a> <a href="#7" id=7>If we take the best simple classifier (random forests), the precision and recall are 68.1 u'\u2062' % and 24.2 u'\u2062' % for an F-score of 35.7 u'\u2062' % , and this is significantly beaten by the Naive Bayes method as precision and recall are more even (F-score of 41.5%</a>
<a name="8">[8]</a> <a href="#8" id=8>One advantage of distributional similarities is to exhibit a lot of different semantic relations, not necessarily standard lexical relations</a>
<a name="9">[9]</a> <a href="#9" id=9>They are not suitable for the evaluation of the</a>
</body>
</html>