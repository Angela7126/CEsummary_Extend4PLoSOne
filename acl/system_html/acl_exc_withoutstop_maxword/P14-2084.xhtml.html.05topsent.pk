(lp0
VWe show that the misclassifications (with respect to whether comments contain irony or not) made by a standard text classification model significantly correlate with those comments for which human annotators requested additional context
p1
aVOn average, annotators requested additional context for 30% of comments (range across annotators of 12% to 56%
p2
aVThese pieces of information (previous comments by the same user, the external link of the embedding reddit thread, and the other comments in this thread) constitute our context
p3
aVAnd indeed, all three annotators requested additional context for this comment
p4
aVWe introduce the first version of the reddit irony corpus , composed of annotated comments from the social news website reddit
p5
aVRecall that our annotation tool allows labelers to request additional context if they cannot make a decision based on the comment text alone (Figure 1
p6
aVPut another way, the model makes mistakes on those comments for which annotators requested additional context (even after accounting for the annotator designation of comments
p7
aVWe now explore empirically whether these misclassifications are made
p8
a.