(lp0
VThe model consists of a lookup layer, a hidden layer, and an output layer, which have weight matrices
p1
aVFinally, the output layer receives the output of the hidden layer ( z 1 ) and computes a lexical translation score
p2
aVThe output of the hidden layer ( y j ) is copied and fed to the output layer and the next hidden layer
p3
aVNext, the hidden layer receives the output of the lookup layer ( x j ) and that of the previous hidden layer ( y j - 1
p4
aVThe model consists of a lookup layer, a hidden layer, and an output layer, which have weight matrices L , { H d , R d , B H d } , and { O , B O } , respectively
p5
aVWe evaluated the proposed RNN-based alignment models against two baselines the IBM Model 4 and the FFNN-based model with one hidden layer
p6
aVIn the lookup layer, each of these words is converted to its word embedding, and then the concatenation of the two embeddings ( x j ) is fed to the hidden layer in the same manner as the FFNN-based model
p7
aVThe proposed RNN produces a single score
p8
a.