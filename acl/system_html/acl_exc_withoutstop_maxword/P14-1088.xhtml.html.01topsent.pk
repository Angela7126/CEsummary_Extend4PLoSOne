(lp0
V4) \u005ctnote [c]3 annotators, avg
p1
aV[botcap, caption=Sizes of the different IAA corpora, label=tbl:corpora, mincapwidth=]lcc \u005ctnote [a]2 annotators \u005ctnote [b]4 annotators, avg
p2
aV6) \u005ctnote [e]3 annotators, avg
p3
aV2.7 annotators/text \u005ctnote [d]11 annotators, avg
p4
aVThe tree edit distance (TED) problem is defined analogously to the more familiar problem of string edit distance what is the minimum number of edit operations required to transform one tree into the other
p5
aVInstead, we base our work on tree edit distance
p6
aVFor large data sets such as the PCEDT set used in this work, computing u'\u005cu0391' with tree edit distance as the distance measure can take a very long time
p7
aVIn this article we propose a family of chance-corrected measures of agreement, applicable to both dependency- and constituency-based syntactic annotation, based on Krippendorff u'\u005cu2019' s u'\u005cu0391' and tree edit distance
p8
aVInstead, we propose to use an agreement measure based on Krippendorff u'\u005cu2019' s u'\u005cu0391' [] and tree edit distance
p9
aVTree edit distance has previously been used in the TedEval software [] for parser evaluation agnostic to both annotation scheme and theoretical framework, but this by itself is still an uncorrected accuracy measure and thus unsuitable for our purposes
p10
aVSee \u005cciteN Bille05 for a thorough introduction to the tree edit distance problem and other related problems
p11
aV2, max
p12
aV2, max
p13
aVIn future work, we would like to investigate the use of other distance functions, in particular the use of approximate tree edit distance functions such as the p u'\u005cu2062' q -gram algorithm []
p14
aV[botcap, caption=Agreement scores on real-world corpora, label=tbl:alpha-real, mincapwidth=]lcccc \u005ctnote [a]2 sentences ignored \u005ctnote [b]15 sentences ignored \u005ctnote [c]1178 sentences ignored \u005ctnote [d]Mean pairwise Jaccard similarity \u005cFL Corpus Align u'\u005cu0391' p u'\u005cu2062' l u'\u005cu2062' a u'\u005cu2062' i u'\u005cu2062' n Align u'\u005cu0391' d u'\u005cu2062' i u'\u005cu2062' f u'\u005cu2062' f Align u'\u005cu0391' n u'\u005cu2062' o u'\u005cu2062' r u'\u005cu2062' m Align LAS \u005cML NDT 1 Align 98.4 Align 93.0 Align 98.8 Align 94.0 \u005cNN NDT 2 Align 98.9 Align 95.0 Align 99.1 Align 94.4 \u005cNN NDT 3 Align 97.9 Align 91.2 Align 98.7 Align 95.3 \u005cML CDT (da) Align 95.7 Align 84.7 Align 96.2 Align 90.4 \u005cNN CDT (en) Align 92.4 Align 70.7 Align 95.0 Align 88.4 \u005cNN CDT (es) Align 86.6 Align 48.8 Align 85.8 Align 78.9 \u005ctmark [a] \u005cNN CDT (it) Align 84.5 Align 55.7 Align 89.2 Align 81.3 \u005ctmark [b] \u005cML PCEDT Align 95.9 Align 89.9 Align 96.5 Align 68.0 \u005ctmark [c] \u005cML SSD Align
p15
a.