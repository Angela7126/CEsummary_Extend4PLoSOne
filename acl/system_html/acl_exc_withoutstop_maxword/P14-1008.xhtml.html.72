<html>
<head>
<title>P14-1008.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Moreover, to compensate the lack of background knowledge in practical inference, we combine our framework with the idea of tree transformation [] , to propose a way of generating knowledge in logical representation from entailment rules [] , which are by now typically considered as syntactic rewriting rules</a>
<a name="1">[1]</a> <a href="#1" id=1>The experiments show i) a competitive performance on FraCaS dataset; (ii) a big impact of our automatically generated on-the-fly knowledge in achieving high recall for a logic-based RTE system; and (iii) a result that outperforms state-of-the-art RTE system on RTE5 data</a>
<a name="2">[2]</a> <a href="#2" id=2>To formulate the database querying process defined by a DCS tree, we provide formal semantics to DCS trees by employing relational algebra [] for representing the query</a>
<a name="3">[3]</a> <a href="#3" id=3>The labels on both ends of an edge, such as SUBJ (subject) and OBJ (object), are considered as semantic roles of the corresponding words 1 1 The semantic role ARG is specifically defined for denoting nominal predicate</a>
<a name="4">[4]</a> <a href="#4" id=4>We extract fragments of DCS trees as paraphrase candidates, translate them back to linguistic expressions, and apply distributional similarity to judge their validity</a>
<a name="5">[5]</a> <a href="#5" id=5>To obtain DCS trees from natural language, we use Stanford CoreNLP 5 5 http://nlp.stanford.edu/software/corenlp.shtml for dependency parsing [] , and convert Stanford dependencies to DCS trees by pattern matching on POS tags and dependency labels</a>
<a name="6">[6]</a> <a href="#6" id=6>For example, the similarity score of the path alignment u'\u201c' OBJ ( blame ) IOBJ - ARG ( death ) u'\u2248' SUBJ ( cause ) OBJ - ARG ( loss ) MOD - ARG ( life ) u'\u201d' is calculated as the cosine similarity of vectors blame + death and cause + loss + life</a>
<a name="7">[7]</a> <a href="#7" id=7>In this section we describe the idea of representing natural language semantics by DCS trees, and achieving inference by computing logical relations among the corresponding abstract denotations</a>
<a name="8">[8]</a> <a href="#8" id=8>In this logical system, we treat abstract denotations as terms and statements as atomic sentences , which are far more easier to handle than first order predicate logic (FOL) formulas</a>
<a name="9">[9]</a> <a href="#9" id=9>The idea is to borrow a minimal set of operators from relational algebra [] , which is already able to formulate the calculation in DCS and define abstract denotation , which is an abstraction of the computation of denotations guided by DCS trees</a>
<a name="10">[10]</a> <a href="#10" id=10>Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved in Figure 6 , though the tree transformation can be seen as generated from the entailment rule u'\u201c' X is blamed for death u'\u2192' X causes loss of life u'\u201d' , the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby</a>
<a name="11">[11]</a> <a href="#11" id=11>DCS trees can be extended to represent linguistic phenomena such as quantification and coreference, with additional markers introducing additional operations on tables</a>
<a name="12">[12]</a> <a href="#12" id=12>For example, though u'\u201c' Italy beats Kazakhstan u'\u201d' is not primarily proven from u'\u201c' Italy is defeated by Kazakhstan u'\u201d' , our system does produce the path alignment u'\u201c' SUBJ ( beat ) OBJ u'\u2248' OBJ ( defeat ) SUBJ u'\u201d' with a high similarity score</a>
<a name="13">[13]</a> <a href="#13" id=13>Bos06 [] is a hybrid system combining deep features from a theorem prover and a model builder, together with shallow features such as lexical overlap and text length</a>
<a name="14">[14]</a> <a href="#14" id=14>Our solution is to redefine DCS trees without the aid of any databases, by considering each node of a DCS tree as a content word in a sentence (but may no longer be a table in a specific database), while each edge represents semantic relations between two words</a>
<a name="15">[15]</a> <a href="#15" id=15>Applied by our logical system, the noisy on-the-fly knowledge can achieve a precision comparable to higher quality resources such as DIRT</a>
<a name="16">[16]</a> <a href="#16" id=16>These are algebraic properties of abstract denotations, among which we choose a set of axioms that can be handled efficiently and enable most common types of inference seen in natural language</a>
<a name="17">[17]</a> <a href="#17" id=17>As a comparison, studied the proportion of proven pairs and precision by applying DIRT rules to tree skeletons in RTE2 and RTE3 data</a>
<a name="18">[18]</a> <a href="#18" id=18>Selection operators are implemented as markers assigned</a>
</body>
</html>