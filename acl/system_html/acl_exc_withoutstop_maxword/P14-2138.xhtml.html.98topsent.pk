(lp0
VThe results of this experiment are reported in the Indicative Bigrams column of Table 2
p1
aVThe results are shown in the Baseline column of Table 2
p2
aVUsing Algorithm 2 , we identify the top 20 character bigrams, and replace them with randomly selected bigrams
p3
aVHowever, we limit the set of features to the 200 most frequent bigrams for the sake of consistency with previous work
p4
aVWe follow the setup of Tsur and Rappoport ( 2007 ) by extracting two sets, denoted I1 and I2 (Table 1 ), from the International Corpus of Learner English (ICLE), Version 2 [ 10 ]
p5
aVWe replicate the experiments of Tsur and Rappoport ( 2007 ) by limiting the features to the 200 most frequent character bigrams
p6
aVWe use these feature vectors as input to the SVM-Multiclass classifier [ 14 ]
p7
aVThe remaining bigrams indicate function words, toponymic terms like Germany , and frequent content words like take and new
p8
aVUsing Algorithm 2 , we identify the 100 most discriminative words, and remove them from the training data
p9
aVAs the orthography of alphabetic languages is at least partially representative of the underlying phonology, character bigrams may capture these phonological preferences
p10
aVHowever, the fact that the two bigrams are also on the list for the I2 set, which does not include these languages, suggests that their importance is mostly due to the function words
p11
aVWe see a statistically significant drop in
p12
a.