<html>
<head>
<title>P14-1124.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>For the Tagalog conversations, as with English newswire, we observe that the document frequency, DF w , of a word w is not a linear function of word frequency f w in the log domain, as would be expected under a naive Poisson generative assumption</a>
<a name="1">[1]</a> <a href="#1" id=1>We evaluate term detection and word repetition-based re-scoring on the IARPA BABEL training and development corpora 1 1 Language collection releases IARPA-babel101-v0.4c, IARPA-babel104b-v0.4bY, IARPA-babel105b-v0.4, IARPA-babel106-v0.2g and IARPA-babel107b-v0.7 respectively for five languages Cantonese, Pashto, Turkish, Tagalog and Vietnamese []</a>
<a name="2">[2]</a> <a href="#2" id=2>Our observation of the variability in co-occurrence statistics between Tagalog training and development partitions leads us to narrow the scope of document context to same word co-occurrences, i.e., word repetitions</a>
<a name="3">[3]</a> <a href="#3" id=3>The primary difference between this and previous work on similar language models is the narrower focus here on the term detection task, in which we consider each search term in isolation, rather than all words in the vocabulary</a>
<a name="4">[4]</a> <a href="#4" id=4>Given the rise of unsupervised latent topic modeling with Latent Dirchlet Allocation [] and similar latent variable approaches for discovering meaningful word co-occurrence patterns in large text corpora, we ought to be able</a>
</body>
</html>