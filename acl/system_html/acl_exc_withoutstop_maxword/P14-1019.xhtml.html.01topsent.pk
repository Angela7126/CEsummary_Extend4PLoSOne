(lp0
VStarting with an initial candidate tree, our inference procedure climbs the scoring function in small (cheap) stochastic steps towards a high scoring parse
p1
aVWe first compare our model to the Turbo parser using the Turbo parser feature set
p2
aVBecause the number of alternatives is small, the scoring function could in principle involve arbitrary (global) features of parse trees
p3
aVJoint Parsing and POS Correction Table 3 shows the results of joint parsing and POS correction on the CATiB dataset, for our model and state-of-the-art systems
p4
aVBaselines We compare our model with the Turbo parser and the MST parser
p5
aVPOS Tag Features In the joint POS correction scenario, we also add additional features specifically for POS prediction
p6
aVWe extend our model such that it jointly learns how to predict a parse
p7
a.