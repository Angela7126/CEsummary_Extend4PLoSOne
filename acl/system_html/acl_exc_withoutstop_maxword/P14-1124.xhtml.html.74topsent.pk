(lp0
VWe consider term detection rather than the transcription task in considering how to exploit topic context, because in evaluating the retrieval of certain key terms we need not focus on improving the entire word sequence
p1
aVLastly, the reductions in P u'\u005cu2062' ( Miss ) suggests that we are improving the term detection metric, which is sensitive to threshold changes, by doing what we set out to do, which is to boost lower confidence repeated words and correctly asserting them as true hits
p2
aVWe illustrate this variability by looking at how consistent word co-occurrences are between two separate corpora in the same language i.e.,, if we observe words that frequently co-occur with a keyword in the training corpus, do they also co-occur with the keywords in a second held-out corpus
p3
aVIn general, we can think of using word repetitions to re-score term detection as applying a limited form of adaptive or cache language model []
p4
aVAs it turns out this u'\u005cu2018' burstiness u'\u005cu2019' of words within documents, as the term is defined by Church and Gale in their work on Poisson mixtures (1995), provides a
p5
a.