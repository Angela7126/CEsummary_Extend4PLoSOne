(lp0
VConsequently, the Wsabie Embedding model can share more information between different examples in the training data than the Log-Linear Embedding model
p1
aVSo the second baseline has the same input representation as Wsabie Embedding but uses a log-linear model instead of Wsabie
p2
aVWe believe that the Wsabie Embedding model performs better than the Log-Linear Embedding baseline (that uses the same input representation) because the former setting allows examples with different labels and confusion sets to share information; this is due to the fact that all labels live in the same label space, and a single projection matrix is shared across the examples to map the input features to this space
p3
aVThe second baseline, tries to decouple the Wsabie training from the embedding input, and trains a log linear model using the embeddings
p4
aVSince the Log-Linear Words model always performs better than the Log-Linear Embedding model, we conclude that the primary benefit does not come from the input embedding representation
p5
aVFor FrameNet, the Wsabie Embedding model we propose strongly outperforms the baselines on all metrics, and sets a new state of the art
p6
aVThe model computes a composed representation of the predicate instance by using distributed vector representations for words (3) u'\u005cu2013' the (red) vertical embedding vectors for each word are concatenated into a long vector
p7
aVA word embedding is a distributed representation of meaning where each word is represented as a vector in u'\u005cu211d' n
p8
aVFirst, we extract the words in the syntactic context of runs ; next, we concatenate their word embeddings as described in § 2.2 to create an initial vector space representation
p9
aVAdditionally, this model uses the un-conjoined words as backoff features
p10
aVFor FrameNet, estimating the label embedding is not as much of a problem because even if a lexical unit is rare, the potential frames can be frequent
p11
aVSubsequently, we learn a mapping from this initial representation into a low-dimensional space; we also learn an embedding for each possible frame label in the same low-dimensional space
p12
aVThe first one computes the direct dependents and dependency paths as described in § 3.1 but conjoins them with the word identity rather than a word embedding
p13
aVOn the PropBankdata, we see that the Log-Linear Words baseline has roughly the same performance as our model on most metrics slightly better on the test data and slightly worse on the development data
p14
aVSuch representations allow a model to share meaning between similar words, and have been used to capture semantic, syntactic and morphological content [ 6 , 25 , inter alia ]
p15
aVThis set of dependency paths were deemed as possible positions in the initial vector space representation
p16
aVIf a label occurs multiple times, then the embeddings of the words below this label are averaged
p17
aVHowever, since the input representation is shared across all frames, every other training example from all the lexical units affects the optimal estimate, since they all modify the joint parameter matrix M
p18
aVSince Wsabie learns a single mapping from g u'\u005cu2062' ( x ) to u'\u005cu211d' m , parameters are shared between different words and different frames
p19
aVIn other words, it must estimate 512 parameters based on at most 10 training examples
p20
aVThus, the context is a vector in u'\u005cu211d' n u'\u005cu2062' k with the embedding of He at the subject position, the embedding of company in direct object position and zeros everywhere else
p21
aVWe denote the frames that associate with u'\u005cu2113' in the frame lexicon 5 5 The frame lexicon stores the frames, corresponding semantic roles and the lexical units associated with the frame and our training corpus as F u'\u005cu2113'
p22
aVSo for example u'\u005cu201c' He runs the company u'\u005cu201d' could help the model disambiguate u'\u005cu201c' He owns the company u'\u005cu201d' Moreover, since g u'\u005cu2062' ( x ) relies on word embeddings rather than word identities, information is shared between words
p23
aVThis can be partially explained with the significantly larger training set size for PropBank, making features based on words more useful
p24
aVThe mapping from g u'\u005cu2062' ( x ) to the low dimensional space u'\u005cu211d' m is a linear transformation, so the model parameters to be learnt are the matrix M u'\u005cu2208' u'\u005cu211d' n u'\u005cu2062' k × m as well as the embedding of each possible frame label, represented as another matrix Y u'\u005cu2208' u'\u005cu211d' F × m where there are F frames in total
p25
aVFor example, if the label on the edge between runs and He is nsubj , we would put the embedding of He in the block corresponding to nsubj
p26
aVIn addition, akin to the first context function, we also added all dependency labels to the context set
p27
aVFrameNet The FrameNetproject [ 2 ] is a lexical database that contains information about words and phrases (represented as lemmas conjoined with a coarse part-of-speech tag) termed as lexical units, with a set of semantic frames that they could evoke
p28
aVGiven a predicate in its sentential context, we therefore extract only those context words that appear in positions warranted by the above set
p29
aVWe noted that this renders every lexical unit as seen ; in other words, at frame disambiguation time on our test set, for all instances, we only had to score the frames in F u'\u005cu2113' for a predicate with lexical unit u'\u005cu2113' (see § 3 and § 5.2
p30
aVWe search for the stochastic gradient learning rate in { 0.0001 ¯ , 0.001 , 0.01 } , the margin u'\u005cu0393' u'\u005cu2208' { 0.001 , 0.01 ¯ , 0.1 , 1 } and the dimensionality of the final vector space m u'\u005cu2208' { 256 ¯ , 512 } , to maximize the frame identification accuracy of ambiguous lexical units; by ambiguous, we imply lexical units that appear in the training data or the lexicon with more than one semantic frame
p31
aVThus for this context function, the block cardinality k was the sum of the number of scanned gold dependency path types and the number of dependency labels
p32
aVWsabie performs gradient-based updates on an objective that tries to minimize the distance between M u'\u005cu2062' ( g u'\u005cu2062' ( x ) ) and the embedding of the correct label Y u'\u005cu2062' ( y ) , while maintaining a large distance between M u'\u005cu2062' ( g u'\u005cu2062' ( x ) ) and the other possible labels Y u'\u005cu2062' ( y ¯ ) in the confusion set F u'\u005cu2113'
p33
aVTo elaborate, the positions of interest are the labels of the direct dependents of the predicate, so k is the number of labels that the dependency parser can produce
p34
aVLet the lexical unit (the lemma conjoined with a coarse POS tag) for the marked predicate be u'\u005cu2113'
p35
aVThis would be a standard NLP approach for the frame identification problem, but is surprisingly competitive with the state of the art
p36
aVFor fair comparison, we took the lexical units for the predicates that Das et al. considered as seen, and constructed a lexicon with only those; training instances, if any, for the unseen predicates under Das et al u'\u005cu2019' s setup were thrown out as well
p37
aVIf we have F possible frames we can store those parameters in an F × m matrix, one m -dimensional point for each frame, which we will refer to as the linear mapping Y
p38
aV14 14 The last row of Table 6 refers to a system which used the combination of two syntactic parsers as input
p39
aVInference Although our learning mechanism uses a local log-linear model, we perform inference globally on a per-frame basis by applying hard structural constraints
p40
aVAdditionally, since we use a frame lexicon that gives us the possible frames for a given predicate, we usually only consider a handful of candidate labels
p41
aVIf we used all training examples for a given predicate for finding a nearest-neighbor match at inference time, we would have to consider many more candidates, making the process very slow
p42
aVAll the verb frame files in Ontonotes were used for creating our frame lexicon
p43
aVAt test time, this model chooses the best frame as argmax y u'\u005cu2062' u'\u005cud835' u'\u005cudf4d' u'\u005cu22c5' u'\u005cud835' u'\u005cudc1f' u'\u005cu2062' ( y , x , u'\u005cu2113' ) where argmax iterates over the possible frames y u'\u005cu2208' F u'\u005cu2113' if u'\u005cu2113' was seen in the lexicon or the training data, or y u'\u005cu2208' F , if it was unseen, like the disambiguation scheme of § 3
p44
aVAt disambiguation time, we use a simple dot product similarity as our distance metric, meaning that the model chooses a label by computing the argmax y u'\u005cu2062' s u'\u005cu2062' ( x , y ) where s u'\u005cu2062' ( x , y ) = M u'\u005cu2062' ( g u'\u005cu2062' ( x ) ) u'\u005cu22c5' Y u'\u005cu2062' ( y ) , where the argmax iterates over the possible frames y u'\u005cu2208' F u'\u005cu2113' if u'\u005cu2113' was seen in the lexicon or the training data, or y u'\u005cu2208' F , if it was unseen
p45
aVWe could represent the syntactic context of runs as a vector with blocks for all the possible dependents warranted by a syntactic parser; for example, we could assume that positions 0 u'\u005cu2062' u'\u005cu2026' u'\u005cu2062' n in the vector correspond to the subject dependent, n + 1 u'\u005cu2062' u'\u005cu2026' u'\u005cu2062' 2 u'\u005cu2062' n correspond to the clausal complement dependent, and so forth
p46
aVWe train this model by maximizing L 2 regularized log-likelihood, using L-BFGS; the regularization constant was set to 0.1 in all experiments
p47
aVFor all our experiments, setting 3) which concatenates the direct dependents and dependency path always dominated the other two, so we only report results for this setting
p48
aVAccording to the theory of frame semantics [ 12 ] , a semantic frame represents an event or scenario, and possesses frame elements (or semantic roles ) that participate in the event
p49
aVMoreover, for full frame-semantic parsing, with the presented frame identification technique followed by our argument identification method, we report the best results on this task to date
p50
aVFinally, Table 6 presents SRL results that measures argument performance only, irrespective of the frame; we use the evaluation script from CoNLL 2005 [ 5 ]
p51
aV2 2 Additional information such as finer distinction of the coreness properties of roles, the relationship between frames, and that of roles are also present, but we do not leverage that information in this work
p52
aVFor each frame, there is a list of associated frame elements (or roles, henceforth), that are also distinguished as core or non-core
p53
aVArgument Candidates The candidate argument extraction method used for the FrameNet data, (as mentioned in § 4 ) was adapted from the algorithm of Xue and Palmer ( 2004 ) applied to dependency trees
p54
aVa set of tuples that associates each role r in u'\u005cu211b' y with a span a according to the gold data
p55
aVSince the original algorithm was designed for verbs, we added a few extra rules to handle non-verbal predicates we added 1) the predicate itself as a candidate argument, 2) the span ranging from the sentence position to the right of the predicate to the rightmost index of the subtree headed by the predicate u'\u005cu2019' s head; this helped capture cases like u'\u005cu201c' a few months u'\u005cu201d' (where few is the predicate and months is the argument), and 3) the span ranging from the leftmost index of the subtree headed by the predicate u'\u005cu2019' s head to the position immediately before the predicate, for cases like u'\u005cu201c' your gift to Goodwill u'\u005cu201d' (where to is the predicate and your gift is the argument
p56
aVBy providing richer representations of meaning than what can be encompassed in a discrete representation, such approaches have successfully been applied to tasks such as sentiment analysis [ 24 ] , topic classification [ 16 ] or word-word similarity [ 20 ]
p57
aV2008 ) we use the log-probability of the local classifiers as a score in an integer linear program (ILP) to assign roles subject to hard constraints described in § 5.4 and § 5.5
p58
aVSince the CoNLL 2004-2005 shared tasks [ 4 , 5 ] on PropBank semantic role labeling (SRL), it has been treated as an important NLP problem
p59
aVHyperparameters As in § 5.4 , we made a hyperparameter sweep in the same space
p60
aVChoosing L u'\u005cu2062' ( u'\u005cu0397' ) = C u'\u005cu2062' u'\u005cu0397' for any positive constant C optimizes the mean rank, whereas a weighting such as L u'\u005cu2062' ( u'\u005cu0397' ) = u'\u005cu2211' i = 1 u'\u005cu0397' 1 / i (adopted here) optimizes the top of the ranked list, as described in [ 26 ]
p61
aVFrom x , a rule-based candidate argument extraction algorithm extracts a set of spans u'\u005cud835' u'\u005cudc9c' that could potentially serve as the overt 7 7 By overtness, we mean the non-null instantiation of a semantic role in a frame-semantic parse arguments u'\u005cud835' u'\u005cudc9c' y for y (see § 5.4 -§ 5.5 for the details of the candidate argument extraction algorithms
p62
aVWe used the same test set as Das et al containing 23 documents with 4,458 predicates
p63
aVWe see the same trend as in Table 4
p64
aV1) each span could have only one role, 2) each core role could be present only once, and 3) all overt arguments had to be non-overlapping
p65
aVOf the remaining 55 documents, 16 documents were randomly chosen for development
p66
aVWe call this model Log-Linear Embedding
p67
aVWsabie also learns an embedding for each frame label ( y , henceforth
p68
aVFor comparison with our model from § 3 , which we call Wsabie Embedding , we implemented two baselines with the log-linear model
p69
aV[25][t] Context representation extraction for the embedding model
p70
aVThe Wsabie Embedding model from § 3 performs significantly better than the Log-Linear Words baseline, while Log-Linear Embedding underperforms in every metric
p71
aVWe present a model that takes word embeddings as input and learns to identify semantic frames
p72
aVRecall that the Wsabie Embedding model needs to estimate the label location in u'\u005cu211d' m for each frame
p73
aVWe learn the initial embedding representations for our frame identification model (§ 3 ) using a deep neural language model similar to the one proposed by Bengio et al
p74
aVSimultaneously, the model learns an embedding for all the possible labels (i.e., the frames in a given lexicon
p75
aVWsabie Embedding performs poorly in this setting while Log-Linear Embedding performs well
p76
aVGiven a dependency parse (1) the model extracts all words matching a set of paths from the frame evoking predicate and its direct dependents (2
p77
aVHyperparameters For our frame identification model with embeddings, we search for the Wsabie hyperparameters using the development data
p78
aVWe call this baseline Log-Linear Words
p79
aVThe advantage of learning an embedding for the frame labels is that at inference time we need to consider only the set of labels for classification rather than all training examples
p80
aVMost work on frame-semantic parsing has usually divided the task into two major subtasks frame identification , namely the disambiguation of a given predicate to a frame, and argument identification (or semantic role labeling), the analysis of words and phrases in the sentential context that satisfy the frame u'\u005cu2019' s semantic roles [ 8 , 7 ]
p81
aVFrame Lexicon In our experimental setup, we scanned the XML files in the u'\u005cu201c' frames u'\u005cu201d' directory of the FrameNet 1.5 release, which lists all the frames, the corresponding roles and the associated lexical units, and created a frame lexicon to be used in our frame and argument identification models
p82
aVWe use word embeddings to represent the syntactic context of a particular predicate instance as a vector
p83
aVThe Log-Linear Words model does not have this entanglement, but cannot share information between words
p84
aVGiven input vectors of this form for our training data, we learn a matrix that maps this high dimensional and sparse representation into a lower dimensional space
p85
aVHere, we briefly describe the argument identification model used in our frame-semantic parsing experiments, post frame identification
p86
aVA particularly interesting comparison is between our Log-Linear Words baseline and the supervised model of Das et al
p87
aVGiven x , the sentence with a marked predicate, the argument identification model assumes that the predicate frame y has been disambiguated
p88
aVWe present a new technique for semantic frame identification that leverages distributed word representations
p89
aVAt inference time, the predicate-context is mapped to the low dimensional space, and we choose the nearest frame label as our classification
p90
aV15 15 One could imagine training a Wsabie model with word features, but we did not perform this experiment
p91
aVWe note that with a better frame identification model, our performance on SRL improves in general
p92
aVModeling In this paper, we model the frame-semantic parsing problem in two stages frame identification and argument identification
p93
aVFor example g selects some important positions relative to the predicate, and reserves a block in its output space for the embedding of words found at that position
p94
aVWe scanned the training data for a given task (either the PropBank or the FrameNet domains) for the dependency paths that connected the gold predicates to the gold semantic arguments
p95
aV11 11 Instead of using the frame files, Das et al. built a frame lexicon from FrameNet u'\u005cu2019' s exemplars and the training corpus
p96
aVIn both variants, our representation is a block vector where each block corresponds to a syntactic position relative to the predicate, and each block u'\u005cu2019' s values correspond to the embedding of the word at that position
p97
aVFor PropBank, these drawbacks and benefits balance out and we see similar performance for Log-Linear Words and Log-Linear Embedding
p98
aVThe goal of learning is to make sure that the correct frame label is as close as possible to the mapped context, while competing frame labels are farther away
p99
aVHere, too, the embedding model barely misses the performance of the best baseline, but we are at par and sometimes better than the single parser setting of a state-of-the-art SRL system [ 23 ]
p100
aVOn the test set, the Log-Linear Words baseline performs best by a very narrow margin
p101
aVModel learning is performed using the margin ranking loss function as described in Weston et al
p102
aVWe model our objective function following Weston et al
p103
aVWe performed initial experiments using context extracted from 1) direct dependents, 2) dependency paths, and 3) both
p104
aVWe present results on all predicates, ambiguous predicates seen in the lexicon or the training data, and rare ambiguous predicates that appear u'\u005cu2264' 11 times in the training data
p105
aVTable 3 presents results on the full frame-semantic parsing task (measured by a reimplementation of the SemEval 2007 shared task evaluation script) when our argument identification model (§ 4 ) is used after frame identification
p106
aVThe baselines use a log-linear model that models the following probability at training time
p107
aVFrame Lexicon For the PropBankexperiments we scanned the frame files for propositions in Ontonotes 4.0, and stored possible core roles for each verb frame
p108
aVLike FrameNet, it also has a lexical database that stores type information about verbs, in the form of sense frames and the possible semantic roles each frame could take
p109
aVThe mapping M is a linear transformation, and we learn it using the Wsabie algorithm [ 29 ]
p110
aVTable 2 presents accuracy results on frame identification
p111
aVHere, we focus on the first subtask of frame identification for given predicates; we use our novel method (§ 3 ) in conjunction with a standard argument identification model (§ 4 ) to perform full frame-semantic parsing
p112
aVDirect Dependents u'\u005cu2004' The first context function we considered corresponds to the examples in § 3
p113
aVWe call this setup Full Lexicon
p114
aVDependency Paths u'\u005cu2004' To capture more relevant context, we developed a second context function as follows
p115
aVWe next describe this model in detail
p116
aVWe evaluate our novel frame identification approach in isolation and also conjoined with argument identification resulting in full frame-semantic structures; before presenting our model u'\u005cu2019' s performance we first focus on the datasets, baselines and the experimental setup
p117
aVAnother difference is that when training the log-linear model, they normalize over all frames, while we normalize over the allowed frames for the current lexical unit
p118
aVWe use the same word clusters for the argument identification features in Table 1
p119
aVFinally, we learn a linear transformation function parametrized by the context blocks (4
p120
aVFor example, consider the sentence u'\u005cu201c' He runs the company u'\u005cu201d' The predicate runs has two syntactic dependents u'\u005cu2013' a subject and direct object (but no prepositional phrases or clausal complements
p121
aVBoth the baselines use features very similar to the input representations described in § 3.1
p122
aVSection 3.1 describes the context positions we use in our experiments
p123
aVV has three verb frames and in sentential context, we want to disambiguate its frame
p124
aVFrom a frame lexicon, we look up the set of semantic roles u'\u005cu211b' y that associate with y
p125
aVWe call this setup Semafor Lexicon
p126
aVOn the development set, our best model performs with the highest accuracy on all and ambiguous predicates, but performs worse on rare ambiguous predicates
p127
aVTable 4 shows frame identification results on the PropBankdata
p128
aV2014 ) , but they use unlemmatized words to define their confusion set
p129
aVV is a rare lexical unit
p130
aVWe continue using the example sentence from § 2.2 u'\u005cu201c' He runs the company u'\u005cu201d' where we want to disambiguate the frame of runs in context
p131
aVAlthough PropBank never formally uses the term lexical unit, we adopt its usage from the frame semantics literature.) and a stage that finds the various arguments that fulfill the frame u'\u005cu2019' s semantic roles within the sentence, respectively
p132
aVPart of the explanation has to do with the specifics of Wsabie training
p133
aVFormally, let x represent the actual sentence with a marked predicate, along with the associated syntactic parse tree; let our initial representation of the predicate context be g u'\u005cu2062' ( x
p134
aVAs mentioned in § 1 , these correspond to a frame disambiguation stage, 4 4 For example in PropBank, the lexical unit buy
p135
aVWe use the same test set as in Das et al
p136
aVFirst, we show that for frame identification on the FrameNet corpus [ 2 , 11 ] , we outperform the prior state of the art [ 7 ]
p137
aVFor the Semafor Lexicon setup, we also compare with the state of the art from Das et al
p138
aVClosely related to SRL, frame-semantic parsing consists of the resolution of predicate sense into a frame, and the analysis of the frame u'\u005cu2019' s arguments
p139
aV2014 ) describe the state of the art in FrameNet-based analysis, but their argument identification strategy considered all possible dependency subtrees in a parse, resulting in a much larger search space
p140
aVMoreover, role labels, although few in number, take specific meaning for each verb frame
p141
aVFinally, for the Full Lexicon setting, the absolute accuracy numbers are even better for our best model
p142
aVIn our setting, this means that each frame corresponds to a point in u'\u005cu211d' m
p143
aVDistributed representations of words have proved useful for a number of tasks
p144
aVwhere p u'\u005cud835' u'\u005cudf3d' is a log-linear model normalized over the set u'\u005cu211b' y , with features described in Table 1
p145
aVCommerce_buy is a frame that can be evoked by morphological variants of the two example lexical units buy
p146
aVTable 5 presents results where we measure precision, recall and F 1 for frames and arguments together; this strict metric penalizes arguments for mismatched frames, like in Table 3
p147
aVIn comparison to prior work on FrameNet, even our baseline models outperform the previous state of the art
p148
aVThe training objective function minimizes
p149
aVThere are modifier roles that are shared across verb frames, somewhat similar to the non-core roles in FrameNet
p150
aVConsider u'\u005cu201c' He runs the company u'\u005cu201d' vs u'\u005cu201c' It was the company that he runs u'\u005cu201d' In the second sentence, the discriminating word, company dominates the predicate runs
p151
aVBy contrast, in the log-linear models each label has its own set of parameters, and they interact only via the normalization constant
p152
aVWe also experimented on the set of unseen instances used by Das et al
p153
aVAnother important distinction between PropBankand FrameNetis that the latter shares frames between multiple lexical units
p154
aVFor comparison, we implemented a set of baseline models, with varying feature configurations
p155
aVFigure 1 highlights this difference while both sell v and buy v are members of the same frame in FrameNet, they evoke different frames in PropBank
p156
aVThe lexical units were simply the verb associating with the verb frames
p157
aVSecond, we present results on PropBank-style semantic role labeling [ 22 , 19 , 21 ] , that approach strong baselines, and are on par with prior state of the art [ 23 ]
p158
aVHowever, research has mostly focused on argument analysis, skipping the frame disambiguation step, and its interaction with argument identification
p159
aVSentences are annotated using this universal frame inventory
p160
aVThey also use a log-linear model, but they incorporate a latent variable that uses WordNet [ 10 ] to get lexical-semantic relationships and smooths over frames for ambiguous lexical units
p161
aVWe notice similar trends as in Table 2 , and our results outperform the previously published best results, setting a new state of the art
p162
aVWhile comparing with prior state of the art on the same corpus, we noted that Das et al
p163
aVWe process our PropBank and FrameNet training, development and test corpora with a shift-reduce dependency parser that uses the Stanford conventions [ 9 ] and uses an arc-eager transition system with beam size of 8; the parser and its features are described by Zhang and Nivre ( 2011
p164
aVFor unseen predicates from the Das et al. system, we perform better as well
p165
aV6 6 This disambiguation scheme is similar to the one adopted by Das et al
p166
aVwhere x , y are the training inputs and their corresponding correct frames, and y ¯ are negative frames, u'\u005cu0393' is the margin
p167
aV1 1 There are exceptions, wherein the task has been modeled using a pipeline of three classifiers that perform frame identification, a binary stage that classifies candidate arguments, and argument identification on the filtered candidates [ 1 , 15 ]
p168
aVThen g is a function from a parsed sentence x to u'\u005cu211d' n u'\u005cu2062' k , where k is the number of possible syntactic context types
p169
aVNote that this two-stage approach is unusual for the PropBank corpora when compared to prior work, where the vast majority of published papers have not focused on the verb frame disambiguation problem at all, only focusing on the role labeling stage (see the overview paper of Màrquez et al
p170
aVWe optimize the following log-likelihood to train our model
p171
aVAmbiguous lexical units were used for this selection process
p172
aVThe novelty of this paper lies in the frame identification stage (§ 3
p173
aVBefore parsing the data, it is tagged with a POS tagger trained with a conditional random field [ 17 ] with the following emission features word, the word cluster, word suffixes of length 1, 2 and 3, capitalization, whether it has a hyphen, digit and punctuation
p174
aV2010 ) improved performance, and later set the current state of the art on this task [ 7 ]
p175
aVGeneric core role labels (of which there are seven, namely A0 - A5 and AA ) for the verb frames are marked in the figure
p176
aVFigure 1 (b) shows annotations for two verbs u'\u005cu201c' bought u'\u005cu201d' and u'\u005cu201c' sold u'\u005cu201d' , with their lemmas (akin to the lexical units in FrameNet) and their verb frames buy.01 and sell.01
p177
aVTable 7 features a list of the 16 randomly selected documents from the FrameNet 1.5 corpus, which we used for development
p178
aVIn this section, we present our experiments and the results achieved
p179
aVFollowing Das et al
p180
aVX u'\u005cu2192' u'\u005cu211d' 2 u'\u005cu2062' n and for the example sentence it has zeros in positions 0 u'\u005cu2062' u'\u005cu2026' u'\u005cu2062' n and the embedding of the word company in positions n + 1 u'\u005cu2062' u'\u005cu2026' u'\u005cu2062' 2 u'\u005cu2062' n
p181
aVBuyer , Seller and Goods are some example roles for this frame
p182
aVA key difference between the two annotation systems is that PropBankuses a local frame inventory, where frames are predicate-specific
p183
aVFor experiments with PropBank, we used the Ontonotes corpus [ 14 ] , version 4.0, and only made use of the Wall Street Journal documents; we used sections 2-21 for training, section 24 for development and section 23 for testing
p184
aVSuppose that the word embeddings we start with are of dimension n
p185
aVWe set C = 1.0 and use L-BFGS [ 18 ] for training
p186
aVWe use 3 hidden layers each with 1024 neurons and learn a 128-dimensional embedding from a large corpus containing over 100 billion tokens
p187
aVThe objective tries to ensure that the correct word scores higher than a random incorrect word, and we train with minibatch stochastic gradient descent
p188
aV2014 ) , who used a semi-supervised learning method to improve upon a supervised latent-variable log-linear model
p189
aVLet the low dimensional space we map to be u'\u005cu211d' m and the learned mapping be M u'\u005cu211d' n u'\u005cu2062' k u'\u005cu2192' u'\u005cu211d' m
p190
aVFor example, we might have seen the Sending frame many times, even though telex
p191
aVArgument Candidates For PropBankwe use the algorithm of Xue and Palmer ( 2004 ) applied to dependency trees
p192
aVThe resultant development set consists of roughly 4,500 predicates
p193
aVThe PropBankcorpus has verbs annotated with sense frames and their arguments
p194
aVILP constraints For FrameNet, we used three ILP constraints during argument identification (§ 4
p195
aV2014 ) found several unseen predicates at test time
p196
aVFor example u'\u005cu201c' He runs the company u'\u005cu201d' could help us to learn about u'\u005cu201c' She runs a corporation u'\u005cu201d'
p197
aVThis resembles the framework of Das et al
p198
aVBeyond the bias transition feature, we have two cluster features for the left and right words in the transition
p199
aV2011 ) , and in more detail in section 3.2
p200
aVUnfortunately, using only the direct dependents can miss a lot of useful information
p201
aVThe underlined values are the chosen hyperparameters used to analyze the test data
p202
aV10 10 Note that Das et al
p203
aVThe effect of this is clearly observable from the u'\u005cu201c' Rare u'\u005cu201d' column in Table 4
p204
aVFor example, topicalization can place discriminating information farther from the predicate
p205
aVWe present experiments on two tasks
p206
aVNote that an alternative approach could learn only the matrix M , and then use a k -nearest neighbor classifier in u'\u005cu211d' m , as in Weinberger and Saul ( 2009
p207
aVThis would tend to encourage their model to expend more of its modeling power to rule out possibilities that will be pruned out at test time
p208
aVIt is possible that this reduces the model u'\u005cu2019' s power and causes it to over-generalize
p209
aVPropBank The PropBankproject [ 22 ] is another popular resource related to semantic role labeling
p210
aVThis set also contains the null role r u'\u005cu2205'
p211
aVHere, r u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' k y u'\u005cu2062' ( x ) is the rank of the positive frame y relative to all the negative frames
p212
aVNote that this mapping associates spans with the null role r u'\u005cu2205' as well
p213
aVThis resembles the setup used by Punyakanok et al
p214
aV13 13 We do not report partial frame accuracy that has been reported by prior work
p215
aV12 12 We got Das et al u'\u005cu2019' s seen predicates from the authors
p216
aVSimilarly, predicates in embedded clauses may have a distant agent which cannot be captured using direct dependents
p217
aVSee Figure 3 for an illustration of this process
p218
aV3 3 NomBank [ 19 ] is a similar resource for nominal predicates, but we do not consider it in our experiments
p219
aVThere were no unseen verbs at test time
p220
aV2014 ) and Punyakanok et al
p221
aVWe use Brown clusters learned using the algorithm of Uszkoreit and Brants ( 2008 ) on a large English newswire corpus for cluster features
p222
aVILP constraints We used the constraints of Punyakanok et al
p223
aVFor example, consider the pair of sentences in Figure 1 (a
p224
aVWe briefly discuss FrameNet, and subsequently PropBank annotation conventions here
p225
aVConsider u'\u005cu201c' The athlete ran the marathon u'\u005cu201d' vs u'\u005cu201c' The athlete prepared himself for three months to run the marathon u'\u005cu201d' In the second example, for the predicate run , the agent The athlete is not a direct dependent, but is connected via a longer dependency path
p226
aVSuppose g considers clausal complements and direct objects
p227
aVIn principle g u'\u005cu2062' ( x ) could be any feature function, but we performed an initial investigation of two particular variants
p228
aVJohansson and Nugues ( 2007 ) presented the best performing system at SemEval 2007 [ 1 ] , and Das et al
p229
aVLearning Given training data of the form u'\u005cu27e8' u'\u005cu27e8' x ( i ) , y ( i ) , u'\u005cu2133' ( i ) u'\u005cu27e9' u'\u005cu27e9' i = 1 N , where
p230
aVWork in this area exclusively uses the FrameNet full text annotations
p231
aVWe evaluate our models on both FrameNet- and PropBank-style structures
p232
aVFor the choices of the stochastic gradient learning rate, margin ( u'\u005cu0393' ) and dimensionality ( m ), please refer to § 5.4 -§ 5.5
p233
aVWe use an off-the-shelf ILP solver for inference
p234
aV2014 ) , containing 23 documents and 4,458 predicates
p235
aVFor FrameNet, we use the full-text annotations in the FrameNet 1.5 release 8 8 See https://framenet.icsi.berkeley.edu which was used by §3.2]das-etal-semafor-2013
p236
aV2011 ) , using a weighted approximate-rank pairwise loss, learned with stochastic gradient descent
p237
aV2014 ) , who solely focus on FrameNet corpora, unlike this paper
p238
aVTo train with such an objective, stochastic gradient is employed
p239
aVThe chosen learning rate was 0.01 , while the other values were u'\u005cu0393' = 0.01 and m = 512
p240
aVIn order to speed up learning, we use an unnormalized output layer and a hinge-loss objective
p241
aVEarly work in frame-semantic analysis was pioneered by Gildea and Jurafsky ( 2002
p242
aVFor speed the computation of r u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' k y u'\u005cu2062' ( x ) is then replaced with a sampled approximation sample N items y ¯ until a violation is found, i.e., max ( 0 , u'\u005cu0393' + s ( x , y ¯ ) - s ( x , y ) ) ) 0 and then approximate the rank with ( F - 1 ) / N , see Weston et al
p243
aVIn spite of this difference, nearly identical statistical models could be employed for both frameworks
p244
aVSubsequent work in this area focused on either the FrameNetor PropBankframeworks, and research on the latter has been more popular
p245
aVV and sell
p246
aV9 9 These documents are listed in appendix A
p247
aVand L u'\u005cu2062' ( u'\u005cu0397' ) converts the rank to a weight
p248
aV2011 ) for more details on this procedure
p249
aVWe thank Emily Pitler for comments on an early draft, and the anonymous reviewers for their valuable feedback
p250
aVSee § 6 for a discussion
p251
aV2003
p252
aV2014
p253
aV2008
p254
aV2008 ) for example
p255
aV2008 )
p256
aVV
p257
aVThen g
p258
a.