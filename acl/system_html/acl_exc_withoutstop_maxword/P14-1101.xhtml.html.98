<html>
<head>
<title>P14-1101.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The form of the semantic information added in the TLD model is itself quite weak, so the improvements shown here are in line with what infant learners could achieve</a>
<a name="1">[1]</a> <a href="#1" id=1>Overall, the contextual semantic information added in the TLD model leads to both better phonetic categorization and to a better protolexicon, especially when the input is noisier, using degraded consonants</a>
<a name="2">[2]</a> <a href="#2" id=2>The TLD supervowels are used much less frequently than the supervowels found by the LD model, containing, on average, only two-thirds as many tokens</a>
<a name="3">[3]</a> <a href="#3" id=3>In the individual components of VM, TLD and LD have similar VC ( u'\u201c' recall u'\u201d' ), but TLD has higher VH ( u'\u201c' precision u'\u201d' ), demonstrating that the semantic information given by the topics can separate potentially ambiguous words, as hypothesized</a>
<a name="4">[4]</a> <a href="#4" id=4>Again performance decreases as the consonant categories become coarser, but the additional semantic information in the TLD model compensates for the lack of consonant information</a>
<a name="5">[5]</a> <a href="#5" id=5>To demonstrate the benefit of situational information, we develop the Topic-Lexical-Distributional (TLD) model, which extends the LD model by assuming that words appear in situations analogous to documents in a topic model</a>
<a name="6">[6]</a> <a href="#6" id=6>Figure 5 shows that TLD also outperforms LD on the lexeme/word categorization task</a>
<a name="7">[7]</a> <a href="#7" id=7>The TLD model retains the IGMM vowel phone component, but extends the lexicon of the LD model by adding topic-specific lexicons, which capture the notion that lexeme probabilities are topic-dependent</a>
<a name="8">[8]</a> <a href="#8" id=8>As noted above, the learned document-topic distributions u'\ud835' u'\udf3d' are treated as observed variables in the TLD model to represent the situational context</a>
<a name="9">[9]</a> <a href="#9" id=9>We compare all three models u'\u2014' TLD, LD, and IGMM u'\u2014' on the vowel categorization task, and TLD and LD on the lexical categorization task (since IGMM does not infer a lexicon</a>
<a name="10">[10]</a> <a href="#10" id=10>Thus, the model has trouble distinguishing minimal pairs</a>
<a name="11">[11]</a> <a href="#11" id=11>Since our model is not a model of the learning process, we do not compare the infant learning process to the learning algorithm.) We evaluate both the inferred phonetic categories and words using the clustering evaluation measure V-Measure (VM; 36</a>
<a name="12">[12]</a> <a href="#12" id=12>Although we</a>
</body>
</html>