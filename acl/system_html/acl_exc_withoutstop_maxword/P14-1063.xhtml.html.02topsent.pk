(lp0
VThis is because the weight tensors learned by T-MIRA are highly structured, which significantly reduces model/training complexity and makes the learning process very effective in a low-resource environment, but as the amount of data increases, the more complex and expressive vector-based models adapt to the data better, whereas further improvements from the tensor model is impeded by its structural constraints, making it insensitive to the increase of training data
p1
aVThis also makes training the model parameters a challenging problem, since the amount of labeled training data is usually small compared to the size of feature sets the feature weights cannot be estimated reliably
p2
aVAssuming the tensor volume V is the same as the number of features, then there are in all V ways of mapping, which is an intractable number of possibilities even for modest sized feature sets, making it impractical to carry out a brute force search
p3
aVA theoretically guaranteed optimal approach to determining the mode sizes remains an open problem, and will be explored in our future work
p4
aVTo make further comparison of the two strategies, in Figure 8 we plot the 20 largest singular values of the matrices which the surrogate weights (given by the Perceptron after running for 1 epoch) are mapped to by both strategies (from the
p5
a.