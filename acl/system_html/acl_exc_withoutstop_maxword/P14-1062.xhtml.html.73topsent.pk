(lp0
VFor example, the second layer is obtained by applying a convolution to the sentence matrix u'\u005cud835' u'\u005cudc2c' itself
p1
aVIn the network the width of a feature map at an intermediate layer varies depending on the length of the input sentence; the resulting architecture is the Dynamic Convolutional Neural Network
p2
aVConcretely, we think of u'\u005cud835' u'\u005cudc2c' as the input sentence and u'\u005cud835' u'\u005cudc2c' i u'\u005cu2208' u'\u005cu211d' is a single feature value associated with the i -th word in the sentence
p3
aVBy adding a max pooling layer to the network, the TDNN can be adopted as a sentence model []
p4
aVLike in the convolutional networks for object recognition [] , we enrich the representation in the first layer by computing multiple feature maps with different filters applied to the input sentence
p5
aVHigher-order features have
p6
a.