(lp0
VThe structural similarity component, instead, is a novel graph-based similarity measurement technique which calculates the similarity between a pair of concepts across the semantic networks of the two resources by leveraging the semantic structure of those networks
p1
aVInstead of measuring the similarity of two concepts on the basis of their distance in the combined graph, our approach models each concept through a rich vectorial representation we refer to as semantic signature and compares the two concepts in terms of the similarity of their semantic signatures
p2
aVThe definitional similarity component computes the similarity of two concepts in terms of the similarity of their definitions, a method that has also been used in previous work for aligning lexical resources [ 27 , 12 ]
p3
aVIn Section 2 , we presented our approach for aligning lexical resources
p4
aVThe other two resources, i.e.,, wt and ow , do not provide a reliable network of semantic relations, therefore we used our ontologization approach to construct their corresponding semantic graphs
p5
aVHowever, not all lexical resources provide explicit semantic relations between concepts and, hence, machine-readable dictionaries like Wiktionary have first to be transformed into semantic graphs before such graph-based approaches can be applied to them
p6
aVHowever, other resources such as Wiktionary do not provide semantic relations between concepts and, therefore, have first to be transformed into semantic networks before they can be aligned using our alignment algorithm
p7
aVHaving lexical resources represented as semantic networks is highly beneficial
p8
aVThe consistency in the performance of SemAlign in its different configurations and across different resource pairs indicates its robustness and shows that our system can be utilized effectively for aligning any pair of lexical resources, irrespective of their structure or availability of training data
p9
aVTherefore, we assume that a lexical resource L can be represented as an undirected graph G = ( V , E ) where V is the set of nodes, i.e.,, the concepts defined in the resource, and E is the set of undirected edges, i.e.,, semantic relations between concepts
p10
aVLast year Matuschek and Gurevych ( 2013 ) proposed Dijkstra-WSA, a graph-based approach relying on shortest paths between two concepts when the two corresponding resources graphs were combined by leveraging monosemous linking
p11
aVWhen applied to a semantic graph by initializing the random walks from a set of concepts (nodes), ppr yields a vector in which each concept is associated with a weight denoting its semantic relevance to the initial concepts
p12
aVOur approach, in contrast, aims at transforming a lexical resource into a full-fledged semantic network, hence providing a denser graph with most of its nodes connected
p13
aVTherefore, the considerable performance improvement over Dijkstra-WSA on this resource pair shows the effectiveness of our novel concept similarity measure independently of the underlying semantic network
p14
aVHowever, this alignment method still involves tuning of parameters which are highly dependent on the characteristics of the generated graphs and, hence, requires hand-crafted sense alignments for the specific pair of resources to be aligned, a task which has to be replicated every time the resources are updated
p15
aVThis enables our system to be applied effectively for aligning new pairs of resources for which no training data is available, with state-of-the-art performance
p16
aVAs can be seen, the approach consists of two main components definitional similarity and structural similarity
p17
aVOur ontologization algorithm takes as input a lexicon L and outputs a semantic graph G = ( V , E ) where, as already defined in Section 2 , V is the set of concepts in L and E is the set of semantic relations between these concepts
p18
aVHere, we describe how the four semantic graphs for our four lexical resources (i.e.,, wn , wp , wt , ow ) were constructed
p19
aVWe use the same semantic graph H for computing the semantic signatures of both definitions
p20
aVAs mentioned earlier, semantic signatures are vectors with dimension equal to the number of nodes in the semantic graph
p21
aVEach of these components gets, as its input, a pair of concepts belonging to two different semantic networks and produces a similarity score
p22
aVThe aim of this stage is to model a given concept or set of concepts through a vectorial semantic representation, which we refer to as the semantic signature of the input
p23
aVAs an example, assume we are given two semantic signatures computed for two concepts in WordNet and Wiktionary
p24
aVThis component goes beyond the surface realization of concepts, thus providing a deeper measure of concept similarity
p25
aVIn order to address this issue and hence generalize our alignment approach to any given lexical resource, we propose a method for transforming a given machine-readable dictionary into a semantic network, a process we refer to as ontologization
p26
aVMeyer and Gurevych ( 2012a ) and Matuschek and Gurevych ( 2013 ) provided approaches for building graph representations of Wiktionary and OmegaWiki
p27
aVThis rich representation leads to our approach having a good degree of robustness such that it can achieve competitive results even in the absence of training data
p28
aVAligning lexical resources has been a very active field of research in the last decade
p29
aVIn the following, we present our novel approach for measuring the similarity of concept pairs
p30
aVThis is particularly interesting as the wktwsd system uses a rule-based technique specific to relation disambiguation in wt , whereas our method is resource independent and can be applied to arbitrary words in the definition of any concept
p31
aVAs a matter of fact, most efforts have been concentrated on aligning the de facto community standard sense inventory, i.e., WordNet, to other resources
p32
aVNow that all the four resources are transformed into semantic graphs, we move to our alignment experiments
p33
aVIn the structural similarity component (Figure 1 (b), bottom), the semantic signature for each concept c i is computed by running the ppr algorithm on its corresponding graph G i , hence a different u'\u005cud835' u'\u005cudc0c' i is built for each of the two concepts
p34
aVIn this case, both the definitional and structural similarity scores are treated as equally important and two concepts are aligned if their overall similarity exceeds the middle point of the similarity scale
p35
aVTo gain more insight into the effectiveness of our structural similarity measure in comparison to the Dijkstra-WSA method, we carried out an experiment where our alignment system used only the structural similarity component, a variant of our system we refer to as SemAlign s u'\u005cu2062' t u'\u005cu2062' r
p36
aVNevertheless, when it comes to aligning textual definitions in different resources, the lexical approach [ 32 , 5 , 11 ] falls short because of the potential use of totally different wordings to define the same concept
p37
aVIn spite of its simplicity, the mere calculation of the similarity of concept definitions provides a strong baseline, especially for cases where the definitional texts for a pair of concepts to be aligned are lexically similar, yet distinguishable from the other definitions
p38
aVFor instance, WordNet can be readily represented as an undirected graph G whose nodes are synsets and edges are modeled after the relations between synsets defined in WordNet (e.g.,, hypernymy, meronymy, etc.), and u'\u005cu2112' G is the mapping between each synset node and the set of synonyms which express the concept
p39
aVAs mentioned in Section 2.1.1 , we build the wn graph by including all the synsets and semantic relations defined in WordNet (e.g.,, hypernymy and meronymy) and further populate the relation set by connecting a synset to all the other synsets that appear in its disambiguated gloss
p40
aVFor ontologizing wt and ow , the bag of content words W is given by the content words in sense definitions and, if available, additional related words obtained from lexicon relations (see Section 3
p41
aVAs a result of this procedure, we obtain a semantic graph representation G for the lexicon L
p42
aVIn addition, as we mentioned earlier, for wn - wp we used the same graph as that of Dijkstra-WSA, since both wn and wp provide a full-fledged semantic network and thus neither needed to be ontologized
p43
aVWe utilized Personalized PageRank [ 10 , ppr ] , a random walk graph algorithm, for calculating semantic signatures
p44
aVIn this component the personalization vector u'\u005cud835' u'\u005cudc2f' i is set by uniformly distributing the probability mass over the nodes corresponding to the senses of all the content words in the extended definition of d i according to the sense inventory of a semantic network H
p45
aVAs a result of the unification process, we obtain a pair of equally-sized semantic signatures with comparable components
p46
aVWe therefore propose an approach (part (c) of Figure 1 ) that finds a common ground between the two signatures to this end we consider all the concepts associated with monosemous words in the two signatures as landmarks and restrict the two signatures exclusively to those common concepts
p47
aVFor this purpose we used the WordNet [ 7 ] graph which was further enriched by connecting each concept to all the concepts appearing in its disambiguated gloss
p48
aVOne of the main objectives in this area has been to enrich existing ontologies by means of complementary information from other resources
p49
aVA good example is WordNet, which has been exploited as a semantic network in dozens of NLP tasks [ 7 ]
p50
aVHaving at hand the semantic signatures for the two input concepts, we proceed to comparing them (part (d) in Figure 1
p51
aVFor each source concept c u'\u005cu2208' V we create a bag of content words W = { w 1 , u'\u005cu2026' , w n } which includes all the content words in its definition d and, if available, additional related words obtained from lexicon relations (e.g.,, synonyms in Wiktionary
p52
aVOwing to its ability to bring together features like multilinguality and increasing coverage, over the past few years resource alignment has proven beneficial to a wide spectrum of tasks, such as Semantic Parsing [ 33 ] , Semantic Role Labeling [ 28 ] , and Word Sense Disambiguation [ 25 ]
p53
aVLeveraging monosemous words as bridges between two signatures is a particularly reliable technique as typically a significant portion of all words in a lexicon are monosemous
p54
aVOur approach, however, thanks to the connections obtained through ambiguous words, can provide graphs with significantly higher coverage
p55
aVAs an example, for wt , Matuschek and Gurevych ( 2013 ) generated a graph where around 30% of the nodes were in isolation, whereas this number drops to around 5% in our corresponding graph
p56
aVFigure 1 illustrates the procedure underlying our cross-resource concept similarity measurement technique
p57
aVWe compared our similarity-based disambiguation approach against the state of the art on this dataset, i.e.,, the wktwsd system, which is a wt relation disambiguation algorithm based on a series of rules [ 22 ]
p58
aVGiven a pair of lexical resources L 1 and L 2 , we align each concept in L 1 by mapping it to its corresponding concept(s) in the target lexicon L 2
p59
aVWe therefore measure the similarity between the definition of cone 4 n and all the 5 definitions of fruit and introduce a link from cone 4 n to the sense of fruit which yields the maximal similarity value (defined as u'\u005cu201c' (botany) The seed-bearing part of a plant u'\u005cu2026' u'\u005cu201d'
p60
aV[t!] Lexical Resource Aligner {algorithmic} [1] \u005cREQUIRE graphs H = ( V H , E H ) , G 1 = ( V 1 , E 1 ) and G 2 = ( V 2 , E 2 ) , the similarity threshold u'\u005cu0398' , and the combination parameter u'\u005cu0392' \u005cENSURE A , the set of all aligned concept pairs
p61
aVHowever, the dataset for wn - ow was originally built for the German language and, hence, was missing many English ow concepts that could be considered as candidate target alignments
p62
aVWe would like to thank Michael Matuschek for providing us with Wikipedia graphs and alignment datasets
p63
aVThe main feature worth remarking upon is the consistency in the results across different resource pairs the unsupervised system gains the best recall among the three configurations (with the improvement over sb+dwsa being always statistically significant 4 4 All significance tests are done using z-test at p 0.05 whereas tuning, both on a subset or through cross-validation, consistently leads to the best performance in terms of F1 and accuracy (with the latter being statistically significant with respect to sb+dwsa on wn - wp and wn - wt
p64
aVAlso, consider the noun tradeoff which is monosemous according to both these resources
p65
aVAs our benchmark we tested on the gold standard datasets used in Matuschek and Gurevych ( 2013 ) for three alignment tasks
p66
aVAs can be seen, our method proves to be very accurate, surpassing the performance of the wktwsd system in terms of precision, F1, and accuracy
p67
aVIn this latter case, we choose the most appropriate concept c i u'\u005cu2208' u'\u005cu2110' G L u'\u005cu2062' ( w i ) by finding the maximal similarity between the definition of c and the definitions of each sense of w i
p68
aVWe also show the results for this system as sb+dwsa in the table
p69
aVFor ow , however, the encoded relations, though relatively small in number, are already disambiguated and, therefore, the ontologization was just performed on the definition u'\u005cu2019' s content words
p70
aVMoreover, the unsupervised system proves to be very robust inasmuch as it provides competitive results on all the three datasets, while it surpasses the performance of sb+dwsa on wn - wt
p71
aVThis is particularly interesting as the latter system involves tuning of several parameters, whereas SemAlign, in its unsupervised configuration, does not need any training data nor does it involve any tuning
p72
aVThe algorithm iterates over all concepts c 1 u'\u005cu2208' V 1 and, for each of them, obtains the set of concepts C u'\u005cu2282' V 2 , which can be considered as alignment candidates for c 1 (line 2
p73
aVHowever, as mentioned in the introduction, definition similarity-based techniques fail at identifying the correct alignments in cases where different wordings are used or definitions are not of high quality
p74
aVHence, given that a large portion of edges came from ambiguous words (see Table 1 ), we carried out an experiment to evaluate the accuracy of our disambiguation method
p75
aVTo this end, we took as our benchmark the dataset provided by Meyer and Gurevych ( 2010 ) for evaluating relation disambiguation in wt
p76
aVThe latter word is monosemous in Wiktionary, hence we directly connect cone 4 n to the only sense of conifer n
p77
aVWe first create the empty undirected graph G L = ( V , E ) such that V is the set of concepts in L and E = u'\u005cu2205'
p78
aVThen, given two signatures u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' 1 and u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' 2 , computed on the respective graphs G 1 and G 2 , we first obtain the set u'\u005cu2133' of words that are monosemous according to both semantic networks, i.e.,, u'\u005cu2133' = { w u'\u005cu2110' G 1 u'\u005cu2062' ( w
p79
aVWe therefore fixed the dataset for the English language and reproduced the performance of previous work on the new dataset
p80
aVA recent prominent case is Wikipedia [ 18 , 13 ] which, thanks to its inter-article hyperlink structure, provides a rich backbone for structuring additional information [ 2 , 34 , 23 , 8 ]
p81
aVWe show the results for this setting in the bottom part of the table (last three lines
p82
aVThe edges obtained from unambiguous entries are essentially sense disambiguated on both sides whereas those obtained from ambiguous terms are a result of our similarity-based disambiguation
p83
aVBoth words in these relations, however, should be disambiguated according to the given lexicon [ 29 ] , making the task particularly prone to mistakes due to the high number of possible sense pairings
p84
aVThe problem is then cast as a disambiguation task whose goal is to identify the intended sense of each word w i u'\u005cu2208' W according to the sense inventory of L if w i is monosemous, i.e
p85
aVWe show in Table 4 the performance of the two systems on our three datasets
p86
aVFormally, we first represent a semantic network consisting of N concepts as a row-stochastic transition matrix u'\u005cud835' u'\u005cudc0c' u'\u005cu2208' u'\u005cu211d' N × N
p87
aVThe noun fruit , however, has 5 senses in Wiktionary
p88
aVThe u'\u005cu201c' Human u'\u005cu201d' row corresponds to the inter-rater F1 and accuracy scores, i.e.,, the upperbound performance on this dataset, as calculated by Meyer and Gurevych ( 2010
p89
aVHere, we take an alternative approach which requires disambiguation on the target side only, hence reducing the size of the search space significantly
p90
aVIn wt , both of these are in word surface form and hence had to be disambiguated
p91
aVUnsupervised , where the two parameters are set to their middle values (i.e.,, 0.5), hence, no tuning is performed for either of the parameters
p92
aVSince the structural similarity signatures u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' 1 and u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' 2 are calculated on different graphs and thus have different dimensions, we need to make them comparable by unifying them
p93
aVAs an example, consider the 4 t u'\u005cu2062' h sense of the noun cone in Wiktionary (i.e.,, cone 4 n ) which is defined as u'\u005cu201c' The fruit of a conifer u'\u005cu201d'
p94
aVWe also report results for accuracy which, in addition to true positives, takes into account true negatives, i.e.,, pairs which are correctly judged as unaligned
p95
aVThe cell ( i , j ) in the matrix denotes the probability of moving from a concept i to j in the graph
p96
aVAs can be seen in the table, SemAlign s u'\u005cu2062' t u'\u005cu2062' r consistently improves over Dijkstra-WSA according to recall, F1 and accuracy with all the differences in recall and accuracy being statistically significant (p 0.05
p97
aVFor a concept c 1 , alignment candidates in G 2 usually consist of every concept c 2 u'\u005cu2208' V 2 that shares at least one lexicalization with c 1 in the same part of speech tag, i.e.,, u'\u005cu2112' G 1 u'\u005cu2062' ( c 1 ) u'\u005cu2229' u'\u005cu2112' G 2 u'\u005cu2062' ( c 2 ) u'\u005cu2260' u'\u005cu2205' [ 31 , 20 ]
p98
aVWe then transform each of the two signatures u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' i into a new sub-signature u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' i u'\u005cu2032' whose dimension is u'\u005cu2133' the k t u'\u005cu2062' h component of u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' i u'\u005cu2032' corresponds to the weight in u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' i of the only concept of w k in u'\u005cu2110' G i u'\u005cu2062' ( w k
p99
aVHaving found the intended sense c ^ w i of w i , we add the edge { c , c ^ w i } to E
p100
a.