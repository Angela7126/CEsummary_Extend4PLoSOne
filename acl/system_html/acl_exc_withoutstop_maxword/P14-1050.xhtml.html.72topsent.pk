(lp0
VOur algorithm is in spirit to double propagation [ 15 ] , however, the differences are apparent in that firstly, we use very lightweight linguistic information (except POS tags); secondly, our major contributions are to propose statistical measures to address the following key issues first, to measure the utility of lexical patterns; second, to measure the possibility of a candidate word being a new word
p1
aVTypical models include conditional random fields proposed by [ 14 ] , and a joint model trained with adaptive online gradient descent based on feature frequency information [ 18 ]
p2
aVAutomatic extraction of new words is indispensable to many tasks such as Chinese word segmentation, machine translation, named entity extraction, question answering, and sentiment analysis
p3
aVThe algorithm works as follows starting from very few seed words (for example, a word in Table 1 ), the algorithm can find lexical patterns that have strong statistical association with the seed words in which the likelihood ratio test (LRT) is used to quantify the degree of association
p4
aVIn order to obtain lexical patterns, we
p5
a.