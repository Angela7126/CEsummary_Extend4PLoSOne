(lp0
VTo create further baselines for comparison, we selected the following features that represent ways one might approximate grammaticality if a comprehensive model was unavailable whether the link parser can fully parse the sentence ( complete_link ), the Gigaword language model score ( gigaword_avglogprob ), and the number of misspelled tokens ( num_misspelled
p1
aVTo train our system on binarized data, we replaced the u'\u005cu2113' 2 -regularized linear regression model with an u'\u005cu2113' 2 -regularized logistic regression and used Kendall u'\u005cu2019' s u'\u005cu03a4' rank correlation between the predicted probabilities of the positive class and the binary gold standard labels as the grid search metric (§ 3.1 ) instead of Pearson u'\u005cu2019' s r
p2
aVWe created a dataset consisting of 3,129 sentences randomly selected from essays written by non-native speakers of English as part of a test of English language proficiency
p3
aV4 4 Regression models typically produce conservative predictions with lower variance than the original training data
p4
aVSince the predictions from the binary and ordinal systems are on different scales, we include the nonparametric statistic Kendall u'\u005cu2019' s u'\u005cu03a4' as a secondary evaluation metric for
p5
a.