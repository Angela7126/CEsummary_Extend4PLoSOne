(lp0
VSimilar to the model presented in this paper, BabySRL is based on simple ordering features such as argument position relative to the verb and argument position relative to the other arguments
p1
aVThe model represents the preferred locations of semantic roles relative to the verb as distributions over real numbers
p2
aVWhen imperatives are filtered out of the training corpus, the symmetric model obtains a worse BIC fit than a model that lacks the non-canonical subject Gaussian
p3
aVThe BabySRL corpus is annotated with 5 different roles, but the model described in this paper only uses 2 roles
p4
aVThe model presented here learns a single, non-recursive ordering for the semantic roles in each sentence relative to the verb since several studies have suggested that early child grammars may consist of simple linear grammars that are dictated by semantic roles []
p5
aVFor the intransitive
p6
a.