(lp0
VThe proposed RNN produces a single score that is constructed in the hidden layer by employing the distance-dependent weight matrices
p1
aVNext, the hidden layer receives the output of the lookup layer ( x j ) and that of the previous hidden layer ( y j - 1
p2
aVIn the lookup layer, each of these words is converted to its word embedding, and then the concatenation of the two embeddings ( x j ) is fed to the hidden layer in the same manner as the FFNN-based model
p3
aVFirst, the lookup layer converts each input word into its word embedding by looking up its corresponding column in the embedding matrix ( L ), and then concatenates them
p4
aVUnder the recurrence, the proposed model compactly encodes the entire history of previous alignments in the hidden layer configuration y i
p5
aVAs described above, the RNN-based model has a hidden layer with recurrent connections
p6
aVThus, the Viterbi alignment is computed approximately using heuristic beam search
p7
aVTherefore, the proposed model can find alignments by taking advantage of the long alignment history, while the FFNN-based model considers only the last alignment
p8
aVNote that alignments in the FFNN-based model are also governed by first-order Markov dynamics
p9
a.