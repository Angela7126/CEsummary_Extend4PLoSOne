<html>
<head>
<title>P14-1146.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We compare sentiment-specific word embedding (SSWE h , SSWE r , SSWE u ) with baseline embedding learning algorithms by only using word embedding as features for Twitter sentiment classification</a>
<a name="1">[1]</a> <a href="#1" id=1>A typical case in sentiment analysis is that the composed phrase and multiword expression may have a different sentiment polarity than the individual words it contains, such as not [bad] and [great] deal of (the word in the bracket has different sentiment polarity with the ngram</a>
<a name="2">[2]</a> <a href="#2" id=2>The training objectives of SSWE u are that (1) the original ngram should obtain a higher language model score u'\ud835' u'\udc87' 0 u u'\u2062' ( t ) than the corrupted ngram u'\ud835' u'\udc87' 0 u u'\u2062' ( t r ) , and (2) the sentiment score of original ngram u'\ud835' u'\udc87' 1 u u'\u2062' ( t ) should be more consistent with the gold polarity annotation of sentence than corrupted ngram u'\ud835' u'\udc87' 1 u u'\u2062' ( t r</a>
<a name="3">[3]</a> <a href="#3" id=3>The sharp decline at u'\u0391' =1 reflects the importance of sentiment information in learning word embedding for Twitter sentiment classification</a>
<a name="4">[4]</a> <a href="#4" id=4>Experimental results further demonstrate that sentiment-specific word embeddings are able to capture the sentiment information of texts and distinguish words with opposite sentiment polarity, which are not well solved in traditional neural models like C W and word2vec</a>
<a name="5">[5]</a> <a href="#5" id=5>The lexicon-based approaches [ 44 ,</a>
</body>
</html>