(lp0
VWe show that the misclassifications (with respect to whether comments contain irony or not) made by a standard text classification model significantly correlate with those comments for which human annotators requested additional context
p1
aVOn average, annotators requested additional context for 30% of comments (range across annotators of 12% to 56%
p2
aVAnd indeed, all three annotators requested additional context for this comment
p3
aVThese pieces of information (previous comments by the same user, the external link of the embedding reddit thread, and the other comments in this thread) constitute our context
p4
aVWe introduce the first version of the reddit irony corpus , composed of annotated comments from the social news website reddit
p5
aVPut another way, the model makes mistakes on those comments for which annotators requested additional context (even after accounting for the annotator designation of comments
p6
aVWe now explore empirically whether these misclassifications are made on the same comments for which annotators requested context
p7
aVReddit is a good corpus for the irony detection task in part because it provides a
p8
a.