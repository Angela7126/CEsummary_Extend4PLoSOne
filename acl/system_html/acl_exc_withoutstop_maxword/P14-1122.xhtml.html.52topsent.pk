(lp0
VBy constructing N c directly from the knowledge base, play actions may be validated based on recognition of true negatives, removing the heavy burden for ever manually creating a gold standard test set
p1
aVFirst, both games intentionally uniformly sample between V and N to increase player engagement, 4 4 Earlier versions that used mostly items from V proved less engaging due to players frequently performing the same action, e.g.,, saving most humans or collecting most pictures which generates a larger number of annotations for items in N than are produced by crowdsourcing
p2
aVThis bias leads to annotations with few false positives, but as Column 5 shows, crowdflower workers consistently performed much worse than game players at identifying valid relations, producing many false negative annotations
p3
aVThese mechanics ensure the game naturally produces better quality annotations; in contrast, common crowdsourcing platforms do not support analogous mechanics for enforcing this type of correctness at annotation time
p4
aVIn contrast, concept-concept associations require more background knowledge to determine if a relation exists; furthermore, Infection gives players limited time to decide (due to board length) and also contains cognitive distractors (zombies
p5
aVScoring is based on both the number of zombies killed and the percentage of uninfected humans saved, motivating players to kill infected humans in order to increase their score
p6
aVTherefore, in Table 1
p7
a.