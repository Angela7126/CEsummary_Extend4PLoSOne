(lp0
VMoreover, Goldfrab and Ma [ 11 ] proved the convergence of the FPC algorithm for solving the nuclear norm minimization problem
p1
aVThe matrix rank minimization problem is NP-hard
p2
aVTherefore, Candés and Recht [ 5 ] suggested to use a convex relaxation, the nuclear norm minimization instead
p3
aVIn such a way, relation classification is transformed into a problem of completing the unknown labels for testing items in the sparse matrix that concatenates training and testing textual features with training labels, based on the assumption that the item-by-feature and item-by-label joint matrix is of low rank
p4
aV\u005cENSURE Completed Matrix Z
p5
aVDue to the noisy features and incomplete labels, the underlying low-rank data matrix with truly effective information tends to be corrupted and the rank of observed data matrix can be extremely high
p6
aVFPC algorithm for solving DRMC-1 {algorithmic} \u005cREQUIRE Initial matrix u'\u005cud835' u'\u005cudc19' u'\u005cud835' u'\u005cudfce' ; Parameters u'\u005cu039c' , u'\u005cu039b' ; Step sizes u'\u005cu03a4' z
p7
aVThe new framework for classification enhances the robustness to data noise by penalizing different cost functions for features and labels
p8
aVMore specifically, as shown in Figure 2, we model the task with a sparse matrix whose rows present items (entity pairs) and columns contain noisy textual features and incomplete relation labels
p9
aVSuppose that we have built a training corpus for relation classification with n items (entity
p10
a.