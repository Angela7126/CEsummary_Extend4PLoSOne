(lp0
VNext, the hidden layer receives the output of the lookup layer ( x j ) and that of the previous hidden layer ( y j - 1
p1
aVIn the lookup layer, each of these words is converted to its word embedding, and then the concatenation of the two embeddings ( x j ) is fed to the hidden layer in the same manner as the FFNN-based model
p2
aVNote that alignments in the FFNN-based model are also governed by first-order Markov dynamics because an alignment score depends on the previous alignment a j - 1
p3
aVThe proposed RNN produces a single score that is constructed in the hidden layer by employing the distance-dependent weight matrices
p4
aVTherefore, the proposed model can find alignments by taking advantage of the long alignment history, while the FFNN-based model considers only the last alignment
p5
aVThe alignment model based on an FFNN is formed in the same manner as the lexical translation model
p6
aVTherefore, the RNN-based model has less effect on French-English word alignment than Japanese-English word alignment, as indicated in Table 2
p7
aVUnder the recurrence, the proposed model compactly encodes the entire history of previous alignments in the hidden layer configuration y i
p8
aVAs described
p9
a.