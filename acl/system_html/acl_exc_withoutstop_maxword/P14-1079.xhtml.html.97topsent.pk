(lp0
VMoreover, Goldfrab and Ma [ 11 ] proved the convergence of the FPC algorithm for solving the nuclear norm minimization problem
p1
aVDue to the noisy features and incomplete labels, the underlying low-rank data matrix with truly effective information tends to be corrupted and the rank of observed data matrix can be extremely high
p2
aVThe matrix rank minimization problem is NP-hard
p3
aVIn such a way, relation classification is transformed into a problem of completing the unknown labels for testing items in the sparse matrix that concatenates training and testing textual features with training labels, based on the assumption that the item-by-feature and item-by-label joint matrix is of low rank
p4
aVMore specifically, as shown in Figure 2, we model the task with a sparse matrix whose rows present items (entity pairs) and columns contain noisy textual features and incomplete relation labels
p5
aVSuppose that we have built a training corpus for relation classification with n items (entity pairs), d -dimensional textual features, and t labels (relations), based on the basic alignment assumption proposed by Mintz et al
p6
aVThe new framework for classification enhances the robustness to data noise by penalizing different cost functions for features and labels
p7
aVSimilar to noisy features, the generated labels can be incomplete
p8
aVTherefore, Candés and Recht [ 5 ] suggested to use a convex relaxation, the nuclear
p9
a.