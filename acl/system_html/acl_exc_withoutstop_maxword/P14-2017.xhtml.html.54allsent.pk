(lp0
V2013 ) proposed a method for cognate production relying on statistical character-based machine translation, learning orthographic production patterns, and Mulloni ( 2007 ) introduced an algorithm for cognate production based on edit distance alignment and the identification of orthographic cues when words enter a new language
p1
aVFinally, we obtain 445 pairs of cognates for Romanian-French 2 2 The number of pairs of cognates is much lower for French than for the other languages because there are numerous Romanian words which have French etymology and, in this paper, we do not consider these words to be cognate candidates
p2
aVWe discard pairs of words for which the forms across languages are identical (i.e.,, the Romanian word matrice and its Italian cognate pair matrice , having the same form), because these pairs do not provide any orthographic changes to be learned
p3
aVFirst, we compute the pairwise distances between pairs of words for each orthographic metric individually, as a single feature 5 5 SpSim cannot be computed directly, as the other metrics, so we introduce an additional step in which we use 1/3 of the training set (only cognates are needed) to learn orthographic changes
p4
aVTherefore, because the edit distance was widely used in this research area and produced good results, we are encouraged to employ orthographic alignment for identifying pairs of cognates, not only to compute similarity scores, as was previously done, but to use aligned subsequences as features for machine learning algorithms
p5
aVWe investigate the performance of the method we propose in comparison to previous approaches for automatic detection of cognate pairs based on orthographic similarity
p6
aVFor measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input
p7
aVGomes and Lopes ( 2011 ) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words
p8
aVAlgorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic
p9
aVKondrak ( 2000 ) developed the ALINE system, which aligns words u'\u005cu2019' phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming
p10
aVBecause we need sets of approximately equal size for comparison across languages, we keep 400 pairs of cognates and 400 pairs of non-cognates for each pair of languages
p11
aVThe wide range of applications in which cognates prove useful attracted more and more attention on methods for detecting such related pairs of words
p12
aVWe use Naive Bayes as a baseline and we experiment with Support Vector Machines (SVMs) to learn orthographic changes and to discriminate between pairs of cognates and non-cognates
p13
aVWe assume that rules for adapting foreign words to the orthographic system of the target languages might not have been very well defined in their period of early development, but they may have since become complex and probably language-specific
p14
aVTherefore, to align pairs of words we employ the Needleman-Wunsch global alignment algorithm [ 29 ] , which is mainly used for aligning sequences of proteins or nucleotides
p15
aVFor orthographic alignment, we consider words as input sequences and we use a very simple substitution matrix, which gives equal scores to all substitutions, disregarding diacritics (e.g.,, we ensure that e and è are matched
p16
aVUsing the best threshold value selected for each metric and pair of languages, we further classify the pairs of words in our test sets as cognates or non-cognates
p17
aVIn order to detect the best threshold for discriminating between cognates and non-cognates, we run a decision stump classifier (provided by Weka) on the training set for each pair of languages and for each metric
p18
aVDetecting pairs of cognates based on etymology is useful and reliable, but, for resource-poor languages, methods which require less linguistic knowledge might be necessary
p19
aVString alignment is closely related to the task of sequence alignment in computational biology
p20
aVIn addition, we use SpSim [ 11 ] , which outperformed the longest common subsequence ratio and a similarity measure based on the edit distance in previous experiments
p21
aVOur intuition is that inferring language-specific rules for aligning words will lead to better performance in the task of cognate identification
p22
aVUsing aligned pairs of words as input, we extract features around mismatches in the alignments
p23
aVTherefore, the research [ 17 , 25 , 16 ] focused on automatic identification of cognate pairs, starting from lists of known cognates
p24
aVIts main idea is that any partial path of the alignment along the optimal path should be the optimal path leading up to that point
p25
aVWe use the radial basis function kernel (RBF), which can handle the case when the relation between class labels and attributes is non-linear, as it maps samples non-linearly into a higher dimensional space
p26
aVAccording to Gusfield ( 1997 ) , an edit transcript (representing the conversion of one string to another) and an alignment are mathematically equivalent ways of describing relationships between strings
p27
aVVarious measures were investigated and compared [ 17 , 14 ] ; Levenshtein distance [ 22 ] , XDice [ 3 ] and the longest common subsequence ratio [ 24 ] are among the most frequently used metrics in this field
p28
aVThe algorithm uses dynamic programming and, thus, guarantees to find the optimal alignment
p29
aVIn order to provide information regarding the position of the features, we mark the beginning and the end of the word with a $ symbol
p30
aVFinally, in Section 5 we draw the conclusions of our study and describe our plans for extending the method
p31
aVFor Portuguese, both Naive Bayes and SVM misclassify more non-cognates as cognates than viceversa
p32
aVTherefore, the optimal path can be determined by incremental extension of the optimal subpaths [ 31 ]
p33
aVA possible explanation might be the occurrence, in the dataset, of more remotely related words, which are not labeled as cognates
p34
aVTo evaluate these metrics on our dataset, we use the same train/test sets as we did in our previous experiments and we follow the strategy described in [ 17 ]
p35
aVTherefore, because there is one feature ( xh s- ) which occurs twice in our example, we have 8 features for the pair (exhaustiv, esaustivo)
p36
aVThis task is most challenging for resource-poor languages, for which etymologically related information is not accessible
p37
aVThus, for the above-mentioned pair of cognates, (exhaustiv, esaustivo) , we extract the following features when n = 2
p38
aVFor identical features we account only once
p39
aVWe achieve slight improvements by combining n -grams, i.e.,, for a given n , we use all i -grams, where i u'\u005cu2208' { 1 , u'\u005cu2026' , n }
p40
aVThe second alternative leads to better performance, so we account for all mismatches
p41
aVAs for the length of the grams, we experiment with n u'\u005cu2208' { 1 , 2 , 3 }
p42
a.