(lp0
VExcept for the phrase feature X 1 [ Maskey and Zhou2012 ] , our introduced input features X significantly improve the DAE feature learning (row 11 vs
p1
aVNext, we adapt and extend some original phrase features as the input features for DAE feature learning
p2
aVOur semi-supervised DAE features significantly outperform the unsupervised DBN features and the baseline features, and our introduced input phrase features significantly improve the performance of DAE feature learning
p3
aVCompared with the unsupervised DBN features, our semi-supervised DAE features are more effective for translation decoder (row 3 vs
p4
aVThus, these new m 1 + m 2 -dimensional DAE features are added as extra features to the phrase table
p5
aVFirst, the input original features for the DBN feature learning are too simple, the limited 4 phrase features of each phrase pair, such as bidirectional phrase translation probability and bidirectional lexical weighting [ Koehn et al.2003 ] , which are a bottleneck for learning effective feature representation
p6
aVFor our semi-supervised DAE feature learning task, we use the unsupervised pre-trained DBN to initialize DAE u'\u005cu2019' s parameters and use the input original phrase features as the u'\u005cu201c' teacher u'\u005cu201d' for semi-supervised back-propagation
p7
aVSection 3 presents our introduced input features for DNN feature learning
p8
aV16), and further improve the performance of DAE feature learning, which can also somewhat address the bring shortcoming of the limited input features
p9
aVSpecially, Table 4 shows the detailed effectiveness of our introduced input features for DAE feature learning, and the results show that each type of features are very effective for DAE feature learning
p10
aVMoreover, although we have introduced another four types of
p11
a.