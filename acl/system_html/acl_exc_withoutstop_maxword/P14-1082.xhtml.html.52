<html>
<head>
<title>P14-1082.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The choice for this algorithm is motivated by the fact that it handles multiple classes with ease, but first and foremost because it has been successfully employed for word sense disambiguation in other studies [] , in particular in cross-lingual word sense disambiguation, a task closely resembling our current task []</a>
<a name="1">[1]</a> <a href="#1" id=1>Whilst other thresholds may possibly produce cleaner sets, this is hard to evaluate as finding optimal values causes a prohibitive increase in complexity of the search space, and again this is not necessary to test our hypothesis</a>
<a name="2">[2]</a> <a href="#2" id=2>Preparing the data to build training and test data for our intended translation assistance system is not trivial, as the type of interactive translation assistant we aim to develop does not exist yet</a>
<a name="3">[3]</a> <a href="#3" id=3>The main research question in this research is how to disambiguate an L1 word or phrase to its L2 translation based on an L2 context, and whether such cross-lingual contextual approaches provide added value compared to baseline models that are not context informed or compared to standard language models</a>
<a name="4">[4]</a> <a href="#4" id=4>It invokes GIZA++ [] to establish statistical word alignments based on the IBM Models and subsequently extracts phrases using the grow-diag-final algorithm []</a>
<a name="5">[5]</a> <a href="#5" id=5>Step 4 is effectively a filter two thresholds can be configured to discard weak alignments, i.e., those with low probabilities, from the phrase-translation table so that only strong couplings make it into the generated set</a>
<a name="6">[6]</a> <a href="#6" id=6>The word accuracy for the entire set is then computed by taking the sum of the word accuracies per sentence pair, divided by the total number of sentence pairs</a>
<a name="7">[7]</a> <a href="#7" id=7>In order to draw accurate conclusions, experiments on a single data set and language pair are not sufficient</a>
<a name="8">[8]</a> <a href="#8" id=8>We first measure absolute accuracy by simply counting all output fragments that exactly match the reference fragments, as a fraction of the total amount of fragments</a>
<a name="9">[9]</a> <a href="#9" id=9>If not, we check for the presence of a classifier expert for the offered L1 fragment; only then we can proceed by extracting the desired number of L2 local context words to the immediate left and right of this fragment and adding those to the feature vector</a>
<a name="10">[10]</a> <a href="#10" id=10>Automatic configuration selection was done by performing leave-one-out testing (for small number of instances) or 10-fold-cross validation (for larger number of instances, n u'\u2265' 20 ) on the training data per classifier expert</a>
<a name="11">[11]</a> <a href="#11" id=11>This measure may be too strict, so we add a more flexible word accuracy measure which takes into account partial matches at the word level</a>
<a name="12">[12]</a> <a href="#12" id=12>In earlier work , we reported a decrease in performance due to overfitting when this is done, so we do not expect it to make a positive impact</a>
<a name="13">[13]</a> <a href="#13" id=13>Third, we observe that adding the language model to our classifier leads to another significant gain (configuration l1r1 + LM in the results in Table 2</a>
<a name="14">[14]</a> <a href="#14" id=14>Our</a>
</body>
</html>