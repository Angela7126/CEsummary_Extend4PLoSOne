<html>
<head>
<title>P14-1024.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Tsvetkov et al</a>
<a name="1">[1]</a> <a href="#1" id=1>Tsvetkov et al</a>
<a name="2">[2]</a> <a href="#2" id=2>In the case of SVO relations, we use software and datasets from Tsvetkov et al</a>
<a name="3">[3]</a> <a href="#3" id=3>Turney et al</a>
<a name="4">[4]</a> <a href="#4" id=4>Turney et al</a>
<a name="5">[5]</a> <a href="#5" id=5>Similarly to Tsvetkov et al</a>
<a name="6">[6]</a> <a href="#6" id=6>2013 ) in that it uses additional features (vector space word representations) and a different classification method (we use random forests while Tsvetkov et al</a>
<a name="7">[7]</a> <a href="#7" id=7>Namely, we use a trained English model discussed in Section 5.1 to classify literal and metaphoric SVO and AN relations in English, Spanish, Farsi and Russian test sets, listed in Section 4.2</a>
<a name="8">[8]</a> <a href="#8" id=8>We also use the same thresholds for classifier posterior probabilities as Tsvetkov et al</a>
<a name="9">[9]</a> <a href="#9" id=9>Strzalkowski et al</a>
<a name="10">[10]</a> <a href="#10" id=10>Strzalkowski et al</a>
<a name="11">[11]</a> <a href="#11" id=11>In this section, we compare our method to state-of-the-art methods of Tsvetkov et al</a>
<a name="12">[12]</a> <a href="#12" id=12>2013 ) , we use a logistic regression classifier to propagate abstractness and imageability scores from MRC ratings to all words for which we have vector space representations</a>
<a name="13">[13]</a> <a href="#13" id=13>English, Spanish, Farsi, and Russian</a>
<a name="14">[14]</a> <a href="#14" id=14>2013 ) and of Turney et al</a>
<a name="15">[15]</a> <a href="#15" id=15>Our approach is different from that</a>
</body>
</html>