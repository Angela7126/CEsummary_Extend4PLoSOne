<html>
<head>
<title>P14-2135.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The filtering approach described thus far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts</a>
<a name="1">[1]</a> <a href="#1" id=1>The Turney et al algorithm quantifies the concreteness of concepts that lack such a rating based on their proximity to rated concepts in a semantic vector space</a>
<a name="2">[2]</a> <a href="#2" id=2>To evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u'\u222a' C introduced in Section 2</a>
<a name="3">[3]</a> <a href="#3" id=3>By classifying concepts with image dispersion below the median as concrete and concepts above this threshold as abstract we achieved an abstract-concrete prediction accuracy of 81%</a>
<a name="4">[4]</a> <a href="#4" id=4>On a different set of 200 concepts extracted by random sampling from the USF dataset stratified by concreteness rating (including concepts across the concreteness spectrum), we observed a high correlation between abstractness and dispersion (Spearman u'\u03a1' = 0.61 , p 0.001</a>
<a name="5">[5]</a> <a href="#5" id=5>We use Google Images as our image source, and extract the first n image results for each concept word</a>
<a name="6">[6]</a> <a href="#6" id=6>We apply image dispersion-based filtering as follows if both concepts in an evaluation pair have an image dispersion below a given threshold, both</a>
</body>
</html>