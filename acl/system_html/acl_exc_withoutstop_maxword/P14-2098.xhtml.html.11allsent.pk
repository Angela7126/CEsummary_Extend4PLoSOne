(lp0
VWe propose to improve upon the correction detection component by training a classifier that determines which edits in a revised sentence address the same error in the original sentence
p1
aVAlso, as suggested by the experimental result, among the four corpora, FCE corpus is a comparably good resource for training correction detection models with our current feature set
p2
aVIf the resulting basic edits do not match with those that compose the actual corrections, we attribute the error to the first step
p3
aVThe teachers u'\u005cu2019' annotations are treated as gold standard for the detailed corrections
p4
aVRecent work therefore focuses on identifying the alignment/edits between two sentences [ 13 , 8 ]
p5
aVComparing a student-written sentence with its revision, we observe that each correction can be decomposed into a set of more basic edits such as word insertions, word deletions and word substitutions
p6
aVBecause the classifier were trained on revisions where corrections are explicitly marked by English experts, it is also possible to build systems adjusted to different annotation standards
p7
aVFor example, in Figure 11 , when the insertion of one word is followed by the deletion of the same word, the insertion and deletion are likely addressing one single error
p8
aVThe models built on corpora can generally improve the correction detection accuracy 5 5 We currently do not evaluate the end-to-end system over different corpora
p9
aVOur analysis confirms that the merging step is the bottleneck in the current correction detection system u'\u005cu2013' it accounts for 75% of the mis-detections
p10
aVSince mis-detected corrections cannot be analyzed down the pipeline, the correction detection component became the bottle-neck of their overall system
p11
aVIn the example shown in Figure 1 , the correction u'\u005cu201c' to change u'\u005cu21d2' changing u'\u005cu201d' is composed of a deletion of to and a substitution from change to changing ; the correction u'\u005cu201c' moment u'\u005cu21d2' minute u'\u005cu201d' is itself a single word substitution
p12
aVWe simulate the revisions by applying corrections onto the original sentence
p13
aVFirst, Table 4 shows that by incorporating correction patterns into the merging algorithm, the errors in correction detection step were reduced
p14
aVThis is because these two edits would combine together as a word-order change
p15
aVTherefore, to effectively reduce the algorithm u'\u005cu2019' s mis-detection errors, we propose to build a classifier to merge with better accuracies
p16
aVTo predict whether two basic-edits address the same writing problem more discriminatively, we train a Maximum Entropy binary classifier based on features extracted from relevant contexts for the basic edits
p17
aVWe then create a training instance for each pair of two consecutive basic edits if two consecutive basic edits need to be merged, we will mark the outcome as True , otherwise it is False
p18
aVOne reason is that FCE corpus has many more training instances, which benefits model training
p19
aVThis is because different corpora employ different error type categorization standards
p20
aVOn the other hand, in Figure 11 , if one edit includes a substitution between words with the same POS u'\u005cu2019' s, then it is likely fixing a word choice error by itself
p21
aVThus, we can build systems to detect corrections which operates in two steps
p22
aVDue to the effort involved in comparing revisions with the original texts, students often fail to learn from these revisions [ 16 ]
p23
aVThis led to a significant improvement on the overall system u'\u005cu2019' s F 1 -score on all corpora
p24
aVFurthermore, it is not clear if the heuristics will work as well for tutors trained to mark up revisions under different guidelines
p25
aVWe considered four corpora with different ESL populations and annotation standards, including FCE corpus [ 17 ] , NUCLE corpus [ 2 ] , UIUC corpus 2 2 UIUC corpus contains annotations of essays collected from ICLE [ 6 ] and CLEC [ 7 ]
p26
aVA bigger concern is to guarantee the extracted phrase pairs are indeed translations or paraphrases
p27
aVBecause the Levenshtein algorithm only tries to minimize the number of edits, it does not care whether the edits make any linguistic sense
p28
aVIn practice, however, this two-step approach may result in mis-detections due to ambiguities
p29
aVBecause this is time consuming, tutors often just rewrite the sentences without giving any explanations [ 5 ]
p30
aVComputer aided language learning tools offer a solution for providing more detailed feedback
p31
a.