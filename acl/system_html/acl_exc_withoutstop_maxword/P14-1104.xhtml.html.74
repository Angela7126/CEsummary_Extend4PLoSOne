<html>
<head>
<title>P14-1104.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We employ Amazon u'\u2019' s Mechanical Turk (AMT) to label the emotions of Twitter data, and apply the proposed methods to the AMT dataset with the goals of improving the annotation quality at low cost, as well as learning accurate emotion classifiers</a>
<a name="1">[1]</a> <a href="#1" id=1>While these feature weighting models can be used to score and rank instances for data cleaning, better classification and regression models can be built by using the feature weights generated by these models as a pre-weight on the data points for other machine learning algorithms</a>
<a name="2">[2]</a> <a href="#2" id=2>One widely used approach [ 1 , 22 ] is to create an ensemble classifier that combines the outputs of multiple classifiers by either majority vote or consensus, and an instance is tagged as mislabeled and removed from the training set if it is classified into a different class than its training label by the ensemble classifier</a>
<a name="3">[3]</a> <a href="#3" id=3>Active learning for data cleaning differs from traditional active learning because the data already has low quality labels</a>
<a name="4">[4]</a> <a href="#4" id=4>Note that some tweets</a>
</body>
</html>