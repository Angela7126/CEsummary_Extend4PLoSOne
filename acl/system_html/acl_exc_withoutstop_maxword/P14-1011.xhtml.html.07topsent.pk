(lp0
VWith the semantic phrase embeddings and the vector space transformation function, we apply the BRAE to measure the semantic similarity between a source phrase and its translation candidates in the phrase-based SMT
p1
aVAccordingly, we evaluate the BRAE model on two end-to-end SMT tasks (phrase table pruning and decoding with phrasal semantic similarities) which need to check whether a translation candidate and the source phrase are in the same meaning
p2
aVAs the semantic phrase embedding can fully represent the phrase, we can go a step further in the phrase-based SMT and feed the semantic phrase embeddings to DNN in order to model the whole translation process (e.g., derivation structure prediction
p3
aVAssuming the phrase is a meaningful composition of its internal words, we propose Bilingually-constrained Recursive Auto-encoders (BRAE) to learn semantic phrase embeddings
p4
aVInstead, we focus on learning phrase embeddings from the view of semantic meaning, so that our phrase embedding can fully represent the phrase and best fit the phrase-based SMT
p5
aVIn phrase table pruning, we discard the phrasal translation rules with low semantic similarity
p6
aVAs translation equivalents share the same semantic meaning, we employ high-quality phrase translation pairs as training corpus in this work
p7
aVWith the learned model, we can accurately measure the semantic similarity between a source phrase and a translation
p8
a.