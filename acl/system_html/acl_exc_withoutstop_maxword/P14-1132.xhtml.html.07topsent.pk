(lp0
VWhen the induced projection function maps an object onto the linguistic space, the derived text vector will inherit a mixture of textual features from the concepts that activated the same hidden unit as the object
p1
aVObjects corresponding to concepts are represented in visual terms by vectors in an image-based semantic space (Section 4.2
p2
aVWe use a set of approximately 9,500 concepts, the intersection of the ESP-based visual semantic space with the linguistic space
p3
aVThe process of learning to map objects to the their word label is implemented by training a projection function f proj v u'\u005cu2192' w from the visual onto the linguistic semantic space
p4
aVConcretely, we assume that concepts, denoted for convenience by word labels, are represented in linguistic terms by vectors in a text-based distributional semantic space (see Section 4.3
p5
aVTable 3 presents both seen and unseen concepts corresponding to visual vectors that trigger the highest activation for a subset of hidden units
p6
aVThe zero-shot framework leads us to frame fast mapping as the task of projecting visual representations of new objects onto language space for retrieving their word labels ( v u'\u005cu2192' w
p7
aVFor the zero-shot task we report the accuracy of retrieving the correct label among the top k neighbors from a semantic space populated with the union of seen and unseen concepts
p8
aVFor fast mapping, we report the mean rank of the correct concept among fast mapping candidates
p9
aV2013 ) use linear regression to transform vector-based image representations onto vectors representing the same concepts in linguistic semantic space
p10
aVThis object is projected onto the linguistic space and associated with the word label of the nearest neighbor in that space ( degus in Figure 1
p11
aVIn both tasks, the projected vector of the unseen concept is labeled with
p12
a.