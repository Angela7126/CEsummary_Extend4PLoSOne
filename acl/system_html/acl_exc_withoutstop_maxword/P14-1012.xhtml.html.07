<html>
<head>
<title>P14-1012.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Our semi-supervised DAE features significantly outperform the unsupervised DBN features and the baseline features, and our introduced input phrase features significantly improve the performance of DAE feature learning</a>
<a name="1">[1]</a> <a href="#1" id=1>Next, we adapt and extend some original phrase features as the input features for DAE feature learning</a>
<a name="2">[2]</a> <a href="#2" id=2>First, the input original features for the DBN feature learning are too simple, the limited 4 phrase features of each phrase pair, such as bidirectional phrase translation probability and bidirectional lexical weighting [ Koehn et al.2003 ] , which are a bottleneck for learning effective feature representation</a>
<a name="3">[3]</a> <a href="#3" id=3>Specially, Table 4 shows the detailed effectiveness of our introduced input features for DAE feature learning, and the results show that each type of features are very effective for DAE feature learning</a>
<a name="4">[4]</a> <a href="#4" id=4>Compared with the unsupervised DBN features, our semi-supervised DAE features are more effective for translation decoder (row 3 vs</a>
<a name="5">[5]</a> <a href="#5" id=5>Except for the phrase feature X 1 [ Maskey and Zhou2012 ] , our introduced input features X significantly improve the DAE feature learning (row 11 vs</a>
<a name="6">[6]</a> <a href="#6" id=6>To address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new DNN feature learning, and these features have been shown significant improvement for SMT, such as, phrase pair similarity [ Zhao et al.2004 ] , phrase frequency, phrase length [ Hopkins and May2011 ] , and phrase generative probability [ Foster et al.2010 ] , which also show further improvement for new phrase feature learning in our experiments</a>
<a name="7">[7]</a> <a href="#7" id=7>Using the 4 original phrase features in the phrase table as the input features, they pre-trained the DBN by</a>
</body>
</html>