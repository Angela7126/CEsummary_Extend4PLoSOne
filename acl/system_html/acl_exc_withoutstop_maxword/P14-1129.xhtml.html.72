<html>
<head>
<title>P14-1129.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Le u'\u2019' s model also uses minimal phrases rather than being purely lexicalized, which has two main downsides a) a number of complex, hand-crafted heuristics are required to define phrase boundaries, which may not transfer well to new languages, (b) the effective vocabulary size is much larger, which substantially increases data sparsity issues</a>
<a name="1">[1]</a> <a href="#1" id=1>Unlike previous approaches to joint modeling [ 13 ] , our feature can be easily integrated into any statistical machine translation (SMT) decoder, which leads to substantially larger improvements than k -best rescoring only</a>
<a name="2">[2]</a> <a href="#2" id=2>DARPA BOLT is a major research project with the goal of improving translation of informal, dialectical Arabic and Chinese into English</a>
<a name="3">[3]</a> <a href="#3" id=3>We chose these values for the hidden layer size, vocabulary size, and source window size because they seemed to work best on our data sets u'\u2013' larger sizes did not improve results, while smaller sizes degraded results</a>
<a name="4">[4]</a> <a href="#4" id=4>In this paper we use a basic neural network architecture and a lexicalized probability model to create a powerful MT decoding feature</a>
<a name="5">[5]</a> <a href="#5" id=5>Training is performed</a>
</body>
</html>