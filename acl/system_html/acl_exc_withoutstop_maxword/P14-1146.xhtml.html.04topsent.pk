(lp0
VWe compare sentiment-specific word embedding (SSWE h , SSWE r , SSWE u ) with baseline embedding learning algorithms by only using word embedding as features for Twitter sentiment classification
p1
aVA typical case in sentiment analysis is that the composed phrase and multiword expression may have a different sentiment polarity than the individual words it contains, such as not [bad] and [great] deal of (the word in the bracket has different sentiment polarity with the ngram
p2
aVThe training objectives of SSWE u are that (1) the original ngram should obtain a higher language model score u'\u005cud835' u'\u005cudc87' 0 u u'\u005cu2062' ( t ) than the corrupted ngram u'\u005cud835' u'\u005cudc87' 0 u u'\u005cu2062' ( t r ) , and (2) the sentiment score of original ngram u'\u005cud835' u'\u005cudc87' 1 u u'\u005cu2062' ( t ) should be more consistent with the gold polarity annotation of sentence than corrupted ngram u'\u005cud835' u'\u005cudc87' 1 u u'\u005cu2062' ( t r
p3
aVThe sharp decline at u'\u005cu0391' =1 reflects the importance of sentiment information in learning word embedding for Twitter sentiment classification
p4
aVExperimental results further demonstrate that sentiment-specific word embeddings are able to capture the sentiment information of texts and distinguish words with opposite sentiment polarity, which are not well solved in traditional neural models like C W and word2vec
p5
aVThe lexicon-based approaches [ 44 ,
p6
a.