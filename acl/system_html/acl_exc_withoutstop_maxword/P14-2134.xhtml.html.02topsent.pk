(lp0
VThe coupling of text with demographic information has enabled computational modeling of linguistic variation, including uncovering words and topics that are characteristic of geographical regions [] , learning correlations between words and socioeconomic variables [] ; and charting how new terms spread geographically []
p1
aVTable 2 likewise presents the terms with the highest cosine similarity to city in both California and New York; while the terms most evoked by city in California include regional locations like Chinatown, Los Angeles u'\u005cu2019' South Bay and San Francisco u'\u005cu2019' s East Bay, in New York the most similar terms include hamptons , upstate and borough (New York City u'\u005cu2019' s term of administrative division
p2
aVTo illustrate how the model described above can learn geographically-informed semantic representations of words, table 1 displays the terms with the highest cosine similarity to wicked in Kansas and Massachusetts after running our joint model on the full 1.1 billion words of Twitter data; while wicked in Kansas is close to other evaluative terms like evil and pure and religious terms like gods and spirit , in Massachusetts it is most similar to other intensifiers like super , ridiculously
p3
a.