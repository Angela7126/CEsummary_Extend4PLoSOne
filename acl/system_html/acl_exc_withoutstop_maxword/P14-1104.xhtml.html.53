<html>
<head>
<title>P14-1104.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We employ Amazon u'\u2019' s Mechanical Turk (AMT) to label the emotions of Twitter data, and apply the proposed methods to the AMT dataset with the goals of improving the annotation quality at low cost, as well as learning accurate emotion classifiers</a>
<a name="1">[1]</a> <a href="#1" id=1>Using Formula ( 1 ) and dataset D l ^ , we get the Delta IDF weight vector for each class l u'\u0394' l = ( u'\u0394' u'\u2062' _ u'\u2062' i u'\u2062' d u'\u2062' f 1 l , u'\u2026' , u'\u0394' u'\u2062' _ u'\u2062' i u'\u2062' d u'\u2062' f</a>
<a name="2">[2]</a> <a href="#2" id=2>Active learning for data cleaning differs from traditional active learning because the data already has low quality labels</a>
<a name="3">[3]</a> <a href="#3" id=3>With the proposed algorithm, the active learner becomes more accurate and resistant to label noise, thus the mislabeled data points can be more easily and accurately identified</a>
<a name="4">[4]</a> <a href="#4" id=4>This AMT annotated dataset was used as the low quality dataset D ^ in our evaluation</a>
<a name="5">[5]</a> <a href="#5" id=5>Specifically, according to Formula ( 3 ), a high (absolute value of) spread score</a>
</body>
</html>