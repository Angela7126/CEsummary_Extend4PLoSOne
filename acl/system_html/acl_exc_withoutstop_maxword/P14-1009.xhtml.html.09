<html>
<head>
<title>P14-1009.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>For the lf (lexical function) model, we construct functional matrix representations of adjectives, determiners and intransitive verbs</a>
<a name="1">[1]</a> <a href="#1" id=1>Indeed, in order to train a transitive verb tensor (e.g.,, eat ), the method of Grefenstette et al</a>
<a name="2">[2]</a> <a href="#2" id=2>Tensor by vector multiplication formalizes function application and serves as the general composition method</a>
<a name="3">[3]</a> <a href="#3" id=3>In plf, a functional word is not represented by a single tensor of arity-dependent order, but by a vector plus an ordered set of matrices, with one matrix for each argument the function takes</a>
<a name="4">[4]</a> <a href="#4" id=4>Training plf (practical lexical function) proceeds similarly, but we also build preposition matrices (from u'\u27e8' noun , preposition-noun u'\u27e9' vector pairs), and for verbs we prepare separate subject and object matrices</a>
<a name="5">[5]</a> <a href="#5" id=5>We call our proposal practical lexical function model, or plf</a>
<a name="6">[6]</a> <a href="#6" id=6>If distributional vectors encode certain aspects of word meaning, it is natural to expect that similar aspects of sentence meaning can also receive vector representations, obtained compositionally from word vectors</a>
<a name="7">[7]</a> <a href="#7" id=7>First, one estimates matrices of verb-object phrases from subject and subject-verb-object vectors; next, transitive verb tensors are estimated from verb-object matrices and object vectors</a>
<a name="8">[8]</a> <a href="#8" id=8>The add (additive) model produces the vector of a sentence by summing the vectors of all content words in it</a>
<a name="9">[9]</a> <a href="#9" id=9>We conjecture that the lf 3-way tensor representation of transitive verbs leads to a stronger asymmetry between sentences with inverted arguments, and thus makes this model particularly sensitive to word order differences</a>
<a name="10">[10]</a> <a href="#10" id=10>As follows from section 1.2 , it would be desirable to have a compositional distributional model that encodes function-argument relations</a>
</body>
</html>