(lp0
VWe use the method to do two types of summarization tasks a) generic news summarization which uses a large random collection of news articles as the background, and b) update summarization where the background is a smaller but specific set of news documents on the same topic as the input set
p1
aVWords with - 2 u'\u005cu2062' log u'\u005cu2061' u'\u005cu039b' 10 are considered topic words u'\u005cu2019' s system gives a weight of 1 to the topic words and scores sentences using the number of topic words normalized by sentence length
p2
aVIn this generic task, some of the best reported results were obtained by a system [] which computed importance scores for words in the input by examining if the word occurs with significantly higher probability in the input compared to a large background collection of news articles
p3
aVCentral to this approach is the use of a likelihood ratio test to compute topic words , words that have significantly higher probability in the input compared to the background corpus, and are hence descriptive of the input u'\u005cu2019' s topic
p4
aVIn this work, we compare our system to topic word based ones since the latter is also a general method to find surprising new words in a set of input documents but is not a bayesian approach
p5
aVSurprise is computed based on the changes in probabilities of all of these hypotheses upon seeing the summarization input ii) The computation of topic words is local, it assumes a binomial distribution and the occurrence of a word is independent of others
p6
aVSo new words in an input are added to the background corpus with a count of 1 and the counts of existing words in the background are incremented by 1 before computing the prior parameters
p7
aVThese systems combine (i) a score based on the background ( KL back , TS or SR ) with (ii) the score based on the input only ( KL inp
p8
aVTo reduce redundancy, once a sentence is added, the topic words contained in it are removed from the topic word list before the next sentence selection
p9
aVu'\u005cud835' u'\u005cudc13' u'\u005cud835' u'\u005cudc12' u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2e' u'\u005cud835' u'\u005cudc26' , u'\u005cud835' u'\u005cudc13' u'\u005cud835' u'\u005cudc12' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2f' u'\u005cud835' u'\u005cudc20' use topic words computed as described in Section 2 and utilizing the same background corpus for the generic and update tasks as the surprise-based methods
p10
aVIn this work, we present a Bayesian model for assessing the novelty of a sentence taken from a summarization input with respect to a background corpus of documents
p11
aVThen we normalize the two sets of scores for candidate sentences using z-scores and compute the best sentence as arg u'\u005cu2062' max s i ( TS sum u'\u005cu2062' ( s i ) - KL inp u'\u005cu2062' ( s i )
p12
aVIn future, we plan to use latent topic models to assign a topic to a sentence so that the counts of all the sentence u'\u005cu2019' s words can be aggregated into one dimension
p13
aVFor illustration, assume that a user u'\u005cu2019' s background knowledge comprises of multiple hypotheses about the current state of the world and a probability distribution over these hypotheses indicates his degree of belief in each hypothesis
p14
aV1 1 An alternative algorithm could directly compute the surprise of a sentence by incorporating the words from the sentence into the posterior
p15
aVRather the method creates a summary by optimizing for high similarity of the summary with the input word distribution
p16
aVFor example, to combine TS sum and KL inp for each sentence, we compute its scores based on the two methods
p17
aVIn practice for both tasks, a new summarization input can have words unseen in the background
p18
aVThe surprise S u'\u005cu2062' ( D , u'\u005cud835' u'\u005cudc07' ) created by D on hypothesis space H is defined as the difference between the prior and posterior distributions over the hypotheses, and is computed using KL divergence
p19
aVHowever, we found this specific method to not work well probably because the few and unrepeated content words from a sentence did not change the posterior much
p20
aVIn some cases, surprise can be computed analytically, in particular when the prior distribution is conjugate to the form of the hypothesis, and so the posterior has the same functional form as the prior
p21
aVEven for generic summarization, some of the best results were obtained by by using a large random corpus of news articles as the background while summarizing a new article, an idea first proposed by
p22
aVFor the generic task, we use a critical value of 10 (0.001 significance level) for the u'\u005cu03a7' 2 distribution during topic word computation
p23
aVP u'\u005cu2062' ( H ) gives a prior probability to each hypothesis based on the information in the background corpus
p24
aVFirst, consider generic summarization and the systems which use the background corpus only (those above the horizontal line
p25
aVNow consider a new observation I (a text, sentence, or paragraph from the summarization input ) and the word counts in I given by ( c 1 , c 2 , u'\u005cu2026' , c V
p26
aVV are the concentration parameters of the Dirichlet distribution (and will be set using the background corpus as explained in Section 4.2
p27
aVWe follow a greedy approach to optimize the summary surprise by choosing the most surprising sentence, the next most surprising and so on
p28
aVAt the same time, we aim to avoid redundancy, i.e., selecting sentences with similar content
p29
aVNumerically, SR sum has the highest ROUGE-1 score and TS sum tops according to ROUGE-2
p30
aVOur model is based on the idea of Bayesian Surprise []
p31
aVSo for a resulting - 2 u'\u005cu2062' log u'\u005cu2061' u'\u005cu039b' value, we can use the u'\u005cu03a7' 2 table to find the significance level with which the null hypothesis H 1 can be rejected
p32
aVSystems were given a list of documents ranked according to relevance to a query
p33
aVNote that since KL-divergence is not symmetric, we could also compute KL ( P ( H ) , P ( H
p34
aVFor example, one hypothesis may be that the political situation in Ukraine is peaceful , another where it is not
p35
aVWe refer to the surprise-based summaries as u'\u005cud835' u'\u005cudc12' u'\u005cud835' u'\u005cudc11' u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2e' u'\u005cud835' u'\u005cudc26' and u'\u005cud835' u'\u005cudc12' u'\u005cud835' u'\u005cudc11' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2f' u'\u005cud835' u'\u005cudc20' depending on the type of composition function (Section 4.1
p36
aVH 2 t is a topic word, hence p ( t
p37
aVFor example, a value of 10 corresponds to a significance level of 0.001 and is standardly used as the cutoff
p38
aVA convenient aspect of this approach is that - 2 u'\u005cu2062' log u'\u005cu2061' u'\u005cu039b' is asymptotically u'\u005cu03a7' 2 distributed
p39
a.