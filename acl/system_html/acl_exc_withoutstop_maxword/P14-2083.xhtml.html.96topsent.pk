(lp0
VThe results show that the majority of disagreements are due to hard cases, and only about 20% of conflicting annotations are actual errors
p1
aVIf this was true, the specific theory should be learnable from the annotated data
p2
aVIn NLP, we often model annotation as if it reflected a single ground truth that was guided by an underlying linguistic theory
p3
aVHowever, it is well known that there are linguistically hard cases [] , where no theory provides a clear answer, so annotation schemes commit to more or less arbitrary decisions
p4
aVNote that the spoken language data does not include punctuation
p5
aVWe then collect a corpus of such disagreements and have experts mark which ones are due to actual annotation errors , and which ones reflect linguistically
p6
a.