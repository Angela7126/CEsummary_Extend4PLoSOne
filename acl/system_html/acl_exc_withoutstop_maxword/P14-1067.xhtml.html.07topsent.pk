(lp0
VOn each combination of training and test sets, the batch , adaptive , and empty models are trained and evaluated in terms of global MAE scores on the test set
p1
aVEvaluation is carried out by measuring the performance of the batch (learning only from the training set), the adaptive (learning from the training set and adapting to the test set), and the empty (learning from scratch from the test set) models in terms of global MAE scores on the test set
p2
aVThe batch model is built by learning only from the training data and is evaluated on the test set without exploiting information from the test instances
p3
aVAs a final analysis of our results, we investigated how the performance of the different types of models ( batch , adaptive , empty ) relates to the distance between training and test sets
p4
aVThese values confirm that batch models are heavily affected by the dissimilarity between training and test data large differences in the label distribution imply higher MAE results and vice-versa
p5
aVFor the user_change experiments, training and test sets are selected from different post-editors within the same domain
p6
aVThe lower correlation observed for the adaptive models also confirms our intuitions adapting to the new test points, these models are in fact more robust to differences with the training data
p7
aVWhen this distance is minimal, batch models can be a reasonable option, but when the gap between training and test data increases, adaptive or empty models are a preferable choice to achieve good results
p8
aVThis is in line with our previous findings about batch models that, learning only from
p9
a.