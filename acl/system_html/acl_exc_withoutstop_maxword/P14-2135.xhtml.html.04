<html>
<head>
<title>P14-2135.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>On a different set of 200 concepts extracted by random sampling from the USF dataset stratified by concreteness rating (including concepts across the concreteness spectrum), we observed a high correlation between abstractness and dispersion (Spearman u'\u03a1' = 0.61 , p 0.001</a>
<a name="1">[1]</a> <a href="#1" id=1>Multi-modal models that learn semantic concept representations from both linguistic and perceptual input were originally motivated by parallels with human concept acquisition, and evidence that many concepts are grounded in the perceptual system [ 3 ]</a>
<a name="2">[2]</a> <a href="#2" id=2>To evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u'\u222a' C introduced in Section 2</a>
<a name="3">[3]</a> <a href="#3" id=3>Multi-modal models in which perceptual input is filtered according to our algorithm learn higher-quality semantic representations than previous approaches, resulting in a significant performance improvement of up to 17% in capturing the semantic similarity of concepts</a>
<a name="4">[4]</a> <a href="#4" id=4>Indeed, experiments indicate that while the addition of perceptual input is generally beneficial for representations of concrete concepts [ 13 , 7 ] , it can in fact be detrimental to representations of abstract concepts [ 13 ]</a>
<a name="5">[5]</a> <a href="#5" id=5>Formally, we propose a measure, image dispersion d</a>
</body>
</html>