<html>
<head>
<title>P14-1013.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>By measuring the similarity between the source texts and bilingual translation rules, the SMT decoder is able to encourage topic relevant translation candidates and penalize topic irrelevant candidates</a>
<a name="1">[1]</a> <a href="#1" id=1>To incorporate topic representations as translation knowledge into SMT, our neural network based approach directly optimizes similarities between the source language and target language in a compact topic space</a>
<a name="2">[2]</a> <a href="#2" id=2>Since the vectors from DAE are trained using information from monolingual training data independently, these vectors may be inadequate to measure bilingual topic similarity due to their different topic spaces</a>
<a name="3">[3]</a> <a href="#3" id=3>Since the information within the sentence is insufficient for topic modeling, we first enrich sentence contexts via Information Retrieval (IR) methods using content words in the sentence as queries, so that topic-related monolingual documents can be collected</a>
<a name="4">[4]</a> <a href="#4" id=4>Therefore, it is important to leverage topic information to learn smarter translation models and achieve better translation performance</a>
<a name="5">[5]</a> <a href="#5" id=5>We directly optimized bilingual topic similarity in the deep learning framework with the help of sentence-level parallel data, so that the learned representation could be easily used in SMT decoding procedure</a>
<a name="6">[6]</a> <a href="#6" id=6>The results confirm that topic information is indispensable for SMT since both [ 34 ] and our neural network based method significantly outperforms the baseline system</a>
<a name="7">[7]</a> <a href="#7" id=7>This is not simply coincidence since we can interpret their approach as a special case</a>
</body>
</html>