(lp0
VWe directly optimized bilingual topic similarity in the deep learning framework with the help of sentence-level parallel data, so that the learned representation could be easily used in SMT decoding procedure
p1
aVTo incorporate topic representations as translation knowledge into SMT, our neural network based approach directly optimizes similarities between the source language and target language in a compact topic space
p2
aVTherefore, it helps to train a smarter translation model with the embedded topic information
p3
aVThis is not simply coincidence since we can interpret their approach as a special case in our neural network method when a parallel sentence pair has document-level information, that document will be retrieved for training; otherwise, the most relevant document will be retrieved from the monolingual data
p4
aVThe results confirm that topic information is indispensable for SMT since both [ 34 ] and our neural network based method significantly outperforms the baseline system
p5
aVSince a parallel sentence pair should have the same topic, our goal is to maximize the similarity score between the source sentence and target sentence
p6
aVBy measuring the similarity between the source texts and bilingual translation rules, the SMT decoder is able to encourage topic relevant translation candidates and penalize topic irrelevant candidates
p7
aVIrrelevant documents bring so many unrelated topic words hence degrade neural network learning performance
p8
a.