<html>
<head>
<title>P14-1027.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Their experiments suggest that function words play a special role in the acquisition process children learn function words before they learn the vast bulk of the associated content words, and they use function words to help identify context words</a>
<a name="1">[1]</a> <a href="#1" id=1>We have shown that a model that expects function words on the left periphery performs more accurate word segmentation on English, where function words do indeed typically occur on the left periphery, leaving open the question how could a learner determine whether function words generally appear on the left or the right periphery of phrases in the language they are learning</a>
<a name="2">[2]</a> <a href="#2" id=2>Section 4 explains how a learner could use Bayesian model selection to determine that function words appear on the left periphery in English by comparing the posterior probability of the data under our u'\u201c' function word u'\u201d' Adaptor Grammar to that obtained using a grammar which is identical except that rules ( 22 u'\u2013' 24 ) are replaced with the mirror-image rules in which u'\u201c' function words u'\u201d' are attached to the right periphery</a>
<a name="3">[3]</a> <a href="#3" id=3>historically, the rate of innovation of function words is much lower than the rate of innovation of content words (i.e.,, function words are typically u'\u201c' closed class u'\u201d' , while content words are u'\u201c' open class u'\u201d'</a>
<a name="4">[4]</a> <a href="#4" id=4>By comparing the posterior probability of two models u'\u2014' one in which function words appear at the left edges of phrases, and another in which function words appear at the right edges of phrases u'\u2014' we show that a learner could use Bayesian posterior probabilities to determine that function words appear at the left edges of phrases in English, even though they are not told the locations of word boundaries or which words are function words</a>
<a name="5">[5]</a> <a href="#5" id=5>Function words differ from content words in at least the following ways</a>
<a name="6">[6]</a> <a href="#6" id=6>Section 2 describes the specific word segmentation models studied in this paper, and the way we extended them to capture certain properties of function words</a>
<a name="7">[7]</a> <a href="#7" id=7>function word types typically have much higher token frequency than content word types</a>
<a name="8">[8]</a> <a href="#8" id=8>semantically, content words denote sets of objects or events, while function words denote more complex relationships over the entities denoted by content words</a>
<a name="9">[9]</a> <a href="#9" id=9>Thus, the present model, initially aimed at segmenting words from continuous speech, shows three interesting characteristics that are also exhibited by human infants it distinguishes between function words and content words [] , it allows learners to acquire at least some of the function words of their language (e.g., [] ); and furthermore, it may also allow them to</a>
</body>
</html>