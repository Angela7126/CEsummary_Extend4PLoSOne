(lp0
VUsing unlabeled data with the results of Berkeley Parser ( u'\u005cu201c' Unlabeled u'\u005cu2190' B u'\u005cu201d' ) significantly improves parsing accuracy by 0.55% (93.40-92.85) on English and 1.06% (83.34-82.28) on Chinese
p1
aVThe second major row shows the results when we use single 1-best parse trees on unlabeled data
p2
aVEvaluation on labeled data shows the oracle accuracy of parse forest is much higher than that of 1-best outputs of single parsers (see Table 3
p3
aVResults show all the three sets of unlabeled data can help the parser
p4
aVWe adopt the best settings on development data for semi-supervised GParser with our proposed approach, and make comparison with previous results on test data
p5
aVDifferent from traditional self/co/tri-training which only use 1-best parse trees on unlabeled data, our approach adopts ambiguous labelings, represented by parse forest, as gold-standard for unlabeled sentences
p6
aVWe divide the unlabeled data into three sets according to the divergence of the 1-best outputs of Berkeley Parser and ZPar
p7
aVWhen the parse forests of the unlabeled data are the union of the outputs of GParser and ZPar, denoted as u'\u005cu201c' Unlabeled u'\u005cu2190' Z+G u'\u005cu201d' , each word has 1.053 candidate heads on English and 1.136 on Chinese, and the oracle accuracy is higher than using 1-best outputs of single parsers (94.97% vs
p8
aVWe propose a generalized ambiguity-aware ensemble training framework for semi-supervised dependency parsing, which can make better use of unlabeled data, especially when parsers from different views produce
p9
a.