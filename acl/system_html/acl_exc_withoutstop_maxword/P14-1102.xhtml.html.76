<html>
<head>
<title>P14-1102.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Similar to the model presented in this paper, BabySRL is based on simple ordering features such as argument position relative to the verb and argument position relative to the other arguments</a>
<a name="1">[1]</a> <a href="#1" id=1>When imperatives are filtered out of the training corpus, the symmetric model obtains a worse BIC fit than a model that lacks the non-canonical subject Gaussian</a>
<a name="2">[2]</a> <a href="#2" id=2>The model represents the preferred locations of semantic roles relative to the verb as distributions over real numbers</a>
<a name="3">[3]</a> <a href="#3" id=3>The BabySRL corpus is annotated with 5 different roles, but the model described in this paper only uses 2 roles</a>
<a name="4">[4]</a> <a href="#4" id=4>The model presented here learns a single, non-recursive ordering for the semantic roles in each sentence relative to the verb since several studies have suggested that early child grammars may consist of simple linear grammars that are dictated by semantic roles []</a>
<a name="5">[5]</a> <a href="#5" id=5>For the intransitive</a>
</body>
</html>