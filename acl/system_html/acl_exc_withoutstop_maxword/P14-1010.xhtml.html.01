<html>
<head>
<title>P14-1010.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>2008 ) also tune on unsegmented references by simply desegmenting SMT output before MERT collects sufficient statistics for BLEU and translate with both segmented and unsegmented language models for English-to-Finnish translation</a>
<a name="1">[1]</a> <a href="#1" id=1>Work on target language morphological segmentation for SMT can be divided into three subproblems segmentation, desegmentation and integration</a>
<a name="2">[2]</a> <a href="#2" id=2>For English-to-Arabic, 1-best desegmentation results in a 0.7 BLEU point improvement over training on unsegmented Arabic</a>
<a name="3">[3]</a> <a href="#3" id=3>Our first baseline is Unsegmented , where we train on unsegmented target text, requiring no desegmentation step</a>
<a name="4">[4]</a> <a href="#4" id=4>Lattice desegmentation is a non-local lattice transformation</a>
<a name="5">[5]</a> <a href="#5" id=5>This is a natural place to introduce features that describe the desegmentation process, such as scores provided by a desegmentation table, which can be incorporated into the desegmenting transducer u'\u2019' s edge weights</a>
<a name="6">[6]</a> <a href="#6" id=6>We approach this problem by augmenting an SMT system built over target segments with features that reflect the desegmented target words</a>
<a name="7">[7]</a> <a href="#7" id=7>They introduce an additional desegmentation technique that augments the table-based approach with an unsegmented language model</a>
<a name="8">[8]</a> <a href="#8" id=8>Moving to lattice desegmentation more than doubles that improvement, resulting in a BLEU score of 34.4 and an improvement of 1.0 BLEU point over 1-best desegmentation</a>
<a name="9">[9]</a> <a href="#9" id=9>In this setting,</a>
</body>
</html>