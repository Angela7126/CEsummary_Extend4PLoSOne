(lp0
VWith this in mind, we consider whether we can reduce variance in the initialization by tuning the initial model
p1
aVThe results, shown in Figure 3 , show that we can ameliorate the variance due to initialization by tuning the initial model to NMI or perplexity
p2
aVWe observed previously that variance in the Gibbs initialization of the model contributes significantly to variance of the overall algorithm, as measured by NMI
p3
aVThus we perform a set of experiments in which we perform Gibbs initialization 20 times on the initialization set, setting the particle filter u'\u005cu2019' s initial model to the model out of these 20 with the highest in-sample NMI
p4
aVThus, if initialization continues to be crucial to performance, at least we may have the flexibility of initializing without gold-standard labels
p5
aVWe may not always have labeled data for initialization, so we
p6
a.