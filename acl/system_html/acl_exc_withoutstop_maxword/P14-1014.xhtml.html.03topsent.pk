(lp0
VThe input for the this module is the word n-gram ( w i - l , u'\u005cu2026' , w i + r ) , the form of which is identical to the training data of the pre-trained WRRBM
p1
aVWe can choose to use only the word representations of the learned WRRBM
p2
aVThis can be achieved by initializing only the first layer of the web module with the projection matrix u'\u005cud835' u'\u005cudc03' of the learned WRRBM
p3
aV2011 ) propose to learn representations from the mixture of both source and target domain unlabelled data to improve cross-domain sentiment classification
p4
aVWe conduct experiments to test whether using the target domain data to train the WRRBM yields better performance compared with using mixed data from all sub-domains
p5
aVThe parameters { u'\u005cud835' u'\u005cudc1b' , u'\u005cud835' u'\u005cudc1c' , u'\u005cud835' u'\u005cudc03' , u'\u005cud835' u'\u005cudc16' ( 1 ) , u'\u005cu2026' , u'\u005cud835' u'\u005cudc16' ( n ) } can be trained using a Metropolis-Hastings-based CD
p6
a.