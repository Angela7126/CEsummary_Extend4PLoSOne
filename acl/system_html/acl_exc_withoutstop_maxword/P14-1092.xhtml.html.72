<html>
<head>
<title>P14-1092.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We propose a novel answer reranking (AR) model that combines lexical semantics (LS) with discourse information, driven by two representations of discourse a shallow representation centered around discourse markers and surface text information, and a deep one based on the Rhetorical Structure Theory (RST) discourse framework [ 7 ]</a>
<a name="1">[1]</a> <a href="#1" id=1>[ 22 ] recently addressed the problem of answer sentence selection and demonstrated that LS models, including recurrent neural network language models (RNNLM), have a higher contribution to overall performance than exploiting syntactic analysis</a>
<a name="2">[2]</a> <a href="#2" id=2>So far, we have treated LS and discourse as distinct features in the reranking model, However, given that LS features greatly improve the CR baseline, we hypothesize that a natural extension to the discourse models would be to make use of LS similarity (in addition to the traditional information retrieval similarity) to label discourse segments</a>
<a name="3">[3]</a> <a href="#3" id=3>More specifically, DMM and DPM show similar performance benefits when used individually, but their combination generally outperforms the individual models, illustrating the fact that the two models capture related but different discourse information</a>
<a name="4">[4]</a> <a href="#4" id=4>AR analyzes the candidates using more expensive techniques to extract discourse and LS features</a>
</body>
</html>