<html>
<head>
<title>P14-2088.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Finally, we compare against Structural Correspondence Learning ( SCL ; Blitzer et al., 2006) , another feature learning algorithm</a>
<a name="1">[1]</a> <a href="#1" id=1>As we will show, substantial efficiency improvements can be obtained by designing domain adaptation methods for learning in structured feature spaces</a>
<a name="2">[2]</a> <a href="#2" id=2>Chen et al</a>
<a name="3">[3]</a> <a href="#3" id=3>Chen et al</a>
<a name="4">[4]</a> <a href="#4" id=4>1) feature scrambling , which randomly chooses a feature template and randomly selects an alternative value within the template, and (2) structured dropout , which randomly eliminates all but a single feature template</a>
<a name="5">[5]</a> <a href="#5" id=5>To solve this problem, Chen et al</a>
<a name="6">[6]</a> <a href="#6" id=6>We show how it is possible to marginalize over both types of noise, and find that the solution for structured dropout is substantially simpler and more efficient than the mDA approach of</a>
</body>
</html>