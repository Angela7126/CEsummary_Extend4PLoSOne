(lp0
VThe structural similarity component, instead, is a novel graph-based similarity measurement technique which calculates the similarity between a pair of concepts across the semantic networks of the two resources by leveraging the semantic structure of those networks
p1
aVInstead of measuring the similarity of two concepts on the basis of their distance in the combined graph, our approach models each concept through a rich vectorial representation we refer to as semantic signature and compares the two concepts in terms of the similarity of their semantic signatures
p2
aVThe definitional similarity component computes the similarity of two concepts in terms of the similarity of their definitions, a method that has also been used in previous work for aligning lexical resources [ 27 , 12 ]
p3
aVThe other two resources, i.e.,, wt and ow , do not provide a reliable network of semantic relations, therefore we used our ontologization approach to construct their corresponding semantic graphs
p4
aVIn Section 2 , we presented our approach for aligning lexical resources
p5
aVHowever, not all lexical resources provide explicit semantic relations between concepts and, hence, machine-readable dictionaries like Wiktionary have first to be transformed into semantic graphs before such graph-based approaches can be applied to them
p6
aVHowever, other resources such as Wiktionary do not provide semantic relations between concepts and, therefore, have first to be transformed into semantic networks before they can be aligned using our alignment algorithm
p7
aVTherefore, we assume that a lexical resource L can be represented as an undirected graph G = ( V , E ) where V is the set of nodes, i.e.,, the concepts defined in the resource, and E is the set of undirected edges, i.e.,, semantic relations between concepts
p8
aVHaving lexical resources represented as semantic networks is highly beneficial
p9
aVThe consistency in the performance of SemAlign in its different configurations and across different resource pairs indicates its robustness and shows that our system can be utilized effectively for aligning any pair of lexical resources, irrespective of their structure or availability of training data
p10
aVWhen applied to a semantic graph by initializing the random walks from a set of concepts (nodes), ppr yields a vector in which each concept is associated with a weight denoting its semantic relevance to the initial concepts
p11
aVLast year Matuschek and Gurevych ( 2013 ) proposed Dijkstra-WSA, a graph-based approach relying on shortest paths between two concepts when the two corresponding resources graphs were combined by leveraging monosemous linking
p12
aVOur approach, in contrast, aims at transforming a lexical resource into a full-fledged semantic network, hence providing a denser graph with most of its nodes connected
p13
aVTherefore, the considerable performance improvement over Dijkstra-WSA on this resource pair shows the effectiveness of our novel concept similarity measure independently of the underlying semantic network
p14
aVOur ontologization algorithm takes as input a lexicon L and outputs a semantic graph G = ( V , E ) where, as already defined in Section 2 , V is the set of concepts in L and E is the set of semantic relations between these concepts
p15
aVHowever, this alignment method still involves tuning of parameters which are highly dependent on the characteristics of the generated graphs and, hence, requires hand-crafted sense alignments for the specific pair of resources to be aligned, a task which has to be replicated every time the resources are updated
p16
aVWe use the same semantic graph H for computing the semantic signatures of both definitions
p17
aVAs can be seen, the approach consists of two main components definitional similarity and structural similarity
p18
aVAs mentioned earlier, semantic signatures are vectors with dimension equal to the number of nodes in the semantic graph
p19
aVThis enables our system to be applied effectively for aligning new pairs of resources for which no training data is available, with state-of-the-art performance
p20
aVEach of these components gets, as its input, a pair of concepts belonging to two different semantic networks and produces a similarity score
p21
aVHere, we describe how the four semantic graphs for our four lexical resources (i.e.,, wn , wp , wt , ow ) were constructed
p22
aVThe aim of this stage is to model a given concept or set of concepts through a vectorial semantic representation, which we refer to as the semantic signature of the input
p23
aVThis component goes beyond the surface realization of concepts, thus providing a deeper measure of concept similarity
p24
aVAs an example, assume we are given two semantic signatures computed for two concepts in WordNet and Wiktionary
p25
aVMeyer and Gurevych ( 2012a ) and Matuschek and Gurevych ( 2013 ) provided approaches for building graph representations of Wiktionary and OmegaWiki
p26
aVIn order to address this issue and hence generalize our alignment approach to any given lexical resource, we propose a method for transforming a given machine-readable dictionary into a semantic network, a process we refer to as ontologization
p27
aVThis rich representation leads to our approach having a good degree of robustness such that it can achieve competitive results even in the absence of training data
p28
aVIn the following, we present our novel approach for measuring the similarity of concept pairs
p29
aVThis is particularly interesting as the wktwsd system uses a rule-based technique specific to relation disambiguation in wt , whereas our method is resource independent and can be applied to arbitrary words in the definition of any concept
p30
aVIn the structural similarity component (Figure 1 (b), bottom), the semantic signature for each concept c i is computed by running the ppr algorithm on its corresponding graph G i , hence a different u'\u005cud835' u'\u005cudc0c' i is built for each of the two concepts
p31
aVIn this case, both the definitional and structural similarity scores are treated as equally important and two concepts are aligned if their overall similarity exceeds the middle point of the similarity scale
p32
aVNow that all the four resources are transformed into semantic graphs, we move to our alignment experiments
p33
aVIn spite of its simplicity, the mere calculation of the similarity of concept definitions provides a strong baseline, especially for cases where the definitional texts for a pair of concepts to be aligned are lexically similar, yet distinguishable from the other definitions
p34
aVTo gain more insight into the effectiveness of our structural similarity measure in comparison to the Dijkstra-WSA method, we carried out an experiment where our alignment system used only the structural similarity component, a variant of our system we refer to as SemAlign s u'\u005cu2062' t u'\u005cu2062' r
p35
aVFor instance, WordNet can be readily represented as an undirected graph G whose nodes are synsets and edges are modeled after the relations between synsets defined in WordNet (e.g.,, hypernymy, meronymy, etc.), and u'\u005cu2112' G is the mapping between each synset node and the set of synonyms which express the concept
p36
aVFor ontologizing wt and ow , the bag of content words W is given by the content words in sense definitions and, if available, additional related words obtained from lexicon relations (see Section 3
p37
aVAs mentioned in Section 2.1.1 , we build the wn graph by including all the synsets and semantic relations defined in WordNet (e.g.,, hypernymy and meronymy) and further populate the relation set by connecting a synset to all the other synsets that appear in its disambiguated gloss
p38
aVAs a result of this procedure, we obtain a semantic graph representation G for the lexicon L
p39
aVNevertheless, when it comes to aligning textual definitions in different resources, the lexical approach [ 32 , 5 , 11 ] falls short because of the potential use of totally different wordings to define the same concept
p40
aVWe utilized Personalized PageRank [ 10 , ppr ] , a random walk graph algorithm, for calculating semantic signatures
p41
aVIn addition, as we mentioned earlier, for wn - wp we used the same graph as that of Dijkstra-WSA, since both wn and wp provide a full-fledged semantic network and thus neither needed to be ontologized
p42
aVAligning lexical resources has been a very active field of research in the last decade
p43
aVIn this component the personalization vector u'\u005cud835' u'\u005cudc2f' i is set by uniformly distributing the probability mass over the nodes corresponding to the senses of all the content words in the extended definition of d i according to the sense inventory of a semantic network H
p44
aVAs a result of the unification process, we obtain a pair of equally-sized semantic signatures with comparable components
p45
aVWe therefore propose an approach (part (c) of Figure 1 ) that finds a common ground between the two signatures to this end we consider all the concepts associated with monosemous words in the two signatures as landmarks and restrict the two signatures exclusively to those common concepts
p46
aVAs a matter of fact, most efforts have been concentrated on aligning the de facto community standard sense inventory, i.e., WordNet, to other resources
p47
aVFor this purpose we used the WordNet [ 7 ] graph which was further enriched by connecting each concept to all the concepts appearing in its disambiguated gloss
p48
aVFor each source concept c u'\u005cu2208' V we create a bag of content words W = { w 1 , u'\u005cu2026' , w n } which includes all the content words in its definition d and, if available, additional related words obtained from lexicon relations (e.g.,, synonyms in Wiktionary
p49
aVA good example is WordNet, which has been exploited as a semantic network in dozens of NLP tasks [ 7 ]
p50
aVLeveraging monosemous words as bridges between two signatures is a particularly reliable technique as typically a significant portion of all words in a lexicon are monosemous
p51
aVHaving at hand the semantic signatures for the two input concepts, we proceed to comparing them (part (d) in Figure 1
p52
aVAs an example, for wt , Matuschek and Gurevych ( 2013 ) generated a graph where around 30% of the nodes were in isolation, whereas this number drops to around 5% in our corresponding graph
p53
aVFigure 1 illustrates the procedure underlying our cross-resource concept similarity measurement technique
p54
aVOur approach, however, thanks to the connections obtained through ambiguous words, can provide graphs with significantly higher coverage
p55
aVOwing to its ability to bring together features like multilinguality and increasing coverage, over the past few years resource alignment has proven beneficial to a wide spectrum of tasks, such as Semantic Parsing [ 33 ] , Semantic Role Labeling [ 28 ] , and Word Sense Disambiguation [ 25 ]
p56
aVWe therefore measure the similarity between the definition of cone 4 n and all the 5 definitions of fruit and introduce a link from cone 4 n to the sense of fruit which yields the maximal similarity value (defined as u'\u005cu201c' (botany) The seed-bearing part of a plant u'\u005cu2026' u'\u005cu201d'
p57
aVGiven a pair of lexical resources L 1 and L 2 , we align each concept in L 1 by mapping it to its corresponding concept(s) in the target lexicon L 2
p58
aV[t!] Lexical Resource Aligner {algorithmic} [1] \u005cREQUIRE graphs H = ( V H , E H ) , G 1 = ( V 1 , E 1 ) and G 2 = ( V 2 , E 2 ) , the similarity threshold u'\u005cu0398' , and the combination parameter u'\u005cu0392' \u005cENSURE A , the set of all aligned concept pairs
p59
aVWe compared our similarity-based disambiguation approach against the state of the art on this dataset, i.e.,, the wktwsd system, which is a wt relation disambiguation algorithm based on a series of rules [ 22 ]
p60
aVHowever, the dataset for wn - ow was originally built for the German language and, hence, was missing many English ow concepts that could be considered as candidate target alignments
p61
aVWe would like to thank Michael Matuschek for providing us with Wikipedia graphs and alignment datasets
p62
aVOne of the main objectives in this area has been to enrich existing ontologies by means of complementary information from other resources
p63
aVAlso, consider the noun tradeoff which is monosemous according to both these resources
p64
aVIn this latter case, we choose the most appropriate concept c i u'\u005cu2208' u'\u005cu2110' G L u'\u005cu2062' ( w i ) by finding the maximal similarity between the definition of c and the definitions of each sense of w i
p65
aVThe main feature worth remarking upon is the consistency in the results across different resource pairs the unsupervised system gains the best recall among the three configurations (with the improvement over sb+dwsa being always statistically significant 4 4 All significance tests are done using z-test at p 0.05 whereas tuning, both on a subset or through cross-validation, consistently leads to the best performance in terms of F1 and accuracy (with the latter being statistically significant with respect to sb+dwsa on wn - wp and wn - wt
p66
aVAs can be seen, our method proves to be very accurate, surpassing the performance of the wktwsd system in terms of precision, F1, and accuracy
p67
aVAs our benchmark we tested on the gold standard datasets used in Matuschek and Gurevych ( 2013 ) for three alignment tasks
p68
aVHowever, as mentioned in the introduction, definition similarity-based techniques fail at identifying the correct alignments in cases where different wordings are used or definitions are not of high quality
p69
aVFor ow , however, the encoded relations, though relatively small in number, are already disambiguated and, therefore, the ontologization was just performed on the definition u'\u005cu2019' s content words
p70
aVWe also show the results for this system as sb+dwsa in the table
p71
aVThe algorithm iterates over all concepts c 1 u'\u005cu2208' V 1 and, for each of them, obtains the set of concepts C u'\u005cu2282' V 2 , which can be considered as alignment candidates for c 1 (line 2
p72
aVMoreover, the unsupervised system proves to be very robust inasmuch as it provides competitive results on all the three datasets, while it surpasses the performance of sb+dwsa on wn - wt
p73
aVWe first create the empty undirected graph G L = ( V , E ) such that V is the set of concepts in L and E = u'\u005cu2205'
p74
aVThe latter word is monosemous in Wiktionary, hence we directly connect cone 4 n to the only sense of conifer n
p75
aVThen, given two signatures u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' 1 and u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' 2 , computed on the respective graphs G 1 and G 2 , we first obtain the set u'\u005cu2133' of words that are monosemous according to both semantic networks, i.e.,, u'\u005cu2133' = { w u'\u005cu2110' G 1 u'\u005cu2062' ( w
p76
aVThis is particularly interesting as the latter system involves tuning of several parameters, whereas SemAlign, in its unsupervised configuration, does not need any training data nor does it involve any tuning
p77
aVHence, given that a large portion of edges came from ambiguous words (see Table 1 ), we carried out an experiment to evaluate the accuracy of our disambiguation method
p78
aVTo this end, we took as our benchmark the dataset provided by Meyer and Gurevych ( 2010 ) for evaluating relation disambiguation in wt
p79
aVA recent prominent case is Wikipedia [ 18 , 13 ] which, thanks to its inter-article hyperlink structure, provides a rich backbone for structuring additional information [ 2 , 34 , 23 , 8 ]
p80
aVWe therefore fixed the dataset for the English language and reproduced the performance of previous work on the new dataset
p81
aVWe show the results for this setting in the bottom part of the table (last three lines
p82
aVBoth words in these relations, however, should be disambiguated according to the given lexicon [ 29 ] , making the task particularly prone to mistakes due to the high number of possible sense pairings
p83
aVThe edges obtained from unambiguous entries are essentially sense disambiguated on both sides whereas those obtained from ambiguous terms are a result of our similarity-based disambiguation
p84
aVFormally, we first represent a semantic network consisting of N concepts as a row-stochastic transition matrix u'\u005cud835' u'\u005cudc0c' u'\u005cu2208' u'\u005cu211d' N × N
p85
aVThe noun fruit , however, has 5 senses in Wiktionary
p86
aVThe problem is then cast as a disambiguation task whose goal is to identify the intended sense of each word w i u'\u005cu2208' W according to the sense inventory of L if w i is monosemous, i.e
p87
aVWe show in Table 4 the performance of the two systems on our three datasets
p88
aVThe u'\u005cu201c' Human u'\u005cu201d' row corresponds to the inter-rater F1 and accuracy scores, i.e.,, the upperbound performance on this dataset, as calculated by Meyer and Gurevych ( 2010
p89
aVHere, we take an alternative approach which requires disambiguation on the target side only, hence reducing the size of the search space significantly
p90
aVIn wt , both of these are in word surface form and hence had to be disambiguated
p91
aVSince the structural similarity signatures u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' 1 and u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' 2 are calculated on different graphs and thus have different dimensions, we need to make them comparable by unifying them
p92
aVUnsupervised , where the two parameters are set to their middle values (i.e.,, 0.5), hence, no tuning is performed for either of the parameters
p93
aVAs an example, consider the 4 t u'\u005cu2062' h sense of the noun cone in Wiktionary (i.e.,, cone 4 n ) which is defined as u'\u005cu201c' The fruit of a conifer u'\u005cu201d'
p94
aVThe cell ( i , j ) in the matrix denotes the probability of moving from a concept i to j in the graph
p95
aVWe also report results for accuracy which, in addition to true positives, takes into account true negatives, i.e.,, pairs which are correctly judged as unaligned
p96
aVAs can be seen in the table, SemAlign s u'\u005cu2062' t u'\u005cu2062' r consistently improves over Dijkstra-WSA according to recall, F1 and accuracy with all the differences in recall and accuracy being statistically significant (p 0.05
p97
aVFor a concept c 1 , alignment candidates in G 2 usually consist of every concept c 2 u'\u005cu2208' V 2 that shares at least one lexicalization with c 1 in the same part of speech tag, i.e.,, u'\u005cu2112' G 1 u'\u005cu2062' ( c 1 ) u'\u005cu2229' u'\u005cu2112' G 2 u'\u005cu2062' ( c 2 ) u'\u005cu2260' u'\u005cu2205' [ 31 , 20 ]
p98
aVWe then transform each of the two signatures u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' i into a new sub-signature u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' i u'\u005cu2032' whose dimension is u'\u005cu2133' the k t u'\u005cu2062' h component of u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' i u'\u005cu2032' corresponds to the weight in u'\u005cud835' u'\u005cudcae' u'\u005cud835' u'\u005cudc2f' i of the only concept of w k in u'\u005cu2110' G i u'\u005cu2062' ( w k
p99
aVHaving found the intended sense c ^ w i of w i , we add the edge { c , c ^ w i } to E
p100
a.