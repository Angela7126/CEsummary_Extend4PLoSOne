(lp0
VWe would like to thank Jey Han Lau for providing us with the labels selected by Lau et al
p1
aVThe results obtained by applying PageRank over the unweighted graph (2.05, 1.98, 2.04 and 1.88) are consistently better than the supervised and unsupervised methods reported by Lau et al
p2
aV2009 ) introduced an approach for labelling topics that relied on two hierarchical knowledge resources labelled by humans, while Lau et al
p3
aVA set of candidate labels is generated from Wikipedia article titles by querying using topic terms
p4
aVThe 10 terms with the highest marginal probabilities in the topic are used to query Wikipedia and the titles of the articles retrieved used as candidate labels
p5
aVThey reported that the supervised version achieves better performance than a previously reported approach [ 17 ]
p6
aVFurther candidate labels are generated by processing the titles of these articles to identify noun chunks and n-grams within the noun chunks that are themselves the titles of Wikipedia articles
p7
aVThe most important keywords can be used to generate keyphrases for labelling the topic or weight pre-existing candidate labels
p8
aVA common way to represent topics is as set of keywords generated from the n terms with the highest marginal probabilities
p9
aVConsequently, it is not necessary to measure semantic similarity between topic keywords and candidate labels as previous approaches have done
p10
aV2011 ) report two versions of their approach, one unsupervised (which is used as a baseline) and another which is supervised
p11
aVResults from the nDCG metric imply that our methods provide better rankings of the candidate labels in the majority of the cases
p12
aVFor example, a topic which has keywords school, student, university, college, teacher, class, education, learn, high, program , could be labelled as Education and a suitable label for the topic shown above would be Global Financial Crisis
p13
aVIn Figure 6 , we show the scores of Top-1 average rating obtained in the different domains by experimenting with the number of search results used to generate the text graph
p14
aVHowever, this has a negative effect on performance since it favoured short labels of one or two words which were not sufficiently descriptive of the topics
p15
aVIn addition, performance improvement gained from using the weighted graph is modest, suggesting that the computation of association scores over a large reference corpus could be omitted if resources are limited
p16
aVImportant terms are identified by applying the PageRank algorithm [ 19 ] in a similar way to the approach used by Mihalcea and Tarau ( 2004 ) for document keyphrase extraction
p17
aVAn interesting finding is that, although limited in length, the textual information in the search result u'\u005cu2019' s metadata contain enough salient terms relevant to the topic to provide reliable estimates of term importance
p18
aVThis is expected since the weighted graph contains additional information about word relatedness
p19
aVWord co-occurrences are computed using Wikipedia as a a reference corpus
p20
aVBut interpreting such lists is not always straightforward, particularly since background knowledge may be required [ 5 ]
p21
aVFor example, the word hardware is more related and, therefore, closer in the graph to the word virtualization than to the word investments
p22
aVIn addition, we weight the edges of the graph by computing the relatedness between two nodes, v i and v j , as their normalised Pointwise Mutual Information (NPMI) [ 3 ]
p23
aVWe consider any remaining words in the search result metadata as nodes, v u'\u005cu2208' V , in a graph G = ( V , E
p24
aVEach node is connected to its neighbouring words in a context window of ± n words
p25
aVPairs of words are connected with edges only if NPMI u'\u005cu2062' ( w i , w j ) 0.2 avoiding connections between words co-occurring by chance and hence introducing noise
p26
a.