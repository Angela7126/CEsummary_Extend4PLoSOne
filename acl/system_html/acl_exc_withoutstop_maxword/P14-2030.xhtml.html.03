<html>
<head>
<title>P14-2030.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>To explore whether language provides signal for future work in fine-grain social role prediction, we constructed a set of experiments, one per role, where training and test sets were balanced between users from a random background sample and self-reported users</a>
<a name="1">[1]</a> <a href="#1" id=1>From the remaining attribute terms, we identified users with tweets scoring 4.0 or better as positive examples of the associated roles</a>
<a name="2">[2]</a> <a href="#2" id=2>These tweets served as representative content for that role, with any tweet matching the self-reporting patterns filtered</a>
<a name="3">[3]</a> <a href="#3" id=3>Tweets from those users were scraped via the Twitter API to construct corpora for each role</a>
<a name="4">[4]</a> <a href="#4" id=4>This left fewer than 30 attribute terms per role, with many roles having fewer than 10</a>
<a name="5">[5]</a> <a href="#5" id=5>First, we counted all terms matching a target social role u'\u2019' s possessive pattern (e.g.,, doctor u'\u2019' s ) in the web-scale n-gram corpus Google V2 [ 13 ] 5 5 In this corpus, follower-type roles like belieber and directioner are not at all prevalent</a>
<a name="6">[6]</a> <a href="#6" id=6>The authors examined</a>
</body>
</html>