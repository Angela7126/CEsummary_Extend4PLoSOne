(lp0
VTo improve word ordering decisions, White Rajkumar [ 36 ] demonstrated that incorporating a feature into the ranker inspired by Gibson u'\u005cu2019' s [ 12 ] dependency locality theory can deliver statistically significant improvements in automatic evaluation scores, better match the distributional characteristics of sentence orderings, and significantly reduce the number of serious ordering errors (some involving vicious ambiguities) as confirmed by a targeted human evaluation
p1
aVFinally, to reduce the number of subject-verb agreement errors, Rajkumar and White ( 2010 ) extended the earlier model with features enabling it to make correct verb form choices in sentences involving complex coordinate constructions and with expressions such as a lot of where the correct choice is not determined solely by the head noun
p2
aVIn the figure, nodes correspond to discourse referents labeled with lexical predicates, and dependency relations between nodes encode argument structure (gold standard CCG lexical categories are also shown); note that semantically empty function words such as infinitival- to are missing
p3
aVThe ranking model makes choices addressing all three interrelated sub-tasks traditionally considered part of the surface realization task in natural language generation research [ 29 , 30 ] inflecting lemmas with grammatical word forms, inserting function words and linearizing the words in a grammatical and natural order
p4
aVTable 1 shows examples from White and Rajkumar ( 2012 ) of how the dependency length feature ( deplen ) affects the OpenCCG realizer u'\u005cu2019' s output even in comparison to a model ( depord ) with a rich set of discriminative syntactic and dependency ordering features, but no features directly targeting relative weight
p5
aVIn inspecting the results of reranking with this strategy, we observe that while it does sometimes succeed in avoiding egregious errors involving vicious ambiguities, common parsing mistakes such as PP-attachment errors lead to unnecessarily sacrificing conciseness or fluency in order to avoid ambiguities that would be
p6
a.