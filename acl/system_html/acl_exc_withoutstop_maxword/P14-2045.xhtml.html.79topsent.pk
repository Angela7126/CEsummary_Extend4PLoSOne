(lp0
VWe chose Amazon u'\u005cu2019' s Mechanical Turk (MTurk) crowdsourcing platform as a source of study participants
p1
aVAmong these relations, adverb modifiers stood out (Figure 5 ), because evidence suggested that words (63% success) made the relation more recognizable than phrases (47% success, p=0.056, W=574.0) u'\u005cu2013' but the difference was only almost significant, due to the smaller sample size (only 96 participants encountered this relation
p2
aVClausal relations operate over longer distances in sentences, and so it is to be expected that showing longer stretches of context would perform better in these cases; that is indeed what the results showed
p3
aVFor instance, the Linguist u'\u005cu2019' s Search Engine [ 17 ] uses a query-by-example strategy in which a user types in an initial sentence in English, and the system produces a graphical view of a parse tree as output, which the user can alter
p4
aVThis may be because the words are the most salient piece of information in an adverbial relation u'\u005cu2013' adverbs usually end in u'\u005cu2018' ly u'\u005cu2019' u'\u005cu2013' and in the phrases condition the additional information distracts from recognition of this pattern
p5
aVAhab, ___ the sentences each contained u'\u005cu2018' Ahab u'\u005cu2019' , highlighted in yellow, as the subject of different verbs highlighted in pink
p6
aVOne current presentation (not used with auto-suggest) is to name the relation and show blanks where the words that satisfy it would appear as in X is the subject of Y [ 14 ] ; we used this as the baseline presentation in our experiments because it employs the relation definitions found in the Stanford Dependency Parser u'\u005cu2019' s manual [
p7
a.