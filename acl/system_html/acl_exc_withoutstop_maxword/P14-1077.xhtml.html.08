<html>
<head>
<title>P14-1077.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In contrast, our approach learn implicit clues from existing KBs, and jointly optimize local predictions among different entity tuples to capture both relation argument type clues and cardinality clues</a>
<a name="1">[1]</a> <a href="#1" id=1>Specifically, the joint inference framework operates on the output of a sentence level relation extractor as input, derives 5 types of constraints from an existing KB to implicitly capture the expected type and cardinality requirements for a relation u'\u2019' s arguments, and jointly resolve the disagreements among candidate predictions</a>
<a name="2">[2]</a> <a href="#2" id=2>However, in the Riedel u'\u2019' s dataset, Mintz++, the MaxEnt relation extractor, does not perform well, and our framework cannot improve its performance</a>
<a name="3">[3]</a> <a href="#3" id=3>In order to implicitly capture the expected type and cardinality requirements for a relation u'\u2019' s arguments, we derive two kinds of clues from an existing KB, which are further utilized to discover the disagreements among local candidate predictions</a>
<a name="4">[4]</a> <a href="#4" id=4>We also find an interesting results in the DBpedia dataset, ILP is more likely to introduce correct predictions to the results, while in the Chinese dataset it tends to reduce more incorrect predictions, which may be caused by the differences between performances</a>
</body>
</html>