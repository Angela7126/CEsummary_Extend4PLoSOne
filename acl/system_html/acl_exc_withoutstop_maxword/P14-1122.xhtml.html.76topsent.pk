(lp0
VCrowdsourcing was slightly more cost-effective than both games in the paid condition, as shown in Table 1 , Column 8
p1
aVWhile their game is among the most video game-like, the annotation task is a chore the player must perform in order to return to the game, rather than an integrated, fun part of the game u'\u005cu2019' s objectives, which potentially decreases motivation for answering correctly
p2
aVFor all three games, two players play the same game under time limits and then are rewarded if their answers match
p3
aVNon-video Game with a Purpose To measure the impact of the video game itself on the annotation process, we developed a non-video game with a purpose, referred to as SuchGame
p4
aVFor each task we developed a video game with a purpose that integrates the task within the game, as illustrated in Sections 4 and 5
p5
aVWe refer to these as the paid and free versions of the game, respectively
p6
aVFor images, crowdsourcing workers have a higher IAA than game players; however, this increased agreement is due to adversarial workers consistently selecting the same, incorrect answer
p7
aVSuchGame was promoted with same free recognition incentive as Infection and TKT
p8
aVThe strength of both crowdsourcing and games with a purpose comes from aggregating multiple annotations of a single item; i.e.,, while IAA may be low,
p9
a.