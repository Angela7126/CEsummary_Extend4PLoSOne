<html>
<head>
<title>P14-1121.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We can see that the best results are obtained by the S u'\u2062' o u'\u2062' u u'\u2062' r u'\u2062' c u'\u2062' e p u'\u2062' r u'\u2062' e u'\u2062' d approach for both comparable corpora</a>
<a name="1">[1]</a> <a href="#1" id=1>Since the context vectors are computed from each part of the comparable corpus rather than through the parts of the comparable corpora, the standard approach is relatively insensitive to differences in corpus sizes</a>
<a name="2">[2]</a> <a href="#2" id=2>We chose the balanced corpora where the standard approach has shown the best results in the previous experiment, namely [ breast cancer corpus 12 ] and [ diabetes corpus 7 ]</a>
<a name="3">[3]</a> <a href="#3" id=3>We then conducted a second experiment where we varied the size of the English part of the comparable corpus, from 530,000 to 7.4 million words for the breast cancer corpus in 530,000 words steps, and from 250,000 to 3.5 million words for the diabetes corpus in 250,000 words steps (we refer to these corpora as unbalanced corpora</a>
<a name="4">[4]</a> <a href="#4" id=4>Within this context, our main contribution consists in a re-reading of the standard approach putting emphasis on the unfounded assumption of the balance of the specialized comparable corpora</a>
<a name="5">[5]</a> <a href="#5" id=5>The main work in bilingual lexicon extraction from comparable corpora is based on lexical context</a>
</body>
</html>