(lp0
VThus, we investigate the semantics of each verb in each syntactic frame available to it (as described by VerbNet
p1
aVThe exact semantics associated with a verb may depend on its syntactic frame
p2
aVAs noted above, the question is not whether all verbs in the same syntactic class share the same semantic entailments
p3
aVIn Phase 1 of the project, we focused on 11 verb classes (Table 3) comprising 641 verbs and seven different semantic entailments (Table 2
p4
aVPrevious work suggests that it is the semantic entailments that matter, particularly for explaining the syntactic behavior of verbs [ 10 ]
p5
aVEven a single verb may have different semantic entailments when placed in different syntactic frames
p6
aVOne significant challenge for any such project is first classifying verbs according to the syntactic frames they can appear in
p7
aVVerbNet (Kipper et al., 2008; based on Levin, 1993) lists over 6,000 verbs, categorized into 280 classes according to the syntactic frames they can appear in
p8
aVVerbs such as hit and like do not describe a change of state and so cannot appear in both forms
p9
aVWe next investigated whether our results support the Semantic Consistency Hypothesis
p10
aVThe Semantic Consistency Hypothesis would be supported if, within that database, predicates with the same syntactic properties were systematically related semantically
p11
aVThus, calculating consistency of a class must take differing frames into account
p12
aVThe consistency for the class as a whole is the average across frames
p13
aVAs such, the VerbCorner Project is also verifying and validating the semantics currently encoded in VerbNet
p14
aVMean consistency averaged across classes is shown for each task in Table 2
p15
aVThus, at least initially, we are focusing on the 6,000+ verbs already cataloged in VerbNet
p16
aVThus Sally rolled the ball entails that somebody applied force to the ball (namely
p17
aVWe selected semantic features of interest based on those most commonly cited in the linguistics literature, with a particular focus on those that u'\u005cu2013' according to VerbNet u'\u005cu2013' apply to many predicates
p18
aVVerbNet will be edited as necessary based on the empirical results
p19
aVSally), whereas The ball rolled does not
p20
aVIntegration with VerbNet has additional benefits, since VerbNet itself is integrated with a variety of linguistic resources, such as PropBank and Penn TreeBank
p21
aVCollecting data from naive subjects is even more laborious, particularly since the average Man on the Street is not necessarily equipped with metalinguistic concepts like caused change of state and propositional attitude
p22
aVAs expected, consistency was lowest for Evaluation , which is not expected to necessarily correlate with syntax
p23
aVIn fact, annotators frequently flagged these items as ungrammatical, which is a valuable result in itself for improving VerbNet
p24
aVThe consistency for this class/frame combination is 60%
p25
aVIn principle, these judgments would come from naive annotators, since researchers u'\u005cu2019' intuitions about subtle judgments may be unconsciously clouded by theoretical commitments [ 4 ]
p26
aVPrevious research has shown that humans find it easier to reason about real-world scenarios than make abstract judgments [ 3 ]
p27
aVThere are many sophisticated rubrics for calculating consistency
p28
aVThus, for each feature (e.g.,, movement ), we converted the metalinguistic judgment ( u'\u005cu201c' Does this verb entail movement on the part of some entity u'\u005cu201d' ) into a real-world problem
p29
aVGiven the sheer scale of the project, data-collection is expected to take several years at least
p30
aVBelow, we summarize the main findings thus far
p31
aVBecause we recruited large numbers of annotators, most of whom annotated only a few items, typical measures of inter-annotator agreement such as Cohen u'\u005cu2019' s kappa are not easily calculated
p32
aVHowever, these pilot studies involved a small number of items which were coded by all annotators
p33
aVEach task had been iteratively piloted and redesigned until inter-annotator reliability was acceptable, as described in a previous publication
p34
aVThus, data-collection has been broken up into a series of phases
p35
aVSince there were typically 4 or more possible answers per item, inter-annotator agreement was well above chance
p36
a.