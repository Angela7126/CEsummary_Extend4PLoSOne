<html>
<head>
<title>P14-1068.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Several other models have been extensions of Latent Dirichlet Allocation () where topic distributions are learned from words and other perceptual units use visual words which they extract from a corpus of multimodal documents (i.e.,, BBC news articles and their associated images), whereas others () use feature norms obtained in longitudinal elicitation studies (see for an example) as an approximation of the visual environment</a>
<a name="1">[1]</a> <a href="#1" id=1>As baselines, we also report the performance of a model based solely on textual attributes (which we obtain from Strudel), visual attributes (obtained from our classifiers), and their concatenation (see row Attributes in Table 2 , and columns T, V, and T+V, respectively</a>
<a name="2">[2]</a> <a href="#2" id=2>Unlike most previous work, our model is defined at a finer level of granularity u'\u2014' it computes meaning representations for individual words and is unique in its use of attributes as a means of representing the textual and visual modalities</a>
<a name="3">[3]</a> <a href="#3" id=3>As our input consists of natural language attributes, the model would infer textual attributes given visual attributes and vice versa</a>
<a name="4">[4]</a> <a href="#4" id=4>As an indicator to</a>
</body>
</html>