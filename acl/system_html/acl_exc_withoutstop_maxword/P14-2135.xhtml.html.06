<html>
<head>
<title>P14-2135.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The filtering approach described thus far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts</a>
<a name="1">[1]</a> <a href="#1" id=1>The Turney et al algorithm quantifies the concreteness of concepts that lack such a rating based on their proximity to rated concepts in a semantic vector space</a>
<a name="2">[2]</a> <a href="#2" id=2>We use Google Images as our image source, and extract the first n image results for each concept word</a>
<a name="3">[3]</a> <a href="#3" id=3>Our experiments focus on multi-modal models that extract their perceptual input automatically from images</a>
<a name="4">[4]</a> <a href="#4" id=4>Multi-modal models that learn semantic concept representations from both linguistic and perceptual input were originally motivated by parallels with human concept acquisition, and evidence that many concepts are grounded in the perceptual system [ 3 ]</a>
<a name="5">[5]</a> <a href="#5" id=5>To evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u'\u222a' C introduced in Section 2</a>
<a name="6">[6]</a> <a href="#6" id=6>Since research has demonstrated the applicability of concreteness to a range of other NLP tasks [ 28 , 16 ] , it is important to examine the connection between image dispersion and concreteness in more detail</a>
<a name="7">[7]</a> <a href="#7" id=7>We apply image dispersion-based</a>
</body>
</html>