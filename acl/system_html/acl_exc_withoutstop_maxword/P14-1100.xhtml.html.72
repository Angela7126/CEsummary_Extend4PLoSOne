<html>
<head>
<title>P14-1100.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Intuitively, however, latent tree models encode low rank dependencies among the observed variables permitting the development of u'\u201c' spectral u'\u201d' methods that can lead to provably correct solutions</a>
<a name="1">[1]</a> <a href="#1" id=1>Most existing solutions treat the problem of unsupervised parsing by assuming a generative process over parse trees e.g., probabilistic context free grammars [ Jelinek et al.1992 ] , and the constituent context model [ Klein and Manning2002 ]</a>
<a name="2">[2]</a> <a href="#2" id=2>From the engineering perspective, training data for unsupervised parsing exists in abundance (i.e., sentences and part-of-speech tags), and is much cheaper than the syntactically annotated data required for supervised training</a>
<a name="3">[3]</a> <a href="#3" id=3>Thus, strong experimental results are often achieved by initialization techniques [ Klein and Manning2002 , Gimpel and Smith2012 ] , incremental dataset use [ Spitkovsky et al.2010a ]</a>
</body>
</html>