<html>
<head>
<title>P14-1020.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>As expected, binary rules account for the vast majority of the time in the unpruned Viterbi case, but much less time in the pruned case, with the total time taken for binary rules in the coarse and fine passes taking about 1/5 of the time taken by binaries in the unpruned version</a>
<a name="1">[1]</a> <a href="#1" id=1>Their system uses a grammar based on the Berkeley parser [ 9 ] (which is particularly amenable to GPU processing), u'\u201c' compiling u'\u201d' the grammar into a sequence of GPU kernels that are applied densely to every item in the parse chart</a>
<a name="2">[2]</a> <a href="#2" id=2>Figure 1 shows an overview of the approach we first parse densely with a coarse grammar and then parse sparsely with the fine grammar, skipping symbols that the coarse pass deemed sufficiently unlikely</a>
<a name="3">[3]</a> <a href="#3" id=3>The X-bar grammar can compute pruning masks at just over 1000 sentences per second, the 1-split grammar parses 858 sentences per second, and the 2-split grammar parses 526 sentences per second</a>
<a name="4">[4]</a> <a href="#4" id=4>Because the grammar used in the coarse pass is a projection of the grammar used in the fine pass, these coarse scores correlate reasonably closely with the probabilities computed in the fine pass</a>
<a name="5">[5]</a> <a href="#5" id=5>The coarse to fine pruning approach of</a>
</body>
</html>