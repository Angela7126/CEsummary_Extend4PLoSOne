(lp0
V1) We ran LDA on TW and NW separately for each category with the number of topics set to 100; 1) We then aligned the Twitter topics and Newswire topics by the similarity measurement of word distributions of these topics [ 8 , 10 , 33 , 5 ] ; 1) Finally to generate the GS label for each aligned topic pair ( t i - t j ) , we extracted the headlines of the news articles relevant to t j and selected the top x most frequent words (after stop word removal and stemming
p1
aVBased on the observation that a short summary of a collection of documents can serve as a label characterising the collection, we propose to generate topic label candidates based on the summarisation of a topic u'\u005cu2019' s relevant documents
p2
aV\u005cENDFOR \u005cSTATE Select topic j which has the highest similarity to i and whose similarity measure is greater than a threshold (in this case 0.7) \u005cENDFOR \u005cFOR each of the extracted topic pairs ( t i - t j
p3
a.