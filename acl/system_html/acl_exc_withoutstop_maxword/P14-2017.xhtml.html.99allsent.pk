(lp0
VWe investigate the performance of the method we propose in comparison to previous approaches for automatic detection of cognate pairs based on orthographic similarity
p1
aV2013 ) proposed a method for cognate production relying on statistical character-based machine translation, learning orthographic production patterns, and Mulloni ( 2007 ) introduced an algorithm for cognate production based on edit distance alignment and the identification of orthographic cues when words enter a new language
p2
aVFor measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input
p3
aVIn addition, we use SpSim [ 11 ] , which outperformed the longest common subsequence ratio and a similarity measure based on the edit distance in previous experiments
p4
aVTherefore, because the edit distance was widely used in this research area and produced good results, we are encouraged to employ orthographic alignment for identifying pairs of cognates, not only to compute similarity scores, as was previously done, but to use aligned subsequences as features for machine learning algorithms
p5
aVAlgorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic
p6
aVFirst, we compute the pairwise distances between pairs of words for each orthographic metric individually, as a single feature 5 5 SpSim cannot be computed directly, as the other metrics, so we introduce an additional step in which we use 1/3 of the training set (only cognates are needed) to learn orthographic changes
p7
aVGomes and Lopes ( 2011 ) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words
p8
aVString alignment is closely related to the task of sequence alignment in computational biology
p9
aVKondrak ( 2000 ) developed the ALINE system, which aligns words u'\u005cu2019' phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming
p10
aVIn order to detect the best threshold for discriminating between cognates and non-cognates, we run a decision stump classifier (provided by Weka) on the training set for each pair of languages and for each metric
p11
aVTherefore, to align pairs of words we employ the Needleman-Wunsch global alignment algorithm [ 29 ] , which is mainly used for aligning sequences of proteins or nucleotides
p12
aVWe discard pairs of words for which the forms across languages are identical (i.e.,, the Romanian word matrice and its Italian cognate pair matrice , having the same form), because these pairs do not provide any orthographic changes to be learned
p13
aVUsing the best threshold value selected for each metric and pair of languages, we further classify the pairs of words in our test sets as cognates or non-cognates
p14
aVFor orthographic alignment, we consider words as input sequences and we use a very simple substitution matrix, which gives equal scores to all substitutions, disregarding diacritics (e.g.,, we ensure that e and è are matched
p15
aVOur intuition is that inferring language-specific rules for aligning words will lead to better performance in the task of cognate identification
p16
aVAccording to Gusfield ( 1997 ) , an edit transcript (representing the conversion of one string to another) and an alignment are mathematically equivalent ways of describing relationships between strings
p17
aVFinally, we obtain 445 pairs of cognates for Romanian-French 2 2 The number of pairs of cognates is much lower for French than for the other languages because there are numerous Romanian words which have French etymology and, in this paper, we do not consider these words to be cognate candidates
p18
aVThe algorithm uses dynamic programming and, thus, guarantees to find the optimal alignment
p19
aVBecause we need sets of approximately equal size for comparison across languages, we keep 400 pairs of cognates and 400 pairs of non-cognates for each pair of languages
p20
aVWe assume that rules for adapting foreign words to the orthographic system of the target languages might not have been very well defined in their period of early development, but they may have since become complex and probably language-specific
p21
aVVarious measures were investigated and compared [ 17 , 14 ] ; Levenshtein distance [ 22 ] , XDice [ 3 ] and the longest common subsequence ratio [ 24 ] are among the most frequently used metrics in this field
p22
aVDetecting pairs of cognates based on etymology is useful and reliable, but, for resource-poor languages, methods which require less linguistic knowledge might be necessary
p23
aVUsing aligned pairs of words as input, we extract features around mismatches in the alignments
p24
aVTo evaluate these metrics on our dataset, we use the same train/test sets as we did in our previous experiments and we follow the strategy described in [ 17 ]
p25
aVTherefore, the research [ 17 , 25 , 16 ] focused on automatic identification of cognate pairs, starting from lists of known cognates
p26
aVWe use Naive Bayes as a baseline and we experiment with Support Vector Machines (SVMs) to learn orthographic changes and to discriminate between pairs of cognates and non-cognates
p27
aVFinally, in Section 5 we draw the conclusions of our study and describe our plans for extending the method
p28
aVThe wide range of applications in which cognates prove useful attracted more and more attention on methods for detecting such related pairs of words
p29
aVIts main idea is that any partial path of the alignment along the optimal path should be the optimal path leading up to that point
p30
aVA possible explanation might be the occurrence, in the dataset, of more remotely related words, which are not labeled as cognates
p31
aVThis task is most challenging for resource-poor languages, for which etymologically related information is not accessible
p32
aVTherefore, the optimal path can be determined by incremental extension of the optimal subpaths [ 31 ]
p33
aVIn order to provide information regarding the position of the features, we mark the beginning and the end of the word with a $ symbol
p34
aVFor Portuguese, both Naive Bayes and SVM misclassify more non-cognates as cognates than viceversa
p35
aVThus, for the above-mentioned pair of cognates, (exhaustiv, esaustivo) , we extract the following features when n = 2
p36
aVTherefore, because there is one feature ( xh s- ) which occurs twice in our example, we have 8 features for the pair (exhaustiv, esaustivo)
p37
aVFor identical features we account only once
p38
aVThe second alternative leads to better performance, so we account for all mismatches
p39
aVAs for the length of the grams, we experiment with n u'\u005cu2208' { 1 , 2 , 3 }
p40
aVWe achieve slight improvements by combining n -grams, i.e.,, for a given n , we use all i -grams, where i u'\u005cu2208' { 1 , u'\u005cu2026' , n }
p41
aVWe propose a method for automatic detection of cognate pairs using orthographic alignment
p42
aVWe employ several orthographic metrics widely used in this research area the edit distance [ 22 ] , the longest common subsequence ratio [ 24 ] and the XDice metric [ 3 ] 4 4 We use normalized similarity metrics
p43
aVThere are three important aspects widely investigated in the task of cognate identification semantic, phonetic and orthographic similarity
p44
aVThese results support the relevance of accounting for orthographic cues in cognate identification
p45
aVDelmestri and Cristianini ( 2010 ) used basic sequence alignment algorithms [ 29 , 33 , 12 ] to obtain orthographic alignment scores for cognate candidates
p46
aVOur method performs better than the orthographic metrics considered as individual features
p47
aVIn order to maintain a stratified dataset, we discard an equal number of non-cognates in the training set and then we compute the distances for the rest of the training set and for the test set
p48
aVGlobal sequence alignment aims at determining the best alignment over the entire length of the input sequences
p49
aVWhile the purpose of cognate detection is to determine whether two given words form a cognate pair, the aim of cognate production is, given a word in a source language, to automatically produce its cognate pair in a target language
p50
aVIn Section 3 we introduce our approach for detection of cognates using orthographic alignment
p51
aVFor each pair of languages we determine a number of non-cognate pairs equal to the number of cognate pairs
p52
aVFor the edit distance, we subtract the normalized value from 1 in order to obtain similarity
p53
aVList ( 2012 ) proposed a framework for automatic detection of cognate pairs, LexStat, which combines different approaches to sequence comparison and alignment derived from those used in historical linguistics and evolutionary biology
p54
aVFor example, for the Romanian word exhaustiv and its Italian cognate pair esaustivo , the alignment is as follows
p55
aVIn this paper, we propose a method for automatically determining pairs of cognates across languages
p56
aVOut of the four similarity metrics, SpSim obtains, overall, the best performance
p57
aVThe values which optimize accuracy on the training set are reported, for each pair of languages, in Table 3
p58
aVWe apply our method on an automatically extracted dataset of cognates for four pairs of languages
p59
aVThese orthographic changes have also been used in cognate production, which is closely related to the task of cognate detection, but has not yet been as intensively studied
p60
aVIn Tables 1 and 2 we provide, for each pair of languages, the five most relevant 2-gram orthographic changes, determined using the u'\u005cu03a7' 2 distribution implemented in Weka, and the five most frequent 2-gram orthographic changes in the cognate pairs from our dataset 3 3 For brevity, we use in the tables the ISO 639-1 codes for language abbreviation
p61
aVThe changes undergone by words when entering from one language into another and the transformation rules they follow have been successfully employed in various approaches to cognate detection [ 18 , 25 , 28 ]
p62
aVThe features we use are character n -grams around mismatches
p63
aVIn other several research areas, such as language acquisition, bilingual word recognition [ 9 ] , corpus linguistics [ 32 ] , cross-lingual information retrieval [ 4 ] and machine translation [ 19 ] , the condition of common etymology is usually not essential and cognates are regarded as words with high cross-lingual meaning and orthographic or phonetic similarity
p64
aVWe denote pairs of languages by the target language, given the fact that Romanian is always the source language in our experiments
p65
aVWe use the remaining of the initial training set for the next step of the procedure
p66
aVCognates are words in different languages having the same etymology and a common ancestor
p67
aVAlthough there are multiple aspects that are relevant in the study of language relatedness, such as orthographic, phonetic, syntactic and semantic differences, in this paper we focus only on lexical evidence
p68
aVThey were employed both individually [ 32 , 17 , 6 ] and combined [ 21 , 34 ] in order to detect pairs of cognates across languages
p69
aVWords undergo various changes when entering new languages
p70
aVWe experiment with two types of features
p71
aVIn Table 4 we report the results for each approach
p72
aVIn Table 3 we report the results of our research
p73
aVThe orthographic approach relies on the idea that sound changes leave traces in the orthography and alphabetic character correspondences represent, to a fairly large extent, sound correspondences [ 8 ]
p74
aVWe split the data in two subsets, for training and testing, with a 3:1 ratio, and we perform grid search and 3-fold cross validation over the training set in order to optimize hyperparameters c and u'\u005cu0393'
p75
aVFor determining semantic similarity, external lexical resources, such as WordNet [ 10 ] , or large corpora, might be necessary
p76
aVn -grams around any type of mismatch, i.e.,, we account for all three types of mismatches
p77
aVThe proposed method requires a list of known cognates and, for languages for which additional linguistic information is available, it can be customized to integrate historical information regarding the evolution of the language
p78
aVA decision stump is a decision tree classifier with only one internal node and two leaves corresponding to our two class labels
p79
aVThe SVM produces better results for all languages except Portuguese, where the accuracy is equal
p80
aVIn Section 4 we describe the experiments we conduct and we report and analyze the results, together with a comparison with previous methods
p81
aVInvestigating pairs of cognates is very useful in historical and comparative linguistics, in the study of language relatedness [ 30 ] , phylogenetic inference [ 1 ] and in identifying how and to what extent languages change over time
p82
aVNone of the top ranked orthographic cues occurs at the beginning of the word, while many of them occur at the end of the word
p83
aVThe first mismatch (between x and s ) is caused by a substitution, the second mismatch (between h and - ) is caused by a deletion from source language to target language, and the third mismatch (between - and o ) is caused by an insertion from source language to target language
p84
aVThere are three types of mismatches, corresponding to the following operations insertion, deletion and substitution
p85
aVn -grams around gaps, i.e.,, we account only for insertions and deletions;
p86
aVWe put our system together using the Weka workbench [ 15 ] , a suite of machine learning algorithms and tools
p87
aVIn order to build the dataset, we apply the methodology proposed by Ciobanu and Dinu ( 2014 ) on the DexOnline 1 1 http://dexonline.ro machine-readable dictionary for Romanian
p88
aVWe report the n -gram values for which the best results are obtained and the hyperparameters for SVM, c and u'\u005cu0393'
p89
aVWe experiment with two machine-learning approaches
p90
aVWe plan to investigate this assumption and to apply the proposed method on other datasets in our future work
p91
aVThe rest of the paper is organized as follows in Section 2 we present and analyze alternative methods and related work in this area
p92
aVNaive Bayes and SVM
p93
aVFor SVM, we use the wrapper provided by Weka for LibSVM [ 5 ]
p94
aVThe best results are obtained for French and Spanish, while the lowest accuracy is obtained for Portuguese
p95
aVRomanian-French, Romanian-Italian, Romanian-Spanish and Romanian-Portuguese
p96
aVWe use the radial basis function kernel (RBF), which can handle the case when the relation between class labels and attributes is non-linear, as it maps samples non-linearly into a higher dimensional space
p97
aVBeinborn et al
p98
aVThe most frequent operation in Tables 1 and 2 is substitution
p99
aVThe contribution of the authors to this paper is equal
p100
aV3,477 for Romanian-Italian, 5,113 for Romanian-Spanish and 7,858 for Romanian-Portuguese
p101
aVResearch supported by CNCS UEFISCDI, project number PN-II-ID-PCE-2011-3-0959
p102
aVwhere u'\u005cu0393' is a kernel parameter
p103
aVGiven two instances x i and x j , where x i u'\u005cu2208' u'\u005cu211d' n , the RBF kernel function for x i and x j is defined as follows
p104
aVWe search over { 1 , 2 , u'\u005cu2026' , 10 } for c and over { 10 - 5 , 10 - 4 , u'\u005cu2026' , 10 , 4 10 } 5 for u'\u005cu0393'
p105
aVWe thank the anonymous reviewers for their helpful and constructive comments
p106
a.