<html>
<head>
<title>P14-1020.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Therefore, in the fine pass, we normalize the inside scores at the leaves to sum to 1.0</a>
<a name="1">[1]</a> <a href="#1" id=1>Thus, we can use the coarse pass u'\u2019' s inside and outside scores as the scaling values for the fine pass u'\u2019' s scores</a>
<a name="2">[2]</a> <a href="#2" id=2>Because the grammar used in the coarse pass is a projection of the grammar used in the fine pass, these coarse scores correlate reasonably closely with the probabilities computed in the fine pass</a>
<a name="3">[3]</a> <a href="#3" id=3>We use a coarse-to-fine approach as in Petrov and Klein ( 2007 ) , but with only one coarse pass</a>
<a name="4">[4]</a> <a href="#4" id=4>If a span has a very high or very low score in the coarse pass, it typically has a similar score in the fine pass</a>
<a name="5">[5]</a> <a href="#5" id=5>Because we are summing instead of maxing scores in the fine pass, the scaling factors computed using max scores are not quite large enough, and so the rescaled inside probabilities grow too large when multiplied together</a>
<a name="6">[6]</a> <a href="#6" id=6>The coarse to fine pruning approach of Petrov and Klein ( 2007 ) employs an X-bar grammar as its first pruning phase, but there is no reason why we cannot begin with a more complex grammar for our initial pass</a>
<a name="7">[7]</a> <a href="#7" id=7>Figure 1 shows</a>
</body>
</html>