<html>
<head>
<title>P14-2007.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We wish to predict sentiment annotation complexity of the text using a supervised technique</a>
<a name="1">[1]</a> <a href="#1" id=1>However, saccade duration is not significant for annotation of short text, as in our case</a>
<a name="2">[2]</a> <a href="#2" id=2>To measure the u'\u201c' actual u'\u201d' time spent by an annotator on a piece of text, we use an eye-tracker to record eye-fixation duration the time for which the annotator has actually focused on the sentence during annotation</a>
<a name="3">[3]</a> <a href="#3" id=3>The next level of sentiment annotation complexity arises due to syntactic complexity</a>
<a name="4">[4]</a> <a href="#4" id=4>Using the idea of u'\u201c' annotation time u'\u201d' linked with complexity, we devise a technique to create a dataset annotated with SAC</a>
<a name="5">[5]</a> <a href="#5" id=5>With regard to this, we introduce a metric called sentiment annotation complexity (SAC</a>
<a name="6">[6]</a> <a href="#6" id=6>However, u'\u201c' simple time measurement u'\u201d' is not reliable because the annotator may spend time not doing any annotation due to fatigue or distraction</a>
<a name="7">[7]</a> <a href="#7" id=7>To understand how the formula records sentiment annotation complexity, consider the SACs of examples in section 2</a>
<a name="8">[8]</a> <a href="#8" id=8>Measuring annotation complexity is beneficial in annotation crowdsourcing</a>
<a name="9">[9]</a> <a href="#9" id=9>Our proposed metric measures complexity of sentiment annotation, as perceived by human annotators</a>
<a name="10">[10]</a> <a href="#10" id=10>The simplest form of sentiment annotation complexity is at the lexical level</a>
<a name="11">[11]</a> <a href="#11" id=11>Fort et al2012 describe</a>
</body>
</html>