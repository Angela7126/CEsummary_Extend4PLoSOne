<html>
<head>
<title>P14-1122.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Second, we demonstrate that converting games with a purpose into more traditional video games creates an increased player incentive such that players annotate for free, thereby significantly lowering annotation costs below that of crowdsourcing</a>
<a name="1">[1]</a> <a href="#1" id=1>Second, for both annotation tasks, crowdsourcing produced lower quality annotations, especially for valid relations</a>
<a name="2">[2]</a> <a href="#2" id=2>Players in both free and paid games had similar IAA, though the free version is consistently higher (Table 1 , Col. 4</a>
<a name="3">[3]</a> <a href="#3" id=3>The paid and free versions of TKT had similar numbers of players, while the paid version of Infection attracted nearly twice the players compared to the free version, shown in Table 1 , Column 1</a>
<a name="4">[4]</a> <a href="#4" id=4>Two games with a purpose have incorporated video game-like mechanics for annotation</a>
<a name="5">[5]</a> <a href="#5" id=5>Here, the annotation tasks are transformed into elements of a video game where players accomplish their jobs by virtue of playing the game, rather than by performing a more traditional annotation task</a>
<a name="6">[6]</a> <a href="#6" id=6>For both games, players were equally likely to select novel items, suggesting the games can serve a useful purpose of adding these missing relations in automatically constructed knowledge bases</a>
<a name="7">[7]</a> <a href="#7" id=7>Third, for both games, we show that games produce better quality annotations than crowdsourcing</a>
<a name="8">[8]</a> <a href="#8" id=8>To compare with the video games, items were annotated using two additional methods crowdsourcing and a non-video game with a purpose</a>
<a name="9">[9]</a> <a href="#9" id=9>In contrast, we introduce two video</a>
</body>
</html>