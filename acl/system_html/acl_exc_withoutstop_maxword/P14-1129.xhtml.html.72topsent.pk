(lp0
VLe u'\u005cu2019' s model also uses minimal phrases rather than being purely lexicalized, which has two main downsides a) a number of complex, hand-crafted heuristics are required to define phrase boundaries, which may not transfer well to new languages, (b) the effective vocabulary size is much larger, which substantially increases data sparsity issues
p1
aVUnlike previous approaches to joint modeling [ 13 ] , our feature can be easily integrated into any statistical machine translation (SMT) decoder, which leads to substantially larger improvements than k -best rescoring only
p2
aVDARPA BOLT is a major research project with the goal of improving translation of informal, dialectical Arabic and Chinese into English
p3
aVWe chose these values for the hidden layer size, vocabulary size, and source window size because they seemed to work best on our data sets u'\u005cu2013' larger sizes did not improve results, while smaller sizes degraded results
p4
aVIn this paper we use a basic neural network architecture and a lexicalized probability model to create a powerful MT decoding feature
p5
aVTraining is performed
p6
a.