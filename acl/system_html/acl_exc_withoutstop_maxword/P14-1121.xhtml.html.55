<html>
<head>
<title>P14-1121.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We then conducted a second experiment where we varied the size of the English part of the comparable corpus, from 530,000 to 7.4 million words for the breast cancer corpus in 530,000 words steps, and from 250,000 to 3.5 million words for the diabetes corpus in 250,000 words steps (we refer to these corpora as unbalanced corpora</a>
<a name="1">[1]</a> <a href="#1" id=1>The bilingual lexicon extraction task from bilingual corpora was initially addressed by using parallel corpora (i.e., a corpus that contains source texts and their translation</a>
<a name="2">[2]</a> <a href="#2" id=2>Since the context vectors are computed from each part of the comparable corpus rather than through the parts of the comparable corpora, the standard approach is relatively insensitive to differences in corpus sizes</a>
<a name="3">[3]</a> <a href="#3" id=3>We chose the balanced corpora where the standard approach has shown the best results in the previous experiment, namely [ breast cancer corpus 12 ] and [ diabetes corpus 7 ]</a>
<a name="4">[4]</a> <a href="#4" id=4>In specialized domains, the comparable corpora are traditionally of small size (around 1 million words) in comparison with comparable corpus-based general language (up to 100 million words</a>
<a name="5">[5]</a> <a href="#5" id=5>21) observe, a specialized comparable corpus is built as balanced by analogy with a parallel corpus u'\u201c' Therefore, in relation to parallel corpora, it is more</a>
</body>
</html>