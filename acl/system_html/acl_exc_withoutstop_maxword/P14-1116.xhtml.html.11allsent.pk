(lp0
VContent selection decisions based on trends in time-series data determine the selection of the useful and important variables, which we refer to here as factors , that should be conveyed in a summary
p1
aVWe frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not
p2
aVContent is regarded as labels (each template represents a label) and thus the task can be thought of as a classification problem
p3
aVHere, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously []
p4
aVFor the corpus creation, 11 lecturers selected the content to be conveyed in a summary, given the set of raw data []
p5
aVOur contributions to the field are as follows we present a novel and efficient method for tackling the challenge of content selection using a ML classification approach; we applied this method to the domain of feedback summarisation; we present a comparison with an optimisation technique (Reinforcement Learning), and we discuss the similarities and differences between the two methods
p6
aVRAkEL is based on Label Powerset (LP), a problem transformation method []
p7
aVThe decisions of factor selection can be influenced by other factors that their values are correlated with; can be based on the appearance or absence of other factors in the summary; and can be based on the factors u'\u005cu2019' behaviour over time
p8
aVEnsemble methods [] are algorithms that use ensembles to perform ML learning and they are based on problem transformation or algorithm adaptation methods
p9
aVHowever, simple classification assumes that the templates are independent of each other, thus the decision for each template is taken in isolation from the others, which is not appropriate for our domain
p10
aVIt was found out that Decision Trees achieved on average 3% higher accuracy
p11
aVRAkEL overcomes this limitation by constructing a set of LP classifiers, which are trained with different random subsets of the set of labels []
p12
aVThis method did not take into account other selected templates u'\u005cu2013' it was only based on the time-series data
p13
aVRAkEL tackles this problem by constructing an ensemble of LP classifiers and training each one on a different random subset of the set of labels []
p14
aVThis algorithm does not perform well when considering a large number of labels, due to the fact that the label space grows exponentially []
p15
aVTherefore, classification can reduce the decision workload by deciding either in which way to talk about it, or not to talk about a factor at all
p16
aVThere is evidently a mismatch between the rules and the test-set; the content selection rules are based on heuristics provided by a L T Expert rather than by the same pool of lecturers that created the test-set
p17
aVRule-based System generates summaries based on Content Selection rules derived by working with a L T expert and a student []
p18
aVInstead of dealing with this task in a hierarchical way, where the algorithm will first learn whether to talk about a factor and then to decide how to refer to it, we transformed the task in order to reduce the learning steps
p19
aVThe reduced accuracy of the classification with predicted history is due to the error in the predicted values
p20
aVML classification achieved significantly higher accuracy, which was expected as it is a supervised learning method
p21
aVMoreover, we plan to utilise the results from this student evaluation in order to train an optimisation algorithm to perform summarisation according to students u'\u005cu2019' preferences
p22
aVTherefore, when generating feedback, we need to take into account all variables simultaneously in order to capture potential dependencies and provide more effective and useful feedback that is relevant to the students
p23
aVIn order to have a more objective view on the results, the score achieved by each algorithm using the reward function was also calculated
p24
aVWe compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with student users
p25
aVTraditional single-label classification is the task of identifying which label one new observation is associated with, by choosing from a set of labels L []
p26
aVRL is trained to optimise for this function, and therefore it achieves higher reward, whereas ML is trained to learn by examples, therefore it produces output closer to the gold standard (lecturer u'\u005cu2019' s produced summaries
p27
aVThe difference between the two methods lies in that the collective content selection requires the consideration of an individual preference score (which is defined as the preference of the entity to be selected or omitted, and it is based on the values of entity attributes and is computed using a boosting algorithm) and the identification of links between the entities with similar labels
p28
aVLP benefits from taking into consideration label correlations, but does not perform well when trained with few examples as in our case []
p29
aV1) the numbers of iterations m (which is developer specified and denotes the number of models that the algorithm will produce), (2) the size of labelset k (which is also developer specified), (3) the set of labels L , and (4) the training set D
p30
aVThe classification method reduces the generation steps, by making the decision of the factor selection and the template selection jointly
p31
aVContent selection is seen as a Markov Decision problem and the goal of the agent is to learn to take the sequence of actions that leads to optimal content selection
p32
aVOn the contrary, the RL is trained to optimise the selected content and not to replicate the existing lecturer summaries, hence there is a difference in accuracy
p33
aVIf the agent decides to refer to a factor, the template is selected in a deterministic way, i.e., from the available templates it selects the template that results in higher expected cumulative future reward
p34
aVML classification performs better because it does take into account these correlations and dependencies in the data
p35
aVConsequently, a single poor decision in the ML classification can result in much less reward
p36
aVIn this case, optimisation would be the preferred method as it would not be appropriate to collect gold standard data from students
p37
aVDuring run time, RAkEL estimates the average decision for each label in L and if the average is greater than a threshold t (determined by the developer) it includes the label in the predicted labelset
p38
aVThis result is indicative of the significance of the relations between the factors showing that the predicted decisions are dependent due to existing correlations as discussed in Section 1 , therefore the system should not take these decisions independently
p39
aVFinally, our domain for feedback generation is motivated by previous studies [] who show that text summaries are more effective in decision making than graphs therefore it is advantageous to provide a summary over showing users the raw data graphically
p40
aVMoreover, some factors may have to be discussed together in order to achieve some communicative goal, for instance, a teacher might want to refer to student u'\u005cu2019' s marks as a motivation for increasing the number of hours studied
p41
aVMoreover, each decision is rewarded with a different value as some combinations of factors and templates have greater or negative regression coefficients
p42
aVWe, therefore, went on to use Decision Trees that use generation history in three ways
p43
aVAs we will discuss further in Section 5.1 , content decisions are influenced by the previously generated content, for example, if the lecturer has previously mentioned health_issues, mentioning hours_studied has a high probability of also being mentioned
p44
aVML classification requires no history, i.e., does not keep track of previous decisions, and thus has a smaller feature space
p45
aVIn order to reduce the confounding variables, we kept the ordering of content in all systems the same, by adopting the ordering of the rule-based system
p46
aVOverall, for all factors there are 29 different templates 1 1 There are fewer than 36 templates, because for some factors there are less than 4 possible ways of referring to them
p47
aVAs mentioned, there are 4 ways to refer to a factor
p48
aVThe upper-bound accuracy is 78.09% calculated by using the expert previous decisions and not the potentially erroneous predicted decisions
p49
aVAccuracy was estimated as the proportion of the correctly classified templates to the population of templates
p50
aVOn the other hand, when mentioning the average difficulty the summary is u'\u005cu201c' punished u'\u005cu201d' with -81 (see description of the reward function in Section 5.2
p51
aVFor this initial experiment, we evaluated with students and not with lecturers, since the students are the recipients of feedback
p52
aVOur analysis of the dataset showed that there are significant correlations between the factors, for example, the number of lectures attended (LA) correlates with the student u'\u005cu2019' s understanding of the material (Und), see Table 5
p53
aVThe algorithm was implemented using the MULAN Open Source Java library [] , which is based on WEKA []
p54
aVIn future, we could perform parameter optimisation by using a technique similar to []
p55
aVAs a result, for the same student there are various summaries provided by the different experts
p56
aVReinforcement Learning (RL) is a machine learning technique that defines how an agent learns to take optimal actions so as to maximise a cumulative reward []
p57
aVRAkEL takes as input the following parameters
p58
aVML-kNN identifies for each new instance its k nearest neighbours in the training set and then it predicts the label set by utilising the maximum a posteriori principle according to statistical information derived from the label sets of the k neighbours
p59
aVFirstly, they change over time, and secondly they can be dependent on or independent of each other
p60
a.