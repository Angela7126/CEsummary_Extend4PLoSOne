(lp0
VAs mentioned in Section 2.1 , a tensor model has many more degrees of u'\u005cu201c' design freedom u'\u005cu201d' than a vector model, which makes the problem of finding a good tensor structure a nontrivial one
p1
aVA linear tensor model represents both features and weights in tensor-space, hence the weight tensor can be factorized and approximated by a linear sum of rank-1 tensors
p2
aVThe linear tensor model is illustrated in Figure 1
p3
aVSo what is the advantage of learning with a tensor model instead of a vector model
p4
aVSpecifically, a vector is a 1 st order tensor, a matrix is a 2 nd order tensor, and data organized as a rectangular cuboid is a 3 rd order tensor etc
p5
aVHowever if we use a 2 nd order tensor model, organize the features into a 1000 × 1000 matrix u'\u005cud835' u'\u005cudebd' , and use just one rank-1 matrix to approximate the weight tensor, then the linear model becomes
p6
aVMost traditional models are linear models, in the sense that both the features of the data and model parameters are represented as vectors in a vector space
p7
aVSpecifically, a vector space model assumes each feature weight to be a u'\u005cu201c' free u'\u005cu201d' parameter, and estimating them reliably could therefore be hard when training data are not
p8
a.