<html>
<head>
<title>P14-1008.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Moreover, to compensate the lack of background knowledge in practical inference, we combine our framework with the idea of tree transformation [] , to propose a way of generating knowledge in logical representation from entailment rules [] , which are by now typically considered as syntactic rewriting rules</a>
<a name="1">[1]</a> <a href="#1" id=1>To formulate the database querying process defined by a DCS tree, we provide formal semantics to DCS trees by employing relational algebra [] for representing the query</a>
<a name="2">[2]</a> <a href="#2" id=2>The labels on both ends of an edge, such as SUBJ (subject) and OBJ (object), are considered as semantic roles of the corresponding words 1 1 The semantic role ARG is specifically defined for denoting nominal predicate</a>
<a name="3">[3]</a> <a href="#3" id=3>For example, the similarity score of the path alignment u'\u201c' OBJ ( blame ) IOBJ - ARG ( death ) u'\u2248' SUBJ ( cause ) OBJ - ARG ( loss ) MOD - ARG ( life ) u'\u201d' is calculated as the cosine similarity of vectors blame + death and cause + loss + life</a>
<a name="4">[4]</a> <a href="#4" id=4>In this logical system, we treat abstract denotations as terms and statements as atomic sentences , which are far more easier to handle than first order predicate logic (FOL) formulas</a>
<a name="5">[5]</a> <a href="#5" id=5>Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved in Figure 6 , though the tree transformation can be seen as generated from the entailment rule u'\u201c' X is blamed for death u'\u2192' X causes loss of life u'\u201d' , the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby</a>
<a name="6">[6]</a> <a href="#6" id=6>Our solution is to redefine DCS trees without the aid of any databases, by considering each node of a DCS tree as a content word in a sentence (but may no longer be a table in a specific database), while each edge represents semantic relations between two words</a>
<a name="7">[7]</a> <a href="#7" id=7>Selection operators are implemented as markers assigned to abstract denotations, with specially designed axioms</a>
<a name="8">[8]</a> <a href="#8" id=8>Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values [] of that variable</a>
<a name="9">[9]</a> <a href="#9" id=9>Most of the problems do not require lexical knowledge, so we use our primary textual inference system without on-the-fly knowledge nor WordNet, to test the performance of the DCS framework as formal semantics</a>
<a name="10">[10]</a> <a href="#10" id=10>However, this method does not work for real-world datasets such as PASCAL RTE [] , because of the knowledge bottleneck it is often the case that the lack of sufficient linguistic knowledge causes failure of inference, thus the system outputs u'\u201c' no entailment u'\u201d' for almost all pairs []</a>
<a name="11">[11]</a> <a href="#11" id=11>Based on abstract denotations, we briefly describe our process to apply DCS to textual inference</a>
<a name="12">[12]</a> <a href="#12" id=12>Thus, our first step is to fix a notation which abstracts the calculation process of DCS trees, so as to clarify its meaning without the aid of any existing database</a>
<a name="13">[13]</a> <a href="#13" id=13>Abstract denotations and statements are convenient for representing semantics of various types of expressions and linguistic knowledge</a>
<a name="14">[14]</a> <a href="#14" id=14>The DCS tree in Figure 1 is interpreted as a command for querying these tables, obtaining u'\u201c' reading u'\u201d' entries whose u'\u201c' SUBJ u'\u201d' field is student and whose u'\u201c' OBJ u'\u201d' field is book</a>
<a name="15">[15]</a> <a href="#15" id=15>Since our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences</a>
<a name="16">[16]</a> <a href="#16" id=16>We use Stanford CoreNLP to resolve coreferences [] , whereas coreference is implemented as a special type of selection</a>
<a name="17">[17]</a> <a href="#17" id=17>As shown in Figure 8 , though the precision drops for Turian10 , both curves show the pattern that our system keeps gaining recall while maintaining precision to a certain level</a>
<a name="18">[18]</a> <a href="#18" id=18>The conversion is done by first performing a DCS tree transformation according to the aligned paths, and then declare a subsumption relation between the denotations of aligned germs</a>
<a name="19">[19]</a> <a href="#19" id=19>Since meanings of sentences</a>
</body>
</html>