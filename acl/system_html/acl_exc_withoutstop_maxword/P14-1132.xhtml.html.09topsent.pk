(lp0
VObjects corresponding to concepts are represented in visual terms by vectors in an image-based semantic space (Section 4.2
p1
aVWe use a set of approximately 9,500 concepts, the intersection of the ESP-based visual semantic space with the linguistic space
p2
aVWhen the induced projection function maps an object onto the linguistic space, the derived text vector will inherit a mixture of textual features from the concepts that activated the same hidden unit as the object
p3
aVThe process of learning to map objects to the their word label is implemented by training a projection function f proj v u'\u005cu2192' w from the visual onto the linguistic semantic space
p4
aVThe zero-shot framework leads us to frame fast mapping as the task of projecting visual representations of new objects onto language space for retrieving their word labels ( v u'\u005cu2192' w
p5
aVConcretely, we assume that concepts, denoted for convenience by word labels, are represented in linguistic terms by vectors in a text-based distributional semantic space (see Section 4.3
p6
aVWhereas for the latter our system assumes that all concepts have rich linguistic representations (i.e.,, representations estimated from a large corpus), in the case of the former, new concepts are assumed to be encounted in a limited linguistic context and therefore lacking rich linguistic representations
p7
aV2013 ) use linear regression to transform vector-based image representations onto vectors representing the same concepts in linguistic semantic space
p8
aVThis object is projected onto the linguistic space and associated with the word label of the nearest neighbor in that space ( degus in Figure 1
p9
aVIn this setting, we assume that our system possesses linguistic and visual information for a set of concepts in the form of text-based representations of words and image-based vectors of the corresponding objects, used for vision-to-language-mapping training
p10
aVAfter
p11
a.