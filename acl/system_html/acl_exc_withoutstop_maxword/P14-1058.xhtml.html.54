<html>
<head>
<title>P14-1058.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Consequently, a tagger trained on WSJ would incorrectly tag signal in MEDLINE append the source domain labeled data with predicted pivots (i.e., words that appear in both the source and target domains) to adapt a POS tagger to a target domain propose a cross-domain POS tagging method by training two separate models a generalised model and a domain-specific model</a>
<a name="1">[1]</a> <a href="#1" id=1>Domain adaptation (DA) of sentiment classification becomes extremely challenging when the distributions of words in the source and the target domains are very different, because the features learnt from the source domain labeled reviews might not appear in the target domain reviews that must be classified</a>
<a name="2">[2]</a> <a href="#2" id=2>At test time, for each word w that appears in a target domain test sentence, we measure the similarity, sim u'\u2062' ( \mat u'\u2062' M u'\u2062' u u'\u2192' \cS ( i ) , w u'\u2192' \cT ) , and select the most similar r words u ( i ) in the source domain labeled sentences as</a>
</body>
</html>