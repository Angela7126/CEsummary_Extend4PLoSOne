<html>
<head>
<title>P14-2036.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>With the above two distributions, we then add a number of words from news as additional information to microblogs by evaluating the relatedness of between each word and microblog, since words not appearing in the microblog may still be highly relevant</a>
<a name="1">[1]</a> <a href="#1" id=1>The word distribution of every microblog is based on topic analysis and its accuracy relies heavily on the accuracy of topic inference in step (b</a>
<a name="2">[2]</a> <a href="#2" id=2>We first infer the topic distribution of each microblog based on the topic-word distribution of news corpus obtained by the LDA estimation</a>
<a name="3">[3]</a> <a href="#3" id=3>The experiment corresponding to Figure 2 is to discover how the classification accuracy changes when we fix the number of added words ( L = 300 ) and change the number of topics ( K</a>
</body>
</html>