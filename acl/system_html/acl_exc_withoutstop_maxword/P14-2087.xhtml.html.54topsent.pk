(lp0
VDistributional methods have been used in many WSD systems in quite different flavours than the current study proposed a Lesk variant where each gloss word is weighted by its idf score in relation to all glosses, and gloss-context association was incremented by these weights rather than binary, overlap counts used distributional thesauri as a knowledge base to increase overlaps, which were, again, assessed by string matching
p1
aVThe input of the proposed NBM is bags of words, and thus it is straightforward to incorporate various forms of lexical knowledge (LK) for word senses by concatenating a tokenized knowledge source to the existing knowledge representation u'\u005cud835' u'\u005cudc1f' , while the similarity measure remains unchanged
p2
aVMore recently, proposed a tree-matching algorithm that measured gloss-context overlap as the weighted sum of dependency-induced lexical distance constructed a sentential similarity measure () using lexical
p3
a.