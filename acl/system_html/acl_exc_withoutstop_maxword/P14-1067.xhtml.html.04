<html>
<head>
<title>P14-1067.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>This new paradigm for QE makes it possible to i) let the QE system learn from one point at a time without complete re-training from scratch, ii) customize the predictions of an existing QE model with respect to a specific situation (post-editor or domain), or even iii) build a QE model from scratch when training data is not available</a>
<a name="1">[1]</a> <a href="#1" id=1>QE is generally cast as a supervised machine learning task, where a model trained from a collection of ( source, target, label ) instances is used to predict labels 1 1 Possible label types include post-editing effort scores ( e.g., 1-5 Likert scores indicating the estimated percentage of MT output that has to be corrected), HTER values [ 28 ] , and post-editing time ( e.g., seconds per word for new, unseen test items [ 31 ]</a>
<a name="2">[2]</a> <a href="#2" id=2>Evaluation is carried out by measuring the performance of the batch (learning only from the training set), the adaptive (learning from the training set and adapting to the test set), and the empty (learning from scratch from the test set) models in terms of global MAE scores on the test set</a>
<a name="3">[3]</a> <a href="#3" id=3>Our results show that the sensitivity of online QE models to different distributions of training and test instances makes them more suitable than batch methods for integration in a CAT framework</a>
<a name="4">[4]</a> <a href="#4" id=4>To this aim, our QE models are created using a training set coming from one domain (L or IT), and then used to predict the HTER labels for the test instances coming from the other domain ( e.g., training on L, testing on IT</a>
<a name="5">[5]</a> <a href="#5" id=5>The batch model is built</a>
</body>
</html>