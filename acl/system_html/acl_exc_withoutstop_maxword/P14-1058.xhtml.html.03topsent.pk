(lp0
VWe train a PLSR model, \u005cmat u'\u005cu2062' M , that predicts the target domain distribution \u005cmat u'\u005cu2062' M u'\u005cu2062' u u'\u005cu2192' \u005ccS ( i ) of a word u ( i ) in the source domain labeled sentences, given its distribution, u u'\u005cu2192' \u005ccS ( i
p1
aVGiven the distribution w u'\u005cu2192' \u005ccS of a word w in a source domain \u005ccS , we propose a method for learning its distribution w u'\u005cu2192' \u005ccT in a target domain \u005ccT
p2
aVWe propose a method to learn a model that can predict the distribution w u'\u005cu2192' \u005ccT of a word w in the target domain \u005ccT , given its distribution w u'\u005cu2192' \u005ccS in the source domain \u005ccS
p3
aVAt test time, for each word w that appears in a target domain test sentence, we measure the similarity, sim u'\u005cu2062' ( \u005cmat u'\u005cu2062' M u'\u005cu2062' u u'\u005cu2192' \u005ccS ( i ) , w u'\u005cu2192' \u005ccT ) , and select the most similar r words
p4
a.