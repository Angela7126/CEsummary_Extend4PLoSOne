<html>
<head>
<title>P14-2036.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Differing from step (a), the method used for topic inference for microblogs is not directly running LDA estimation on microblog collection but following the topics from external knowledge to ensure topic consistence</a>
<a name="1">[1]</a> <a href="#1" id=1>With the above two distributions, we then add a number of words from news as additional information to microblogs by evaluating the relatedness of between each word and microblog, since words not appearing in the microblog may still be highly relevant</a>
<a name="2">[2]</a> <a href="#2" id=2>Compared with our method, the topic model based methods mentioned above remain in finding latent space representation of short text and ignore that relevant words from external knowledge are informative as well</a>
<a name="3">[3]</a> <a href="#3" id=3>The word distribution of every microblog is based on topic analysis and its accuracy relies heavily on the</a>
</body>
</html>