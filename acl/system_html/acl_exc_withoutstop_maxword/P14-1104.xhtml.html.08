<html>
<head>
<title>P14-1104.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We employ Amazon u'\u2019' s Mechanical Turk (AMT) to label the emotions of Twitter data, and apply the proposed methods to the AMT dataset with the goals of improving the annotation quality at low cost, as well as learning accurate emotion classifiers</a>
<a name="1">[1]</a> <a href="#1" id=1>Ground Truth Annotation</a>
<a name="2">[2]</a> <a href="#2" id=2>Amazon Mechanical Turk Annotation we posted the set of 100K tweets to the workers on AMT for emotion annotation</a>
<a name="3">[3]</a> <a href="#3" id=3>Compared with the ground truth, many emotion bearing tweets were missed by the AMT annotators, despite the quality control we applied</a>
<a name="4">[4]</a> <a href="#4" id=4>Active learning for data cleaning differs from traditional active learning because the data already has low quality labels</a>
<a name="5">[5]</a> <a href="#5" id=5>We used this annotated dataset as ground truth</a>
<a name="6">[6]</a> <a href="#6" id=6>After that, the same dataset was annotated independently by a group of expert annotators to create the ground truth</a>
<a name="7">[7]</a> <a href="#7" id=7>After we obtained the annotated dataset from AMT, we posted the same dataset (without the labels) to a group of expert annotators</a>
<a name="8">[8]</a> <a href="#8" id=8>In order to evaluate our approach in real world scenarios, instead of creating a</a>
</body>
</html>