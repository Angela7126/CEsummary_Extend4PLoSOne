<html>
<head>
<title>P14-1082.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>A second baseline was constructed by weighing the probabilities from the translation table directly with the L2 language model described earlier</a>
<a name="1">[1]</a> <a href="#1" id=1>Third, we observe that adding the language model to our classifier leads to another significant gain (configuration l1r1 + LM in the results in Table 2</a>
<a name="2">[2]</a> <a href="#2" id=2>The baseline selects the most probable L1 fragment per L2 fragment according to the phrase-translation table</a>
<a name="3">[3]</a> <a href="#3" id=3>In other words, for each word type or phrase type that occurs as a fragment in the training set, and which does not map to just a single translation, a classifier is trained</a>
<a name="4">[4]</a> <a href="#4" id=4>The main research question in this research is how to disambiguate an L1 word or phrase to its L2 translation based on an L2 context, and whether such cross-lingual contextual approaches provide added value compared to baseline models that are not context informed or compared to standard language models</a>
<a name="5">[5]</a> <a href="#5" id=5>If not, we check for the presence of a classifier expert for the offered L1 fragment; only then we can proceed by extracting the desired number of L2 local context words to the immediate left and right of this fragment and adding those to the feature vector</a>
<a name="6">[6]</a> <a href="#6" id=6>We do so by normalising the class probability from the classifier ( s u'\u2062' c u'\u2062' o u'\u2062' r u'\u2062' e T u'\u2062' ( H ) ), which is our translation model, and the language model ( s u'\u2062' c u'\u2062' o u'\u2062' r u'\u2062' e l u'\u2062' m u'\u2062' ( H ) ), in such a way that the highest classifier score for the alternatives under consideration is always 1.0 , and the highest language model score of the sentence is always 1.0</a>
<a name="7">[7]</a> <a href="#7" id=7>When presented with test data, in which the L1 fragment is explicitly marked, we first check whether there is ambiguity for this L1 fragment and if a direct translation is available in our simple mapping table</a>
<a name="8">[8]</a> <a href="#8" id=8>Words or phrases that always map to a single translation are stored in a simple mapping table, as a classifier would have no added value in such cases</a>
<a name="9">[9]</a> <a href="#9" id=9>We therefore conducted a number of experiments with other language pairs, and present the abridged results in Table 6</a>
<a name="10">[10]</a> <a href="#10" id=10>We see that the language model baseline for English u'\u2192' French shows the same substantial improvement over the baseline as our English u'\u2192' Spanish results</a>
<a name="11">[11]</a> <a href="#11" id=11>Output a pair ( s u'\u2062' e u'\u2062' n u'\u2062' t u'\u2062' e u'\u2062' n u'\u2062' c u'\u2062' e t u'\u2032' , s u'\u2062' e u'\u2062' n u'\u2062' t u'\u2062' e u'\u2062' n u'\u2062' c u'\u2062' e t ) where s u'\u2062' e u'\u2062' n u'\u2062' t u'\u2062' e u'\u2062' n u'\u2062' c u'\u2062' e t u'\u2032' is a copy of t but with fragment f t substituted by f s , i.e., the introduction of an</a>
</body>
</html>