(lp0
VWe frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not
p1
aVContent selection decisions based on trends in time-series data determine the selection of the useful and important variables, which we refer to here as factors , that should be conveyed in a summary
p2
aVHere, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously []
p3
aVEnsemble methods [] are algorithms that use ensembles to perform ML learning and they are based on problem transformation or algorithm adaptation methods
p4
aVML classification achieved significantly higher accuracy, which was expected as it is a supervised learning method
p5
aVContent is regarded as labels (each template represents a label) and thus the task can be thought of as a classification problem
p6
aVRAkEL is based on Label Powerset (LP), a problem transformation method []
p7
aVWe compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with student users
p8
aVRL is trained to optimise for this function, and therefore it achieves higher reward, whereas ML is trained to learn by examples, therefore it produces output closer to the gold standard (lecturer u'\u005cu2019' s produced summaries
p9
aVThe reduced accuracy of the classification with predicted history is due to the error in the predicted values
p10
aVOur contributions to the field are as follows we present a novel and efficient
p11
a.