(lp0
VCompared to the previous work, ( i )  we use a different discourse representation (RST), ( ii )  we compare discourse parses using all-subtree kernels [] , ( iii )  we evaluate on much larger datasets, for several language pairs and for multiple metrics, and ( iv )  we do demonstrate better correlation with human judgments
p1
aVThe field of automatic evaluation metrics for MT is very active, and new metrics are continuously being proposed, especially in the context of the evaluation campaigns that run as part of the Workshops on Statistical Machine Translation (WMT 2008-2012), and NIST Metrics for Machine Translation Challenge (MetricsMATR), among others
p2
aVAlthough modern SMT systems have switched to a discriminative log-linear framework, which allows for additional sources as features, it is generally hard to incorporate dependencies beyond a small window of adjacent words, thus making it difficult to use linguistically-rich models
p3
aVTo determine the relative weights for the tuned combinations, we followed a similar approach to the one used by PRO to tune the relative weights of the components of a log-linear SMT model [] , also using Maximum Entropy as the base learning algorithm
p4
aVIn order to allow the tree kernel to find subtree matches at the word level, we include an additional layer of dummy leaves as was done in [] ; not shown in Figure 7 , for simplicity
p5
aVNote that the Asiya metrics are combinations of several metrics, and these combinations (which exclude DR and DR- lex ) can be also tuned; this yields sizable improvements over the untuned versions as column three in the table shows
p6
aVRecently,
p7
a.