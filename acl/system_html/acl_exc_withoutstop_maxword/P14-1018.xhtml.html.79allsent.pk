(lp0
VEach edge e i u'\u005cu2062' j u'\u005cu2208' E represents a connection between v i and v j , e i u'\u005cu2062' j = ( v i , v j ) and defines different social circles between Twitter users e.g.,, follower ( f ) , friend ( b ) , user mention ( m ) , hashtag ( h ) , reply ( y ) and retweet ( w
p1
aVHowever, most Twitter users are less prolific than those examined in these works, and thus do not produce the thousands of tweets required to obtain their levels of accuracy e.g.,, the median number of tweets produced by a random Twitter user per day is 10
p2
aVFinally, similarly to the results for the user model given in Figure 3 , increasing the number of tweets per neighbor from 5 to 200 leads to a significant gain in performance for all neighborhood types
p3
aVFor each such user we collect recent tweets and randomly sample their immediate k = 10 neighbors from follower, friend, user mention, reply, retweet and hashtag social circles
p4
aVSharing restrictions and rate limits on Twitter data collection only allowed us to recreate a semblance of ZLR data 6 6 This inability to perfectly replicate prior work based on Twitter is a recognized problem throughout the community of computational social science, arising from the data policies of Twitter itself, it is not specific to this work u'\u005cu2013' 193 Democratic and 178 Republican users with 1K tweets per user, and 20 neighbors of four types including follower, friends, user mention and retweet with 200 tweets per neighbor for each user of interest
p5
aVOur goal is to classify users of interest using evidence (e.g.,, communications) from their local neighborhood u'\u005cu2211' n f u'\u005cu2192' t u'\u005cu2062' [ N r u'\u005cu2062' ( v i ) ] u'\u005cu2261' f u'\u005cu2192' u'\u005cu2062' ( N r ) as Democratic or Republican
p6
aVWe show that three of six social circles u'\u005cu2013' friend, retweet and user-mention yield better accuracy compared to the user model for all graphs when t u'\u005cu2265' 250
p7
aVBaseline User Model As input we are given a set of vertices representing users of interest v i u'\u005cu2208' V along with feature vectors f u'\u005cu2192' u'\u005cu2062' ( v i ) derived from content authored by the user of interest
p8
aVThe proposed baseline model follows the same trends as the existing state-of-the-art approaches for user attribute classification in social media as described in Section 8
p9
aV[ 7 ] rely on identifying strong partisan clusters of Democratic and Republican users in a Twitter network based on retweet and user mention degree of connectivity, and then combine this clustering information with the follower and friend neighborhood size features
p10
aVThese results follow naturally from the underlying feature representation having more tweets per user leads to a lower variance estimate of a target multinomial distribution
p11
aVThe existing batch models for predicting latent user attributes rely on thousands of tweets per author [ 31 , 7 , 27 , 5 , 42 , 21 ]
p12
aVThe model dynamically updates posterior probability estimates p ( a ( v i ) = R t k ) for a given user v i as an additional evidence t k is acquired, as defined in a general form below for any latent attribute a u'\u005cu2062' ( v i ) u'\u005cu2208' A given the tweets T of user v i
p13
aVNext we propose to extend the baseline model by taking advantage of language in user social circles as describe below
p14
aVFigure 3 demonstrates that more tweets during prediction time lead to higher accuracy by showing that more users with 100 tweets are correctly classified e.g.,, filled green markers in the right upper quadrant are true Republicans and in the left lower quadrant are true Democrats
p15
aVThe average probability estimates p u'\u005cu039c' ( R u'\u005cu2223' T ) are reported for every 5 tweets in a stream T = ( t 1 , u'\u005cu2026' u'\u005cu2062' t k ) as u'\u005cu2211' P n ( R u'\u005cu2223' t k ) n , where n is the total number of users with the same attribute R or D
p16
aVSuch extreme divergences in the amount of time required for classification across all graphs should be of strong interest to researchers concerned with latent attribute prediction tasks because Twitter users produce messages with extremely different frequencies
p17
aVSimilar to our work, they assume that users from a particular class tend to reply and retweet messages of the users from the same class
p18
aVFor instance, 85.3% of all Twitter users post less than one update per day as reported at http://www.sysomos.com/insidetwitter/
p19
aVThus, for effectively classifying a given user v i it is better to take 200 tweets each from 10 neighbors rather than 2,000 tweets from the user
p20
aVWe demonstrate that increasing the size of the neighborhood leads to better performance across six neighborhood types
p21
aV[ 30 ] suggest a hierarchical Bayesian model which takes advantage of user name morphology for predicting user gender and ethnicity
p22
aVOur results demonstrate that even small changes to the neighborhood size n lead to better performance which does not support the claims by Zamal et al
p23
aVAs a result, less active users in G g u'\u005cu2062' e u'\u005cu2062' o just need more than 250 tweets to converge to a true 0 or 1 class
p24
aVFor example, to predict user political preference, we start with a prior P u'\u005cu2062' ( R ) = 0.5 , and sequentially update the posterior p ( R u'\u005cu2223' T ) by accumulating evidence from the likelihood p ( t k
p25
aVOther works explore political blogs to predict what content will get the most comments [ 41 ] or analyze communications from Capitol Hill 12 12 http://www.tweetcongress.org to predict campaign contributors based on this content [ 40 ]
p26
aVOther methods characterize Twitter users by applying limited amounts of network structure information in addition to lexical features
p27
aVFollowing the streaming nature of social media, we see the scarce available resource as the number of requests allowed per day to the Twitter API
p28
aVThe amount of time needed can be evaluated for different accuracy levels e.g.,, 0.75 and 0.95
p29
aVIn addition, we propose streaming models for personal analytics that dynamically update user labels based on their stream of communications which has been addressed previously by Van Durme ( 2012b
p30
aVOur goal is assign to a category each user of interest v i based on f u'\u005cu2192' u'\u005cu2062' ( v i
p31
aVUnsupervised Batch Approaches Bergsma et al
p32
aV[ 15 ] propose a bilinear user-centric model for predicting voting intentions in the UK and Australia from social media data
p33
aVWe denote a set of vertices adjacent to v i by social circle type r as N r u'\u005cu2062' ( v i ) which is equivalent to { v j u'\u005cu2223' e i u'\u005cu2062' j u'\u005cu2208' u'\u005cu03a6' r u'\u005cu2062' ( E ) }
p34
aVIt means that users in G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d are more politically vocal compared to users in G Z u'\u005cu2062' L u'\u005cu2062' R and G g u'\u005cu2062' e u'\u005cu2062' o
p35
aVWe collectively refer to D and R as our u'\u005cu201c' users of interest u'\u005cu201d' for which we aim to predict political preference
p36
aVWe rely on straightforward Bayesian rule update to our batch models in order to simulate a real-time streaming prediction scenario as a first step beyond the existing models as shown in Figure 2
p37
aVThese findings further confirm that differences in performance are caused by various biases present in the data due to distinct sampling and annotation approaches
p38
aVThus, with 75% accuracy we classify
p39
aVFollowing Filippova ( 2012 ) we refer to N r u'\u005cu2062' ( v i ) as v i u'\u005cu2019' s social circle, otherwise known as a neighborhood
p40
aVWe represent p u'\u005cu039c' ( R u'\u005cu2223' T ) as a box and whisker plot with the median, lower and upper quantiles to show the variance; the length of whiskers indicate lower and upper extreme values
p41
aVThus, their communications are scare even if we could get all of them without rate limiting from Twitter API
p42
aVThe corresponding log-linear model is defined as
p43
aVAdditionally, using social media for mining political opinions [ 23 , 19 ] or understanding socio-political trends and voting outcomes [ 36 , 12 , 15 ] is becoming a common practice
p44
aV11 11 For brevity we omit reporting results for bigram and trigram features, since unigrams showed superior performance
p45
aVThe more robustly this distribution is estimated (based on having more tweets) the more confident we should be in the classifier output
p46
aVWe denote a set of edges of a given type as u'\u005cu03a6' r u'\u005cu2062' ( E ) for r u'\u005cu2208' { f , b , h , m , w , y }
p47
aVWe labeled users as Democratic if they exclusively follow both Democratic candidates 4 4 As of Oct 12, 2012, the number of followers for Obama, Biden, Romney and Ryan were 2m, 168k, 1.3m and 267k u'\u005cu2013' BarackObama and JoeBiden but do not follow both Republican candidates u'\u005cu2013' MittRomney and RepPaulRyan and vice versa
p48
aVWe prefer binary to normalized count-based features to overcome sparsity issues caused by making predictions on each tweet individually
p49
aVResources like Twitter 1 1 http://www.demographicspro.com/ or Facebook 2 2 http://www.wolframalpha.com/facebook/ become extremely valuable for studying the underlying properties of such informal communications because of its volume, dynamic nature, and diverse population [ 18 , 33 ]
p50
aVT ) depending on the number of tweets is similar to the user model results presented in Figure 6
p51
aVR users in 1.2 weeks and D users in 3.5 weeks which is on average 6 times faster across attributes than for the user model
p52
aVR users in 3.2 weeks and D users in 1.1 weeks which is 7 times faster on average across attributes than for the user model;
p53
aVThus, E u'\u005cu2208' V ( 2 ) × { f , b , h , m , w , y }
p54
aVWe experiment with our static neighbor model defined in Eq
p55
aVT ) convergence in terms of the number of tweets and, especially, in the amount of time needed for user and user-neighbor models further confirms that neighborhood content is useful for political preference prediction
p56
aVTo investigate all types of social relationships between Twitter users and construct Twitter social graphs we collect lists of followers and friends, and extract user mentions, hashtags, replies and retweets from communications
p57
aVIn particular, the posterior estimates converge faster when predicting Democratic than Republican users but it has been trained on an equal number of tweets per class
p58
aVSimilar to the candidate-centric graph, for each user we collect recent tweets and randomly sample user social circles in the Fall of 2012
p59
aVfor the baseline user model
p60
aVOur goal is to maximize posterior probability estimates given a stream of communications for each user in the data over (a) time u'\u005cu03a4' and (b) the number of tweets T
p61
aV100 tweets per user
p62
aV1 and the neighborhood model from Eq
p63
aVWe compare our static neighbor and user models using the cost functions from Eq
p64
aVTo check whether our static models are cognizant of low-resource prediction settings we compare the performance of the user model from Eq
p65
aVThis dataset consists of 200 Republican and 200 Democratic users associated with 925 tweets on average per user
p66
aVBoth models defined in Eq
p67
aV2012 ) , where the authors apply features from the tweets authored by a user u'\u005cu2019' s friend to infer attributes of that user
p68
aVfor the neighborhood model
p69
aVWe train streaming models on an attribute balanced subset of tweets for each user v i excluding v i u'\u005cu2019' s tweets (or v i u'\u005cu2019' s neighbor tweets for a joint model
p70
aVT ) estimates for users in G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d converge 2-3 times faster in terms of number of tweets than for users in G Z u'\u005cu2062' L u'\u005cu2062' R
p71
aVWe study the influence of the neighborhood type r and size in terms of the number of neighbors n and tweets t per neighbor
p72
aVThe variance for average posterior estimates decreases when the number of tweets increases for all three datasets
p73
aVWe rely on communications from four types of neighbors such as friends, followers, retweets and user mentions
p74
aVWe also examine the ability of our static models to predict user political preferences in low-resource setting e.g.,, 5 tweets
p75
aVWe experiment with log-linear models defined in Eq
p76
aVWe design a set of experiments to analyze static and dynamic models for political affiliation classification defined in Sections 3 and 4
p77
aVFigure 7 a and 7 b illustrate the amount of time required for the user model to infer political preferences estimated for 1,031 users in G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d and 371 users in G Z u'\u005cu2062' L u'\u005cu2062' R
p78
aVUnlike static model experiments, we are not modeling the influence of the number of neighbors or the amount of content per neighbor
p79
aVRepublican users in 23 minutes and Democratic users in 10 minutes;
p80
aVUser-Neighbor Model with Dynamic Updates relies on both neighbor N r communications including friend, follower, retweet, user mention and user tweets t 1 ( v i ) , u'\u005cu2026' , t k ( N r ) following the order they arrive over time u'\u005cu03a4' ; here we dynamically update the posterior probability p ( R u'\u005cu2223' t 1 ( v i ) , u'\u005cu2026' , t k ( N r ) )
p81
aVTo make a fair comparison with a streaming user model, we start with the same user tweet t 0 u'\u005cu2062' ( v i
p82
aV2 are learned using normalized count-based word ngram features extracted from either user or neighbor tweets
p83
aVEach user has on average 6155 friends with 642 tweets per friend
p84
aVHere we discuss the results for our static neighborhood model
p85
aVFor a static neighbor model we go beyond that, and train our the model on all data available per user, but only apply part of the data at the test time, pushing the boundaries of how little is truly required for classification
p86
aVThe existing models follow a standard setup when either user or neighbor tweets are available during train and test
p87
aVWe observe that average posterior estimates P u'\u005cu039c' ( R u'\u005cu2223' T ) converge faster to 0 (Democratic) than to 1 (Republican) in Figures 6 and 6
p88
aVIn this paper, we study different types of user social circles in addition to a friend network
p89
aVWe collect this data to get a sample of politically less active users compared to the users from candidate-centric graph
p90
aVFigures 6 and 6 demonstrate dynamic user model prediction results averaged over users from G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d and G Z u'\u005cu2062' L u'\u005cu2062' R graphs
p91
aVFriend, user mention and retweet neighborhoods yield the highest accuracy for all graphs
p92
aVThe convergence rate for the average posterior probability estimates P u'\u005cu039c' ( R
p93
aVWe investigate classification decision probabilities for our static user model u'\u005cu03a6' v i by making predictions on a random set of 5 vs
p94
aVEach figure outlines changes in sequential average probability estimates p u'\u005cu039c' ( R u'\u005cu2223' T ) for each individual self-authored tweet t k as defined in Eq
p95
aV3 and 4 , we spent an equal amount of resources to obtain 100 user tweets and 10 tweets from 10 neighbors
p96
aVHere we abstract this to a model assumption where we receive one tweet t k at a time and aim to maximize classification performance with as few tweets per user as possible
p97
aVSupervised Batch Approaches The vast majority of work on predicting latent user attributes in social media apply supervised static SVM models for discrete categorical e.g.,, gender and regression models for continuous attributes e.g.,, age with lexical bag-of-word features for classifying user gender [ 11 , 31 , 5 , 38 ] , age [ 31 , 22 , 21 ] or political orientation
p98
aVthe order of the social circle u'\u005cu2013' the number of neighbors per user of interest
p99
aVThe classifier is learned using binary word ngram features extracted from user or user-neighbor communications
p100
aVStreaming Approaches Van Durme ( 2012b ) proposed streaming models to predict user gender in Twitter
p101
aVwhere y is the number of all possible attribute values, and k is the number of tweets per user
p102
aVFor that, for each user we take tweets that arrive continuously over time and apply two different streaming models
p103
aVdevelop low-resource and real-time dynamic approaches for personal analytics using as an example the prediction of political preference of Twitter users;
p104
aVFigures 7 c and 7 d show the amount of time required for a joint user-neighbor model to infer political preferences estimated for users in G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d and G Z u'\u005cu2062' L u'\u005cu2062' R
p105
aVThen instead of waiting for the next user tweet we rely on any neighbor tweets that appear until the user produces the next tweet t 1 u'\u005cu2062' ( v i
p106
aVEach user is associated with a non-zero number of publicly posted tweets
p107
aVHere, we order user and neighbor communication streams by real world time of posting and measure changes in posterior probabilities over time
p108
aVWe evaluate our models with dynamic Bayesian updates on a continuous stream of communications over time as shown in Figure 2
p109
aVevaluate neighborhood size influence, we change the number of neighbors and try n = [ 1 , 2 , 5 , 10 ] neighbor(s) per user;
p110
aVWe annotate these u'\u005cu2018' points of equal number of communications u'\u005cu2019' with a line on top marked with a corresponding number of user tweets
p111
aVThe main purpose of these experiments is to quantitatively evaluate (1) the number of tweets and (2) the amount of real world time it takes to observe enough evidence on Twitter to make reliable predictions
p112
aVMoreover, a lot of users with 100 tweets are close to 0.5 decision probability which suggests that the classifier is just uncertain rather then being completely off, e.g.,, misclassified Republican users with 5 tweets (not filled blue markers in the right lower quadrant) are close to 0
p113
aVT ) u'\u005cu2192' 1 for Republicans in less than 110 tweets which is u'\u005cu0394' u'\u005cu2062' t = 40 tweets faster than the user model; for G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d the convergence for both P u'\u005cu039c' ( R
p114
aV1 and 2 and continuously estimate the posterior probabilities P ( R u'\u005cu2223' T ) as defined in Eq
p115
aVIn Figure 5 we present accuracy results to show neighborhood size influence on classification performance for G g u'\u005cu2062' e u'\u005cu2062' o and G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d graphs
p116
aVUser Model with Dynamic Updates relies exclusively on user tweets t 1 ( v i ) , u'\u005cu2026' , t k ( v i ) following the order they arrive over time u'\u005cu03a4' , where for each user v i we dynamically update the posterior p ( R u'\u005cu2223' t 1 ( v i ) , u'\u005cu2026' , t k ( v i ) )
p117
aV1 and Eq
p118
aVFollowing Eq
p119
aV[ 13 ] incorporate Twitter data in a spatial model of political ideology
p120
aV100 ( u'\u005cu223c' 20%) Republican users in 3.6 hours and Democratic users in 2.2 hours for G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d ;
p121
aVWe extend this assumption and study other relationship types e.g.,, friends, user mentions etc
p122
aVNeighbor Model As input we are given user-local neighborhood N r u'\u005cu2062' ( v i ) , where r is a neighborhood type
p123
aVWe find that with 75% accuracy we can classify 100 users for
p124
aV[ 1 ] show that large-scale clustering of user names improves gender, ethnicity and location classification on Twitter
p125
aVThese results are coherent with the outcomes for our static models shown in Figures 4 and 5
p126
aVWe first answer whether communications from user-local neighborhoods can help predict political preference for the user
p127
aVThe best accuracy for G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d is 0.75 for friend, follower, retweet and user-mention neighborhoods which is 0.03 higher than the user baseline; for G g u'\u005cu2062' e u'\u005cu2062' o is 0.67 for user-mention and 0.64 for retweet circles compared to 0.57 for the user model; for G Z u'\u005cu2062' L u'\u005cu2062' R is 0.863 for retweet and 0.849 for friend circles which is 0.11 higher that the user baseline
p128
aVestimate neighbor content influence, we alternate the amount of content per neighbor and try t = [ 5 , 10 , 15 , 25 , 50 , 100 , 200 ] tweets
p129
aV[ 27 , 26 ] focus on user behavior, network structure and linguistic features
p130
aVT ) u'\u005cu2192' 0 is not significantly different than the user model
p131
aVTwitter users interact with one another and engage in direct communication in different ways e.g.,, using retweets, user mentions e.g.,, @youtube or hashtags e.g.,, #tcot , in addition to having explicit connections among themselves such as following, friending
p132
aVWe estimate dynamic posterior updates from a joint stream of user and neighbor communications in G g u'\u005cu2062' e u'\u005cu2062' o , G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d and G Z u'\u005cu2062' L u'\u005cu2062' R graphs
p133
aV3 3 The code and detailed explanation on how we collected all six types of user neighbors and their communications using Twitter API can be found here http://www.cs.jhu.edu/ svitlana/
p134
aV3 and Eq
p135
aVFor that purpose, we take a random partition containing 100 users of G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d graph and perform four independent classification experiments u'\u005cu2013' two runs using 5 and two runs using 100 tweets per user
p136
aVSuch setup will simulate different real-world prediction scenarios which have not been previously explored, to our knowledge e.g.,, when a user has a private profile or has not tweeted yet, and only user neighbor tweets are available
p137
aVFor example, frequent politically influenced terms used widely by Democratic users include faith4liberty, constitutionally, pass, vote2012, terroristic
p138
aVTo explore the contribution of different neighborhood types we learn static user and neighbor models on G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d , G g u'\u005cu2062' e u'\u005cu2062' o and G Z u'\u005cu2062' L u'\u005cu2062' R graphs
p139
aVWe find similar behavior across all three graphs
p140
aVEach vertex is attributed with a feature vector f u'\u005cu2192' u'\u005cu2062' ( v i ) which encodes communications e.g.,, tweets available for a given user
p141
aVThe model makes predictions of a latent user attribute e.g.,, Republican under a model assumption of sequentially arriving, independent and identically distributed observations T = ( t 1 , u'\u005cu2026' , t k ) 9 9 Given the dynamic character of online discourse it will clearly be of interest in the future to consider models that go beyond the iid assumption
p142
aV100 ( u'\u005cu223c' 75%) R users in 12 weeks and 80 ( u'\u005cu223c' 60%) D users in 19 weeks for G g u'\u005cu2062' e u'\u005cu2062' o
p143
aVIn our case, users in G Z u'\u005cu2062' L u'\u005cu2062' R tweet approximately 800 times less frequently than users in G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d
p144
aVWe present an overview of the existing models for political preference prediction in Table 1
p145
aVThe most similar work to ours is by Zamal et al
p146
aVMoreover, communications from a joint stream allow to make an inference up to 7 times faster
p147
aV[ 2 ] following up on Rao u'\u005cu2019' s work [ 31 ] on adding socio-linguistic features to improve gender, ethnicity and political preference prediction show that incorporating stylistic and syntactic information to the bag-of-word features improves gender classification
p148
aVInferring latent user attributes such as gender, age, and political preferences [ 30 , 42 , 6 ] automatically from personal communications and social media including emails, blog posts or public discussions has become increasingly popular with the web getting more social and volume of data available
p149
aVIn this paper we analyze and go beyond static models formulating personal analytics in social media as a streaming task
p150
aVWe construct candidate-centric graph G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d by looking into following relationships between the users and Democratic or Republican candidates during the 2012 US Presidential election
p151
aVWe average the posterior probability results over the users in G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d , G g u'\u005cu2062' e u'\u005cu2062' o and G Z u'\u005cu2062' L u'\u005cu2062' R graphs
p152
aVRecent work by Wong et al
p153
aVThis setup is similar to leave-one-out classification
p154
aVThe log-linear model 7 7 We use log-linear models over reasonable alternatives such as perceptron or SVM, following the practice of a wide range of previous work in related areas [ 34 , 17 , 29 ] including text classification in social media [ 38 , 39 ] for such binary classification is
p155
aVT ) is higher for Democratic users; for G Z u'\u005cu2062' L u'\u005cu2062' R P u'\u005cu039c' ( R
p156
aVWe construct a geo-centric graph G g u'\u005cu2062' e u'\u005cu2062' o by collecting n = 135 Democratic and m = 135 Republican users from the Maryland, Virginia and Delaware region of the US with self-reported political preference in their biographies
p157
aVIn the Fall of 2012, leading up to the elections, we randomly sampled n = 516 Democratic and m = 515 Republican users
p158
aV[ 24 ] following the work by Eisenstein [ 8 ] propose a Bayesian generative model to discover demographic language variations in Twitter
p159
aVEach vertex v i represents someone in a communication graph i.e.,, communicant here a Twitter user
p160
aV100 ( u'\u005cu223c' 56%) R users in 20 weeks and 100 ( u'\u005cu223c' 52%) D users in 8.9 weeks for G Z u'\u005cu2062' L u'\u005cu2062' R which is 800 times longer that for G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d ;
p161
aVFigure 1 presents an example of a social graph derived from Twitter
p162
aVWe observe that when the number of neighbors is n = 1 , the difference in accuracy across all neighborhood types is less significant but for n u'\u005cu2265' 2 it becomes more significant
p163
aVEach vertex is associated with a latent attribute a u'\u005cu2062' ( v i ) , in our case it is binary a u'\u005cu2062' ( v i ) u'\u005cu2208' { D , R } , where D stands for Democratic and R for Republican users
p164
aVPennacchiotti et al
p165
aVexperiments are performed across multiple datasets supporting the prediction of political preference in Twitter, to highlight the significant differences in performance that arise from the underlying collection and annotation strategies
p166
aVexamine the relative utility of six different notions of u'\u005cu201c' similarity u'\u005cu201d' between users in an implicit Twitter social network for personal analytics;
p167
aVConnover et al
p168
aVwhere features are normalized word ngram counts extracted from v i u'\u005cu2019' s tweets f u'\u005cu2192' t u'\u005cu2062' ( v i
p169
aVBergsma et al
p170
aVIt suggests that language of Democrats is more expressive of their political preference than language of Republicans
p171
aVRao et al
p172
aVGolbeck et al
p173
aVNotably, users from different social circles can be shared across the users of the same or different classes e.g.,, a user v j can be in both follower circle v j u'\u005cu2208' N f u'\u005cu2062' ( v i ) , v i u'\u005cu2208' D and retweet circle v j u'\u005cu2208' N w u'\u005cu2062' ( v k ) , v k u'\u005cu2208' R
p174
aVTo the best of our knowledge, this is the first work that makes explicit the tradeoff between accuracy and cost (manifest as calls to the Twitter API), and optimizes to a different tradeoff than state-of-the-art approaches, seeking maximal performance when limited data is available
p175
aVMoreover, recent changes to Twitter API querying rates further restrict the speed of access to this resource, effectively reducing the amount of data that can be collected in a given time period
p176
aVIn Figure 4 we present accuracy results for G c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d and G g u'\u005cu2062' e u'\u005cu2062' o graphs
p177
aVHere we focus on a binary assignment into the categories Democratic D or Republican R
p178
aVThe lowest convergence is detected for G g u'\u005cu2062' e u'\u005cu2062' o where after t k = 250 tweets the average posterior estimate P u'\u005cu039c' ( R u'\u005cu2223' t k ) = 0.904 ± 0.044 and P u'\u005cu039c' ( D u'\u005cu2223' t k ) = 0.861 ± 0.008
p179
aVFor example, we only use follower tweets for G t u'\u005cu2062' e u'\u005cu2062' s u'\u005cu2062' t , but we use tweets from all types of neighbors for G t u'\u005cu2062' r u'\u005cu2062' a u'\u005cu2062' i u'\u005cu2062' n
p180
aVWe first evaluate batch models that are cognizant of low-resource prediction setting described above, maximizing the efficiency of content in calculating personal analytics
p181
aVthe number of communications per neighbor f u'\u005cu2192' t u'\u005cu2062' ( N r ) , t = { 5 , 10 , 15 , 25 , 50 , 100 , 200 } ;
p182
aVWe also consider a G Z u'\u005cu2062' L u'\u005cu2062' R graph constructed from a dataset previously used for political affiliation classification [ 42 ]
p183
aVFor instance, Lampos et al
p184
aVSuch models better capture the real-time nature of evidence being used in latent author attribute predictions tasks
p185
aVO u'\u005cu2019' Connor et al
p186
aV[ 20 ] investigates tweeting and retweeting behavior for political learning during 2012 US Presidential election
p187
aVMassive Online Analysis (MOA) toolkit developed by Bifet et al
p188
aVSimilar or better P u'\u005cu039c' ( R
p189
aVPolitical labels are extracted from http://www.wefollow.com as described by Pennacchiotti and Popescu ( 2011a
p190
aVIn most cases, we only work with a sample of a social circle, denoted by N r u'\u005cu2032' u'\u005cu2062' ( v i ) where
p191
aVMOA has been effectively used to detect sentiment changes in Twitter streams [ 4 ]
p192
aVTo our knowledge only limited work on personal analytics [ 5 , 38 ] have performed this straight-forward comparison
p193
aVLets define an attributed, undirected graph G = ( V , E ) , where V is a set of vertices and E is a set of edges
p194
aVBesides the neighborhood u'\u005cu2019' s type r , each is characterized by
p195
aV70% train, 10% development and 20% test and run 100 random restarts for every n and t parameter combination
p196
aVFor all experiments we use LibLinear [ 9 ] , integrated in the Jerboa toolkit [ 37 ]
p197
aVOther works suggested to process text streams for a variety of NLP tasks e.g.,, real-time opinion mining and sentiment analysis in social media [ 25 ] , named entity disambiguation [ 32 ] , statistical machine translation [ 16 ] , first story detection [ 28 ] , and unsupervised dependency parsing [ 14 ]
p198
aVWe perform 10-fold cross validation 10 10 For each fold we split the data into 3 parts
p199
aV2010 ) is an alternative to the Jerboa package used in this work developed by Van Durme ( 2012a
p200
aV8 8 The separate issue is that many authors simply don u'\u005cu2019' t tweet very often
p201
aV2 with the aim to
p202
aVMoreover, we detect that P u'\u005cu039c' ( R
p203
aVHowever, for G g u'\u005cu2062' e u'\u005cu2062' o the variance for P u'\u005cu039c' ( R
p204
aVOur main contributions include
p205
aV5 5 The original dataset was collected in 2012 and has been recently released at http://icwsm.cs.mcgill.ca/
p206
aVN r u'\u005cu2032' u'\u005cu2062' ( v i k is its size for v i
p207
aVThe authors would like to thank the anonymous reviewers for their helpful comments
p208
aVG c u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' d
p209
aVN r d u'\u005cu2062' e u'\u005cu2062' g u'\u005cu2062' ( v i ) , n = { 1 , 2 , 5 , 10 }
p210
aV2
p211
aVD × t u'\u005cu2062' ( v i ) u'\u005cu2192' u'\u005cu211d'
p212
aVG g u'\u005cu2062' e u'\u005cu2062' o
p213
aVR )
p214
aV4
p215
aV6
p216
aV2012
p217
ag216
aVG Z u'\u005cu2062' L u'\u005cu2062' R
p218
aVT ) u'\u005cu2192' 1 and P u'\u005cu039c' ( D
p219
a.