(lp0
VIn N u'\u005cu2062' T u'\u005cu2062' C u'\u005cu2062' I u'\u005cu2062' R and F u'\u005cu2062' B u'\u005cu2062' I u'\u005cu2062' S , each alignment model was trained from the randomly sampled 100 K data, and then a translation model was trained from all the training data that was word-aligned by the alignment model
p1
aVIn addition, we evaluated the end-to-end translation performance of three tasks a Chinese-to-English translation task with the FBIS corpus ( F u'\u005cu2062' B u'\u005cu2062' I u'\u005cu2062' S ), the IWSLT 2007 Japanese-to-English translation task ( I u'\u005cu2062' W u'\u005cu2062' S u'\u005cu2062' L u'\u005cu2062' T ) [ 10 ] , and the NTCIR-9 Japanese-to-English patent translation task ( N u'\u005cu2062' T u'\u005cu2062' C u'\u005cu2062' I u'\u005cu2062' R ) [ 13 ] 6 6 We did not evaluate the translation performance on the Hansards data because the development data is very small and performance is unreliable
p2
aVTable 4 shows the alignment performance on B u'\u005cu2062' T u'\u005cu2062' E u'\u005cu2062' C with various training data sizes, i.e.,, training data for I u'\u005cu2062' W u'\u005cu2062' S u'\u005cu2062' L u'\u005cu2062' T (40 K), training data for B u'\u005cu2062' T u'\u005cu2062' E u'\u005cu2062' C (9 K), and the randomly sampled 1 K data from the
p3
a.