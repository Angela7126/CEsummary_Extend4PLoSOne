<html>
<head>
<title>P14-2135.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The filtering approach described thus far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts</a>
<a name="1">[1]</a> <a href="#1" id=1>To evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u'\u222a' C introduced in Section 2</a>
<a name="2">[2]</a> <a href="#2" id=2>The USF evaluation set is particularly appropriate in the present context because concepts in the dataset are also rated for conceptual concreteness by at least 10 human annotators</a>
<a name="3">[3]</a> <a href="#3" id=3>Multi-modal models in which perceptual input is filtered according to our algorithm learn higher-quality semantic representations than previous approaches, resulting in a significant performance improvement of up to 17% in capturing the semantic similarity of concepts</a>
<a name="4">[4]</a> <a href="#4" id=4>We apply image dispersion-based filtering as follows if both concepts in an evaluation pair have an image dispersion below a given threshold, both the linguistic and the visual representations are included</a>
<a name="5">[5]</a> <a href="#5" id=5>Since perceptual data sources typically contain information about both abstract and concrete concepts, such information is included for both concept types</a>
<a name="6">[6]</a> <a href="#6" id=6>On this more diverse sample, which reflects the range of concepts typically found in linguistic corpora, image dispersion is a</a>
</body>
</html>