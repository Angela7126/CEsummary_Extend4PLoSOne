(lp0
VWe use them to bring in information from unlabeled data into our string transduction model and then train a character-level SRN language model on unlabeled tweets
p1
aVThe principal contributions of our work are i) we show that a discriminative sequence labeling model is apt for text normalization and performs at state-of-the-art levels with small amounts of labeled training data; (ii) we show that character-level neural text embeddings can be used to effectively incorporate information from unlabeled data into the model and can substantially boost text normalization performance
p2
aVOur string transduction model works by learning the sequence of edits which transform the input string into the output string
p3
aVWe use SRNs to induce character-level text representations from unlabeled Twitter data to use as features in the string transduction model
p4
aVWe use a sequence labeling model to learn to label input strings with edit scripts
p5
aVIn this work we suggest a simple, supervised character-level string transduction model which
p6
a.