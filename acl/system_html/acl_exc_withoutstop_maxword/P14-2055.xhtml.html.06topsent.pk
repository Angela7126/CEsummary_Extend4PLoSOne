(lp0
VInput + background
p1
aVWord score
p2
aVSentence score
p3
aVHere we describe the input sets and background corpus used for the two summarization tasks and define the prior distribution for each
p4
aVA single hypothesis about the background takes the form of a multinomial distribution over word unigrams
p5
aVIn contrast, word surprise although computed for each word type separately, quantifies the surprise when incorporating the new counts of this word into the background multinomials
p6
aVWord scores are aggregated to obtain a score for each sentence
p7
aVWe use the method to do two types of summarization tasks a) generic news summarization which uses a large random collection of news articles as the background, and b) update summarization where the background is a smaller but specific set of news documents on the same topic as the input set
p8
aVWe first compute a surprise value for each word type in the summarization input
p9
aVUpdate summarization
p10
aVThe count of each word in the background is
p11
a.