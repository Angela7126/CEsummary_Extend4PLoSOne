<html>
<head>
<title>P14-1132.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Thus, ESP constitutes a more realistic, and at the same time more challenging, simulation of how things are encountered in real life, testing the potentials of cross-modal mapping in dealing with the complex scenes that one would encounter in event recognition and caption generation tasks</a>
<a name="1">[1]</a> <a href="#1" id=1>Moreover, once the learner observes a new object, she can easily construct a full visual representation for it (and the acquisition literature has shown that humans are wired for good object segmentation and recognition [ 50 ] ) u'\u2013' the more challenging task is to scan the ongoing and very ambiguous linguistic communication for contexts that might be relevant and informative about the new object</a>
<a name="2">[2]</a> <a href="#2" id=2>Finally, we provide preliminary evidence that cross-modal projections can be used effectively to simulate a fast mapping scenario, thus strengthening the claims of this approach as a full-fledged, fully inductive theory of meaning acquisition</a>
<a name="3">[3]</a> <a href="#3" id=3>Regarding the sources of error, a qualitative analysis of predicted word labels and objects as presented in Table 6 suggests that both textual and visual representations, although capturing relevant u'\u201c' topical u'\u201d' or u'\u201c' domain u'\u201d' information, are not enough to single out the properties of the target concept</a>
<a name="4">[4]</a> <a href="#4" id=4>When the induced projection function maps an object onto the linguistic space, the derived text vector will inherit a mixture of textual features from the concepts that activated the same hidden unit as the object</a>
<a name="5">[5]</a> <a href="#5" id=5>However, NN , an architecture that can capture more complex, non-linear relations in features across modalities, emerges as the best performing model, confirming on a larger scale the recent findings of Socher et al</a>
<a name="6">[6]</a> <a href="#6" id=6>For ESP, given the size and amount of noise in this dataset, we build vectors for visual concepts , by normalizing and summing the BoVW vectors of all the images</a>
</body>
</html>