(lp0
VUnlike most previous work, our model is defined at a finer level of granularity u'\u005cu2014' it computes meaning representations for individual words and is unique in its use of attributes as a means of representing the textual and visual modalities
p1
aVFor that purpose, the autoencoders are pre-trained layer by layer, with the current layer being fed the latent representation of the previous autoencoder as input
p2
aVUnlike previous efforts such as the widely used WordSim353 collection () , our dataset contains ratings for visual and textual similarity, thus allowing to study the two modalities (and their contribution to meaning representation) together and in isolation
p3
aVThese results indicate that the participants found the task relatively straightforward and produced similarity ratings with a reasonable level of consistency
p4
aVThese models learn the meaning of words based on textual and perceptual input
p5
aVAs our input consists of natural language attributes, the model would infer textual attributes given visual attributes and vice versa
p6
aVThe similarity data was post-processed so as to identify and remove outliers
p7
aVIt
p8
a.