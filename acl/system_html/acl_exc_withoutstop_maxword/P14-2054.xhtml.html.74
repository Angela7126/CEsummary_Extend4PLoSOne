<html>
<head>
<title>P14-2054.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>where u'\ud835' u'\udc33' is a binary vector, z i indicates x i is kept or not u'\ud835' u'\udc32' is a square matrix denoting the projective dependency parse tree over the remaining words, y i u'\u2062' j indicates if x i is the head of x j (note that each word has exactly one head w i tok is the informativeness of x i , w i u'\u2062' j bgr is the score of bigram x i u'\u2062' x j in an n-gram model, w dep is the score of dependency arc x i u'\u2192' x j in an arc-factored dependency parsing model</a>
<a name="1">[1]</a> <a href="#1" id=1>Recent studies used a subtree deletion model for compression [ 1 , 13 , 15 ] , which deletes a word only if its modifier in the parse tree is deleted</a>
<a name="2">[2]</a> <a href="#2" id=2>We define the sentence compression task as given a sentence composed of n words, u'\ud835' u'\udc31' = x 1 , u'\u2026' , x n , and a length L u'\u2264' n , we need to remove ( n - L ) words from u'\ud835' u'\udc31'</a>
</body>
</html>