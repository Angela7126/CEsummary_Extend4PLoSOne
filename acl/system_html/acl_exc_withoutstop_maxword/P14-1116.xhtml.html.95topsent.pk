(lp0
VML classification achieved significantly higher accuracy, which was expected as it is a supervised learning method
p1
aVWe compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with student users
p2
aVThe reduced accuracy of the classification with predicted history is due to the error in the predicted values
p3
aVHere, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously []
p4
aVRL is trained to optimise for this function, and therefore it achieves higher reward, whereas ML is trained to learn by examples, therefore it produces output closer to the gold standard (lecturer u'\u005cu2019' s produced summaries
p5
aVWe frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not
p6
aVThe classification method reduces the generation steps, by making the decision of the factor selection and the template selection jointly
p7
aVContent is regarded as labels (each template represents a label) and thus the task can be thought of as a classification problem
p8
aVThe upper-bound accuracy is 78.09% calculated by using the expert previous decisions and not the potentially erroneous predicted decisions
p9
aVConsequently, a single poor decision in the ML classification can result in much less reward
p10
aVML classification requires no history, i.e., does not keep track of previous decisions, and thus has a smaller feature space
p11
aVRAkEL is based on Label Powerset (LP), a problem
p12
a.