<html>
<head>
<title>P14-2036.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We first infer the topic distribution of each microblog based on the topic-word distribution of news corpus obtained by the LDA estimation</a>
<a name="1">[1]</a> <a href="#1" id=1>With the above two distributions, we then add a number of words from news as additional information to microblogs by evaluating the relatedness of between each word and microblog, since words not appearing in the microblog may still be highly relevant</a>
<a name="2">[2]</a> <a href="#2" id=2>The word distribution of every microblog is based on topic analysis and its accuracy relies heavily on the accuracy of topic inference in step (b</a>
<a name="3">[3]</a> <a href="#3" id=3>Compared with the original LDA optimization problem (1), the topic inference problem for microblog (2) follows the idea of document generation process, but replaces topics to be estimated with known topics from other corpus</a>
<a name="4">[4]</a> <a href="#4" id=4>So</a>
</body>
</html>