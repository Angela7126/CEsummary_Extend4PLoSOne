<html>
<head>
<title>P14-2135.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The filtering approach described thus far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts</a>
<a name="1">[1]</a> <a href="#1" id=1>The Turney et al algorithm quantifies the concreteness of concepts that lack such a rating based on their proximity to rated concepts in a semantic vector space</a>
<a name="2">[2]</a> <a href="#2" id=2>Multi-modal models that learn semantic concept representations from both linguistic and perceptual input were originally motivated by parallels with human concept acquisition, and evidence that many concepts are grounded in the perceptual system [ 3 ]</a>
<a name="3">[3]</a> <a href="#3" id=3>We use Google Images as our image source, and extract the first n image results for each concept word</a>
<a name="4">[4]</a> <a href="#4" id=4>To evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u'\u222a' C introduced in Section 2</a>
<a name="5">[5]</a> <a href="#5" id=5>We apply image dispersion-based filtering as follows if both concepts in an evaluation pair have an image dispersion below a given threshold, both the linguistic and the visual representations are included</a>
<a name="6">[6]</a> <a href="#6" id=6>On this more diverse sample, which reflects the range of concepts typically found in linguistic corpora, image dispersion is a particularly useful diagnostic</a>
</body>
</html>