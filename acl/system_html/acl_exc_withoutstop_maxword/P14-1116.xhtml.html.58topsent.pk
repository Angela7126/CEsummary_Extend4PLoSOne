(lp0
VML classification achieved significantly higher accuracy, which was expected as it is a supervised learning method
p1
aVWe compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with student users
p2
aVEnsemble methods [] are algorithms that use ensembles to perform ML learning and they are based on problem transformation or algorithm adaptation methods
p3
aVRL is trained to optimise for this function, and therefore it achieves higher reward, whereas ML is trained to learn by examples, therefore it produces output closer to the gold standard (lecturer u'\u005cu2019' s produced summaries
p4
aVHere, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously []
p5
aVThe reduced accuracy of the classification with predicted history is due to the error in the predicted values
p6
aVWe frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not
p7
aVConsequently, a single poor decision in the ML classification can result in much less reward
p8
aVThe classification method reduces the generation steps, by making the decision of the factor selection and the template selection jointly
p9
aVContent is regarded as labels (each template represents a label) and thus the task can be thought of as a classification problem
p10
aVRAkEL is based on Label Powerset (LP), a problem transformation method []
p11
aVML classification requires no history, i.e., does not keep track of previous decisions,
p12
a.