(lp0
VConsequently, the Wsabie Embedding model can share more information between different examples in the training data than the Log-Linear Embedding model
p1
aVFrame Lexicon In our experimental setup, we scanned the XML files in the u'\u005cu201c' frames u'\u005cu201d' directory of the FrameNet 1.5 release, which lists all the frames, the corresponding roles and the associated lexical units, and created a frame lexicon to be used in our frame and argument identification models
p2
aVWe call this model Log-Linear Embedding
p3
aVWe denote the frames that associate with u'\u005cu2113' in the frame lexicon 5 5 The frame lexicon stores the frames, corresponding semantic roles and the lexical units associated with the frame and our training corpus as F u'\u005cu2113'
p4
aVWe learn the initial embedding representations for our frame identification model (§ 3 ) using a deep neural language model similar to the one proposed by Bengio et al
p5
aVThe Wsabie Embedding model from § 3 performs significantly better
p6
a.