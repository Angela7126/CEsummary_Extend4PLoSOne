<html>
<head>
<title>P14-1070.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>training set irregular MWEs merged into one token, regular MWEs are structured, and integration of regular MWE information into the labels ( FCT_r_POS</a>
<a name="1">[1]</a> <a href="#1" id=1>So to sum up on the u'\u201c' labeled evaluation u'\u201d' , we obtain a LAS evaluation for the whole task of parsing plus MWE recognition, but an UAS evaluation that penalizes less errors on MWE status, while keeping a representation that is richer predicted parses contain not only the syntactic dependencies and MWE information, but also a classification of MWEs into regular and irregular, and the internal syntactic structure of regular MWEs</a>
<a name="2">[2]</a> <a href="#2" id=2>Structured representation</a>
<a name="3">[3]</a> <a href="#3" id=3>We describe below the flat representation of MWEs in this dataset, and the modified representation for regular MWEs that we propose</a>
<a name="4">[4]</a> <a href="#4" id=4>training set flat representation of irregular MWEs, with label suffixing ( dep_cpd_POS ), structured representation of regular MWEs without label suffixing</a>
<a name="5">[5]</a> <a href="#5" id=5>For predicted parses with structured MWEs, we use an inverse transformation of structured MWEs into flat MWEs, for evaluation against the</a>
</body>
</html>