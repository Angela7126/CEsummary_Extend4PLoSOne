(lp0
VOn-the-fly knowledge is generated by aligning paths in DCS trees
p1
aVAs the semantics of DCS trees is formulated by abstract denotations, the meanings of declarative sentences are represented by statements on abstract denotations
p2
aVBased on abstract denotations, we briefly describe our process to apply DCS to textual inference
p3
aVPerform rule-based conversion from dependency parses to DCS trees, which are translated to statements on abstract denotations
p4
aVIn this section we describe the idea of representing natural language semantics by DCS trees, and achieving inference by computing logical relations among the corresponding abstract denotations
p5
aVThe strict semantics of DCS trees brings us the idea of applying DCS to logical inference
p6
aVConvert accepted path alignments into statements on abstract denotations, use them in logical inference as new knowledge, and try to prove H again
p7
aVTo formulate the database querying process defined by a DCS tree, we provide formal semantics to DCS trees by employing relational algebra [] for representing the query
p8
aVFurthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved in Figure 6 , though the tree transformation can be seen as generated from the entailment rule u'\u005cu201c' X is blamed for death u'\u005cu2192' X causes loss of life u'\u005cu201d' , the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby
p9
aVDCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees [] (Figure 1
p10
aVWe obtain DCS trees from dependency trees, to bypass the need of a concrete database
p11
aVAbstract denotation of a DCS tree can be calculated in a bottom-up manner
p12
aVSince meanings of sentences are represented by statements on abstract denotations, logical inference among sentences is reduced to deriving new relations among abstract denotations
p13
aVA path is considered as joining two germs in a DCS tree, where a germ is defined as a specific semantic role of a node
p14
aVThe conversion is done by first performing a DCS tree transformation according to the aligned paths, and then declare a subsumption relation between the denotations of aligned germs
p15
aVThis formulation keeps the simpleness and computability of DCS trees mostly unaffected; for example, our semantic calculation for DCS trees is parallel to the denotation computation in original DCS
p16
aVWe built an inference engine to perform logical inference on abstract denotations as above
p17
aVMost of the problems do not require lexical knowledge, so we use our primary textual inference system without on-the-fly knowledge nor WordNet, to test the performance of the DCS framework as formal semantics
p18
aVTechnically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values [] of that variable
p19
aVFor example, to apply the aligned path pair generated in Figure 5 , we use it to transform T into a new tree T u'\u005cu2019' (Figure 6 ), and then the aligned germs, OBJ ( blame ) in T and SUBJ ( cause ) in T u'\u005cu2019' , will generate the on-the-fly knowledge
p20
aVAbstract denotations and statements are convenient for representing semantics of various types of expressions and linguistic knowledge
p21
aVTo obtain DCS trees from natural language, we use Stanford CoreNLP 5 5 http://nlp.stanford.edu/software/corenlp.shtml for dependency parsing [] , and convert Stanford dependencies to DCS trees by pattern matching on POS tags and dependency labels
p22
aVIf H is not proven, compare DCS trees of T and H , and generate path alignments
p23
aVThe idea is to borrow a minimal set of operators from relational algebra [] , which is already able to formulate the calculation in DCS and define abstract denotation , which is an abstraction of the computation of denotations guided by DCS trees
p24
aVFor example, Figure 5 shows DCS trees of the following sentences (a simplified pair from RTE2-dev
p25
aVAccepted aligned paths are converted into statements, which are used as new knowledge
p26
aVOur solution is to redefine DCS trees without the aid of any databases, by considering each node of a DCS tree as a content word in a sentence (but may no longer be a table in a specific database), while each edge represents semantic relations between two words
p27
aVWe extract fragments of DCS trees as paraphrase candidates, translate them back to linguistic expressions, and apply distributional similarity to judge their validity
p28
aVAn inference engine is built to handle inference on abstract denotations
p29
aVAs described below, we represent meanings of sentences with abstract denotations , and logical relations among sentences are computed as relations among their abstract denotations
p30
aVTwo paths are aligned if the joined germs are aligned, and we impose constraints on aligned germs to inhibit meaningless alignments, as described below
p31
aVThe logical clue to align germs is if there exists an abstract denotation, other than W , that is a superset of both abstract denotations of two germs, then the two germs can be aligned
p32
aVThe abstract denotation of a germ is defined in a top-down manner for the root node u'\u005cu03a1' of a DCS tree u'\u005cud835' u'\u005cudcaf' , we define its denotation [[ u'\u005cu03a1' ]] u'\u005cud835' u'\u005cudcaf' as the denotation of the entire tree [[ u'\u005cud835' u'\u005cudcaf' ]] ; for a non-root node u'\u005cu03a4' and its parent node u'\u005cu03a3' , let the edge ( u'\u005cu03a3' , u'\u005cu03a4' ) be labeled by semantic roles ( r , r u'\u005cu2032' ) , then define
p33
aVAs follows, our full system (Figure 4 ) additionally invokes linguistic knowledge on-the-fly
p34
aVAligned paths are evaluated by a similarity score, for which we use distributional similarity of the words that appear in the paths (§ 4.1
p35
aVUse statements of T and linguistic knowledge as premises, and try to prove statements of H by our inference engine
p36
aVFor example, the abstract denotation of H in Figure 2 is calculated from the leaf node Mary , and then
p37
aVOnly path alignments with high similarity scores can be accepted
p38
aVThe abstract denotation of u'\u005cud835' u'\u005cudcaf' is defined as
p39
aVPath alignments with scores higher than a threshold are accepted
p40
aV6 6 In [] DCS trees are learned from QA pairs and database entries
p41
aVFor this, our primary textual inference system operates as
p42
aVMeanings of sentences then can be represented by primary relations among abstract denotations
p43
aVDCS trees can be extended to represent linguistic phenomena such as quantification and coreference, with additional markers introducing additional operations on tables
p44
aVFor example, the similarity score of the path alignment u'\u005cu201c' OBJ ( blame ) IOBJ - ARG ( death ) u'\u005cu2248' SUBJ ( cause ) OBJ - ARG ( loss ) MOD - ARG ( life ) u'\u005cu201d' is calculated as the cosine similarity of vectors blame + death and cause + loss + life
p45
aVAligned paths are evaluated by a similarity score to estimate their likelihood of being paraphrases
p46
aVHowever, it should be noted that using on-the-fly knowledge in logical inference is not a trivial task
p47
aVTo formulate this properly, we define the abstract denotation of a germ, which, intuitively, represents the meaning of the germ in the specific sentence
p48
aVHowever, this method does not work for real-world datasets such as PASCAL RTE [] , because of the knowledge bottleneck it is often the case that the lack of sufficient linguistic knowledge causes failure of inference, thus the system outputs u'\u005cu201c' no entailment u'\u005cu201d' for almost all pairs []
p49
aVOn PASCAL RTE datasets, strict logical inference is known to have very low recall [] , so on-the-fly knowledge is crucial in this setting
p50
aVMoreover, to compensate the lack of background knowledge in practical inference, we combine our framework with the idea of tree transformation [] , to propose a way of generating knowledge in logical representation from entailment rules [] , which are by now typically considered as syntactic rewriting rules
p51
aVThe transparent syntax-to-semantics interface of DCS enables us to back off to NLP techniques during inference for catching up the lack of knowledge
p52
aVIn this logical system, we treat abstract denotations as terms and statements as atomic sentences , which are far more easier to handle than first order predicate logic (FOL) formulas
p53
aVSimilar to the tree transformation based approach to RTE [] , this process can also utilize lexical-syntactic entailment rules []
p54
aVThe threshold for accepted path alignments is set to 0.4 , based on pre-experiments on RTE development sets
p55
aVStatements are declarations of some relations among abstract denotations, for which we consider the following set relations
p56
aVFor example, the abstract denotation of the first sentence of T in Figure 2 ( Mary loves every dog ) is calculated from F 2 ( Mary loves ) as
p57
aVNow for a germ r u'\u005cu2062' ( u'\u005cu03a3' ) , the denotation is defined as the projection of the denotation of node u'\u005cu03a3' onto the specific semantic role r
p58
aVThe labels on both ends of an edge, such as SUBJ (subject) and OBJ (object), are considered as semantic roles of the corresponding words 1 1 The semantic role ARG is specifically defined for denoting nominal predicate
p59
aVFor the example in Figure 2 , by constructing the following abstract denotations
p60
aVApplied by our logical system, the noisy on-the-fly knowledge can achieve a precision comparable to higher quality resources such as DIRT
p61
aVTo calculate the similarity scores of path alignments, we use the sum of word vectors of the words from each path, and calculate the cosine similarity
p62
aVFor a T - H pair, apply dependency parsing and coreference resolution
p63
aVAfter the abstract denotation [[ u'\u005cud835' u'\u005cudcaf' ]] is calculated, the statement representing the meaning of the sentence is defined as [[ u'\u005cud835' u'\u005cudcaf' ]] u'\u005cu2260' u'\u005cu2205'
p64
aVMacCartney08 [] uses natural logic to calculate inference relations between two superficially aligned sentences
p65
aVThe experiments show i) a competitive performance on FraCaS dataset; (ii) a big impact of our automatically generated on-the-fly knowledge in achieving high recall for a logic-based RTE system; and (iii) a result that outperforms state-of-the-art RTE system on RTE5 data
p66
aVAlso, we only accept paths of length u'\u005cu2264' 5 , to prevent too long paths to be aligned
p67
aVIn this way, we can perform inference over formulas of relational algebra, without computing database entries explicitly
p68
aVThese are algebraic properties of abstract denotations, among which we choose a set of axioms that can be handled efficiently and enable most common types of inference seen in natural language
p69
aVIf a node u'\u005cu03a3' in a DCS tree u'\u005cud835' u'\u005cudcaf' belongs to a mention cluster m , we take the abstract denotation [[ u'\u005cud835' u'\u005cudcaf' u'\u005cu03a3' ]] and make a selection s m u'\u005cu2062' ([[ u'\u005cud835' u'\u005cudcaf' u'\u005cu03a3' ]]) , which is regarded as the abstract denotation of that mention
p70
aVSince our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences
p71
aVDependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees []
p72
aVIn this paper, we equip DCS with logical inference , which, in one point of view, is u'\u005cu201c' the best way of testing an NLP system u'\u005cu2019' s semantic capacity u'\u005cu201d' []
p73
aVRecognizing textual entailment (RTE) is the task of determining whether a given textual statement H can be inferred by a text passage T
p74
aVOptimistically, we believe DCS can provide a framework of semantic representation with sufficiently wide coverage for real-world texts
p75
aVNot too much u'\u005cu201c' magic u'\u005cu201d' in Mikolov13 actually for over 80% pairs, every node in DCS tree of H can be covered by a path of length u'\u005cu2264' 5 that has a corresponding path of length u'\u005cu2264' 5 in T with a similarity score 0.4
p76
aVTropical storm Debby is blamed for deaths
p77
aVIn this way, our framework combines distributional and logical semantics, which is also the main subject of and
p78
aVThus, our first step is to fix a notation which abstracts the calculation process of DCS trees, so as to clarify its meaning without the aid of any existing database
p79
aVWhen only primary knowledge is used in inference (the first row), recalls are actually very low; After we activate the on-the-fly knowledge, recalls jump to over 50%, with a moderate fall of precision
p80
aVThe DCS tree in Figure 1 is interpreted as a command for querying these tables, obtaining u'\u005cu201c' reading u'\u005cu201d' entries whose u'\u005cu201c' SUBJ u'\u005cu201d' field is student and whose u'\u005cu201c' OBJ u'\u005cu201d' field is book
p81
aVWe test the effect of on-the-fly knowledge on RTE2, RTE3, RTE4 and RTE5 datasets, and compare our system with other approaches
p82
aVSimilarly, denotation of germ u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cudc1e' ) in T of Figure 5 indicates the object of u'\u005cu201c' blame u'\u005cu201d' as in the sentence u'\u005cu201c' Tropical storm Debby is blamed for death u'\u005cu201d' , which is a tropical storm , is Debby , etc
p83
aVSelection operators are implemented as markers assigned to abstract denotations, with specially designed axioms
p84
aVARG , SUBJ , OBJ , IOBJ , TIME and MOD
p85
aVHence, the process can also be used to generate knowledge from context sensitive rules [] , which are known to have higher quality []
p86
aVA storm has caused loss of life
p87
aVTo deal with negation in our forward-chaining inference engine, we introduce one more relation on abstract denotations, namely disjointness A u'\u005cu2225' B , meaning that A and B are disjoint sets
p88
aVThis fact fairly restricts the applicable tasks of DCS
p89
aVWe test our system on FraCaS [] and PASCAL RTE datasets []
p90
aVTo sum up, the result shows that DCS is good at handling universal quantifiers and negations
p91
aVThe FOL formula for the context-preserved rule in Figure 6 is even more involved
p92
aVOther structures in the paths, such as semantic roles, are ignored in the calculation
p93
aVMost errors are due to wrongly generated DCS trees (e.g., wrongly assigned semantic roles) or unimplemented quantifier triggers (e.g., u'\u005cu201c' neither u'\u005cu201d' ) or generalized quantifiers (e.g., u'\u005cu201c' at least a few u'\u005cu201d'
p94
aVObviously this is unrealistic for logical inference on unrestricted texts, because we cannot prepare a database for everything in the world
p95
aVThe precisions of 1 and 2 pieces on-the-fly knowledge application are over 60%, which is fairly high, given our rough estimation of the similarity score
p96
aVA major type of error is caused by the ignorance of semantic roles in calculation of similarity scores
p97
aVThe semantic role MOD is used for any restrictive modifiers
p98
aVA comparison between our system and other RTE systems is shown in Table 6
p99
aVThe result is a set { John reads Ulysses , u'\u005cu2026' } , which is called a denotation
p100
aVA DCS tree u'\u005cud835' u'\u005cudcaf' = ( u'\u005cud835' u'\u005cudca9' , u'\u005cu2130' ) is defined as a rooted tree, where each node u'\u005cu03a3' u'\u005cu2208' u'\u005cud835' u'\u005cudca9' is labeled with a content word w u'\u005cu2062' ( u'\u005cu03a3' ) and each edge ( u'\u005cu03a3' , u'\u005cu03a3' u'\u005cu2032' ) u'\u005cu2208' u'\u005cu2130' u'\u005cu2282' u'\u005cud835' u'\u005cudca9' × u'\u005cud835' u'\u005cudca9' is labeled with a pair of semantic roles ( r , r u'\u005cu2032' ) 7 7 The definition differs slightly from the original , mainly for the sake of simplicity and clarity
p101
aVStern11 [] and Stern12 [] extend this framework to utilize entailment rules as tree transformations
p102
aVFor example, though u'\u005cu201c' Italy beats Kazakhstan u'\u005cu201d' is not primarily proven from u'\u005cu201c' Italy is defeated by Kazakhstan u'\u005cu201d' , our system does produce the path alignment u'\u005cu201c' SUBJ ( beat ) OBJ u'\u005cu2248' OBJ ( defeat ) SUBJ u'\u005cu201d' with a high similarity score
p103
aVAs a comparison, studied the proportion of proven pairs and precision by applying DIRT rules to tree skeletons in RTE2 and RTE3 data
p104
aVFor the sentence u'\u005cu201c' students read books u'\u005cu201d' , imagine a database consists of three tables, namely, a set of students, a set of books, and a set of u'\u005cu201c' reading u'\u005cu201d' events (Table 1
p105
aVSumming up test data from RTE2 to RTE5, Figure 7 shows the proportion of all proven pairs and their precision
p106
aVFor example, the FOL formula of the rule u'\u005cu201c' X is blamed for death u'\u005cu2192' X causes loss of life u'\u005cu201d' is
p107
aVThis is not trivial, however, because DCS works under the assumption that databases are explicitly available
p108
aVRoughly speaking, the relations correspond to the logical concepts satisfiability and entailment
p109
aVOver 40% pairs can be proven by one piece of on-the-fly knowledge, yet pairs do exist in which more than 2 pieces are necessary
p110
aVThe result shows that our system has comparable performance
p111
aVIn this section, we evaluate our system on FraCaS (§ 4.2 ) and PASCAL RTE datasets (§ 4.3
p112
aVThe result is shown in Table 4
p113
aVIf ( u'\u005cu03a3' , u'\u005cu03a4' i ) is assigned by a quantification marker u'\u005cu201c' u'\u005cu2282' u'\u005cu201d' 8 8 Multiple quantifiers can be processed similarly then the abstract denotation is 9 9 The result of [[ u'\u005cud835' u'\u005cudcaf' ]] depends on the order of the children u'\u005cu03a4' 1 , u'\u005cu2026' , u'\u005cu03a4' n
p114
aVWhen universal quantifiers are involved, we need to add division operators to the formula
p115
aVIt should be noted that, however, a framework primarily designed for question answering is not readily suited for logical inference
p116
aVThe FraCaS test suite contains 346 inference problems divided into 9 sections, each focused on a category of semantic phenomena
p117
aVResults on test data are shown in Table 5
p118
aVThis is done by applying axioms to known statements, and approximately 30 axioms are implemented (Table 3
p119
aVUsing disjointness we implemented two types of negations i) atomic negation, for each content word w we allow negation w ¯ of that word, characterized by the property w u'\u005cu2225' w ¯ ; and (ii) root negation, for a DCS tree u'\u005cud835' u'\u005cudcaf' and its denotation [[ u'\u005cud835' u'\u005cudcaf' ]] , the negation of u'\u005cud835' u'\u005cudcaf' is represented by u'\u005cud835' u'\u005cudcaf' u'\u005cu2225' u'\u005cud835' u'\u005cudcaf' , meaning that u'\u005cud835' u'\u005cudcaf' = u'\u005cu2205' in its effect
p120
aVOn the other hand, Wang10 [] learns a tree-edit model from training data, and captures entailment relation by tree edit distance
p121
aVSelection operators in relational algebra select a subset from a set to satisfy some specific properties
p122
aVIt is expressive enough to represent complex natural language queries on a relational database, yet simple enough to be latently learned from question-answer pairs
p123
aVCurrently we use the following semantic roles
p124
aVAs shown in Figure 8 , though the precision drops for Turian10 , both curves show the pattern that our system keeps gaining recall while maintaining precision to a certain level
p125
aVFurther extensions of our framework are made to deal with additional linguistic phenomena, as briefly explained below
p126
aVHere u'\u005cu03a3' is the node nearer to the root
p127
aVThis can be employed to represent linguistic phenomena such as downward monotonicity and generalized quantifiers
p128
aVAll of the three systems pursue a logical approach, while combining various techniques to achieve robustness
p129
aVClark08 [] is a logic-based system utilizing various resources including WordNet and DIRT paraphrases [] , and is tolerant to partially unproven H sentences in some degree
p130
aVDeterminers such as u'\u005cu201c' all u'\u005cu201d' , u'\u005cu201c' every u'\u005cu201d' and u'\u005cu201c' each u'\u005cu201d' trigger quantifiers, as shown in Figure 2
p131
aVThe germ u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cudc1e' ) and germ u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc1e' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc21' ) in DCS tree of T are joined by the underscored path
p132
aVSome examples are shown in Table 2
p133
aVBos06 [] is a hybrid system combining deep features from a theorem prover and a model builder, together with shallow features such as lexical overlap and text length
p134
aVwhich is not a horn clause
p135
aVTwo germs are aligned if they are both at leaf nodes (e.g., u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc1e' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc21' ) in T and u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc22' u'\u005cud835' u'\u005cudc1f' u'\u005cud835' u'\u005cudc1e' ) in H , Figure 5 ), or they already have part of their meanings in common, by some logical clues
p136
aVFurthermore, for each edge ( u'\u005cu03a3' , u'\u005cu03a3' u'\u005cu2032' ) we can optionally assign a quantification marker
p137
aVBecause, answers returned by a query depend on the specific database, but implication is independent of any databases
p138
aVStill, our unsupervised system outperforms the state-of-the-art on RTE5 dataset
p139
aVwhere u'\u005cud835' u'\u005cudcaf' u'\u005cu2032' is the same tree as u'\u005cud835' u'\u005cudcaf' except that the edge ( u'\u005cu03a3' , u'\u005cu03a4' i ) is removed
p140
aVAs a result, accuracies significantly increase
p141
aVThe lexical knowledge we use are synonyms, hypernyms and antonyms extracted from WordNet 12 12 http://wordnet.princeton.edu/
p142
aVTo obtain the three-valued output (i.e., yes , no , and unknown ), we output u'\u005cu201c' yes u'\u005cu201d' if H is proven, or try to prove the negation of H if H is not proven
p143
aVWe use the data by , and experiment on the first section, Quantifiers , following
p144
aVStill, our system outperforms u'\u005cu2019' s probabilistic CCG-parser
p145
aVFormally, suppose the root u'\u005cu03a3' of a DCS tree u'\u005cud835' u'\u005cudcaf' has children u'\u005cu03a4' 1 , u'\u005cu2026' , u'\u005cu03a4' n , and edges ( u'\u005cu03a3' , u'\u005cu03a4' 1 ) , u'\u005cu2026' , ( u'\u005cu03a3' , u'\u005cu03a4' n ) labeled by ( r 1 , r 1 u'\u005cu2032' ) , u'\u005cu2026' , ( r n , r n u'\u005cu2032' ) , respectively
p146
aVLess than 5% pairs can be proven primarily, with a precision of 77%
p147
aVWe use Stanford CoreNLP to resolve coreferences [] , whereas coreference is implemented as a special type of selection
p148
aVFurthermore, all implemented axioms are horn clauses, hence we can employ forward-chaining, which is very efficient
p149
aVStill, it can be efficiently treated by our inference engine because as a statement, the formula [[ u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cudc1e' ) ]] u'\u005cud835' u'\u005cudc13' u'\u005cu2282' [[ u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1c' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2e' u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc1e' ) ]] T u'\u005cu2019' is an atomic sentence, more than a horn clause
p150
aVFigure 2 shows an example with a quantifier u'\u005cu201c' every u'\u005cu201d' , which is marked as u'\u005cu201c' u'\u005cu2282' u'\u005cu201d' on the edge ( u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2f' u'\u005cud835' u'\u005cudc1e' ) u'\u005cu2062' OBJ-ARG u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc20' ) and interpreted as a division operator q u'\u005cu2282' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' (§ 2.2
p151
aVCompared to and , our system does not need a pre-trained alignment model, and it improves by making multi-sentence inferences
p152
aVDifferent orders correspond to readings of different quantifier scopes
p153
aVFor example, answers to the question u'\u005cu201c' What books are read by students u'\u005cu201d' , should always be a subset of answers to u'\u005cu201c' What books are ever read by anyone u'\u005cu201d' , no matter how we store the data of students and how many records of books are there in our database
p154
aVNode animal ( Animal that Mary loves u'\u005cu2001' F 3 = u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc27' u'\u005cud835' u'\u005cudc22' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc25' u'\u005cu2229' u'\u005cu03a0' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( F 2
p155
aVwe can use the lexical knowledge u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc20' u'\u005cu2282' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc27' u'\u005cud835' u'\u005cudc22' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc25' , the statements of T (i.e., u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc20' u'\u005cu2282' u'\u005cu03a0' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( F 2 ) and F 6 u'\u005cu2260' u'\u005cu2205' ), and the axioms in Table 3 , 11 11 Algebraic identities, such as u'\u005cu03a0' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( F 4 ) = F 3 u'\u005cu2229' F 7 and u'\u005cu03a0' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( F 6 ) = u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc20' u'\u005cu2229' F 7 , are also axioms to prove the statement of H (i.e., F 4 u'\u005cu2260' u'\u005cu2205' ) (Figure 3
p156
aVSubsumption A u'\u005cu2282' B set A is subsumed by B
p157
aVThe word vectors we use are from 13 13 http://code.google.com/p/word2vec/ ( Mikolov13 ), and additional results are also shown using 14 14 http://metaoptimize.com/projects/wordreprs/ ( Turian10
p158
aVNon-emptiness A u'\u005cu2260' u'\u005cu2205' the set A is not empty
p159
aVWe also add axioms on named entities, stopwords, numerics and superlatives
p160
aVOur whole system is publicly released and can be downloaded from http://kmcs.nii.ac.jp/tianran/tifmo/
p161
aVIf the negation of H is proven, we output u'\u005cu201c' no u'\u005cu201d' , otherwise we output u'\u005cu201c' unknown u'\u005cu201d'
p162
aVTo negate H , we use the root negation as described in § 2.5
p163
aVFor example, the abstract denotation of germ u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc24' ) in Figure 1 is defined as u'\u005cu03a0' u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc24' u'\u005cu2229' u'\u005cu03a0' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc2b' u'\u005cud835' u'\u005cudc1e' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc1d' u'\u005cu2229' ( u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc2e' u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc1e' u'\u005cud835' u'\u005cudc27' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' × u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc24' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' ) ) ) , meaning u'\u005cu201c' books read by students u'\u005cu201d'
p164
aVThese are more tailored systems using machine learning with many handcrafted features
p165
aVThis section has 44 single premise and 30 multi premise problems
p166
aVNew rules can be added if necessary
p167
aVNode have ( Tom has an animal that Mary loves u'\u005cu2001' F 4 = u'\u005cud835' u'\u005cudc21' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2f' u'\u005cud835' u'\u005cudc1e' u'\u005cu2229' ( u'\u005cud835' u'\u005cudc13' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' × ( F 3 ) u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' )
p168
aVFinally, to see if we u'\u005cu201c' get lucky u'\u005cu201d' on RTE5 data in the choice of word vectors and thresholds, we change the thresholds from 0.1 to 0.7 and draw the precision-recall curve, using two types of word vectors, Mikolov13 and Turian10
p169
aVThe impact of such errors depends on the data making methodology, though
p170
aV3 3 Using division operator, subsumption can be represented by non-emptiness, since for sets A , B of the same dimension, q u'\u005cu2282' u'\u005cu2062' ( A , B ) u'\u005cu2260' u'\u005cu2205' u'\u005cu21d4' A u'\u005cu2282' B
p171
aVNode love ( Mary loves u'\u005cu2001' F 2 = u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2f' u'\u005cud835' u'\u005cudc1e' u'\u005cu2229' ( u'\u005cud835' u'\u005cudc0c' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2b' u'\u005cud835' u'\u005cudc32' u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' × W u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79'
p172
aVThe proportion is 8% with precision 65% on RTE2, and proportion 6% with precision 72% on RTE3
p173
aVHowever, for example, logical clues can avoid aligning u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2b' u'\u005cud835' u'\u005cudc26' ) to u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2c' ) , which is obviously meaningless
p174
aVA simple example is that u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2b' u'\u005cud835' u'\u005cudc26' ) in T can be aligned to u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2b' u'\u005cud835' u'\u005cudc26' ) in H , because their denotations have a common superset other than W , namely u'\u005cu03a0' u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2b' u'\u005cud835' u'\u005cudc26'
p175
aVThese could be addressed by future work
p176
aVwhere u'\u005cud835' u'\u005cudcaf' u'\u005cu03a4' i is the subtree of u'\u005cud835' u'\u005cudcaf' rooted at u'\u005cu03a4' i , and R u'\u005cu03a3' is the set of possible semantic roles for content word w u'\u005cu2062' ( u'\u005cu03a3' ) (e.g., R u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2f' u'\u005cud835' u'\u005cudc1e' = { u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' , u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' } ), and W R u'\u005cu03a3' u'\u005cu2216' r i is the product of W which has dimension R u'\u005cu03a3' u'\u005cu2216' r i (e.g., W { u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' , u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' } u'\u005cu2216' u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' = W u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79'
p177
aV4 4 Negation and disjointness ( u'\u005cu201c' u'\u005cu2225' u'\u005cu201d' ) are explained in § 2.5
p178
aVFor example superlatives satisfy the following property
p179
aVIt lowers precisions in RTE2 and RTE3 data, particularly in u'\u005cu201c' IE u'\u005cu201d' subtask (where precisions drop under 0.5
p180
aVFor example, the statement of u'\u005cu201c' students read books u'\u005cu201d' is u'\u005cud835' u'\u005cudc2b' u'\u005cud835' u'\u005cudc1e' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc1d' u'\u005cu2229' ( u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc2e' u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc1e' u'\u005cud835' u'\u005cudc27' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' × u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc24' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' ) u'\u005cu2260' u'\u005cu2205' , and the statement of u'\u005cu201c' Mary loves every dog u'\u005cu201d' is q u'\u005cu2282' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cu03a0' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( F 2 ) , u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc20' ) u'\u005cu2260' u'\u005cu2205' , which is logically equivalent to u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc20' u'\u005cu2282' u'\u005cu03a0' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( F 2
p181
aVFor example, named entities are singletons, so we add axioms such as u'\u005cu2200' x ; ( x u'\u005cu2282' u'\u005cud835' u'\u005cudc13' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc26' x u'\u005cu2260' u'\u005cu2205' ) u'\u005cu2192' u'\u005cud835' u'\u005cudc13' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc26' u'\u005cu2282' x
p182
aV10 10 See Footnote 2,3
p183
aVThen all selections of the same mention cluster are declared to be equal
p184
aVIn the current system, we implement (i) superlatives, e.g., s h u'\u005cu2062' i u'\u005cu2062' g u'\u005cu2062' h u'\u005cu2062' e u'\u005cu2062' s u'\u005cu2062' t u'\u005cu2062' ( u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2e' u'\u005cud835' u'\u005cudc27' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc22' u'\u005cud835' u'\u005cudc27' u'\u005cu2229' ( W u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' × u'\u005cud835' u'\u005cudc00' u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc22' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cude7c' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude73' ) ) (the highest mountain in Asia) and (ii) numerics, e.g., s t u'\u005cu2062' w u'\u005cu2062' o u'\u005cu2062' ( u'\u005cud835' u'\u005cudc29' u'\u005cud835' u'\u005cudc1e' u'\u005cud835' u'\u005cudc2d' u'\u005cu2229' u'\u005cud835' u'\u005cudc1f' u'\u005cud835' u'\u005cudc22' u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc21' ) (two pet fish), where s f is a selection marker
p185
aVA more complicated example is that u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cudc1e' ) and u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1c' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2e' u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc1e' ) can be aligned, because inference can induce [[ u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cudc1e' ) ]] u'\u005cud835' u'\u005cudc13' = [[ u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc03' u'\u005cud835' u'\u005cudc1e' u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc32' ) ]] u'\u005cud835' u'\u005cudc13' = [[ u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2b' u'\u005cud835' u'\u005cudc26' ) ]] u'\u005cud835' u'\u005cudc13' , as well as [[ u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1c' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2e' u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc1e' ) ]] u'\u005cud835' u'\u005cudc07' = [[ u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2b' u'\u005cud835' u'\u005cudc26' ) ]] u'\u005cud835' u'\u005cudc07' , so they also have the common superset u'\u005cu03a0' u'\u005cud835' u'\u005cude70' u'\u005cud835' u'\u005cude81' u'\u005cud835' u'\u005cude76' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc2d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc2b' u'\u005cud835' u'\u005cudc26'
p186
aVOn the other hand, it occurs less often in u'\u005cu201c' IR u'\u005cu201d' subtask
p187
aVTom has a dog u'\u005cu2001' F 6 = u'\u005cud835' u'\u005cudc21' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2f' u'\u005cud835' u'\u005cudc1e' u'\u005cu2229' ( u'\u005cud835' u'\u005cudc13' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' × u'\u005cud835' u'\u005cudc1d' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc20' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79'
p188
aVObjects that Tom has u'\u005cu2001' F 7 = u'\u005cu03a0' u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc21' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2f' u'\u005cud835' u'\u005cudc1e' u'\u005cu2229' ( u'\u005cud835' u'\u005cudc13' u'\u005cud835' u'\u005cudc28' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' × W u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' ) )
p189
aVH
p190
aVT
p191
aVA u'\u005cu2282' B u'\u005cu2062' u'\u005cu2062' s h u'\u005cu2062' i u'\u005cu2062' g u'\u005cu2062' h u'\u005cu2062' e u'\u005cu2062' s u'\u005cu2062' t u'\u005cu2062' ( B ) u'\u005cu2282' A u'\u005cu21d2' s h u'\u005cu2062' i u'\u005cu2062' g u'\u005cu2062' h u'\u005cu2062' e u'\u005cu2062' s u'\u005cu2062' t u'\u005cu2062' ( B ) = s h u'\u005cu2062' i u'\u005cu2062' g u'\u005cu2062' h u'\u005cu2062' e u'\u005cu2062' s u'\u005cu2062' t u'\u005cu2062' ( A
p192
aV[[ r u'\u005cu2062' ( u'\u005cu03a3' ) ]] u'\u005cud835' u'\u005cudcaf' = u'\u005cu03a0' r u'\u005cu2062' ( [[ u'\u005cu03a3' ]] u'\u005cud835' u'\u005cudcaf' )
p193
aV[[ u'\u005cud835' u'\u005cude7e' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1b' u'\u005cud835' u'\u005cudc25' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc26' u'\u005cud835' u'\u005cudc1e' ) ]] u'\u005cud835' u'\u005cudc13' u'\u005cu2282' [[ u'\u005cud835' u'\u005cude82' u'\u005cud835' u'\u005cude84' u'\u005cud835' u'\u005cude71' u'\u005cud835' u'\u005cude79' u'\u005cu2062' ( u'\u005cud835' u'\u005cudc1c' u'\u005cud835' u'\u005cudc1a' u'\u005cud835' u'\u005cudc2e' u'\u005cud835' u'\u005cudc2c' u'\u005cud835' u'\u005cudc1e' ) ]] T u'\u005cu2019'
p194
a.