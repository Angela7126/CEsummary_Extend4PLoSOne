<html>
<head>
<title>P14-2036.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>With the above two distributions, we then add a number of words from news as additional information to microblogs by evaluating the relatedness of between each word and microblog, since words not appearing in the microblog may still be highly relevant</a>
<a name="1">[1]</a> <a href="#1" id=1>Select relevant words from external knowledge to enrich the content of microblogs</a>
<a name="2">[2]</a> <a href="#2" id=2>The word distribution of every microblog is based on topic analysis and its accuracy relies heavily on the accuracy of topic inference in step (b</a>
<a name="3">[3]</a> <a href="#3" id=3>Compared with our method, the topic model based methods mentioned above remain in finding latent space representation of short text and ignore that relevant words from external knowledge are informative as well</a>
<a name="4">[4]</a> <a href="#4" id=4>To enrich the content of every microblog, we select relevant words from external</a>
</body>
</html>