<html>
<head>
<title>P14-1130.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We will directly learn a low-rank tensor A (because r is small) in this form as one of our model parameters</a>
<a name="1">[1]</a> <a href="#1" id=1>When u'\u0393' = 0 , the arc scores are entirely based on the low-rank tensor and u'\u0394' u'\u2062' u'\u0398' = 0</a>
<a name="2">[2]</a> <a href="#2" id=2>In contrast, we expand features for parsing into a multi-way tensor, and operate with an explicit low-rank representation of the associated parameter tensor</a>
<a name="3">[3]</a> <a href="#3" id=3>Based on this feature representation, we define the score of each arc as s u'\u0398' ( h u'\u2192' m ) = u'\u27e8' u'\u0398' , u'\u03a6' h u'\u2192' m u'\u27e9' where u'\u0398' u'\u2208' u'\u211d' L represent adjustable parameters to be learned, and L is the number of parameters (and possible features in u'\u03a6' h u'\u2192' m</a>
<a name="4">[4]</a> <a href="#4" id=4>We should note that since our model parameter A is represented and learned in the low-rank form, we only have to store and maintain the low-rank projections U u'\u2062' u'\u03a6' h , V u'\u2062' u'\u03a6' m and W u'\u2062' u'\u03a6' h , m rather than explicitly calculate the feature tensor u'\u03a6' h u'\u2297' u'\u03a6' m u'\u2297' u'\u03a6' h , m</a>
</body>
</html>