<html>
<head>
<title>P14-1009.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Tensor by vector multiplication formalizes function application and serves as the general composition method</a>
<a name="1">[1]</a> <a href="#1" id=1>Training plf (practical lexical function) proceeds similarly, but we also build preposition matrices (from u'\u27e8' noun , preposition-noun u'\u27e9' vector pairs), and for verbs we prepare separate subject and object matrices</a>
<a name="2">[2]</a> <a href="#2" id=2>The add (additive) model produces the vector of a sentence by summing the vectors of all content words in it</a>
<a name="3">[3]</a> <a href="#3" id=3>If distributional vectors encode certain aspects of word meaning, it is natural to expect that similar aspects of sentence meaning can also receive vector representations, obtained compositionally from word vectors</a>
<a name="4">[4]</a> <a href="#4" id=4>2010 ) generalize the simple additive model by applying structure-encoding operators to the vectors of two sister nodes before addition, thus breaking the inherent symmetry of the simple additive model</a>
<a name="5">[5]</a> <a href="#5" id=5>After applying the matrices to the corresponding argument vectors, a single representation is obtained by summing across all resulting vectors</a>
<a name="6">[6]</a> <a href="#6" id=6>Baroni and Zamparelli ( 2010 ) propose a practical and empirically effective way to estimate matrices representing adjectival modifiers of nouns by linear regression from corpus-extracted examples of noun and adjective-noun vectors</a>
<a name="7">[7]</a> <a href="#7" id=7>We conjecture that the lf 3-way tensor representation of transitive verbs leads to a stronger asymmetry between sentences with inverted arguments, and thus makes this model particularly sensitive to word order differences</a>
<a name="8">[8]</a> <a href="#8" id=8>For instance, symmetric operations like vector addition are insensitive to syntactic structure, therefore meaning differences encoded in word order are lost in composition pandas eat bamboo is identical to bamboo eats pandas</a>
<a name="9">[9]</a> <a href="#9" id=9>To model passive usages, we insert the object matrix</a>
</body>
</html>