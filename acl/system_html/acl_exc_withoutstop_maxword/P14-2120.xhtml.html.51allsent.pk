(lp0
VThe task is to recognize whether the predicate-argument relationship, as expressed in the Hypothesis, holds implicitly also in the Text
p1
aVMore concretely, in textual inference the candidate predicate and argument are typically identified, as they are aligned by the RTE system to a predicate and an argument of the Hypothesis
p2
aVThis section describes a semi-automatic method for extracting candidate instances of implied predicate-argument relationship from an RTE dataset
p3
aVComparing to the implied SRL task, our task may better fit the needs of textual inference
p4
aVThus, the only remaining challenge is to verify that the sought relationship is implied in the text
p5
aVFor example, example 1 in Table 1 includes the explicit relationship u'\u005cu201c' derailment of train u'\u005cu201d' , which might indicate the implied relationship u'\u005cu201c' crash of train u'\u005cu201d'
p6
aVOn the other hand, the results obtained for our task, which does fit textual inference scenarios, are promising, and encourage utilizing algorithms for this task in actual inference systems
p7
aVThen, a human reader annotates each instance as u'\u005cu201c' Yes u'\u005cu201d' u'\u005cu2013' meaning that the implied relationship indeed holds in the Text, or u'\u005cu201c' No u'\u005cu201d' otherwise
p8
aVThe high results show that this task is feasible, and its solutions can be adopted as a component in textual inference systems
p9
aVWhile the results reported so far on that annotation task were relatively low, we suggest that the task itself may be more complicated than what is actually required in textual inference scenarios
p10
aVThe Co-occurring predicate feature estimates the probability that a document would contain a as an argument of p , given that a appears elsewhere in that document as an argument of p u'\u005cu2032' , based on explicit predicate-argument relationships in a large corpus
p11
aVWe ran three configurations for the second feature, where in the first only syntactically expressed relationships are used, in the second all the implied relationships, as detected by a human annotator, are added, and in the third only the implied relationships detected by our algorithm are added
p12
aVAnother case is when an implied predicate-argument relationship holds even though the corresponding role is already filled by another argument, hence not an NI
p13
aVBy applying this method on the RTE-6 dataset [ 1 ] , we constructed a dataset of 4022 instances, where 2271 (56%) are annotated as positive instances, and 1751 as negative ones
p14
aVSince our task and dataset are novel, there is no direct baseline with which we can compare this result
p15
aVTo address this task, we provide a large and freely available annotated dataset, and propose methods for coping with it
p16
aVFirst, some relatively complex steps of the implied SRL task are avoided in our setting, while on the other hand it covers more relevant cases
p17
aVAccordingly, the feature quantifies the probability that a document including the relationship p - a u'\u005cu2032' would also include the relationship p - a
p18
aVThis comparison shows that the contribution of our new features (3%) is meaningful, which is also statistically significant with p 0.01 using Bootstrap Resampling test [ 11 ]
p19
aVAs a reference point we mention the majority class proportion, and also report a configuration in which only features adopted from prior works (G C and S F) are utilized
p20
aVSecond, each NI should be classified as Definite NI (DNI) , meaning that the role filler must exist in the discourse, or Indefinite NI otherwise
p21
aVConsider example 1 of Table 1
p22
aVThese features do not depend on manually built resources, and hence are portable to resource-poor languages
p23
aVThird, the DNI fillers should be found (DNI linking
p24
aVThis is exemplified in example 1 of Table 1 , where p = u'\u005cu201c' renew u'\u005cu201d' , a = u'\u005cu201c' Patriot Act u'\u005cu201d' and a u'\u005cu2032' = u'\u005cu201c' law u'\u005cu201d'
p25
aVTherefore, the sub-tasks of identifying and classifying DNIs can be avoided
p26
aVHence p = u'\u005cu201c' crash u'\u005cu201d' , a = u'\u005cu201c' train u'\u005cu201d' and p u'\u005cu2032' = u'\u005cu201c' derailment u'\u005cu201d'
p27
a.