<html>
<head>
<title>P14-2080.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>LinLearn denotes model combination by overloading the vector representation of queries u'\ud835' u'\udc2a' and documents u'\ud835' u'\udc1d' in the VW linear learner by incorporating arbitrary ranking models as dense features</a>
<a name="1">[1]</a> <a href="#1" id=1>The advantage of this technique is an implicit query expansion effect due to the use of probability distributions over term translations [ 27 ]</a>
<a name="2">[2]</a> <a href="#2" id=2>This approach is advantageous if large amounts of in-domain sentence-parallel data are available to train SMT systems, but relevance rankings to train retrieval models are not</a>
<a name="3">[3]</a> <a href="#3" id=3>We will refer to DT and PSQ as SMT-based models that translate a query, and then perform monolingual retrieval using BM25</a>
<a name="4">[4]</a> <a href="#4" id=4>In addition to dense domain-knowledge features, we incorporate</a>
</body>
</html>