<html>
<head>
<title>P14-1126.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Our approach training on only parallel data without unlabeled data for the target language</a>
<a name="1">[1]</a> <a href="#1" id=1>Our approach training on both parallel and unlabeled data</a>
<a name="2">[2]</a> <a href="#2" id=2>In addition to their original results, we also report results by re-implementing the direct transfer parser based on the first-order projective dependency parsing model [ 30 ] (DTP u'\u2020'</a>
<a name="3">[3]</a> <a href="#3" id=3>However, in our scenario we have no labeled training data for target languages but we have some parallel and unlabeled data plus an English dependency parser</a>
<a name="4">[4]</a> <a href="#4" id=4>We report both the results of the direct transfer and projected transfer parsers directly cited from McDonald et al</a>
<a name="5">[5]</a> <a href="#5" id=5>Central to our approach is a maximizing likelihood learning framework, in which we use an English parser and parallel text to estimate the u'\u201c' transferring distribution u'\u201d' of the target language parsing model</a>
</body>
</html>