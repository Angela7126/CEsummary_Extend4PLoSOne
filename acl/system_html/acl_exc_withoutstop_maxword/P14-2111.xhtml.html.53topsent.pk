(lp0
VWhen run on new strings, the activations of the units in the hidden layer at each position in the string are recorded and used as features for training the string transduction model
p1
aVThe trained SRN language model can be used to generate random text by sampling the next byte from its predictive distribution and extending the string with the result
p2
aVOur string transduction model works by learning the sequence of edits which transform the input string into the output string
p3
aVThe training data for the model is generated by computing shortest edit scripts for pairs of original and normalized strings
p4
aVThis is because it is not obvious what kind of data can be used to estimate the language model there is plentiful text from the source domain, but little of it is in normalized target form
p5
aVWe run the trained model on new tweets and record the activation of the hidden layer at each position as
p6
a.