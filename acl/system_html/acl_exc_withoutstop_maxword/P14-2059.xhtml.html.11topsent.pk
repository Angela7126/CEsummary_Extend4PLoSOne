(lp0
VThis is a standard approach in IR, known as building a test collection [ 13 ] , which the author herself notes was an arduous and time-consuming task
p1
aVSo we define a context-based citation recommendation ( cbcr ) system as one that assists the author of a draft document by suggesting other documents with content that is relevant to a particular context in the draft
p2
aVThis context is extracted in the same way as the query as a window, or list of w tokens surrounding the citation left and right
p3
aVAt present, we are applying no cut-off and just rank all of the document u'\u005cu2019' s collection-internal references for each citation context, aiming to rank the correct one in the first positions in the list
p4
aVWe have then chosen top-1 accuracy as our metric, where every time the original citation is first on the list of suggestions, it receives a score of 1, and 0 otherwise, and these scores are averaged over all resolved citations in the document collection
p5
aVThe external representations ( inlink_context ) are based on extracting the context around citation tokens to the document from other documents in the collection, excluding the set of test papers
p6
aVOne is based on the contents of the document itself, one is based on the existing contexts of citations of this
p7
a.