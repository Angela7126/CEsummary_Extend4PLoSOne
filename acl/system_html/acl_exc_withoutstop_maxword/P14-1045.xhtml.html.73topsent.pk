(lp0
VAs a baseline, we can also consider a simple threshold on the lexical similarity score, in our case Lin u'\u005cu2019' s measure, which we have shown to yield the best F-score of 24% when set at 0.22
p1
aVthe ranks of tokens in other related items neighbours r u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' k a - b is defined as the rank of neighbour a among neighbours of neighbour b u'\u005cu2009' ordered with respect to Lin u'\u005cu2019' s score; r u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' g b - a is defined similarly and again we consider as features the min, max and log-product of these ranks
p2
aVeach neighbour productivity p u'\u005cu2062' r u'\u005cu2062' o u'\u005cu2062' d a and p u'\u005cu2062' r u'\u005cu2062' o u'\u005cu2062' d b are defined as the numbers of neighbours of respectively neighbour a and neighbour b in the database (thus related tokens with a similarity above the threshold), from which we derive three features as for frequencies the min, the max, and the log of the product
p3
aVThus there is no need for a syntactic analysis of the context considered when exploiting the resource, and sparsity is less of an issue 1 1 Whenever two predicates with the same lemma have common neighbours, we average the score of the pairs
p4
aVThis can be considered as a baseline for extraction of relevant lexical pairs, to which we turn in the following section
p5
aVFirst, we take into account the frequencies of items within the text, with three features as before the min of the frequencies of the two related items, the max, and the log-product
p6
aVAn important aspect is thus to guarantee that there is a correlation between the similarity score (Lin u'\u005cu2019' s score here), and the evaluated relevance of the neighbour
p7
a.