(lp0
VTo explore whether language provides signal for future work in fine-grain social role prediction, we constructed a set of experiments, one per role, where training and test sets were balanced between users from a random background sample and self-reported users
p1
aVAs compared to prior research that required actively polling users for ground truth in order to construct predictive models for demographic information [ 11 ] , we demonstrate that some users specify such properties publicly through direct natural language
p2
aVEach training set had a target of 600 users (300 background, 300 self-identified); for those roles with less than 300 users self-identifying, all users were used, with an equal number background
p3
aVWe examined tweets with a first person possessive pattern for each attribute term from a small corpus of tweets collected over a single month in 2013, discarding those attribute terms with no positive matches
p4
aVThe attribute term chart , for example, had high PMI with doctor ; but
p5
a.