(lp0
VIn particular, starting from the constituents on the bottom level (EDUs for intra-sentential parsing and sentence-level discourse trees for multi-sentential parsing), at each step of the tree-building, we greedily merge a pair of adjacent discourse constituents such that the merged constituent has the highest probability as predicted by our structure model
p1
aVFor both intra- and multi-sentential parsing, our bottom-up tree-building process adopts a similar greedy pipeline framework like the HILDA discourse parser (discussed in Section 2.1 ), to guarantee efficiency for large documents
p2
aVTherefore, our model incorporates the strengths of both HILDA and Joty et al u'\u005cu2019' s model, i.e.,, the efficiency of a greedy parsing algorithm, and the ability to incorporate sequential information with CRFs
p3
aVHere we analyze the time complexity of each component in our discourse parser, to quantitatively demonstrate the time efficiency of our model
p4
aVHowever, unlike the structure model, adjacent relation nodes do not share discourse constituents on the first layer
p5
aVFirst, with a greedy bottom-up strategy, we develop a discourse parser with a time complexity linear in the total number of sentences in the document
p6
aVFirst, they decomposed the problem of text-level discourse parsing into two stages intra-sentential parsing to produce a discourse tree for each sentence, followed by multi-sentential parsing to combine the sentence-level discourse trees and produce the text-level discourse tree
p7
aVThe linear-chain CRF contains a first layer of all discourse constituents U j u'\u005cu2019' s in the sentence on
p8
a.