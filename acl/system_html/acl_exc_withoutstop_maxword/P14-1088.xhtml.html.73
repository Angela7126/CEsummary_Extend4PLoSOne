<html>
<head>
<title>P14-1088.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In this article we propose a family of chance-corrected measures of agreement, applicable to both dependency- and constituency-based syntactic annotation, based on Krippendorff u'\u2019' s u'\u0391' and tree edit distance</a>
<a name="1">[1]</a> <a href="#1" id=1>These metrics express agreement on a nominal coding task as the ratio u'\u039a' , u'\u03a0' = A o - A e / 1 - A e where A o is the observed agreement and A e the expected agreement according to some model of u'\u201c' random u'\u201d' annotation</a>
<a name="2">[2]</a> <a href="#2" id=2>Instead, we propose to use an agreement measure based on Krippendorff u'\u2019' s u'\u0391' [] and tree edit distance</a>
<a name="3">[3]</a> <a href="#3" id=3>Next, we present a number of synthetic experiments performed in order to find the best distance function for this kind of annotation; finally we contrast our new metric and simple accuracy scores as applied to real-world corpora before concluding and presenting some potential avenues for future work</a>
<a name="4">[4]</a> <a href="#4" id=4>This use of the metrics would consider agreement on categories such as u'\u201c' tokens whose head is token number 24 u'\u201d' , which is obviously not a linguistically informative category</a>
<a name="5">[5]</a> <a href="#5" id=5>Therefore we will also evaluate our metrics on real-world inter-annotator agreement data sets</a>
<a name="6">[6]</a> <a href="#6" id=6>This is due to a mismatch between the formulation of the agreement measures, which assumes that the annotations have no or relatively little internal structure, and syntactic annotation where structure is the entire point of the annotation</a>
<a name="7">[7]</a> <a href="#7" id=7>The idea of using edit distance as the basis for an inter-annotator agreement metric has previously been explored by \citeN Fournier13</a>
<a name="8">[8]</a> <a href="#8" id=8>LAS order the corpora NDT 3, 2, 1, CDT da, en, it, es, PCEDT, whereas u'\u0391' d u'\u2062' i u'\u2062' f u'\u2062' f and u'\u0391' n u'\u2062' o u'\u2062' r u'\u2062' m gives the order NDT 2, 1, 3, PCEDT, CDT da, en, it, es, and u'\u0391' p u'\u2062' l u'\u2062' a u'\u2062' i u'\u2062' n gives the same order as the other alphas but with CDT es and it changing places</a>
<a name="9">[9]</a> <a href="#9" id=9>Therefore we remove the leaf nodes in the case of phrase structure trees, and in the case of dependency trees we compare trees whose edges are unlabelled and nodes are labelled with the dependency relation between that word and its head; the root node receives the label u'\u0395'</a>
<a name="10">[10]</a> <a href="#10" id=10>The data studied in this work has previously been used by \citeN Skjaerholt13 to study agreement, but using simple accuracy measures (UAS, LAS) rather than chance-corrected measures</a>
<a name="11">[11]</a> <a href="#11" id=11>The u'\u0394' d u'\u2062' i u'\u2062' f u'\u2062'</a>
</body>
</html>