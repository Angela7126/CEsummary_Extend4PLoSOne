(lp0
VThe process of learning to map objects to the their word label is implemented by training a projection function f proj v u'\u005cu2192' w from the visual onto the linguistic semantic space
p1
aVWhen the induced projection function maps an object onto the linguistic space, the derived text vector will inherit a mixture of textual features from the concepts that activated the same hidden unit as the object
p2
aVConcretely, we assume that concepts, denoted for convenience by word labels, are represented in linguistic terms by vectors in a text-based distributional semantic space (see Section 4.3
p3
aVThe zero-shot framework leads us to frame fast mapping as the task of projecting visual representations of new objects onto language space for retrieving their word labels ( v u'\u005cu2192' w
p4
aVWhereas for the latter our system assumes that all concepts have rich linguistic representations (i.e.,, representations estimated from a large corpus), in the case of the former, new concepts are assumed to be encounted in a limited linguistic context and therefore lacking rich linguistic representations
p5
aVMost importantly, by projecting visual representations of objects into a shared semantic space , we do not limit ourselves to establishing a link between objects and words
p6
aVThus, this function, given a visual vector, returns its corresponding linguistic representation
p7
aVThis is achieved by means of a simple neural network trained to project image-extracted feature vectors to text-based vectors through a hidden layer that can be interpreted as a cross-modal semantic space
p8
aVDuring training, this cross-modal vocabulary is used to induce a projection function (Section 4.4 ), which u'\u005cu2013' intuitively u'\u005cu2013' represents a mapping between visual and linguistic dimensions
p9
aVWe show that the induced cross-modal semantic space is powerful enough that sensible guesses about the correct word denoting an object can be made,
p10
a.