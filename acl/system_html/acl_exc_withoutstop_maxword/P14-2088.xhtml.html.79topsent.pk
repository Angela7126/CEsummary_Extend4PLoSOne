(lp0
VThen we present three versions of marginalized denoising autoencoders (mDA) by incorporating different types of noise, including two new noising processes that are designed for structured features
p1
aVFor E u'\u005cu2062' [ u'\u005cud835' u'\u005cudc0f' ] , we obtain a scaled version of the scatter matrix, because in each instance u'\u005cud835' u'\u005cudc31' ~ , there is exactly a 1 / K chance that each individual feature survives dropout
p2
aV1 if both features are chosen as noise features, which happens with probability p 2 u'\u005cu2062' q u'\u005cu0391' u'\u005cu2062' q u'\u005cu0392'
p3
aVWhile the marginalized denoising autoencoder (mDA) is considerably faster than the original denoising autoencoder, it requires solving a system of equations that can grow very large, as realistic NLP tasks can
p4
a.