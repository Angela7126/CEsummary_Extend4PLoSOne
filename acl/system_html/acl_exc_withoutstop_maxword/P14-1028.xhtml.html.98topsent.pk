(lp0
VFurther improvement could be obtained if the bigram embeddings are also pre-trained
p1
aVTensor-based transformation was also used in other neural network models for its ability to capture multiple interactions in data
p2
aVOur study is consistent with this line of research, however, our model explicitly models the interactions between tags and context characters and accordingly captures more semantic information
p3
aVThe simple tag-tag transition neglects the impact of context characters and thus limits the ability to capture flexible interactions between tags and context characters
p4
aVIn order to address this problem, we propose a new model called Max-Margin Tensor Neural Network ( MMTNN ) that explicitly models the interactions between tags and context characters by exploiting tag embeddings and tensor-based transformation
p5
aV[ 1 ] which learns the embeddings based on neural language model
p6
aV[ 15 ] , the bigram embeddings are pre-trained on unlabeled data with character embeddings, which significantly improves
p7
a.