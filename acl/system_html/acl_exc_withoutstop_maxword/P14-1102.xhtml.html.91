<html>
<head>
<title>P14-1102.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Similar to the model presented in this paper, BabySRL is based on simple ordering features such as argument position relative to the verb and argument position relative to the other arguments</a>
<a name="1">[1]</a> <a href="#1" id=1>When imperatives are filtered out of the training corpus, the symmetric model obtains a worse BIC fit than a model that lacks the non-canonical subject Gaussian</a>
<a name="2">[2]</a> <a href="#2" id=2>Since the model in this paper operates over global orderings, it implicitly takes into account the positions of other nouns as it models argument position relative to the verb; object and subject are in competition as labels for preverbal nouns, so a preverbal object is usually only assigned once a subject has already been detected</a>
<a name="3">[3]</a> <a href="#3" id=3>Since the model is not lexicalized, these roles correspond to the semantic roles most commonly associated with subject and object</a>
<a name="4">[4]</a> <a href="#4" id=4>For the intransitive case, however, whereas the model</a>
</body>
</html>