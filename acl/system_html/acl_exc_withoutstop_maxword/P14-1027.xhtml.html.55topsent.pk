(lp0
VSection 4 explains how a learner could use Bayesian model selection to determine that function words appear on the left periphery in English by comparing the posterior probability of the data under our u'\u005cu201c' function word u'\u005cu201d' Adaptor Grammar to that obtained using a grammar which is identical except that rules ( 22 u'\u005cu2013' 24 ) are replaced with the mirror-image rules in which u'\u005cu201c' function words u'\u005cu201d' are attached to the right periphery
p1
aVBy comparing the posterior probability of two models u'\u005cu2014' one in which function words appear at the left edges of phrases, and another in which function words appear at the right edges of phrases u'\u005cu2014' we show that a learner could use Bayesian posterior probabilities to determine that function words appear at the left edges of phrases in English, even though they are not told the locations of word boundaries or which words are function words
p2
aVWe do this by comparing two computational models of word segmentation which differ solely in the way that they model function words
p3
aVIn this section, we show that learners could use Bayesian model selection to determine that function words appear on the left periphery in English by comparing the marginal probability of the data for the left-periphery and the right-periphery models
p4
aVAs section 2 explains in more detail, word segmentation is such a case words are composed of syllables and belong to phrases or collocations, and modelling this structure improves word segmentation accuracy
p5
aVThis suggests that there are acquisition advantages to treating function words specially that human learners could take advantage of (at least to the extent that they are learning similar generalisations as our models), and thus supports the hypothesis that function words are treated specially in human lexical acquisition
p6
aVThus, the present model, initially aimed at segmenting words from continuous speech, shows three interesting characteristics that are also exhibited by human infants it distinguishes between function words and content words [] , it allows learners to acquire at least some of the function words of their language (e.g., [] ); and furthermore, it may also allow them to start grouping together function words according to their category []
p7
aVWe put u'\u005cu201c' function words u'\u005cu201d' in scare quotes below because our model only approximately captures the linguistic properties of function words
p8
aVFor comparison purposes we also include results for a mirror-image model that permits u'\u005cu201c' function words u'\u005cu201d' on the right periphery, a model which permits u'\u005cu201c' function words u'\u005cu201d' on both the left and right periphery (achieved
p9
a.