(lp0
VAs mentioned in Section 3.1, the knowledge learned from the WRRBM can be investigated incrementally, using word representation , which corresponds to initializing only the projection layer of web-feature module with the projection matrix of the learned WRRBM, or ngram-level representation , which corresponds to initializing both the projection and sigmoid layers of the web-feature module by the learned WRRBM
p1
aVThis can be achieved by also initializing the parameters of the second layer of the web-feature module using the position-dependent weight matrix and hidden bias of the learned WRRBM
p2
aVThis can be achieved by initializing only the first layer of the web module with the projection matrix u'\u005cud835' u'\u005cudc03' of the learned WRRBM
p3
aVThis may partly be due to the fact that unlike computer vision tasks, the input structure of POS tagging or other sequential labelling tasks is relatively simple, and a single non-linear layer is enough to model the interactions within the input [ 27
p4
a.