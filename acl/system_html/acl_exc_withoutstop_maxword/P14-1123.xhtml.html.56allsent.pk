(lp0
VThe effect of the measure of syntactic complexity is best studied by including it in an automatic scoring model of overall proficiency
p1
aVSubsequently, the feature extraction stage (a VSM or a MaxEnt model as the case may be) generates the syntactic complexity feature which is then incorporated in a multiple linear regression model to generate a score
p2
aVA criterion for evaluating the performance of the scoring model is the extent to which the automatic scores of overall proficiency agree with the human scores
p3
aVWe consider a multiple regression automatic scoring model as studied in Zechner et al
p4
aVAccordingly, we will summarize the previously studied model, outline its limitations, show how our proposed measure addresses those limitations and compare the two measures for the task of automatic scoring of speech
p5
aVBased on this idea, Yoon and Bhat ( 2012 ) developed a set of features of syntactic complexity based on POS sequences extracted from a large corpus of ESL learners u'\u005cu2019' spoken responses, grouped by human-assigned scores of proficiency level
p6
aVThus, the inclusion of the MaxEnt-based measure of syntactic complexity results in improved agreement between machine and human scores compared to the state-of-the-art model (here, Base
p7
aVSeeking to study the robustness of the measures derived using a shallow analysis, we next compare the two measures studied here, with respect to the impact of speech recognition errors on their correlation with scores of syntactic complexity
p8
aVHowever, due to substantial amount of speech recognition errors in our data, the POS error rate (resulting from the combined errors of ASR and automated POS tagger) is expected to be higher
p9
aVThe result is a new measure based on POS bigrams to assess ESL learners u'\u005cu2019' mastery of syntactic complexity
p10
aVTaking an approach different from previous studies, we formulate the task of assigning a score of syntactic complexity to a spoken response as a classification problem given a spoken response, assign the response to a proficiency class
p11
aVThe first stage, ASR, yields an automatic transcription, which is followed by the POS tagging stage
p12
aVThe syntactic complexity of a test spoken response was estimated based on its similarity to the proficiency groups in the reference corpus with respect to the score-specific constructions
p13
aVA distinguishing feature of the current study is that the measure is based on a comparison of characteristics of the test response to models trained on large amounts of data from each score point, as opposed to measures that are simply characteristics of the responses themselves (which is how measures have been considered in prior studies
p14
aVA measure u'\u005cu2019' s utility has been evaluated according to its ability to discriminate between levels of proficiency assigned by human raters
p15
aVIn our case, however, with only access to the overall proficiency scores, we use scores of language proficiency as those of grammatical skill
p16
aVThese high error rates at the recognition stage negatively affect the subsequent stages of the speech scoring system in general, and in particular, during a deep syntactic analysis, which operates on a long sequence of words as its context
p17
aVTherefore, a MaxEnt model has an advantage over the model described in 4.1 in that it uses four different weight schemes (one per score level) and each scheme is optimized for each score level
p18
aVIn order to avoid the problems encountered with deep analysis-based measures, Yoon and Bhat ( 2012 ) explored a shallow analysis-based approach, based on the assumption that the level of grammar sophistication at each proficiency level is reflected in the distribution of part-of-speech (POS) tag bigrams
p19
aVInformed by studies in second language acquisition and language testing that regard these factors as key determiners of spoken language proficiency, some researchers have focused on the objective measurement of these aspects of spoken language in the context of automatic assessment of language ability
p20
aVThis permits us to better represent the score assigned by the MaxEnt classifier as a relative preference over score assignments
p21
aVSince a preliminary analysis of the effect of varying the feature (binary or frequency) revealed that the binary-valued feature was optimal (in terms of yielding the best agreement between human and machine scores), we only report our results for this case
p22
aVChen and Zechner ( 2011 ) found that while using measures of syntactic complexity obtained from transcriptions, errors in ASR transcripts caused over 0.40 drop in correlation from that found with manual transcriptions 5 5 Due to differences in the dataset and ASR system, a direct comparison between the current study and the cited prior study was not possible
p23
aVAutomatic recognition of non-native speakers u'\u005cu2019' spontaneous speech is a challenging task as evidenced by the error rate of the state-of-the-art speech recognizer
p24
aVThe idea that the level of syntactic complexity (in terms of its range and sophistication) can be assessed based on the distribution of POS-tags is informed by prior studies in second language acquisition
p25
aVAs a result, measures of grammatical complexity that are closely tied to a correct syntactic analysis are rendered unreliable
p26
aVWe mentioned that the measure proposed in this study is derived from assumptions similar to those studied in [ 37 ]
p27
aVAs in prior studies, here too the level of agreement is evaluated by means of the weighted kappa measure as well as unrounded and rounded Pearson u'\u005cu2019' s correlations between machine and human scores (since the output of the regression model can either be rounded or regarded as is
p28
aVTo illustrate this, consider a scenario where the classifier assigns two responses A and B to score level 2 (based on the maximum a posteriori condition
p29
aVAlthough the skewed distribution limits the number of score-specific instances for the highest and lowest scores available for model training, we used the data without modifying the distribution since it is representative of responses in a large-scale language assessment scenario
p30
aVThe second limitation, related to the ineffective weighting of terms via the the t u'\u005cu2062' f - i u'\u005cu2062' d u'\u005cu2062' f scheme, seems to be addressed by the fact that the MaxEnt model assigns a weight to each feature (in our case, POS bigrams) on a per-class basis (in our case, score group), by taking every instance into consideration
p31
aVInstead of focusing on grammatical errors that are found to be highly representative of language proficiency, our interest is in capturing the range of forms that surface in language production and the degree of sophistication of such forms, collectively referred to as syntactic complexity in [ 24 ]
p32
aVGrammatical expressions that occur frequently in one score level but rarely in other levels can be assumed to be characteristic of a specific score level
p33
aVAs seen in Table 1 , there is a strong bias towards the middle scores (score 2 and 3) with approximately 84-85% of the responses belonging to these two score levels
p34
aVWe first analyze the limitations of the model studied in [ 37 ] and then describe how our model can address those limitations
p35
aVThe results that follow are based on MaxEnt classifier u'\u005cu2019' s parameter settings initialized to zero
p36
aVWe thus capture the classifier u'\u005cu2019' s finer-grained scoring tendency by calculating the expected value of the classifier output
p37
aVThe choice and design of objective measures of language proficiency is governed by two crucial constraints
p38
aVThis is done by considering the Pearson correlation coefficient between the feature and the human scores
p39
aVFor instance, Chen and Zechner ( 2011 ) reported a 50.5% word error rate (WER) and Yoon and Bhat ( 2012 ) reported a 30% WER in the recognition of ESL students u'\u005cu2019' spoken responses
p40
aVThe assumption that a presence-based view of grammatical level acquisition is also applicable to second language assessment helps validate our observation that binary-valued features yield a better performance when compared with frequency-valued features
p41
aVThe distribution of proficiency scores, along with other details of the data sets, are presented in Table 1
p42
aVThis is done by resorting to a maximum entropy model based approach, to which we turn next
p43
aVOf these, c u'\u005cu2062' o u'\u005cu2062' s 4 was selected based on its empirical performance (it showed the strongest correlation with human-assigned scores of proficiency among the distance-based measures
p44
aVLooking ahead, an important question is the extent to which our measure is sensitive to a mismatch between training and test data
p45
aVThen, regarding POS bigrams as terms, they construct POS-based vector space models for each score-class (there are four score classes denoting levels of proficiency as will be explained in Section 5.2 ), thus yielding four score-specific vector-space models (VSMs
p46
aVTherefore, the more uneven the distribution of a grammatical expression across score classes, the more important that grammatical expression should be as an indicator of a particular score class
p47
aVAs seen in Table 3 , using the proposed measure, m u'\u005cu2062' e u'\u005cu2062' s u'\u005cu2062' c u'\u005cu2062' o u'\u005cu2062' r u'\u005cu2062' e , leads to an improved agreement between human and machine scores of proficiency
p48
aVIt is apparent that the classifier has an overall tendency to assign a higher score to B, but looking at its top preference alone (2 for both responses), masks this tendency
p49
aVFirst, the VSM-based method is likely to over-estimate the contribution of the POS bigrams when highly correlated bigrams occur as terms in the VSM
p50
aVThe D-Level Scale categorizes grammatical development into 8 levels according to the presence of a set of diverse grammatical expressions varying in difficulty (for example, level 0 consists of simple sentences, while level 5 consists of sentences joined by a subordinating conjunction
p51
aVA pattern that occurs rarely but uniformly across different score groups can get the same weight as a pattern which is unevenly distributed to one score group
p52
aVIn the domain of native language acquisition, the presence or absence of a grammatical structure indicates grammatical development
p53
aVSpeaking in a non-native language requires diverse abilities, including fluency, pronunciation, intonation, grammar, vocabulary, and discourse
p54
aVSimilarly, Scarborough ( 1990 ) proposed the Index of Productive Syntax (IPSyn), according to which, the presence of particular grammatical structures, from a list of 60 structures (ranging from simple ones such as including only subjects and verbs, to more complex constructions such as conjoined sentences) is evidence of language acquisition milestones
p55
aVThe performance gain of Base+cos4 over Base , however, is not statistically significant at level = 0.01
p56
aVDespite the functional differences between the indices, there is a fundamental operational similarity - that they both use the presence or absence of grammatical structures, rather than their occurrence count, as evidence of acquisition of certain grammatical levels
p57
aVConsider the presence of a grammar pattern represented by more than one POS bigram
p58
aVTest takers read and/or listened to stimulus materials and then responded to questions based on the stimuli
p59
aVHence we will refer to this approach as u'\u005cu2018' shallow analysis u'\u005cu2019'
p60
aVThey treat the concatenated collection of responses from a particular score-class as a u'\u005cu2018' super u'\u005cu2019' document
p61
aVThe terms of the VSM are weighted by the term frequency-inverse document frequency ( t u'\u005cu2062' f - i u'\u005cu2062' d u'\u005cu2062' f ) weighting scheme [ 29 ]
p62
aVWhen using t u'\u005cu2062' f - i u'\u005cu2062' d u'\u005cu2062' f weighting to extract words that were strongly associated with positive sentiment in a movie review corpus (they considered each review as a document and a word as a term), it was found that a substantial proportion of words with the highest t u'\u005cu2062' f - i u'\u005cu2062' d u'\u005cu2062' f were rare words (e.g.,, proper nouns) which were not directly associated with the sentiment
p63
a.