(lp0
VFinally, we compare against Structural Correspondence Learning ( SCL ; Blitzer et al., 2006) , another feature learning algorithm
p1
aVAs we will show, substantial efficiency improvements can be obtained by designing domain adaptation methods for learning in structured feature spaces
p2
aVChen et al
p3
aVChen et al
p4
aV1) feature scrambling , which randomly chooses a feature template and randomly selects an alternative value within the template, and (2) structured dropout , which randomly eliminates all but a single feature template
p5
aVTo solve this problem, Chen et al
p6
aVWe show how it is possible to marginalize over both types of noise, and find that the solution for structured dropout is substantially simpler and more efficient than the mDA approach of
p7
a.