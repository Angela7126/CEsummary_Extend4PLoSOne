(lp0
VTo incorporate topic representations as translation knowledge into SMT, our neural network based approach directly optimizes similarities between the source language and target language in a compact topic space
p1
aVThen, in the fine-tuning phase (Section 3.2), our model directly optimizes the similarity of two low-dimensional representations, so that it highly correlates to SMT decoding
p2
aVWe directly optimized bilingual topic similarity in the deep learning framework with the help of sentence-level parallel data, so that the learned representation could be easily used in SMT decoding procedure
p3
aVIrrelevant documents bring so many unrelated topic words hence degrade neural network learning performance
p4
aVBy measuring the similarity between the source texts and bilingual translation rules, the SMT decoder is able to encourage topic relevant translation candidates and penalize topic irrelevant candidates
p5
aVAs more documents are retrieved, less relevant information is also used to train the neural networks
p6
aVSince the vectors from DAE are trained using information from monolingual training data independently, these vectors may be inadequate to measure bilingual topic similarity due to their different topic spaces
p7
aVThe similarity scores are integrated into the standard log-linear model for making translation decisions
p8
aVThe results confirm that topic information is indispensable for SMT since both [ 34 ] and our neural network based method significantly outperforms the baseline system
p9
aVIn
p10
a.