(lp0
VThe answer to the question can thus be derived by finding the relation u'\u005cu2013' entity triple r u'\u005cu2062' ( e 1 , e 2 ) in the KB and returning the entity not mentioned in the question
p1
aV2013 ) , we train two semantic similarity models one links a mention from the question to an entity in the KB and the other maps a relation pattern to a relation
p2
aVBy using a general semantic similarity model to match patterns and relations, as well as mentions and entities, our system outperforms the existing rule learning system, Paralex [ 7 ] , with higher precision at all the recall points when answering the questions in the same test set
p3
aVAn example of a single-relation question is u'\u005cu201c' When were DVD players invented u'\u005cu201d' The entity is dvd-player and the relation is be-invent-in
p4
aVIf an exact match was found, then the pattern would be derived by replacing the mention in the question with the special symbol
p5
aVTo train our two CNN semantic models, we derived two parallel corpora based on the Paralex training data
p6
aVThe semantic relevance score between a pattern Q and a relation R is defined as the cosine
p7
a.