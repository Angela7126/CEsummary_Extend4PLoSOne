(lp0
VIn other words, for each word type or phrase type that occurs as a fragment in the training set, and which does not map to just a single translation, a classifier is trained
p1
aVThird, we observe that adding the language model to our classifier leads to another significant gain (configuration l1r1 + LM in the results in Table 2
p2
aVAs expected, the LM baseline substantially outperforms the context-insensitive MLF baseline
p3
aVWe see that the language model baseline for English u'\u005cu2192' French shows the same substantial improvement over the baseline as our English u'\u005cu2192' Spanish results
p4
aVWords or phrases that always map to a single translation are stored in a simple mapping table, as a classifier would have no added value in such cases
p5
aVPer classifier expert, the best scoring configuration was selected, referred to as the auto configuration in Table 2
p6
aVThe language model is a trigram-based back-off language model with Kneser-Ney smoothing, computed using SRILM [] and trained on the same training data as the translation model
p7
aVNumerous classifiers are trained and each is an expert in translating a single word or phrase
p8
aVA second baseline was constructed by weighing the probabilities from the translation table directly with the L2 language model described earlier
p9
aVThe auto configuration improves results over the uniformly applied feature selection
p10
aVThe main research question in this research is how to disambiguate an L1 word or phrase to its L2 translation based on an L2 context, and whether such cross-lingual contextual approaches provide added value compared to baseline models that are not context informed or compared to standard language models
p11
aVAutomatic configuration selection was done by performing leave-one-out testing (for small number of instances) or 10-fold-cross validation (for larger number of instances, n u'\u005cu2265' 20 ) on the training data per classifier expert
p12
aVIf not, we check for the presence of a classifier expert for the offered L1 fragment; only then we can proceed by extracting the desired number of L2 local context words to the immediate left and right of this fragment and adding those to the feature vector
p13
aVWe therefore conducted a number of experiments with other language pairs, and present the abridged results in Table 6
p14
aVPreparing the data to build training and test data for our intended translation assistance system is not trivial, as the type of interactive translation assistant we aim to develop does not exist yet
p15
aVHowever, if we enable the language model as we do in the auto + LM configuration we do not notice an improvement over l1r1 + LM , surprisingly
p16
aVIn order to draw accurate conclusions, experiments on a single data set and language pair are not sufficient
p17
aVThe word accuracy for the entire set is then computed by taking the sum of the word accuracies per sentence pair, divided by the total number of sentence pairs
p18
aVThe choice for this algorithm is motivated by the fact that it handles multiple classes with ease, but first and foremost because it has been successfully employed for word sense disambiguation in other studies [] , in particular in cross-lingual word sense disambiguation, a task closely resembling our current task []
p19
aVAmong the classifier experts are only words and phrases that are ambiguous and may thus map to multiple translations
p20
aVThis intuitively makes sense; a context of one may seem to be better than any other when uniformly applied to all classifier experts, but it may well be that certain classifiers benefit from different feature selections
p21
aVThis baseline, henceforth referred to as the u'\u005cu2019' most likely fragment u'\u005cu2019' baseline (MLF) is analogous to the u'\u005cu2019' most frequent sense u'\u005cu2019' -baseline common in evaluating WSD systems
p22
aVThe baseline selects the most probable L1 fragment per L2 fragment according to the phrase-translation table
p23
aVWhen presented with test data, in which the L1 fragment is explicitly marked, we first check whether there is ambiguity for this L1 fragment and if a direct translation is available in our simple mapping table
p24
aVThe fact that a phrase-translation table needs to be constructed for the test data is also the reason that the parallel corpus split from which the test data is derived has to be large enough, ensuring better quality
p25
aVThis ensures complete independence of training and test data
p26
aVA context size of one prevails in the vast majority of cases, which is not surprising considering the good results we have already seen with this configuration
p27
aVThis number is much larger than the 200 , 000 we mentioned before because single sentence pairs may be reused multiple times with different marked fragments
p28
aVThe classifiers use the IB1 algorithm [] as implemented in TiMBL []
p29
aVConclusions with regard to context width may have to be tempered somewhat, as the performance of the l1r1 configuration was found to not be significantly better than that of the l2r2 configuration
p30
aVIt invokes GIZA++ [] to establish statistical word alignments based on the IBM Models and subsequently extracts phrases using the grow-diag-final algorithm []
p31
aVWe do so by normalising the class probability from the classifier ( s u'\u005cu2062' c u'\u005cu2062' o u'\u005cu2062' r u'\u005cu2062' e T u'\u005cu2062' ( H ) ), which is our translation model, and the language model ( s u'\u005cu2062' c u'\u005cu2062' o u'\u005cu2062' r u'\u005cu2062' e l u'\u005cu2062' m u'\u005cu2062' ( H ) ), in such a way that the highest classifier score for the alternatives under consideration is always 1.0 , and the highest language model score of the sentence is always 1.0
p32
aVOur full system, including the scripts for data preparation, training, and evaluation, is implemented in Python and freely available as open-source from http://github.com/proycon/colibrita/
p33
aVThis implies that such words and phrases must have occurred at least twice in the corpus, though this threshold is made configurable and could have been set higher to limit the number of classifiers
p34
aVWe first measure absolute accuracy by simply counting all output fragments that exactly match the reference fragments, as a fraction of the total amount of fragments
p35
aVThis measure may be too strict, so we add a more flexible word accuracy measure which takes into account partial matches at the word level
p36
aVThe same holds for the Chinese u'\u005cu2192' English experiment
p37
aVThis is due to the nature of the unsupervised method with which the phrase-translation table is constructed
p38
aVIn all of the aforementioned experiments, the system produced a single solution for each of the fragments, the one it deemed best, or no solution at all if it could not find any
p39
aVIn all of our experiments recall is high (well above 90 u'\u005cu2062' % ), mostly because train and test data lie in the same domain and have been generated in the same fashion, lower recall is expected with more real-world data
p40
aVThe experiments however showed that inclusion of such keywords did not make any noticeable impact on any of the results, so we restrict ourselves to mentioning this negative result
p41
aVStep 4 is effectively a filter two thresholds can be configured to discard weak alignments, i.e., those with low probabilities, from the phrase-translation table so that only strong couplings make it into the generated set
p42
aVAn ideal test corpus would consist of L2 sentences with L1 fallback as crafted by L2 language learners with an L1 background
p43
aVIf so, we are done quickly and need not rely on context information
p44
aVNo additional external data was brought in, to keep the comparison fair
p45
aV1 1 http://ilk.uvt.nl/timbl IB1 implements k -nearest neighbour classification
p46
aVIf output o is a subset of reference r then a score of o r is assigned for that sentence pair
p47
aVThe error rate metrics show improvement as well
p48
aVThis metric thus effectively prunes weaker alternative translations in the phrase-translation table from being considered if there is a much stronger candidate
p49
aVA second parameter u'\u005cu039b' 2 further limits the considered phrase pairs ( f s , f t ) to have the product of their conditional probabilities not not deviate more than a fraction u'\u005cu039b' 2 from the joint probability for the strongest possible pairing for f s , the source fragment f s u'\u005cu2062' t u'\u005cu2062' r u'\u005cu2062' o u'\u005cu2062' n u'\u005cu2062' g u'\u005cu2062' e u'\u005cu2062' s u'\u005cu2062' t u'\u005cu2062' _ u'\u005cu2062' t in Figure 1 corresponds to the best scoring translation for a given source fragment f s
p50
aVNevertheless, it has to be noted that even with u'\u005cu039b' 1 and u'\u005cu039b' 2 , the test set will include a certain amount of errors
p51
aVIn earlier work , we reported a decrease in performance due to overfitting when this is done, so we do not expect it to make a positive impact
p52
aVWhilst other thresholds may possibly produce cleaner sets, this is hard to evaluate as finding optimal values causes a prohibitive increase in complexity of the search space, and again this is not necessary to test our hypothesis
p53
aVWe therefore attach low importance to this deviation in BLEU here
p54
aVThe parameter u'\u005cu039b' 1 adds a constraint based on the product of the two conditional probabilities ( P ( f t f s ) u'\u005cu22c5' P ( f s f t ) ) , and sets a threshold that has to be surpassed
p55
aVOutput a pair ( s u'\u005cu2062' e u'\u005cu2062' n u'\u005cu2062' t u'\u005cu2062' e u'\u005cu2062' n u'\u005cu2062' c u'\u005cu2062' e t u'\u005cu2032' , s u'\u005cu2062' e u'\u005cu2062' n u'\u005cu2062' t u'\u005cu2062' e u'\u005cu2062' n u'\u005cu2062' c u'\u005cu2062' e t ) where s u'\u005cu2062' e u'\u005cu2062' n u'\u005cu2062' t u'\u005cu2062' e u'\u005cu2062' n u'\u005cu2062' c u'\u005cu2062' e t u'\u005cu2032' is a copy of t but with fragment f t substituted by f s , i.e., the introduction of an L1 word or phrase in an L2 sentence
p56
aVInput (L1=French,L2=English u'\u005cu201c' I rentre à la maison because I am tired u'\u005cu201d' Desired output u'\u005cu201c' I return home because I am tired u'\u005cu201d'
p57
aVWe therefore proceed with this line of investigation as well
p58
aVIf instead, r is a subset of o , then a score of r o will be assigned
p59
aVThis shall be further discussed in Section 6.1
p60
aVHowever, such corpora do not exist as yet
p61
aVVersion tag v0.2.1 is representative for the version used in this research
p62
aVThe proposed application allows code switching and produces context-sensitive suggestions as writing progresses
p63
a.