(lp0
VIn this way, our model is able to capture a wide range of information including the auxiliary features without having uncontrolled feature explosion, while still having the full accessibility to the manually engineered features that are proven useful
p1
aVThese feature selection methods are particularly promising in parsing scenarios where the optimal feature set is likely to be a small subset of the original set of candidate features
p2
aVOur parameters are divided into a sparse set corresponding to manually chosen MST or Turbo parser features and a larger set governed by a low-rank tensor
p3
aVOur parsing model aims to combine the strengths of both traditional features from the MST/Turbo parser as well as the new low-rank tensor features
p4
aVIndeed, in the full English training set of CoNLL-2008, the tensor involves around 8 × 10 11 entries while the MST feature vector has approximately 1.5 × 10 7 features
p5
aVBased on this feature representation, we define the score of each arc as s u'\u005cu0398' ( h u'\u005cu2192' m ) = u'\u005cu27e8' u'\u005cu0398' , u'\u005cu03a6' h u'\u005cu2192' m u'\u005cu27e9' where u'\u005cu0398' u'\u005cu2208' u'\u005cu211d'
p6
a.