(lp0
VTo demonstrate the benefit of situational information, we develop the Topic-Lexical-Distributional (TLD) model, which extends the LD model by assuming that words appear in situations analogous to documents in a topic model
p1
aVThis is the baseline IGMM model, which clusters vowel tokens using bottom-up distributional information only; the LD model adds top-down information by assigning categories in the lexicon, rather than on the token level
p2
aVSince our model is not a model of the learning process, we do not compare the infant learning process to the learning algorithm.) We evaluate both the inferred phonetic categories and words using the clustering evaluation measure V-Measure (VM; 36
p3
aVLexical information helps with phonetic categorization because it can disambiguate highly overlapping categories, such as the ae and eh categories in Figure 1
p4
aVThe TLD model retains the IGMM vowel phone component, but extends the lexicon of the LD model by adding topic-specific lexicons, which capture the notion that lexeme probabilities are topic-dependent
p5
aVAgain performance decreases as the consonant categories become coarser, but the additional semantic information in the TLD model compensates for the lack of consonant information
p6
aVIn this paper we explore the potential contribution of semantic information to phonetic learning by formalizing a model in which learners attend to the word-level context in which phones appear (as in the lexical-phonetic learning model of 11 ) and also to the situations in which word-forms are used
p7
aVWe compare all three models u'\u005cu2014' TLD, LD, and IGMM u'\u005cu2014' on the vowel categorization task, and TLD and LD on the lexical categorization task (since IGMM does not infer a lexicon
p8
aVHowever, due to a widespread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see 42 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information ( 8 ; 9 ; 11 ; 26 ; 50 )
p9
aV11 ) , we show a
p10
a.