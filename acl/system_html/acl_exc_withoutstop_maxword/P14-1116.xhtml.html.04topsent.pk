(lp0
VPrevious methods for content selection include Reinforcement Learning [] ; multi-objective optimisation [] ; Gricean Maxims [] ; Integer Linear Programming [] ; collective content selection [] ; interest scores assigned to content [] ; a combination of statistical and template-based approaches to NLG [] ; statistical acquisition of rules [] and the Hidden Markov model approach for Content Selection and ordering []
p1
aVNatural Language Generation from time-series data has been investigated for various tasks such as weather forecast generation [] , report generation from clinical data [] , narrative to assist children with communication needs [] and audiovisual debrief generation from sensor data from Autonomous Underwater Vehicles missions []
p2
aVOur contributions to the field are as follows we present a novel and efficient method for tackling the challenge of content selection using a ML classification approach; we applied this method to the domain of feedback summarisation; we present a comparison with an optimisation technique (Reinforcement Learning), and we discuss the similarities and differences between the two methods
p3
aVSecondly, for Decision Tree (with predicted history) , 29 classifiers were also trained, but this time the input included the previous decisions made by the previous classifiers (i.e., the history) as well as the set of time-series data in order to emulate the dependencies in the dataset
p4
aVThe reward function reflects the lecturers u'\u005cu2019' preferences on summaries and is derived through linear regression analysis of a dataset containing lecturer constructed summaries and ratings of randomly generated summaries
p5
aVFinally, our domain for feedback generation is motivated by previous studies [] who show that text summaries are more effective in decision making than graphs therefore it is advantageous to provide a summary over showing users the raw data graphically
p6
a.