<html>
<head>
<title>P14-2008.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We are interested in domain adaptation for citation classification and therefore need a target dataset of citations and a non-citation source dataset</a>
<a name="1">[1]</a> <a href="#1" id=1>We treat citation polarity classification as a sentiment analysis domain adaptation task and therefore must be careful not to define features that are too domain specific</a>
<a name="2">[2]</a> <a href="#2" id=2>These experiments should help answer two questions does a larger amount of training data, even if out of domain, improve citation classification; and how well do the different product domains generalize to citations (i.e.,, which domains are most similar to citations</a>
<a name="3">[3]</a> <a href="#3" id=3>Our initial results show that using mSDA for domain adaptation to citations actually outperforms in-domain classification</a>
<a name="4">[4]</a> <a href="#4" id=4>In our second set of experiments, we follow the domain adaptation approaches described in [ 12 ] and train on product review and citation data before testing on citations</a>
<a name="5">[5]</a> <a href="#5" id=5>Using a larger training set, along with mSDA, which makes use of the unlabeled data, leads to the best results for citation classification</a>
<a name="6">[6]</a> <a href="#6" id=6>We</a>
</body>
</html>