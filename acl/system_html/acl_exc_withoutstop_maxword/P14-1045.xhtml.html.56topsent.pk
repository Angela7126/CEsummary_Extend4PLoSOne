(lp0
VThe outcome of the contextual annotation presented above is a rather sizeable dataset of validated semantic links, and we showed these linguistic judgments to be reliable
p1
aVThey can be divided in three groups, according to their origin they are computed from the whole corpus, gathered from the distributional resource, or extracted from the considered text which contains the semantic pair to be evaluated
p2
aVThe method we propose here has been designed as an intrinsic evaluation with a view to validate semantic proximity links in a broad perspective, to cover what [] call u'\u005cu201c' non classical lexical semantic relations u'\u005cu201d'
p3
aVFinally, we took into account the network of related lexical items, by considering the largest sets of words present in the text and connected in the database (self-connected components), by adding the following features
p4
aVSmote synthetizes and adds new instances similar to the minority class instances and is more efficient than a mere resampling
p5
aVOne advantage of distributional similarities is to exhibit a lot of different semantic relations, not necessarily standard lexical relations
p6
aVWe differ from all these evaluation procedures as we do not focus on an essential view of the relatedness of two lexical items, but evaluate the link in a context where the relevance of the link is in question, an u'\u005cu201c' existential u'\u005cu201d' view of semantic relatedness
p7
aVFor cost-aware learning, a sensible choice is to invert the class ratio for the cost ratio, i.e., here the cost of a mistake on a relevant link (false negative) is exactly 8.5 times higher than the cost on a non-relevant link (false positive), as non-relevant instances are 8.5 times more present than relevant ones
p8
aVWe have seen that the relevant/not relevant classification is very imbalanced, biased towards the u'\u005cu201c' not relevant u'\u005cu201d' category (about 11%/89%),
p9
a.