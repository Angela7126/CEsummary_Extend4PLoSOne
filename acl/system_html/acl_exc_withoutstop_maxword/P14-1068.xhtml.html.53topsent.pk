(lp0
VTable 3 shows examples of word pairs with highest semantic and visual similarity according to the SAE model
p1
aVAs shown in Figure 1 , our model takes as input two (real-valued) vectors representing the visual and textual modalities
p2
aVAs our input consists of natural language attributes, the model would infer textual attributes given visual attributes and vice versa
p3
aVThe third row in the table presents three variants of our model trained on textual and visual attributes only (T and V, respectively) and on both modalities jointly (T+V
p4
aVThe automatically obtained textual and visual attribute vectors serve as input to SVD, kCCA, and our stacked autoencoder (SAE
p5
aVUnlike most previous work, our model is defined at a finer level of granularity u'\u005cu2014' it computes meaning representations for individual words and is unique in its use of attributes as a means of representing the textual and visual modalities
p6
aVAs baselines, we also report the performance of a model based solely on textual attributes (which we obtain from Strudel), visual attributes (obtained from
p7
a.