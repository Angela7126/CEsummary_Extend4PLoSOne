(lp0
VWe generate two features based on the lexicons total number of positive words or negative words found in each tweet
p1
aVThe first row shows the performance of the universal sentiment model as a baseline
p2
aVWith the topic information inferred from Twitter data, the F score is 2 points higher than the baseline without semi-supervised training and 1.4 higher than the baseline with semi-supervised data
p3
aVOnce we identify the topics for tweets in the training data, we can split the data into multiple subsets based on topic distributions
p4
aVSimilar to the universal model, we train T topic-specific sentiment models with LibSVM
p5
aVAs shown in the third column
p6
a.