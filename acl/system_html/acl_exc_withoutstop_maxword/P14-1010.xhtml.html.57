<html>
<head>
<title>P14-1010.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Work on target language morphological segmentation for SMT can be divided into three subproblems segmentation, desegmentation and integration</a>
<a name="1">[1]</a> <a href="#1" id=1>We approach this problem by augmenting an SMT system built over target segments with features that reflect the desegmented target words</a>
<a name="2">[2]</a> <a href="#2" id=2>Nonetheless, the 1000-best and lattice desegmenters both produce significant improvements over the 1-best desegmentation baseline, with Lattice Deseg achieving a 1-point improvement in TER</a>
<a name="3">[3]</a> <a href="#3" id=3>Most techniques approach the problem by transforming the target language in some manner before training the translation model</a>
<a name="4">[4]</a> <a href="#4" id=4>We also tried a similar Morfessor-based segmentation for Arabic, which has an unsegmented test set BLEU of 32.7</a>
<a name="5">[5]</a> <a href="#5" id=5>As in Finnish, the 1-best desegmentation using Morfessor did not surpass the unsegmented baseline, producing a test BLEU of only 31.4 (not shown in Table 1</a>
<a name="6">[6]</a> <a href="#6" id=6>We compose this acceptor with a desegmenting transducer, and then with an unsegmented LM acceptor, producing a fully annotated, desegmented lattice</a>
<a name="7">[7]</a> <a href="#7" id=7>Our goal is to desegment the decoder u'\u2019' s output lattice, and in doing so, gain access to a compact, desegmented view of a large portion of the translation search space</a>
<a name="8">[8]</a> <a href="#8" id=8>In this section, we describe our various strategies for desegmenting the</a>
</body>
</html>