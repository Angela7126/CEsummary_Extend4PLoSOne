<html>
<head>
<title>P14-2050.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Neural word embeddings are often considered opaque and uninterpretable, unlike sparse vector space representations in which each dimension corresponds to a particular known context, or LDA models where dimensions correspond to latent topics</a>
<a name="1">[1]</a> <a href="#1" id=1>In the future, we hope that insights from such model introspection will allow us to develop better contexts, by focusing on conjunctions and prepositions for example, or by trying to figure out why the subject and object relations are absent and finding ways of increasing their contributions</a>
<a name="2">[2]</a> <a href="#2" id=2>Since word2vec removes the subsampled words from the corpus before creating the window contexts, this option effectively increases the window size, resulting in greater topicality</a>
<a name="3">[3]</a> <a href="#3" id=3>The default approach of representing words as discrete and distinct symbols is insufficient for many tasks, and suffers from poor generalization</a>
<a name="4">[4]</a> <a href="#4" id=4>The next two examples</a>
</body>
</html>