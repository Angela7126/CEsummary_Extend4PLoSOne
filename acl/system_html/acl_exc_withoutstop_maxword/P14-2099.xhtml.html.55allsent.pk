(lp0
VWe therefore crowdsourced the privacy policy document collection using Amazon Mechanical Turk
p1
aVPrivacy policy documents are verbose, often esoteric legal documents that many people encounter as clients of companies that provide services on the web
p2
aVDeveloping a gold-standard alignment of privacy policies would either require an interface that allows each annotator to interact with the entire corpus of previously aligned documents while reading the one she is annotating, or the definition (and likely iterative refinement) of a set of categories for manually labeling policy sections
p3
aVThough our model (particularly the restricted variants) treats the problem as one of alignment , our evaluations consider groupings of policy sections
p4
aVIn the human QA evaluation, this is mostly due to recall improvements (i.e.,, more pairs of sections relevant to the same policy question were grouped together
p5
aVWe are inspired by multiple sequence alignment methods in computational biology [ 8 ] and by Barzilay and Lee ( 2004 ) , who described a hidden Markov model (HMM) for document content where each state corresponds to a distinct topic and generates sentences relevant to that topic according to a language model
p6
aVSince every site is different in its placement of the document (e.g.,, buried deep within the website, distributed across several pages, or mingled together with Terms of Service) and format (e.g.,, HTML, PDF, etc.), and since we wish to preserve as much document structure as possible (e.g.,, section labels), full automation was not a viable solution
p7
aVMcDonald and Cranor ( 2008 ) showed that, if users were to read the privacy policies of every website they access during the course of a year, they would end up spending a substantial amount of their time doing just that and would often still not be able to answer basic questions about what these policies really say
p8
aVTogether, these can be used as a gold standard grouping of policy sections, against which we can compare our system u'\u005cu2019' s output
p9
aVExperts were allowed to select as many sections for each question as they saw fit, since answering some questions may require synthesizing information from different sections
p10
aV3 3 The u'\u005cu201c' Adult u'\u005cu201d' category was excluded; the u'\u005cu201c' World u'\u005cu201d' category was excluded since it contains mainly popular websites in different languages, and we opted to focus on policies in English in this first stage of research, though mulitlingual policy analysis presents interesting challenges for future work
p11
aVSample the t th section of the document by drawing a bag of terms, u'\u005cud835' u'\u005cudc90' t , according to the emission multinomial distribution for state y t
p12
aVSuch policies therefore offer an excellent opportunity for NLP tools that summarize or extract key information that (i) helps users understand the implications of agreeing to these policies and (ii) helps legal analysts understand the contents of these policies and make recommendations on how they can be improved or made more clear
p13
aVThese were too costly for us to consider, so we instead propose two generic methods to evaluate models for sequence alignment of a collection of documents with generally similar content
p14
aVOur method allows these to overlap (63% of the sections in any A i occurred in more than one A i ), and they are not exhaustive (since many sections of the policies were not deemed to contain answers to any of the nine questions by any expert
p15
aVIndeed, our model does not even generate these lengths, since doing so would force the states to u'\u005cu201c' explain u'\u005cu201d' the length of each section, not just its content
p16
aVAs in § 4.1 , we calculate precision and recall on pairs
p17
aVSample the next state, y t + 1 , according to the transition distribution over u'\u005cud835' u'\u005cudcae'
p18
aV4 4 The emission distributions are not a proper language models (e.g.,, a bigram may be generated by as many as three draws from the emission distribution once for each unigram it contains and once for the bigram
p19
aVIn this method, the desired K -way clustering solution is computed by performing a sequence of bisections
p20
aVChoose a start state y 1 from u'\u005cud835' u'\u005cudcae' according to the start-state distribution
p21
aVThis does not penalize the model for grouping together a u'\u005cu201c' no u'\u005cu201d' pair; we chose it nonetheless because it is interpretable
p22
aVUnsurprisingly, many people do not read them [ 9 ]
p23
aVIn the sequel, a grouping on a set X is defined as a collection of subsets X i u'\u005cu2286' X ; these may overlap (i.e.,, there might be x u'\u005cu2208' X i u'\u005cu2229' X j ) and need not be exhaustive (i.e.,, there might be x u'\u005cu2208' X u'\u005cu2216' u'\u005cu22c3' i X i
p24
aVAn example is shown in Figure 2
p25
a.