<html>
<head>
<title>P14-1082.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In other words, for each word type or phrase type that occurs as a fragment in the training set, and which does not map to just a single translation, a classifier is trained</a>
<a name="1">[1]</a> <a href="#1" id=1>This measure may be too strict, so we add a more flexible word accuracy measure which takes into account partial matches at the word level</a>
<a name="2">[2]</a> <a href="#2" id=2>Per classifier expert, the best scoring configuration was selected, referred to as the auto configuration in Table 2</a>
<a name="3">[3]</a> <a href="#3" id=3>Automatic configuration selection was done by performing leave-one-out testing (for small number of instances) or 10-fold-cross validation (for larger number of instances, n u'\u2265' 20 ) on the training data per classifier expert</a>
<a name="4">[4]</a> <a href="#4" id=4>Words or phrases that always map to a single translation are stored in a simple mapping table, as a classifier would have no added value in such cases</a>
<a name="5">[5]</a> <a href="#5" id=5>Numerous classifiers are trained and each is an expert in translating a single word or phrase</a>
<a name="6">[6]</a> <a href="#6" id=6>Among the classifier experts are only words and phrases that are ambiguous and may thus map to multiple translations</a>
<a name="7">[7]</a> <a href="#7" id=7>No additional external data was brought in, to keep the comparison fair</a>
<a name="8">[8]</a> <a href="#8" id=8>The auto configuration improves results over the uniformly applied feature selection</a>
<a name="9">[9]</a> <a href="#9" id=9>In all of the aforementioned experiments, the system produced a single solution for each of the fragments, the one it deemed best, or no solution at all if it could not find any</a>
<a name="10">[10]</a> <a href="#10" id=10>This implies that such words and phrases must have occurred at least twice in the corpus, though this threshold is made configurable and could have been set higher to limit the number of classifiers</a>
<a name="11">[11]</a> <a href="#11" id=11>Third, we observe that adding the language model to our classifier leads to another significant gain (configuration l1r1 + LM in the results in Table 2</a>
<a name="12">[12]</a> <a href="#12" id=12>The word accuracy for the entire set is then computed by taking the sum of the word accuracies per sentence pair, divided by the total number of sentence pairs</a>
<a name="13">[13]</a> <a href="#13" id=13>The language model is a trigram-based back-off language model with Kneser-Ney smoothing, computed using SRILM [] and trained on the same training data as the translation model</a>
<a name="14">[14]</a> <a href="#14" id=14>We therefore conducted a number of experiments with other language pairs, and present the abridged results in Table 6</a>
<a name="15">[15]</a> <a href="#15" id=15>This number is much larger than the 200 , 000 we mentioned before because single sentence pairs may be reused multiple times with different marked fragments</a>
<a name="16">[16]</a> <a href="#16" id=16>In order to draw accurate conclusions, experiments on a single data set and language pair are not sufficient</a>
<a name="17">[17]</a> <a href="#17" id=17>The same holds for the Chinese u'\u2192' English experiment</a>
<a name="18">[18]</a> <a href="#18" id=18>The choice for this algorithm is motivated by the fact that it handles multiple classes with ease, but first and foremost because it has been successfully employed for word sense disambiguation in other studies [] , in particular in cross-lingual word sense disambiguation, a task</a>
</body>
</html>