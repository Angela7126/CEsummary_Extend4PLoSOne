<html>
<head>
<title>P14-1079.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The matrix rank minimization problem is NP-hard</a>
<a name="1">[1]</a> <a href="#1" id=1>Moreover, Goldfrab and Ma [ 11 ] proved the convergence of the FPC algorithm for solving the nuclear norm minimization problem</a>
<a name="2">[2]</a> <a href="#2" id=2>In such a way, relation classification is transformed into a problem of completing the unknown labels for testing items in the sparse matrix that concatenates training and testing textual features with training labels, based on the assumption that the item-by-feature and item-by-label joint matrix is of low rank</a>
<a name="3">[3]</a> <a href="#3" id=3>More specifically, as shown in Figure 2, we model the task with a sparse matrix whose rows present items (entity pairs) and columns contain noisy textual features and incomplete relation labels</a>
<a name="4">[4]</a> <a href="#4" id=4>Due to the noisy features and incomplete labels, the underlying low-rank data matrix with truly effective information tends to be corrupted and the rank of observed data matrix can be extremely high</a>
<a name="5">[5]</a> <a href="#5" id=5>FPC algorithm for solving DRMC-1 {algorithmic} \REQUIRE Initial matrix u'\ud835' u'\udc19' u'\ud835' u'\udfce' ; Parameters u'\u039c' , u'\u039b' ; Step sizes u'\u03a4' z</a>
<a name="6">[6]</a> <a href="#6" id=6>Suppose that we have built a training corpus for relation classification with n items (entity pairs), d -dimensional textual features, and t labels (relations), based on the basic alignment assumption proposed by Mintz et al</a>
<a name="7">[7]</a> <a href="#7" id=7>Our models for relation extraction are based on the theoretic framework proposed by Goldberg et al</a>
<a name="8">[8]</a> <a href="#8" id=8>FPC algorithm for solving DRMC-b {algorithmic}</a>
</body>
</html>