(lp0
VIn this section, we describe in detail our system for predicting essays u'\u005cu2019' prompt adherence scores
p1
aVFinally, while features 4 (prompt adherence keywords) and 7 (predicted thesis clarity errors) may by themselves provide useful information to our system, in the presence of the other feature types they tend to be the least important to performance as they are often the first feature types removed
p2
aVWe cast the problem of predicting an essay u'\u005cu2019' s prompt adherence score as 13 regression problems, one for each prompt
p3
aVFor instance, an essay that has a Relevance to Prompt error or an Incomplete Prompt Response error should intuitively receive a low prompt adherence score
p4
aVFeatures 2 (n-grams), 3 (thesis clarity keywords), and 6 (manually annotated LDA topics) tend to be the most important feature types, as they tend to be the last feature types removed in the ablation subtables
p5
aVTo obtain feature values of the first type, we take the RI similarities between the whole essay and each set of prompt adherence keywords from the prompt u'\u005cu2019' s components
p6
aVSo to see how our system performs by the S u'\u005cu2062' 1 metric if we remove only predicted thesis clarity error features, we would look at the first row of results of Table d (a) under the column headed by the number 7 since predicted thesis clarity errors are the seventh feature type introduced in Section 4
p7
aVSince error prediction and prompt adherence scoring are related problems, the features we associate with this instance are features 1 - 6 which we have described earlier in this section
p8
aVSince the feature type whose removal yields the best system is always the rightmost entry in a line, the order of column headings indicates the relative importance of the feature types, with the leftmost feature types being most important to performance and the rightmost feature types being least important in the presence of the other feature types
p9
aVEach essay is represented as an instance whose label is the essay u'\u005cu2019' s true score (one of the values shown in Table 3 ) with up to seven types of features including baseline (Section 4.2) and six other feature types proposed by us (Section 4.3
p10
aVThese topics should not diminish the essay u'\u005cu2019' s prompt adherence score because they are at least related to prompt concepts
p11
aVWhile each of the essays in our data set was previously annotated with these thesis clarity errors, in a realistic setting a prompt adherence scoring system will not have access to these manual error labels
p12
aVIn order to construct manually annotated LDA topic features, we first build 13 topic models, one for each prompt, just as described in the section on LDA topic features
p13
aVFor this reason, we introduce features based on these errors to our feature set for prompt adherence scoring 3 3 See our website at http://www.hlt.utdallas.edu/~persingq/ICLE/ for the complete list of error annotations
p14
aVSince Table 4 shows that when our system includes this feature type (along with all the other feature types), it obtains an S u'\u005cu2062' 1 score of .488, this feature type u'\u005cu2019' s removal costs our system .014 S u'\u005cu2062' 1 points, and thus its inclusion has a beneficial effect on the S u'\u005cu2062' 1 score
p15
aVHence, it is important to know how performance is measured when building a system for scoring prompt adherence
p16
aVFor example, while we identified feature 3 (thesis clarity keywords) as one of the most important feature types generally due to its tendency to have a large beneficial impact on performance, when we are measuring performance using S u'\u005cu2062' 3 , it is the least useful feature type
p17
aVThe top line of each subtable shows what our system u'\u005cu2019' s score would be if we removed just one of the feature types from our system
p18
aVAnd since removing feature 6 harms performance least in the presence of row 2 u'\u005cu2019' s other feature types, we permanently remove both 4 and 6 from our feature set when we generate the third row of results
p19
aVIt should not, however, have a very high prompt adherence score, as the prompt asked the student to discuss whether television is like religion in a particular way, so religion should be at least briefly addressed for an essay to be awarded a high prompt adherence score
p20
aVFrom row 1 of Table d (a), we can see that removing feature 4 yields a system with the best S u'\u005cu2062' 1 score in the presence of the other feature types in this row
p21
aVOur RI feature set necessarily excludes those features from Higgins et al. that are not easily translatable to our problem since we are concerned with an entire essay u'\u005cu2019' s adherence to its prompt rather than with each of its sentences u'\u005cu2019' relatedness to the prompt
p22
aVSince the latter topic is discussed so much in the essay and does not appear to have much to do with the military prompt, this essay should probably get a bad prompt adherence score
p23
aVRegarding task formulation, while Higgins et al. focus on classifying each sentence as having either good or bad adherence to the prompt, we focus on assigning a prompt adherence score to the entire essay , allowing the score to range from one to four points at half-point increments
p24
aVFor this reason, we permanently remove feature 4 from the system before we generate the results on line 2
p25
aVFor the sake of our experiments, whenever annotators disagree on an essay u'\u005cu2019' s prompt adherence score, we assign the essay the average of all annotations rounded to the nearest half point
p26
aVThis results in what we can think of as a soft clustering of words into 1,000 sets for each prompt, where each set of words represents one of the topics LDA identified being discussed in the essays for that prompt
p27
aVAdditionally, our prompt adherence keyword sets do not adopt the notions of primary and secondary groups of keywords for each prompt component, instead collecting all the keywords for a component into one set because u'\u005cu201c' secondary u'\u005cu201d' keywords tend to be things that are important when we are concerned with what a student is saying about the topic rather than just how clearly she said it
p28
aVEach feature u'\u005cu2019' s value is obtained by using the topic model to tell us how much of the essay was spent discussing the feature u'\u005cu2019' s corresponding topic
p29
aVFeature 3 is not the only feature type whose removal sometimes has a beneficial impact on performance
p30
aVThe thesis clarity keyword features described above were intended for the task of determining how clear an essay u'\u005cu2019' s thesis is, but since our goal is instead to determine how well an essay adheres to its prompt, it makes sense to adapt keyword features to our task rather than to adopt keyword features exactly as they have been used before
p31
aVN-grams can be useful for prompt adherence scoring because they can capture useful words and phrases related to a prompt
p32
aVThis being the case, it is interesting to note that while the relative importance of different feature types does not remain exactly the same if we measure performance in different ways, we can see that some feature types tend to be more important than others in a majority of the four scoring metrics
p33
aVFor instance, one thesis clarity keyword feature is computed as follows
p34
aVOur goal in this paper is to develop a computational model for scoring an essay along an under-investigated dimension u'\u005cu2014' prompt adherence
p35
aVWe expect that features based on RI will be useful for prompt adherence scoring because they may help us find text related to the prompt even if some of its concepts have have been rephrased (e.g.,, an essay may talk about u'\u005cu201c' jail u'\u005cu201d' rather than u'\u005cu201c' prison u'\u005cu201d' , which is mentioned in one of the prompts), and because they have already proven useful for the related task of determining which sentences in an essay are related to the prompt [ 7 ]
p36
aVTo more closely examine the behavior of our system, in Table 6 we chart the distributions of scores it predicts for essays having each gold standard score
p37
aVwhere A j , E j , and E j u'\u005cu2032' are the annotator assigned, system predicted, and rounded system predicted scores 4 4 Since our regressor assigns each essay a real value rather than an actual valid score, it would be difficult to obtain a reasonable S u'\u005cu2062' 1 score without rounding the system estimated score to one of the possible values
p38
aVOur baseline system for score prediction employs various features based on Random Indexing
p39
aVWe do this by generating one feature encoding the entire essay u'\u005cu2019' s similarity to the prompt, another encoding the essay u'\u005cu2019' s highest individual sentence u'\u005cu2019' s similarity to the prompt, a third encoding the highest entire essay similarity to one of the prompt sentences, another encoding the highest individual sentence similarity to an individual prompt sentence, and finally one encoding the entire essay u'\u005cu2019' s similarity to a manually rewritten version of the prompt that excludes extraneous material (such as u'\u005cu201c' In his novel Animal Farm, George Orwell wrote, u'\u005cu201d' which is introductory material from the third prompt in Table 1
p40
aVThe next five features are similar to the last, with one feature taking on the sum of the contributions to an essay of topics annotated with the number 0, another feature taking on the sum of the contributions to an essay of topics annotated with the number 1, and so on up to 4
p41
aVFrom this table, we see that our system has a strong bias toward predicting more frequent scores as there are no numbers less than 3.0 in the table, and about 93.7% of all essays have gold standard scores of 3.0 or above
p42
aVA weakness of the LDA topics feature type is that it may result in a regressor that has trouble distinguishing between an infrequent topic that is adherent to the prompt and one that just represents an irrelevant digression
p43
aVIf he was alive at the end of the 20th century, he would replace religion with television u'\u005cu201d' Since the question suggests that students discuss whether television is analogous to religion in this way, our set of prompt adherence keywords for this prompt contains the word u'\u005cu201c' religion u'\u005cu201d' while the previously discussed keyword sets do not
p44
aVThen the most important (primary) and second most important (secondary) words were selected from each prompt component, where a word was considered u'\u005cu201c' important u'\u005cu201d' if it would be a good word for a student to use when stating her thesis about the prompt
p45
aVThese results mean that the greatest improvements our system makes are that it ensures that our score predictions are not too often very far away from an essay u'\u005cu2019' s actual score, as making such predictions would tend to drive up S u'\u005cu2062' 3 , yielding a relative error reduction in S u'\u005cu2062' 3 of 15.8%, and it also ensures a better correlation between predicted and actual scores, thus yielding the 16.6% improvement in P u'\u005cu2062' C
p46
aVThough feature 3 is an extreme example, all feature types fluctuate in importance, as we see when we compare their orders of removal among the four ablation subtables
p47
aVWe do not include a feature for topics annotated with the number 5 because it would always have the same value as the feature for topics u'\u005cu2265' 5
p48
aVThis means that 25% of the time, when our system with parameters tuned for optimizing S u'\u005cu2062' 3 is presented with a test essay having a gold standard score of 2.0, it predicts that the essay has a score less than or equal to 3.06
p49
aVFortunately, this effect does not occur in any other cases than the two listed above, as most feature types usually have a beneficial or at least neutral impact on our system u'\u005cu2019' s performance
p50
aVRather than requesting models of 1,000 topics, however, we request models of only 100 topics 2 2 We use 100 topics for each prompt in the manually annotated version of LDA features rather than the 1,000 topics we use in the regular version of LDA features because 1,300 topics are not too costly to annotate, but manually annotating 13,000 topics would take too much time
p51
aVAs we can see in Table d (b), the removal of features 4, 5, and 7 improves our system u'\u005cu2019' s S u'\u005cu2062' 2 score by .001 points
p52
aVFor this reason, we construct a new list of keywords for each prompt component, though since prompt adherence is more concerned with what the student says about the topics than it is with whether or not what she says about them is stated clearly, our keyword lists look a little different than the ones discussed above
p53
aVThis metric reflects the idea that a system that predicts scores close to the annotator-assigned scores should be preferred over a system whose predictions are further off, even if both systems estimate the correct score at the same frequency
p54
aVWhile n-gram features do not have exactly the same problem, they would still only notice that these example words are related to the prompt if multiple essays use the same words to discuss these concepts
p55
aVThe first five features encode the sum of the contributions to an essay of topics annotated with a number u'\u005cu2265' 1 , the sum of the contributions to an essay of topics annotated with a number u'\u005cu2265' 2 , and so on up to 5
p56
aVFor example, words and phrases like u'\u005cu201c' university degree u'\u005cu201d' , u'\u005cu201c' student u'\u005cu201d' , and u'\u005cu201c' real world u'\u005cu201d' are relevant to the first prompt in Table 1 , so it is more likely that an essay adheres to the prompt if they appear in the essay
p57
aVThis results in one to three features since a prompt has one to three components
p58
aVAs our first novel feature, we use the 10,000 most important lemmatized unigram, bigram, and trigram features that occur in the essay
p59
aVFor example, by the time feature 1 gets permanently removed in Table d (c), its removal harms performance by .002 S u'\u005cu2062' 3 points
p60
aVSince RI does not provide a straightforward way to measure similarity between groups of words such as sentences or essays, we use Higgins and Burstein u'\u005cu2019' s [ 8 ] method to generate these features
p61
aVThe greatest of the fractions generated in this way is encoded as a feature because if it has a low value, that indicates the essay u'\u005cu2019' s thesis may not be very relevant to the prompt
p62
aVNote that each of the c i values can be tuned independently because a c i value that is optimal for predicting scores for p i essays with respect to any of the error performance measures is necessarily also the optimal c i when measuring that error on essays from all prompts
p63
aVThe simplest metric, S u'\u005cu2062' 1 , measures the frequency at which a system predicts the wrong score out of the seven possible scores
p64
aVFor example, consider the prompt u'\u005cu201c' All armies should consist entirely of professional soldiers there is no value in a system of military service u'\u005cu201d' An essay containing words like u'\u005cu201c' peace u'\u005cu201d' , u'\u005cu201c' patriotism u'\u005cu201d' , or u'\u005cu201c' training u'\u005cu201d' are probably not digressions from the prompt, and therefore should not be penalized for discussing these topics
p65
aVFeatures are then computed based on these keywords
p66
aVFor each essay, we therefore attempt to adapt the RI features used by Higgins et al
p67
aVHence, a system that predicts the right score only 25% of the time would receive an S u'\u005cu2062' 1 score of 0.75
p68
aVThis is because a thesis like u'\u005cu201c' Television is bad u'\u005cu201d' can be stated very clearly without making any reference to religion at all, and so an essay with a thesis like this can potentially have a very high thesis clarity score
p69
aVWe can see this is the case by noting that they are not all the least important feature types in their respective subtables as indicated by column order
p70
aV7 7 These numbers are calculated B - O B - P where B is the baseline system u'\u005cu2019' s score, O is our system u'\u005cu2019' s score, and P is a perfect score
p71
aVNext, we introduce six types of novel features
p72
aVThus, we can see what happens when we remove both feature 4 and feature 5 by looking at the second entry in row 2
p73
aVSince the essays vary greatly in length, we normalize each essay u'\u005cu2019' s set of n-gram features to unit length
p74
aVSince progress in prompt adherence modeling is hindered in part by the lack of a publicly annotated corpus, we believe that our data set will be a valuable resource to the NLP community
p75
aVFeatures like these should give the regressor a better idea how much of an essay is composed of prompt-related arguments and discussion and how much of it is irrelevant to the prompt, even if some of the topics occurring in it are too infrequent to judge just from training data
p76
aVFor this reason, we introduce Latent Dirichlet Allocation (LDA) [ 2 ] features
p77
aVA major weakness of many existing scoring engines such as the Intelligent Essay Assessor u'\u005cu2122' [ 13 ] is that they adopt a holistic scoring scheme, which summarizes the quality of an essay with a single score and thus provides very limited feedback to the writer
p78
aVHowever, this is not case with Pearson u'\u005cu2019' s correlation coefficient, as the P u'\u005cu2062' C value for essays from all 13 prompts cannot be simplified as a weighted sum of the P u'\u005cu2062' C values obtained on each individual prompt
p79
aVThe keyword features were formed by first examining the 13 essay prompts, splitting each into its component pieces
p80
aVFor other scoring metrics, we only round the predictions to 1.0 or 4.0 if they fall outside the 1.0 - 4.0 range respectively for essay j , and N is the number of essays
p81
aVIf a training essay is written in response to p , it will be used to generate a training instance whose label is 1 if e was annotated for it or 0 otherwise
p82
aVAs an example of what is meant by a u'\u005cu201c' component piece u'\u005cu201d' , consider the first prompt in Table 1
p83
aVSo since the lemmatized version of the third component of the second prompt in Table 1 is u'\u005cu201c' it should rehabilitate they u'\u005cu201d' , u'\u005cu201c' rehabilitate u'\u005cu201d' was selected as a primary keyword and u'\u005cu201c' society u'\u005cu201d' as a secondary keyword
p84
aVAs far as the approach is concerned, Higgins et al. adopt a knowledge-lean approach to the task, where almost all of the features they employ are computed based on a word-based semantic similarity measure known as Random Indexing [ 10 ]
p85
aVAnother interesting point to note about this table is that the difference in error weighting between the S u'\u005cu2062' 2 and S u'\u005cu2062' 3 scoring metrics appears to be having its desired effect, as every entry in the S u'\u005cu2062' 3 subtable is less than its corresponding entry in the S u'\u005cu2062' 2 subtable due to the greater penalty the S u'\u005cu2062' 3 metric imposes for predictions that are very far away from the gold standard scores
p86
aVThis results in one to three features, as some prompts have one component while others have up to three
p87
aVThis is because an infrequent topic may not appear in the training set often enough for the regressor to make this judgment
p88
aVSo for example, the five most important words in the most frequently discussed topic for the military prompt we mentioned above are u'\u005cu201c' man u'\u005cu201d' , u'\u005cu201c' military u'\u005cu201d' , u'\u005cu201c' service u'\u005cu201d' , u'\u005cu201c' pay u'\u005cu201d' , and u'\u005cu201c' war u'\u005cu201d'
p89
aVAs we will see below, S u'\u005cu2062' 1 , S u'\u005cu2062' 2 , and S u'\u005cu2062' 3 are error metrics, so lower scores imply better performance
p90
aVIf he was alive at the end of the 20th century, he would replace religion with television, u'\u005cu201d' students sometimes write essays about all the evils of television, forgetting that their essay is only supposed to be about whether it is u'\u005cu201c' the opium of the masses u'\u005cu201d'
p91
aVAs mentioned earlier, for each prompt p i , we train a linear regressor r i using LIBSVM with regularization parameter c i
p92
aVAs a result, we first need to predict which of these errors is present in each essay
p93
aVFor that reason, we round the estimated score to the nearest of the seven scores the human annotators were permitted to assign (1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0) only when calculating S u'\u005cu2062' 1
p94
aVAs an example of how to read this table, consider the number 3.06 appearing in row 2.0 in the .25 column of the S u'\u005cu2062' 3 region
p95
aVIn order to obtain an optimal result as measured by P u'\u005cu2062' C , we jointly tune the c i parameters to optimize the P u'\u005cu2062' C value achieved by our system on the same held-out validation data
p96
aVEssay grading software that provides feedback along multiple dimensions of essay quality such as E- rater /Criterion [ 1 ] has also begun to emerge
p97
aVThe test instances are created in the same way as the training instances
p98
aVWe use as our corpus the 4.5 million word International Corpus of Learner English (ICLE) [ 5 ] , which consists of more than 6000 essays written by university undergraduates from 16 countries and 16 native languages who are learners of English as a Foreign Language
p99
aVIn contrast, P u'\u005cu2062' C is a correlation metric, so higher correlation implies better performance
p100
aVHowever, an exact solution to this optimization problem is computationally expensive, as there are too many ( 7 13 ) possible combinations of c values to exhaustively search
p101
aV91% of the ICLE texts are argumentative
p102
aVConsequently, we find a local maximum by employing the simulated annealing algorithm [ 11 ] , altering one c i value at a time to optimize P u'\u005cu2062' C while holding the remaining parameters fixed
p103
aVA positive (negative) P u'\u005cu2062' C implies that the two sets of predictions are positively (negatively) correlated
p104
a.