(lp0
VWe also experimented with a number of alternative high precision approaches that space precludes our presenting in detail here, including pruning the number of expansion candidates based on the pair LM score; only allowing abbreviation expansion when at least one extracted n-gram context is present for that expansion in that context; and CART tree [] training with real valued scores
p1
aVWe also have features that fire for each type of contextual feature (e.g.,, trigram with expansion as middle word, etc.), including u'\u005cu2018' no context u'\u005cu2019' , where none of the trigrams or bigrams from the current example that include the candidate expansion are present in our list
p2
aVWe then take the Bayesian fusion of this model with the pair LM, by adding them in the log space, to get prediction from both the context and abbreviation model
p3
aVThus multiple bin features can be
p4
a.