<html>
<head>
<title>P14-1014.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The input for the this module is the word n-gram ( w i - l , u'\u2026' , w i + r ) , the form of which is identical to the training data of the pre-trained WRRBM</a>
<a name="1">[1]</a> <a href="#1" id=1>We can choose to use only the word representations of the learned WRRBM</a>
<a name="2">[2]</a> <a href="#2" id=2>This can be achieved by initializing only the first layer of the web module with the projection matrix u'\ud835' u'\udc03' of the learned WRRBM</a>
<a name="3">[3]</a> <a href="#3" id=3>2011 ) propose to learn representations from the mixture of both source and target domain unlabelled data to improve cross-domain sentiment classification</a>
<a name="4">[4]</a> <a href="#4" id=4>We conduct experiments to test whether using the target domain data to train the WRRBM yields better performance compared with using mixed data from all sub-domains</a>
<a name="5">[5]</a> <a href="#5" id=5>The parameters { u'\ud835' u'\udc1b' , u'\ud835' u'\udc1c' , u'\ud835' u'\udc03' , u'\ud835' u'\udc16' ( 1 ) , u'\u2026' , u'\ud835' u'\udc16' ( n ) } can be trained using a Metropolis-Hastings-based CD</a>
</body>
</html>