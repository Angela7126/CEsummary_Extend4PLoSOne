<html>
<head>
<title>P14-1116.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not</a>
<a name="1">[1]</a> <a href="#1" id=1>The summaries generated by the ML classification system are then compared with the output of a RL system and two baseline systems in simulation and with real students</a>
<a name="2">[2]</a> <a href="#2" id=2>Content selection decisions based on trends in time-series data determine the selection of the useful and important variables, which we refer to here as factors , that should be conveyed in a summary</a>
<a name="3">[3]</a> <a href="#3" id=3>Collective content selection [] is similar to our proposed method in that it is a classification task that predicts the templates from the same instance simultaneously</a>
<a name="4">[4]</a> <a href="#4" id=4>For instance, classifier n was trained using the data from the 9 factors and the template decisions for templates 0 to n - 1</a>
<a name="5">[5]</a> <a href="#5" id=5>The RL system differs from the classification system in the way it performs content selection</a>
<a name="6">[6]</a> <a href="#6" id=6>We compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with student users</a>
<a name="7">[7]</a> <a href="#7" id=7>Algorithm adaptation approaches [] extend simple classification methods to handle ML data</a>
<a name="8">[8]</a> <a href="#8" id=8>In contrast, ML classification does not need the computation of links between the data and the templates</a>
<a name="9">[9]</a> <a href="#9" id=9>The RAndom k-labELsets (RAkEL) [] was applied in order to perform ML classification</a>
<a name="10">[10]</a> <a href="#10" id=10>Secondly, for Decision Tree (with predicted history) , 29 classifiers were also trained, but this time the input included the previous decisions made by the previous classifiers (i.e., the history) as well as the set of time-series data in order to emulate the dependencies in the</a>
</body>
</html>