(lp0
VWe compare our model to MST and Turbo parsers on non-projective dependency parsing
p1
aVOur model outperforms Turbo parser, MST parser, as well as its own variants without the tensor component
p2
aVBy taking the cross-product of all these component feature vectors, we obtain the full feature representation for arc h u'\u005cu2192' m as a rank-1 tensor
p3
aVFinally, we demonstrate that the model can successfully leverage word vector representations, in contrast to the baselines
p4
aVOur parameters are divided into a sparse set corresponding to manually chosen MST or Turbo parser features and a larger set governed by a low-rank tensor
p5
aVOur parsing model aims to combine the strengths of both traditional features from the MST/Turbo parser as well as the new low-rank tensor features
p6
aVFrom a computational perspective, adding non-sparse vectors directly as features, including their combinations, can significantly increase the number of active features for scoring syntactic structures (e.g.,, dependency arc
p7
aVIn contrast, we expand features for parsing into a multi-way tensor, and operate with an explicit low-rank representation of the associated parameter tensor
p8
aVTo assess the ability of our model
p9
a.