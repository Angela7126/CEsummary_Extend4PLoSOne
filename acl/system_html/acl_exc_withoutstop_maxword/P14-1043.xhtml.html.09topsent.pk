(lp0
VUsing unlabeled data with the results of Berkeley Parser ( u'\u005cu201c' Unlabeled u'\u005cu2190' B u'\u005cu201d' ) significantly improves parsing accuracy by 0.55% (93.40-92.85) on English and 1.06% (83.34-82.28) on Chinese
p1
aVThe second major row shows the results when we use single 1-best parse trees on unlabeled data
p2
aVCombining the outputs of Berkeley Parser and GParser ( u'\u005cu201c' Unlabeled u'\u005cu2190' B+G u'\u005cu201d' ), we get higher oracle score (96.37% on English and 89.72% on Chinese) and higher syntactic divergence (1.085 candidate heads per word on English, and 1.188 on Chinese) than u'\u005cu201c' Unlabeled u'\u005cu2190' Z+G u'\u005cu201d' , which verifies our earlier discussion that Berkeley Parser produces more different structures than ZPar
p3
aVWhen the parse forests of the unlabeled data are the union of the outputs of GParser and ZPar, denoted as u'\u005cu201c' Unlabeled u'\u005cu2190' Z+G u'\u005cu201d' , each word has 1.053 candidate heads on English and 1.136 on Chinese, and the oracle accuracy is higher than using 1-best outputs of single parsers (94.97% vs
p4
aVHowever, we find that although the parser significantly outperforms the supervised GParser on English, it does not gain significant improvement over co-training with ZPar ( u'\u005cu201c' Unlabeled u'\u005cu2190' Z u'\u005cu201d' ) on both English and Chinese
p5
aVUsing unlabeled data with the results of ZPar ( u'\u005cu201c' Unlabeled u'\u005cu2190' Z u'\u005cu201d' ) significantly outperforms the baseline GParser by 0.30% (93.15-82.85) on English
p6
aVAlthough using less unlabeled sentences (0.7M for English and 1.2M for Chinese), tri-training
p7
a.