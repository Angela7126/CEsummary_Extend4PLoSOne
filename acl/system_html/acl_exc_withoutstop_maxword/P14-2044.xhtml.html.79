<html>
<head>
<title>P14-2044.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In contrast, we use pairwise morphological similarity as a prior in a non-parametric clustering model</a>
<a name="1">[1]</a> <a href="#1" id=1>For each evaluation setting we provide two sets of scores u'\u2014' first are the 1-1 and V-m scores for the given model, second are the comparable scores for K-means run with the same number of clusters as induced by the non-parametric model</a>
<a name="2">[2]</a> <a href="#2" id=2>We can create an infinite mixture model by combining the ddCRP prior with a likelihood function defining the probability of the data given the cluster assignments</a>
<a name="3">[3]</a> <a href="#3" id=3>Exponentiating the prior reduces the number of induced clusters and improves results, as it can change the cluster assignment for some words where the likelihood strongly prefers one cluster but the prior clearly indicates another</a>
<a name="4">[4]</a> <a href="#4" id=4>However, almost half the gold standard clusters in MTE contain just a few words and we</a>
</body>
</html>