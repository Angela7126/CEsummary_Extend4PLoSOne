<html>
<head>
<title>P14-1045.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The outcome of the contextual annotation presented above is a rather sizeable dataset of validated semantic links, and we showed these linguistic judgments to be reliable</a>
<a name="1">[1]</a> <a href="#1" id=1>Smote synthetizes and adds new instances similar to the minority class instances and is more efficient than a mere resampling</a>
<a name="2">[2]</a> <a href="#2" id=2>We tested the two strategies, by applying the classical Smote method of [] as a kind of resampling, and the ensemble method MetaCost of [] as a cost-aware learning method</a>
<a name="3">[3]</a> <a href="#3" id=3>The method we propose here has been designed as an intrinsic evaluation with a view to validate semantic proximity links in a broad perspective, to cover what [] call u'\u201c' non classical lexical semantic relations u'\u201d'</a>
<a name="4">[4]</a> <a href="#4" id=4>For cost-aware learning, a sensible choice is to invert the class ratio for the cost ratio, i.e., here the cost of a mistake on a relevant link (false negative) is exactly 8.5 times higher than the cost on a non-relevant link (false positive), as non-relevant instances are 8.5 times more present than relevant ones</a>
<a name="5">[5]</a> <a href="#5" id=5>They can be divided in three groups, according to their origin they are computed from the whole corpus, gathered from the distributional resource, or extracted from the considered text which contains the semantic pair to be evaluated</a>
<a name="6">[6]</a> <a href="#6" id=6>The random forest model is significantly improved by the balancing techniques the overall best F-score of 46.3% is reached with Random Forests and the cost-aware learning method</a>
<a name="7">[7]</a> <a href="#7" id=7>One advantage of distributional similarities is to exhibit a lot of different semantic relations, not necessarily standard lexical relations</a>
<a name="8">[8]</a> <a href="#8" id=8>We have seen that the relevant/not relevant classification is very imbalanced, biased towards the u'\u201c' not relevant u'\u201d' category (about 11%/89%), so we applied methods dedicated to counter-balance this, and will focus on the precision and recall of the predicted relevant links</a>
<a name="9">[9]</a> <a href="#9" id=9>We differ from</a>
</body>
</html>