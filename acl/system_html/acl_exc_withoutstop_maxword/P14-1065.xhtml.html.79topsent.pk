(lp0
VNote that the Asiya metrics are combinations of several metrics, and these combinations (which exclude DR and DR- lex ) can be also tuned; this yields sizable improvements over the untuned versions as column three in the table shows
p1
aVIn this paper, rather than proposing yet another MT evaluation metric, we show that discourse information is complementary to many existing evaluation metrics, and thus should not be ignored
p2
aVFurthermore, when combined with individual metrics in group II, DR- lex is able to improve consistently over each one of them
p3
aVAgain, DR- lex is better than DR; with a positive Tau of +.133, yet as an individual metric, it ranks poorly compared to other metrics in group II
p4
aVAs an example, consider the three discourse trees (DTs) shown in Figure 4 a ) for a reference (human) translation, and ( b ) and ( c ) for translations of two different systems on the WMT12 test dataset
p5
aVIndividually, DR- lex outperforms most of the metrics from group II, and ranks as the second best metric in that group
p6
aVThis suggests that both DR and DR- lex contain information that is complementary to that of the individual metrics that we experimented with
p7
aVHowever, over all metrics and all language pairs, DR- lex is able to obtain an average improvement in correlation of +.035, which is remarkably higher than that of DR
p8
aVTo do so, we contrast different MT evaluation metrics with and without discourse information
p9
aVOur working hypothesis is that the similarity between the discourse structures of an automatic and of a reference translation provides
p10
a.