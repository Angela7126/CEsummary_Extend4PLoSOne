(lp0
VThe results of this experiment are reported in the Indicative Bigrams column of Table 2
p1
aVThe words that are identified as the most discriminative include function words, punctuation, very common content words, and the toponymic terms
p2
aVUsing Algorithm 2 , we identify the top 20 character bigrams, and replace them with randomly selected bigrams
p3
aVThe results are shown in the Baseline column of Table 2
p4
aVWe replicate the experiments of Tsur and Rappoport ( 2007 ) by limiting the features to the 200 most frequent character bigrams
p5
aVThe remaining bigrams indicate function words, toponymic terms like Germany , and frequent content words like take and new
p6
aVUsing Algorithm 2 , we identify the 100 most discriminative words, and remove them from the training data
p7
aVHowever, we limit the set of features to the 200 most frequent bigrams for the sake of consistency with previous work
p8
aVThe classifier computes a weight for each feature coupled with each L1 language by attempting to maximize the overall accuracy on the training set
p9
aVFor example, if we train the classifier using words as features, with values representing their frequency relative to the length of the document, the features corresponding to the word China might receive the following weights
p10
aVHowever, the fact that the two bigrams are also on the list for the I2 set, which does not include these languages, suggests that their importance is mostly due to the
p11
a.