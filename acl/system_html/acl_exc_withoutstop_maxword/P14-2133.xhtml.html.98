<html>
<head>
<title>P14-2133.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>It could be that the distinctions between lexical items that embeddings capture are already modeled by parsers in other ways and therefore provide no further benefit</a>
<a name="1">[1]</a> <a href="#1" id=1>Word embeddings u'\u2014' representations of lexical items as points in a real vector space u'\u2014' have a long history in natural language processing, going back at least as far as work on latent semantic analysis (LSA) for information retrieval [ 4 ]</a>
<a name="2">[2]</a> <a href="#2" id=2>As described above, the full featured model adds indicator features on the bucketed value of each dimension of the word embedding</a>
<a name="3">[3]</a> <a href="#3" id=3>While word embeddings can be constructed directly from surface distributional statistics, as in LSA, more sophisticated tools for unsupervised extraction of word representations have recently gained popularity [ 3 , 10 ]</a>
<a name="4">[4]</a> <a href="#4" id=4>Semi-supervised and unsupervised models for a variety of core NLP tasks, including named-entity recognition [ 5 ] , part-of-speech tagging [ 13 ] , and chunking [ 15 ] have been shown to benefit from the inclusion of word embeddings as features</a>
<a name="5">[5]</a> <a href="#5" id=5>Here, the trend observed in the other two models is even more prominent u'\u2014' embedding features lead to improvements over the featured baseline, but in no case outperform the standard baseline with a generative lexicon</a>
<a name="6">[6]</a> <a href="#6" id=6>A baseline featured model ( u'\u201c' ident u'\u201d' ) contains only indicator features on word identity (and performs considerably worse than its generative counterpart on small data sets</a>
<a name="7">[7]</a> <a href="#7" id=7>In this paper, we investigate this question empirically, by isolating three potential mechanisms for improvement from</a>
</body>
</html>