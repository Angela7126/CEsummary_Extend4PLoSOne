<html>
<head>
<title>P14-2135.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Formally, we propose a measure, image dispersion d of a concept word w , defined as the average pairwise cosine distance between all the image representations { w 1 u'\u2192' u'\u2062' u'\u2026' u'\u2062' w n u'\u2192' } in the set of images for that concept</a>
<a name="1">[1]</a> <a href="#1" id=1>To evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u'\u222a' C introduced in Section 2</a>
<a name="2">[2]</a> <a href="#2" id=2>Multi-modal models in which perceptual input is filtered according to our algorithm learn higher-quality semantic representations than previous approaches, resulting in a significant performance improvement of up to 17% in capturing the semantic similarity of concepts</a>
<a name="3">[3]</a> <a href="#3" id=3>The filtering approach described thus far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts</a>
<a name="4">[4]</a> <a href="#4" id=4>The Turney et al algorithm quantifies the concreteness of concepts that lack such a rating based on their proximity to rated concepts in a semantic vector space</a>
<a name="5">[5]</a> <a href="#5" id=5>We apply image dispersion-based filtering as follows if both concepts in an evaluation pair have an image dispersion below a given threshold, both the linguistic and the visual</a>
</body>
</html>