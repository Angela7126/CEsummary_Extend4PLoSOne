(lp0
VThis dense representation should preserve the information from the bag-of-words input, meanwhile alleviate data sparse problem
p1
aVTo incorporate topic representations as translation knowledge into SMT, our neural network based approach directly optimizes similarities between the source language and target language in a compact topic space
p2
aVOur problem fits well into the neural network framework and we expect that it can further improve inferring the topic representations for sentences
p3
aVTherefore, it helps to train a smarter translation model with the embedded topic information
p4
aVThis is not simply coincidence since we can interpret their approach as a special case in our neural network method when a parallel sentence pair has document-level information, that document will be retrieved for training; otherwise, the most relevant document will be retrieved from the monolingual data
p5
aVSince the vectors from DAE are trained using information from monolingual training data independently, these vectors may be inadequate to measure bilingual topic similarity due to their different topic spaces
p6
aVSince a parallel sentence pair should have the same topic, our goal is to maximize the similarity score between the source sentence and target sentence
p7
aVNeural network is an effective technique for learning different levels of data representations
p8
aVBy measuring the similarity between the source texts and bilingual translation rules, the SMT decoder is able
p9
a.