(lp0
VOur parser can be easily adapted to this task by replacing the X-bar grammar over treebank symbols with a grammar over the sentiment values to encode the output variables and then adding n-gram indicators to our feature set to capture the bulk of the lexical effects
p1
aVThe open question is whether surface features are adequate for key effects like subcategorization, which have deep definitions but regular surface reflexes (e.g., the preposition selected by a verb will often linearly follow it
p2
aVThe u'\u005cu201c' Replaced u'\u005cu201d' system modifies the Berkeley parser by replacing rare words with morphological descriptors of those words computed using language-specific modules, which have been hand-crafted for individual languages or are trained with additional annotation layers in the treebanks that we do not exploit
p3
aVTheir model has high capacity to model complex interactions of words through a combinatory tensor, but it appears that our simpler, feature-driven model is just as effective at capturing the key effects of compositionality for sentiment analysis
p4
aVBy annotating grammar nonterminals with their headwords, the idea is to better model phenomena that depend heavily on the semantics of the words involved, such as coordination and PP attachment
p5
aVFigure 3 shows an example of one instance of this feature template impact is a noun that is more likely to take a PP than other
p6
a.