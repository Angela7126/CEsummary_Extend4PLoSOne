(lp0
VWe first compare our model to the Turbo parser using the Turbo parser feature set
p1
aVBaselines We compare our model with the Turbo parser and the MST parser
p2
aVStarting with an initial candidate tree, our inference procedure climbs the scoring function in small (cheap) stochastic steps towards a high scoring parse
p3
aVJoint Parsing and POS Correction Table 3 shows the results of joint parsing and POS correction on the CATiB dataset, for our model and state-of-the-art systems
p4
aVBecause the number of alternatives is small, the scoring function could in principle involve arbitrary (global) features of parse trees
p5
aVWe extend our model such that it jointly learns how to predict a parse tree and also correct the predicted POS tags for a better parsing performance
p6
aVPOS Tag Features In the
p7
a.