<html>
<head>
<title>P14-1109.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Finally, we investigate the robustness of the proposed semiparametric Gaussian copula regression model by varying the amount of features in the covariate space</a>
<a name="1">[1]</a> <a href="#1" id=1>To do this, we formulate the problem as a text regression task, and use a Gaussian copula with probability integral transform to model the uniform marginals and their dependencies</a>
<a name="2">[2]</a> <a href="#2" id=2>Both linear and non-linear SVM models do not have any advantages over the proposed approach</a>
<a name="3">[3]</a> <a href="#3" id=3>We use the Statistical Toolbox u'\u2019' s linear regression implementation in Matlab, and LibSVM [ 6 ] for training and testing the SVM models</a>
<a name="4">[4]</a> <a href="#4" id=4>In NLP, many of the probabilistic text models work in the discrete space [ 9 , 2 ] , but our model is different since the text features are sparse, we first perform kernel density estimates to smooth out the zeroing items, and then calculate the empirical cumulative distribution function (CDF) of the random variables</a>
<a name="5">[5]</a> <a href="#5" id=5>By applying the Probability Integral Transform to raw features in the copula model, we essentially avoid comparing apples and oranges in the feature space, which is a common problem in bag-of-features models in NLP</a>
<a name="6">[6]</a> <a href="#6" id=6>Note that since the kernel density estimation in the proposed copula model is nonparametric, and we only need to learn the u'\u03a3' in the Gaussian copula, there is no hyperparameters that need to be tuned</a>
<a name="7">[7]</a> <a href="#7" id=7>Last but not least, by using a</a>
</body>
</html>