<html>
<head>
<title>P14-1107.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>To sort good translations from bad, researchers often solicit multiple, redundant translations and then build models to try to predict which translations are the best, or which translators tend to produce the highest quality translations</a>
<a name="1">[1]</a> <a href="#1" id=1>Although hiring professional translators to create bilingual training data for machine translation systems has been deemed infeasible, Mechanical Turk has provided a low cost way of creating large volumes of translations [ 9 , 3 ]</a>
<a name="2">[2]</a> <a href="#2" id=2>The problem definition of the crowdsourcing translation task is straightforward given a set of candidate translations for a source sentence, we want to choose the best output translation</a>
<a name="3">[3]</a> <a href="#3" id=3>To measure effectiveness, we look at the change in TER g u'\u2062' o u'\u2062' l u'\u2062' d that results from the editing; negative u'\u0394' TER g u'\u2062' o u'\u2062' l u'\u2062' d means the editor effectively improved the quality of the translation, while positive u'\u0394' TER g u'\u2062' o u'\u2062' l u'\u2062'</a>
</body>
</html>