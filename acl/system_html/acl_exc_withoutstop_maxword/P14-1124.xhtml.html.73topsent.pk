(lp0
VWe consider term detection rather than the transcription task in considering how to exploit topic context, because in evaluating the retrieval of certain key terms we need not focus on improving the entire word sequence
p1
aVIn general, we can think of using word repetitions to re-score term detection as applying a limited form of adaptive or cache language model []
p2
aVWe illustrate this variability by looking at how consistent word co-occurrences are between two separate corpora in the same language i.e.,, if we observe words that frequently co-occur with a keyword in the training corpus, do they also co-occur with the keywords in a second held-out corpus
p3
aVLastly, the reductions in P u'\u005cu2062' ( Miss ) suggests that we are improving the term detection metric, which is sensitive to threshold changes, by doing what we set out to do, which is to boost lower confidence repeated words and correctly asserting them as true hits
p4
aVThe BABEL task is modeled on the 2006 NIST Spoken Term Detection evaluation [] but focuses on limited resource conditions
p5
aVThe x -coordinate of each point in Figure 1 is
p6
a.