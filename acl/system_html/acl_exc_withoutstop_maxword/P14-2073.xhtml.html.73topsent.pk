(lp0
VAs each token of the training data is ingested by the particle filter, we decide to insert that token into the reservoir, or not, independent of the other tokens in the current document
p1
aVThus, at the end of step i of the particle filter, each of the i tokens seen so far in the training sequence has an equal probability of being in the reservoir, hence being selected for rejuvenation
p2
aVThus we perform a set of experiments in which we perform Gibbs initialization 20 times on the initialization set, setting the particle filter u'\u005cu2019' s initial model to the model out of these 20 with the highest in-sample NMI
p3
aVNow each particle p is propagated forward by drawing a topic z i ( p ) from the conditional posterior distribution u'\u005cud835' u'\u005cudc0f' ( z i ( p ) u'\u005cu2223' u'\u005cud835'
p4
a.