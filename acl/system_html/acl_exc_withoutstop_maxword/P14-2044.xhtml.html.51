<html>
<head>
<title>P14-2044.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In contrast, we use pairwise morphological similarity as a prior in a non-parametric clustering model</a>
<a name="1">[1]</a> <a href="#1" id=1>This means that the membership of a word in a cluster requires only morphological similarity to some other element in the cluster, not to the cluster centroid; which may be more appropriate for languages with multiple morphological paradigms</a>
<a name="2">[2]</a> <a href="#2" id=2>We can create an infinite mixture model by combining the ddCRP prior with a likelihood function defining the probability of the data given the cluster assignments</a>
<a name="3">[3]</a> <a href="#3" id=3>Exponentiating the prior reduces the number of induced clusters and improves results, as it can change the cluster assignment for some words where the likelihood strongly prefers one cluster but the prior clearly indicates another</a>
<a name="4">[4]</a> <a href="#4" id=4>Recent work also shows that the combination of morphological and distributional information yields the best results, especially cross-linguistically [ 9</a>
</body>
</html>