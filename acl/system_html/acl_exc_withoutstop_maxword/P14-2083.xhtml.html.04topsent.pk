(lp0
VLastly, we compare the disagreements of annotators on a French social media data set [] , which we mapped to the universal POS tag set
p1
aVpresents work on detecting linguistically hard cases in the context of word sense annotations, e.g.,, cases where expert annotators will disagree, as well as differentiating between underspecified, overspecified and metaphoric cases
p2
aVFinally, use small samples of doubly-annotated POS data to estimate annotator reliability and show how those metrics can be implemented in the loss function when inducing POS taggers to reflect confidence we can put in annotations
p3
aVIn this study, we had between 2-10 individual annotators with degrees in linguistics annotate different kinds of English text with POS tags, e.g.,, newswire text (PTB WSJ Section 00), transcripts of spoken
p4
a.