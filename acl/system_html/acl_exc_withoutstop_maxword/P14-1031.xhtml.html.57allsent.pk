(lp0
VSpecifically, we use the Conditional Random Field (CRF) model as the learner for sentence-level sentiment classification, and incorporate rich discourse and lexical knowledge as soft constraints into the learning of CRF parameters via Posterior Regularization (PR) [ 7 ]
p1
aVWe can incorporate the proposed constraints (constraints derived from lexical patterns and discourse connectives) as hard constraints into CRF during inference by manually setting u'\u005cu039b' in equation 4 to a large value, 9 9 We set u'\u005cu039b' to 1000 for the lexical constraints and -1000 to the discourse connective constraints in the experiments
p2
aVIn contrast, both PR l u'\u005cu2062' e u'\u005cu2062' x and PR significantly outperform CRF , which implies that incorporating lexical and discourse constraints as posterior constraints is much more effective
p3
aVThis confirms that encoding lexical and discourse knowledge as posterior constraints allows the feature-based model to gain additional learning power for sentence-level sentiment prediction
p4
aVWe develop a rich set of context-aware posterior constraints for sentence-level sentiment analysis by exploiting lexical and discourse knowledge
p5
aVFor the CRF baseline and its invariants, we observe a similar performance trend as in the two-way classification task there is nearly no performance improvement from applying the lexical and discourse-connective-based constraints during CRF inference
p6
aVIn this paper, we propose a sentence-level sentiment classification method that can (1) incorporate rich discourse information at both local and global levels; (2) encode discourse knowledge as soft constraints during learning; (3) make use of unlabeled data to enhance learning
p7
aVSpecifically, we construct the lexical constraints by extracting sentiment-bearing patterns within sentences and construct the discourse-level constraints by extracting discourse relations that indicate sentiment coherence or sentiment changes both within and across sentences
p8
aVIn contrast, the PR model is able to associate stronger sentiment signals to these features by leveraging unlabeled data for indirect supervision
p9
aV1) we encode the coreference relations as soft constraints during learning instead of applying them as hard constraints during inference time; (2) our constraints can apply to both polar and non-polar sentences; (3) our identification of coreference relations is automatic without any fine-grained annotations for opinion targets
p10
aVPR makes the assumption that the labeled data we have is not enough for learning good model parameters, but we have a set of constraints on the posterior distribution of the labels
p11
aVIn addition, we include the discourse connectives as local or transition features and the document-level sentiment labels as features (only available in the MD dataset
p12
aVThe poor performance of CRF-inf l u'\u005cu2062' e u'\u005cu2062' x indicates that directly applying lexical constraints as hard constraints during inference could only hurt the performance
p13
aVNote that sentences with neutral sentiment can also contain such lexical patterns
p14
aVTo better understand the different effects of lexical and discourse constraints, we report results for applying only the lexical constraints ( CRF-inf l u'\u005cu2062' e u'\u005cu2062' x ) as well as results for applying only the discourse constraints ( CRF-inf d u'\u005cu2062' i u'\u005cu2062' s u'\u005cu2062' c
p15
aVIn the supervised setting, we treated the test data as unlabeled data and performed transductive learning
p16
aVIn particular, incorporating discourse constraints leads to consistent improvements to our model
p17
aVIn this work, we apply PR in the context of CRFs for sentence-level sentiment classification
p18
aVThen we introduce the context-aware constraints derived based on intuitive discourse and lexical knowledge
p19
aVIn the MD dataset, a neutral label may be given because the sentence contains mixed sentiment or no sentiment or it is off-topic
p20
aVTherefore we allow the lexical patterns to be assigned a neutral sentiment with a prior probability r 0 (we compute this value as the empirical probability of neutral sentiment in the training documents
p21
aVThe lexical constraints alone are often not sufficient since their coverage is limited by the sentiment lexicon and they can only constrain sentiment locally
p22
aVWe encode the extracted lexical patterns along with their sentiment values as feature-label constraints
p23
aVBy introducing the u'\u005cu201c' neutral u'\u005cu201d' category, the sentiment classification problem becomes harder
p24
aVIn the semi-supervised setting, our unlabeled data consists of both the available unlabeled data and the test data
p25
aVTherefore all the constraints are applied as soft constraints
p26
aVIn general, discourse connectives can also be used to connect non-polar (neutral) sentences
p27
aVWe also show that constraints derived from the discourse context can be highly useful for disambiguating sentence-level sentiment
p28
aVThis is because it over-predicts the polar sentences in the polar documents, and predicts no polar sentences in the neutral documents
p29
aVThis demonstrates that our modeling of discourse information is effective and that taking into account the discourse context is important for improving sentence-level sentiment analysis
p30
aVWe also show that discourse knowledge is highly useful for improving sentence-level sentiment classification
p31
aVThus it is hard to directly constrain the posterior expectation for each type of sentiment transitions using inter-sentential discourse connectives
p32
aVMost of our constraints can be factorized in the same way as factorizing the model features in the first-order CRF model, and we can compute the expectations under q very efficiently using the forward-backward algorithm
p33
aVUsing the polarity indicated by lexical patterns to constrain the sentiment of sentences is quite aggressive
p34
aVAs a result they could not help disambiguate neutral sentiment from polar sentiment, such as the third example in Table 5
p35
aVA plausible explanation is that most of our constraints focus on discriminating polar sentences
p36
aVNote that these constraints are not necessary for our model and can be applied when the document-level sentiment labels are naturally available
p37
aVTo identify discourse connectives, we apply a discourse tagger trained on the Penn Discourse Treebank [ 20 ] 4 4 http://www.cis.upenn.edu/~epitler/discourse.html to our data
p38
aVHowever, the discourse relations were obtained from fine-grained annotations and implemented as hard constraints on polarity
p39
aVWe focus on the equality constraints since we found them to express the sentiment-relevant constraints well
p40
aVWhen u'\u005cu039b' is large enough, it is equivalent to adding hard constraints to the viterbi inference
p41
aVInstead, we impose constraints on the model posteriors by reducing constraint violations
p42
aVIn this work, we also take into account this information and encode it as posterior constraints
p43
aVBased on an analysis of the Amazon review data, we observe that sentence-level sentiment usually doesn u'\u005cu2019' t conflict with the document-level sentiment in terms of polarity
p44
aVIt has the advantages of utilizing rich discourse knowledge at different levels of context and encoding it as soft constraints during learning
p45
aVThis indicates that the document-level sentiment is a very strong indicator of the sentence-level sentiment label
p46
aVWe set the CRF regularization parameter u'\u005cu03a3' = 1 and set the posterior regularization parameter u'\u005cu0392' and u'\u005cu0393' (a trade-off parameter we introduce to balance the supervised objective and the posterior regularizer in 2 ) by using grid search 8 8 We conducted 10-fold cross-validation on each training fold with the parameter space u'\u005cu0392'
p47
aVAs a framework for structured learning with constraints, PR has been successfully applied to many structural NLP tasks [ 6 , 7 , 5 ]
p48
aVTo capture context at the clause or sentence level, we consider discourse connectives, which are cue phrases or words that indicate discourse relations between adjacent sentences or clauses
p49
aVHowever, hard-constraint baselines can hardly improve the performance in general because the contributions of different constraints are not learned and their combination may not lead to better predictions
p50
aVThe rule-based baseline VoteFlip gave the weakest performance because it has no prediction power on sentences with no opinion words
p51
aVOne reason is that they do not constrain the neutral sentiment
p52
aVThe first idea is to exploit sentiment signals at the sentence level by learning the relevance of sentiment and words while taking into account the context in which they occur
p53
aVHowever, if we examine these sentences within the discourse context, we can see that the second sentence expresses sentiment towards the same aspect u'\u005cu2013' the music u'\u005cu2013' as the first sentence; the third sentence expands the second sentence with the discourse connective In fact
p54
aV2013 ) explored the use of explanatory discourse relations as soft constraints in a Markov Logic Network framework for extracting subjective text segments
p55
aVHowever, the improvement on the neutral category is modest
p56
aVWe use accuracy as the performance measure
p57
aVThe PR objective can be written as the original model objective penalized with a regularization term, which minimizes the KL-divergence between the desired model posteriors and the learned model posteriors with an L2 penalty 2 2 Other convex functions can be used for the penalty
p58
aVExisting feature-based classifiers may be effective in identifying the positive sentiment of the first sentence due to the use of the word revelation , but they could be less effective in the last two sentences due to the lack of explicit sentiment signals
p59
aVTherefore we only consider lexical patterns that are strongly discriminative (many opinion words in the lexicon only indicate sentiment with weak strength
p60
aVWe consider a discourse connective to be intra-sentential if it has the Comparison sense and connects two polar clauses with opposite polarities (determined by the lexical patterns
p61
aVIntuitively, discourse connectives with the senses of Expansion (e.g., also, for example, furthermore) and Contingency (e.g., as a result, hence, because) are likely to indicate sentiment coherence; discourse connectives with the sense of Comparison (e.g., but, however, nevertheless) are likely to indicate sentiment changes
p62
aVWe consider a set of polar sentences to be linked by the opinion coreference relation if they contain coreferring opinion-related entities
p63
aVFor documents where the higher-order constraints apply, we use the same Gibbs sampler as described above to infer the most likely label assignment, otherwise, we use the Viterbi algorithm
p64
aVThe desired value for the constraint expectation is set to 0 so that the model is encouraged to have less constraint violations
p65
aVIn our tables, boldface numbers are statistically significant by paired t-test for p 0.05 against the best baseline developed in this paper 7 7 Significance test was not conducted over the previous methods as we do not have their results for each fold
p66
aVWe extract lexical patterns that consist of polar words and negators 3 3 The polar words are identified using the MPQA lexicon and the negators are identified using a handful of seed words extended by the General Inquirer dictionary and WordNet as described in [ 2 ] and apply the heuristics based on compositional semantics [ 2 ] to assign a sentiment value to each pattern
p67
aVThe equality is not strictly enforced (due to the regularization in the PR objective 2
p68
aVEach constraint can be formulated as equality between the expectation of a constraint function value and a desired value set by prior knowledge
p69
aV2010 ) uses tree-CRF to model word interactions based on dependency tree structures; Choi and Cardie ( 2008 ) applies compositional inference rules to handle polarity reversal; Socher et al
p70
aVObtaining sentiment labels at the fine-grained level is costly
p71
aVDenote u'\u005cud835' u'\u005cudc31' as a sequence of sentences within a document and u'\u005cud835' u'\u005cudc32' as a vector of sentiment labels associated with u'\u005cud835' u'\u005cudc31'
p72
aVLexical Patterns The existence of a polarity-carrying word alone may not correctly indicate the polarity of the sentence, as the polarity can be reversed by other polarity-reversing words
p73
aVLexical patterns can be limited in capturing contextual information since they only look at interactions between words within an expression
p74
aVDocOracle performs much better than VoteFlip and performs especially well on the Music domain
p75
aVStill, their methods can encounter difficulty when the sentence on its own does not contain strong enough sentiment signals (due to the lack of statistical evidence or the requirement for background knowledge
p76
aVAs these opinion targets are coreferential (referring to the same entity u'\u005cu201c' the speaker phone u'\u005cu201d' ), they are linked by the opinion coreference relation 5 5 In general, the opinion-related entities include both the opinion targets and the opinion holders
p77
aVLeveraging both ideas, our approach exploits sentiment signals from both intra-sentential and inter-sentential context
p78
aVThe ability to extract sentiment from text is crucial for many opinion-mining applications such as opinion summarization, opinion question answering and opinion retrieval
p79
aVAccordingly, extracting sentiment at the fine-grained level (e.g., at the sentence- or phrase-level) has received increasing attention recently due to its challenging nature and its importance in supporting these opinion analysis tasks [ 18 ]
p80
aVExisting machine learning approaches for the task can be classified based on the use of two ideas
p81
aVThe opinion holders can be included in a similar way as the opinion targets
p82
aVSince the possible label assignments only differ at position i , we can make the computation efficient by maintaining the structure of the coreference clusters and precomputing the constraint function for different types of violations
p83
aVThe constraint function can be written as
p84
aVListing Patterns Another type of coherence relations we observe in online reviews is listing, where a reviewer expresses his/her opinions by listing a series of statements followed by a sequence of numbers
p85
aVMy favorite features are the speaker phone and the radio
p86
aVSolving the minimization problem is equivalent to solving its dual since the objective is convex
p87
aVIn this work, we only consider the targets since we experiment with single-author product reviews
p88
aVWe use L2 norm because it works well in practice u'\u005cu0392' is a regularization constant for the constraint violations
p89
aVWe can derive q by solving the dual problem in 3
p90
aVFor example, the following sentences express opinions towards u'\u005cu201c' the speaker phone u'\u005cu201d' , u'\u005cu201c' The speaker phone u'\u005cu201d' and u'\u005cu201c' it u'\u005cu201d' respectively
p91
aVOur approach is also semi-supervised
p92
a.