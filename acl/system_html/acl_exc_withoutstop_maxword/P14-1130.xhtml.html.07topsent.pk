(lp0
VWe compare our model to MST and Turbo parsers on non-projective dependency parsing
p1
aVBy taking the cross-product of all these component feature vectors, we obtain the full feature representation for arc h u'\u005cu2192' m as a rank-1 tensor
p2
aVWe will commence here by casting first-order dependency parsing as a tensor estimation problem
p3
aVIn contrast, we expand features for parsing into a multi-way tensor, and operate with an explicit low-rank representation of the associated parameter tensor
p4
aVOur parsing model aims to combine the strengths of both traditional features from the MST/Turbo parser as well as the new low-rank tensor features
p5
aVFrom a computational perspective, adding non-sparse vectors directly as features, including their combinations, can significantly increase the number of active features for scoring syntactic structures (e.g.,, dependency arc
p6
aVOur parameters are divided into a sparse set corresponding to manually chosen MST or Turbo parser features and a larger set governed by a low-rank tensor
p7
aVOur model outperforms Turbo parser, MST parser, as well as its own variants without the tensor component
p8
aVWe expect a dependency parsing model to benefit from several
p9
a.