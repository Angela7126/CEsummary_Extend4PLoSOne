<html>
<head>
<title>P14-1029.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>By examining sentiment compositions of negators and arguments, we model the quantitative behavior of negators in changing sentiment</a>
<a name="1">[1]</a> <a href="#1" id=1>Note that the two neural network based models incorporate the syntax and semantics by representing each node with a vector</a>
<a name="2">[2]</a> <a href="#2" id=2>A recursive neural tensor network (RNTN) is a specific form of feed-forward neural network based on syntactic (phrasal-structure) parse tree to conduct compositional sentiment analysis</a>
<a name="3">[3]</a> <a href="#3" id=3>Following the idea of , we regard the sentiment of p 1 as a prior sentiment as it has not been affected by the specific context (negators), so we denote our method as prior sentiment-enriched tensor network (PSTN</a>
<a name="4">[4]</a> <a href="#4" id=4>As we have discussed above, we will use the human annotated sentiment for the arguments, same as in the models discussed in Section 3</a>
<a name="5">[5]</a> <a href="#5" id=5>That is, the model parameters are only based on the sentiment value of the arguments</a>
<a name="6">[6]</a> <a href="#6" id=6>The original RNTN and the PSTN predict 5-class sentiment for each negated phrase; we map the output to real-valued scores based on the scale that used to map real-valued sentiment scores to sentiment categories</a>
<a name="7">[7]</a> <a href="#7" id=7>Data As described earlier, the Stanford Sentiment Treebank [] has manually annotated, real-valued sentiment values for all phrases in parse trees</a>
<a name="8">[8]</a> <a href="#8" id=8>During the derivative computation, the two errors will be summed up as the complement incoming error for</a>
</body>
</html>