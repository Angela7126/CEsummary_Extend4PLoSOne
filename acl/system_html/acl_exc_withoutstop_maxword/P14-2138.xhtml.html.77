<html>
<head>
<title>P14-2138.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The results of this experiment are reported in the Indicative Bigrams column of Table 2</a>
<a name="1">[1]</a> <a href="#1" id=1>The words that are identified as the most discriminative include function words, punctuation, very common content words, and the toponymic terms</a>
<a name="2">[2]</a> <a href="#2" id=2>Using Algorithm 2 , we identify the top 20 character bigrams, and replace them with randomly selected bigrams</a>
<a name="3">[3]</a> <a href="#3" id=3>We replicate the experiments of Tsur and Rappoport ( 2007 ) by limiting the features to the 200 most frequent character bigrams</a>
<a name="4">[4]</a> <a href="#4" id=4>For example, if we train the classifier using words as features, with values representing their frequency relative to the length of the document, the features corresponding to the word China might receive the following weights</a>
<a name="5">[5]</a> <a href="#5" id=5>There is no doubt that the toponymic terms are useful for increasing the NLI accuracy; however, from the psycho-linguistic perspective, we are more interested in what characteristics of L1 show up in L2 texts</a>
<a name="6">[6]</a> <a href="#6" id=6>The remaining bigrams indicate function words, toponymic terms like Germany , and frequent content words like take and new</a>
<a name="7">[7]</a> <a href="#7" id=7>The results are shown in the Baseline column of Table 2</a>
<a name="8">[8]</a> <a href="#8" id=8>Using Algorithm 2 , we identify the 100 most discriminative words, and remove them from the training data</a>
<a name="9">[9]</a> <a href="#9" id=9>However, the fact that the two bigrams are also on the list for the I2 set, which does not include these languages, suggests that their importance is mostly due to the function words</a>
<a name="10">[10]</a> <a href="#10" id=10>We conclude that character bigrams are effective in determining</a>
</body>
</html>