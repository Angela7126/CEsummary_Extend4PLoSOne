<html>
<head>
<title>P14-2122.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Two monolingual corpora and two bilingual corpora are used (Table 2</a>
<a name="1">[1]</a> <a href="#1" id=1>The time cost of the bilingual models is about 5 times that of the monolingual model, which is consistent with the complexity analysis in Section 3</a>
<a name="2">[2]</a> <a href="#2" id=2>We now look in more detail at the complexity of the expectation calculation in monolingual and bilingual models</a>
<a name="3">[3]</a> <a href="#3" id=3>The bilingual model is</a>
<a name="4">[4]</a> <a href="#4" id=4>The proposed method with monolingual bigram model performed poorly on the Chinese monolingual segmentation task; thus, it was not tested</a>
<a name="5">[5]</a> <a href="#5" id=5>It was set to 3 for the monolingual unigram model, and 2 for the bilingual unigram model, which provided slightly higher BLEU scores on the development set than the other settings</a>
<a name="6">[6]</a> <a href="#6" id=6>However, bilingual approaches that model word probabilities suffer from computational complexity</a>
<a name="7">[7]</a> <a href="#7" id=7>The monolingual model u'\u2133' is</a>
<a name="8">[8]</a> <a href="#8" id=8>[] proposed a bilingual method by adding alignment into the generative model, but was only able to test it on small-scale BTEC data</a>
<a name="9">[9]</a> <a href="#9" id=9>This section describes our unified monolingual and bilingual UWS scheme</a>
<a name="10">[10]</a> <a href="#10" id=10>For the monolingual bigram model, the number of states in the HMM is U times more than that of the monolingual unigram model, as the states at specific position of F are not only</a>
</body>
</html>