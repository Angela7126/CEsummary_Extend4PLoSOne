(lp0
VThis drastically limits which languages SMT can be successfully applied to
p1
aVBecause of this, collecting parallel corpora for minor languages has become an interesting research challenge
p2
aVThis allows us to compare the BLEU score achieved by our methods against the BLEU scores achievable by professional translators
p3
aVSince we have four professional translation sets, we can calculate the Bilingual Evaluation Understudy (BLEU) score [ 27 ] for one professional translator (P1) using the other three (P2,3,4) as a reference set
p4
aVUntil relatively recently, little consideration has been given to creating parallel data from scratch
p5
aVIn the following sections, we evaluate each of our methods by calculating BLEU scores against the same four sets of three reference translations
p6
aVUsing the raw translations without post-editing, our graph-based ranking method achieves a BLEU score of 38.89, compared to Zaidan and Callison-Burch ( 2011 ) u'\u005cu2019' s reported score of 28.13, which they achieved using a
p7
a.