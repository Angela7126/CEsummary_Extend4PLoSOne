(lp0
VWe aim to leverage existing, possibly noisy sets of representative stative, dynamic or mixed verb types extracted from LCS (see section 3 ), making up for unseen verbs and noise by averaging over distributional similarities
p1
aVIn addition, we show that type-based features, including novel distributional features based on representative verbs, accurately predict predominant aspectual class for unseen verb types
p2
aVIn contrast to Siegel and McKeown ( 2000 ) , we do not conduct the task of predicting aspectual class solely at the type level, as such an approach ignores the minority class of ambiguous verbs
p3
aVOur work differs from prior work in that we treat the problem as a three-way classification task, predicting dynamic , stative or both as the aspectual class of a verb in context
p4
aVUsing an existing large distributional model [ 31 ] estimated over the set of Gigaword documents marked as stories, for each verb type, we build a syntactically informed vector representing the contexts in which the verb occurs
p5
aVSince then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank [ 25 ] and the TempEval challenges [ 34 , 35
p6
a.