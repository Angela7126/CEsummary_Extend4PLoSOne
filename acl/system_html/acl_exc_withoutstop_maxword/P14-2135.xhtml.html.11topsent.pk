(lp0
VFormally, we propose a measure, image dispersion d of a concept word w , defined as the average pairwise cosine distance between all the image representations { w 1 u'\u005cu2192' u'\u005cu2062' u'\u005cu2026' u'\u005cu2062' w n u'\u005cu2192' } in the set of images for that concept
p1
aVTo evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u'\u005cu222a' C introduced in Section 2
p2
aVWe apply Pyramid Histogram Of visual Words (PHOW) descriptors, which are particularly well-suited for object categorization, a key component of image similarity and thus dispersion [ 5 ]
p3
aVWordSim has been used as a benchmark for distributional semantic models in numerous studies (see e.g., [ 15 , 6 ]
p4
aVMulti-modal models in which perceptual input is filtered according to our algorithm learn higher-quality semantic representations than previous approaches, resulting in a significant performance improvement of up to 17% in capturing the semantic similarity of concepts
p5
aVThe filtering approach described thus far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts
p6
aVSince perceptual data sources typically contain
p7
a.