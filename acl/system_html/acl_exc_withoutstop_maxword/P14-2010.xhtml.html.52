<html>
<head>
<title>P14-2010.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Singular Value Decomposition (SVD) is then performed on the sprinkled training documents and a lower rank approximation is constructed by ignoring dimensions corresponding to lower singular values</a>
<a name="1">[1]</a> <a href="#1" id=1>As LDA uses higher order word associations [] while discovering topics, we hypothesize that sprinkling will improve text classification performance of ClassifyLDA</a>
<a name="2">[2]</a> <a href="#2" id=2>[] used LDA topics as features in text classification, but they use labeled documents while learning a classifier sLDA [] , DiscLDA [] and MedLDA [] are few extensions of LDA which model both class labels and words in the documents</a>
<a name="3">[3]</a> <a href="#3" id=3>If the annotator assigns a wrong class label to a topic representing multiple classes (e.g., first topic in Table 3), then it may affect the performance of the resulting classifier</a>
<a name="4">[4]</a> <a href="#4" id=4>As LDA topics are semantically more meaningful than individual words and can be acquired easily, our approach overcomes limitations of the semi-supervised methods discussed above</a>
<a name="5">[5]</a> <a href="#5" id=5>Hence, our approach exerts a low cognitive load on the annotator, at the same time achieves text classification performance close to LDA-SVM which needs labeled documents</a>
<a name="6">[6]</a> <a href="#6" id=6>The basic idea involves encoding of class labels as artificial words which are u'\u201c' sprinkled u'\u201d' (appended) to training documents</a>
<a name="7">[7]</a> <a href="#7" id=7>In this approach, a topic model on</a>
</body>
</html>