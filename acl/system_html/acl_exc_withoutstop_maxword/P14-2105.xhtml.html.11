<html>
<head>
<title>P14-2105.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The answer to the question can thus be derived by finding the relation u'\u2013' entity triple r u'\u2062' ( e 1 , e 2 ) in the KB and returning the entity not mentioned in the question</a>
<a name="1">[1]</a> <a href="#1" id=1>2013 ) , we train two semantic similarity models one links a mention from the question to an entity in the KB and the other maps a relation pattern to a relation</a>
<a name="2">[2]</a> <a href="#2" id=2>By using a general semantic similarity model to match patterns and relations, as well as mentions and entities, our system outperforms the existing rule learning system, Paralex [ 7 ] , with higher precision at all the recall points when answering the questions in the same test set</a>
<a name="3">[3]</a> <a href="#3" id=3>An example of a single-relation question is u'\u201c' When were DVD players invented u'\u201d' The entity is dvd-player and the relation is be-invent-in</a>
<a name="4">[4]</a> <a href="#4" id=4>If an exact match was found, then the pattern would be derived by replacing the mention in the question with the special symbol</a>
<a name="5">[5]</a> <a href="#5" id=5>To train our two CNN semantic models, we derived two parallel corpora based on the Paralex training data</a>
<a name="6">[6]</a> <a href="#6" id=6>The semantic relevance score between a pattern Q and a relation R is defined as the cosine</a>
</body>
</html>