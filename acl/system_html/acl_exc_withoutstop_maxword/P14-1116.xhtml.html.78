<html>
<head>
<title>P14-1116.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We frame content selection as a simple classification task given a set of time-series data, decide for each template whether it should be included in a summary or not</a>
<a name="1">[1]</a> <a href="#1" id=1>Content selection decisions based on trends in time-series data determine the selection of the useful and important variables, which we refer to here as factors , that should be conveyed in a summary</a>
<a name="2">[2]</a> <a href="#2" id=2>Here, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously []</a>
<a name="3">[3]</a> <a href="#3" id=3>Content is regarded as labels (each template represents a label) and thus the task can be thought of as a classification problem</a>
<a name="4">[4]</a> <a href="#4" id=4>Ensemble methods [] are algorithms that use ensembles to perform ML learning and they are based on problem transformation or algorithm adaptation methods</a>
<a name="5">[5]</a> <a href="#5" id=5>ML classification achieved significantly higher accuracy, which was expected as it is a supervised learning method</a>
<a name="6">[6]</a> <a href="#6" id=6>RAkEL is based on Label Powerset (LP), a problem transformation method []</a>
<a name="7">[7]</a> <a href="#7" id=7>We compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with student users</a>
<a name="8">[8]</a> <a href="#8" id=8>Our contributions to the field are as follows we present a novel and efficient method for tackling the challenge of content selection using a ML classification approach; we applied this method to the domain of feedback summarisation; we present a comparison with an optimisation technique (Reinforcement Learning), and we discuss the similarities and differences between the two methods</a>
<a name="9">[9]</a> <a href="#9" id=9>RL is trained to optimise for this function, and therefore</a>
</body>
</html>