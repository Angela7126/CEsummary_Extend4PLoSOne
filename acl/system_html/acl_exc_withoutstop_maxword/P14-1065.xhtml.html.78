<html>
<head>
<title>P14-1065.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Note that the Asiya metrics are combinations of several metrics, and these combinations (which exclude DR and DR- lex ) can be also tuned; this yields sizable improvements over the untuned versions as column three in the table shows</a>
<a name="1">[1]</a> <a href="#1" id=1>Furthermore, when combined with individual metrics in group II, DR- lex is able to improve consistently over each one of them</a>
<a name="2">[2]</a> <a href="#2" id=2>Again, DR- lex is better than DR; with a positive Tau of +.133, yet as an individual metric, it ranks poorly compared to other metrics in group II</a>
<a name="3">[3]</a> <a href="#3" id=3>Individually, DR- lex outperforms most of the metrics from group II, and ranks as the second best metric in that group</a>
<a name="4">[4]</a> <a href="#4" id=4>In this paper, rather than proposing yet another MT evaluation metric, we show that discourse information is complementary to many existing evaluation metrics, and thus should not be ignored</a>
<a name="5">[5]</a> <a href="#5" id=5>This suggests that both DR and DR- lex contain information that is complementary to that of the individual metrics that we experimented with</a>
<a name="6">[6]</a> <a href="#6" id=6>However, over all metrics and all language pairs, DR- lex is able to obtain an average improvement in correlation of +.035, which is remarkably higher than that of DR</a>
<a name="7">[7]</a> <a href="#7" id=7>As an example, consider the three discourse trees (DTs) shown in Figure 4 a ) for a reference (human) translation, and ( b ) and ( c ) for translations of two different systems on the WMT12 test dataset</a>
<a name="8">[8]</a> <a href="#8" id=8>Interestingly, the tuned combinations that include the much weaker metric DR now improve over 12 out of 13 of the individual metrics in groups II and III, and only slightly degrades the score of the</a>
</body>
</html>