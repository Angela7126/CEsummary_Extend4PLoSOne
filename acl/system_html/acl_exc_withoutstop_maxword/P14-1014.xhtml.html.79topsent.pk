(lp0
VAs mentioned in Section 3.1, the knowledge learned from the WRRBM can be investigated incrementally, using word representation , which corresponds to initializing only the projection layer of web-feature module with the projection matrix of the learned WRRBM, or ngram-level representation , which corresponds to initializing both the projection and sigmoid layers of the web-feature module by the learned WRRBM
p1
aVThis can be achieved by initializing only the first layer of the web module with the projection matrix u'\u005cud835' u'\u005cudc03' of the learned WRRBM
p2
aVWe integrate the learned encoder with a set of well-established features for POS tagging [ 21 , 5 ] in a single neural network, which is applied as a scorer to an easy-first POS tagger
p3
aVThis can be achieved by also initializing the parameters of the second layer of the web-feature module using the position-dependent weight matrix and hidden bias of the learned WRRBM
p4
aVHowever, since fine-tuning is conducted with respect to
p5
a.