<html>
<head>
<title>P14-1146.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>To this end, we extend the existing word embedding learning algorithm [ 9 ] and develop three neural networks to effectively incorporate the supervision from sentiment polarity of text (e.g., sentences or tweets) in their loss functions</a>
<a name="1">[1]</a> <a href="#1" id=1>Socher et al propose Recursive Neural Network (RNN) [ 38 ] , matrix-vector RNN [ 37 ] and Recursive Neural Tensor Network (RNTN) [ 40 ] to learn the compositionality of phrases of any length based on the representation of each pair of children recursively</a>
<a name="2">[2]</a> <a href="#2" id=2>The reason is that RAE and NBSVM learn the representation of tweets from the small-scale manually annotated training set, which cannot well capture the comprehensive linguistic phenomenons of words</a>
<a name="3">[3]</a> <a href="#3" id=3>Many studies on Twitter sentiment classification [ 32 , 10 , 1 , 22 , 48 ] leverage massive noisy-labeled tweets selected by positive and negative emoticons as training set and build sentiment classifiers directly, which is called distant supervision [ 17 ]</a>
<a name="4">[4]</a> <a href="#4" id=4>NRC builds the top-performed system in SemEval 2013 Twitter sentiment classification track which incorporates diverse sentiment lexicons and many manually designed features</a>
<a name="5">[5]</a> <a href="#5" id=5>Twitter sentiment classification, which identifies the sentiment polarity of short, informal tweets, has attracted increasing research interest [ 21 , 20 ] in recent years</a>
<a name="6">[6]</a> <a href="#6" id=6>With the revival of interest in deep learning [ 2 ] , incorporating the continuous representation of a</a>
</body>
</html>