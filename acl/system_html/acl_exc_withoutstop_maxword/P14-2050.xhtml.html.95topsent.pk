(lp0
VA very common paradigm for acquiring such representations is based on the distributional hypothesis of Harris [ 16 ] , stating that words in similar contexts have similar meanings
p1
aVBased on the distributional hypothesis, many methods of deriving word representations were explored in the NLP community
p2
aVWe thus seek a representation that captures semantic and syntactic similarities between words
p3
aVWord representation is central to natural language processing
p4
aVThe default approach of representing words as discrete and distinct symbols is insufficient for many tasks, and suffers from poor generalization
p5
aVThe next two examples demonstrate that similarities induced from Deps share a syntactic function (adjectives and gerunds), while similarities based on BoW are more diverse
p6
aVAn alternative to the bag-of-words approach is to derive contexts based on the syntactic relations the word
p7
a.