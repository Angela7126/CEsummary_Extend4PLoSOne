(lp0
VWhen the induced projection function maps an object onto the linguistic space, the derived text vector will inherit a mixture of textual features from the concepts that activated the same hidden unit as the object
p1
aVFor fast mapping, we report the mean rank of the correct concept among fast mapping candidates
p2
aVWe use a set of approximately 9,500 concepts, the intersection of the ESP-based visual semantic space with the linguistic space
p3
aVFor the zero-shot task we report the accuracy of retrieving the correct label among the top k neighbors from a semantic space populated with the union of seen and unseen concepts
p4
aVObjects corresponding to concepts are represented in visual terms by vectors in an image-based semantic space (Section 4.2
p5
aVTable 3 presents both seen and unseen concepts corresponding to visual vectors that trigger the highest activation for a subset of hidden units
p6
aVIn both tasks, the projected vector of the unseen concept is labeled with the word associated to its cosine-based nearest neighbor vector in the corresponding semantic space
p7
aVThe process of learning to map objects to the their word label is implemented by training a projection function f proj v u'\u005cu2192' w from the visual onto the linguistic semantic space
p8
aVThe table further reports, for each hidden unit, the u'\u005cu201c' correct u'\u005cu201d' unseen concept for the category of the top seen concepts, together with its rank in terms of activation of the unit
p9
aVConcretely, we assume that concepts, denoted for convenience by word labels, are represented in linguistic terms by vectors in a text-based distributional semantic space (see Section 4.3
p10
aVThe zero-shot framework leads us to frame fast mapping as the task of projecting visual representations of new objects onto language space for retrieving their word labels ( v u'\u005cu2192'
p11
a.