<html>
<head>
<title>P14-2138.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The words that are identified as the most discriminative include function words, punctuation, very common content words, and the toponymic terms</a>
<a name="1">[1]</a> <a href="#1" id=1>The results of this experiment are reported in the Indicative Bigrams column of Table 2</a>
<a name="2">[2]</a> <a href="#2" id=2>Using Algorithm 2 , we identify the top 20 character bigrams, and replace them with randomly selected bigrams</a>
<a name="3">[3]</a> <a href="#3" id=3>Using Algorithm 2 , we identify the 100 most discriminative words, and remove them from the training data</a>
<a name="4">[4]</a> <a href="#4" id=4>The results are shown in the Baseline column of Table 2</a>
<a name="5">[5]</a> <a href="#5" id=5>The remaining bigrams indicate function words, toponymic terms like Germany , and frequent content words like take and new</a>
<a name="6">[6]</a> <a href="#6" id=6>We replicate the experiments of Tsur and Rappoport ( 2007 ) by limiting the features to the 200 most frequent character bigrams</a>
<a name="7">[7]</a> <a href="#7" id=7>However, the fact that the two bigrams are also on the list for the I2 set, which does not include these languages, suggests that their importance is mostly due to the function words</a>
<a name="8">[8]</a> <a href="#8" id=8>Therefore, we calculate the importance score for each character bigram by multiplying the scores of each word in which the bigram occurs</a>
<a name="9">[9]</a> <a href="#9" id=9>For example, if we train the classifier using words as features, with values representing their frequency relative to the length of the document, the features corresponding to the word China might receive the following weights</a>
<a name="10">[10]</a> <a href="#10" id=10>However, we limit the set of features to the 200 most frequent bigrams for the sake of consistency with previous work</a>
</body>
</html>