(lp0
VWhile choosing arg u'\u005cu2062' max of the posterior probability is an optimal decision rule in theory, in practice it might not be optimal, due to limitations of the language and error modeling
p1
aVAs any local search method, iterative correction is prone to local minima, stopping before reaching the correct word
p2
aVA common method of avoiding local minima in optimization is the simulated annealing algorithm, key ideas from which can be adapted for spelling correction task
p3
aVIterative correction is hill climbing in the space of possible corrections on each iteration we make a transition to the best point in the neighbourhood, i.e., to correction, that has maximal posterior probability P ( c q
p4
aVExample if we start a random walk from vobemzin and make 3 steps, we most probably will end up in the correct form wobenzym with
p5
a.