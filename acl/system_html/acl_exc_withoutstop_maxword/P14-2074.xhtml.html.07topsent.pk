(lp0
VThe automatic measures are calculated on the sentence level and correlated against human judgements of semantic correctness
p1
aVIn this paper we estimate the correlation of human judgements with five automatic evaluation measures on two image description data sets
p2
aVThe main finding of our analysis is that ter and unigram bleu are weakly correlated against human judgements, rouge-su4 and Smoothed bleu are moderately correlated, and the strongest correlation is found with Meteor
p3
aVSmoothed bleu and rouge-su4 are moderately correlated with human judgements, and the correlation is stronger than with unigram bleu
p4
aVOn the Flickr8k data set, all evaluation measures can be classified as either weakly correlated or moderately correlated with human judgements and all results are significant ter is only weakly correlated with human judgements but could prove useful in comparing the types of differences between models
p5
aVWe estimate Spearman u'\u005cu2019' s u'\u005cu03a1' for five different automatic evaluation measures against human judgements for the automatic image description task
p6
aVTable 1 shows the correlation co-efficients between automatic measures and human judgements and Figures 2 (a) and (b) show the distribution of scores for each measure against human judgements
p7
aVFinally, Meteor is most strongly correlated measure against human judgements
p8
aVAn analysis of the distribution of ter scores in Figure 2 (a) shows that differences in candidate and reference length are prevalent in the image description task
p9
aVFigure 3 shows two images from the test collection of the
p10
a.