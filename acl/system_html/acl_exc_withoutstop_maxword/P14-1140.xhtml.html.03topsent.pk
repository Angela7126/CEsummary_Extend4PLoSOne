(lp0
VSo as to model the translation confidence for a translation phrase pair, we initialize the phrase pair embedding by leveraging the sparse features and recurrent neural network
p1
aVIn this section, we split the phrase pair embedding into two parts to model the translation confidence directly translation confidence with sparse features and translation confidence with recurrent neural network
p2
aVWe first get two translation confidence vectors separately using sparse features and recurrent neural network, and then concatenate them to be the phrase pair embedding
p3
aVWord embedding is used as the input to learn translation confidence score, which is combined with commonly used features in the conventional log-linear model
p4
aV2013 ) propose a joint language and translation model, based on a recurrent neural network
p5
aVWe use recurrent neural network to generate two smoothed translation confidence scores based on source and target word embeddings
p6
aVThe commonly used features, such as translation score, language model score and distortion score, are used as the recurrent input vector x
p7
aV2013 ) extend the recurrent neural network language model, in order to use both the source and target side information to scoring translation candidates
p8
aVWe also explore phrase pair embedding method to model
p9
a.