<html>
<head>
<title>P14-1101.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>If a word token is assigned to a lexeme, x i = u'\u2113' , the vowels within the word are assigned to that lexeme u'\u2019' s vowel categories, w i u'\u2062' j = v u'\u2113' u'\u2062' j = c</a>
<a name="1">[1]</a> <a href="#1" id=1>This is the baseline IGMM model, which clusters vowel tokens using bottom-up distributional information only; the LD model adds top-down information by assigning categories in the lexicon, rather than on the token level</a>
<a name="2">[2]</a> <a href="#2" id=2>To demonstrate the benefit of situational information, we develop the Topic-Lexical-Distributional (TLD) model, which extends the LD model by assuming that words appear in situations analogous to documents in a topic model</a>
<a name="3">[3]</a> <a href="#3" id=3>Again performance decreases as the consonant categories become coarser, but the additional semantic information in the TLD model compensates for the lack of consonant information</a>
<a name="4">[4]</a> <a href="#4" id=4>Each such lexeme is represented as a frame plus a list of vowel categories u'\ud835' u'\udc97' u'\u2113'</a>
<a name="5">[5]</a> <a href="#5" id=5>The TLD model retains the IGMM vowel phone component, but extends the lexicon of the LD model by adding topic-specific lexicons, which capture the notion that lexeme probabilities are topic-dependent</a>
<a name="6">[6]</a> <a href="#6" id=6>We compare all three models u'\u2014' TLD, LD, and IGMM u'\u2014' on the vowel categorization task, and TLD and LD on the lexical categorization task (since IGMM does not infer a lexicon</a>
<a name="7">[7]</a> <a href="#7" id=7>Overall, the contextual semantic information added in the TLD model leads to both better phonetic categorization and to a better protolexicon, especially when the input is noisier, using degraded consonants</a>
<a name="8">[8]</a> <a href="#8" id=8>G L u'\u223c' D u'\u2062' P u'\u2062' ( u'\u0391' l , H L ) (see Section 3.2 ; remember H L includes draws from the IGMM over vowel categories</a>
<a name="9">[9]</a> <a href="#9" id=9>When two word tokens contain the same consonant frame but different vowels (i.e.,, minimal pairs), the model is more likely to categorize those two vowels together</a>
<a name="10">[10]</a> <a href="#10" id=10>In this paper we explore the potential contribution of semantic information to phonetic learning by formalizing a model in which learners attend to the word-level context in which phones appear (as in the lexical-phonetic learning model of 11</a>
</body>
</html>