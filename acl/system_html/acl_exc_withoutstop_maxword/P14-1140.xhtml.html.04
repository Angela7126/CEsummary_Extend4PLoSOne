<html>
<head>
<title>P14-1140.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In this section, we split the phrase pair embedding into two parts to model the translation confidence directly translation confidence with sparse features and translation confidence with recurrent neural network</a>
<a name="1">[1]</a> <a href="#1" id=1>So as to model the translation confidence for a translation phrase pair, we initialize the phrase pair embedding by leveraging the sparse features and recurrent neural network</a>
<a name="2">[2]</a> <a href="#2" id=2>The sparse features can directly model the translation correspondence, and they may be more effective to rank the translation candidates, while recurrent neural network features are smoothed lexical translation confidence</a>
<a name="3">[3]</a> <a href="#3" id=3>And also, translation task is difference from other NLP tasks, that, it is more important to model the translation confidence directly (the confidence of one target phrase as a translation of the source phrase), and our TCBPPE is designed for such purpose</a>
<a name="4">[4]</a> <a href="#4" id=4>The sparse features are phrase pairs in translation table, and recurrent neural network is utilized to learn a smoothed translation score with the source and target side information</a>
<a name="5">[5]</a> <a href="#5" id=5>Word embedding can model translation relationship at word level, but it may not be powerful to model the phrase pair respondents at phrasal level, since the meaning of some phrases cannot be decomposed into the meaning of words</a>
</body>
</html>