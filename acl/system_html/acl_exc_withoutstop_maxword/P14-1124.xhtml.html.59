<html>
<head>
<title>P14-1124.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The first illustration of word burstiness can be seen by plotting observed inverse document frequency, IDF w , versus f w in the log domain (Figure 7</a>
<a name="1">[1]</a> <a href="#1" id=1>Looking close to the y -axis in Figure 9 , we observe a second class of exclusively low frequency words whose burstiness ranges from highly concentrated to singletons</a>
<a name="2">[2]</a> <a href="#2" id=2>However, considering this estimate in light of the two classes of words in Figure 9 , there are clearly words in Class B with high burstiness that will be ignored by trying to compensate for the high adaptation variability in the low-frequency range</a>
<a name="3">[3]</a> <a href="#3" id=3>Close examination of DF statistics by Church and Gale in their work on Poisson Mixtures (1995) resulted in an analysis of the burstiness of content words</a>
<a name="4">[4]</a> <a href="#4" id=4>In applying the burstiness quantity to term detection, we recall that the task requires us to locate a particular instance of a term, not estimate a count, hence the utility of N-gram language models predicting words in sequence</a>
<a name="5">[5]</a> <a href="#5" id=5>The typical use of Document Frequency ( DF ) in information retrieval or text categorization is to emphasize words that occur in</a>
</body>
</html>