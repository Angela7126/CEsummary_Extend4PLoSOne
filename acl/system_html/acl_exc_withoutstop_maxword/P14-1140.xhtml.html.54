<html>
<head>
<title>P14-1140.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>So as to model the translation confidence for a translation phrase pair, we initialize the phrase pair embedding by leveraging the sparse features and recurrent neural network</a>
<a name="1">[1]</a> <a href="#1" id=1>And also, translation task is difference from other NLP tasks, that, it is more important to model the translation confidence directly (the confidence of one target phrase as a translation of the source phrase), and our TCBPPE is designed for such purpose</a>
<a name="2">[2]</a> <a href="#2" id=2>Word embedding can model translation relationship at word level, but it may not be powerful to model the phrase pair respondents at phrasal level, since the meaning of some phrases cannot be decomposed into the meaning of words</a>
<a name="3">[3]</a> <a href="#3" id=3>In order to integrate these crucial information for better translation prediction, we combine recurrent neural networks into the recursive neural networks, so that we can use global information to generate the next hidden state, and select the better translation candidate</a>
<a name="4">[4]</a> <a href="#4" id=4>So as to integrate such global information, and also keep the ability to generate tree structure, we combine the recurrent neural network and the recursive neural network to be a recursive recurrent neural network (R 2 NN</a>
<a name="5">[5]</a> <a href="#5" id=5>We propose a three-step semi-supervised training approach to optimizing the parameters</a>
</body>
</html>