(lp0
VObjects corresponding to concepts are represented in visual terms by vectors in an image-based semantic space (Section 4.2
p1
aV2013 ) use linear regression to transform vector-based image representations onto vectors representing the same concepts in linguistic semantic space
p2
aVThe process of learning to map objects to the their word label is implemented by training a projection function f proj v u'\u005cu2192' w from the visual onto the linguistic semantic space
p3
aVWhen the induced projection function maps an object onto the linguistic space, the derived text vector will inherit a mixture of textual features from the concepts that activated the same hidden unit as the object
p4
aVWe use a set of approximately 9,500 concepts, the intersection of the ESP-based visual semantic space with the linguistic space
p5
aVSocher et al
p6
aVSocher et al
p7
aVUnlike Socher et al
p8
aVConcretely, we assume that concepts, denoted for convenience by word labels, are represented in linguistic terms by vectors in a text-based distributional semantic space (see Section 4.3
p9
aVIn this setting, we assume that our system possesses linguistic and visual information for a set of concepts in the form of text-based representations of words and image-based vectors of the corresponding objects, used for vision-to-language-mapping training
p10
aVThe zero-shot framework leads us to frame fast mapping as the task of projecting visual representations of new objects onto language space for retrieving their word labels ( v u'\u005cu2192' w
p11
aVThis object is projected onto the linguistic space and associated with the word label of the nearest neighbor in that space ( degus in Figure 1
p12
aV2013 ) and the current study that adopt simple unsupervised techniques for constructing image representations, Frome et al
p13
aVWhereas for the latter our system assumes that all concepts have rich linguistic representations (i.e.,, representations estimated from
p14
a.