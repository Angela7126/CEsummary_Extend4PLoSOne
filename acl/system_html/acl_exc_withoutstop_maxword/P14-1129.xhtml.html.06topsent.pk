(lp0
VThis notion of affiliation is derived from the word alignment, but unlike word alignment, each target word must be affiliated with exactly one non-NULL source word
p1
aVFormally, our model approximates the probability of target hypothesis T conditioned on source sentence S
p2
aVSpecifically, we introduce a novel formulation for a neural network joint model (NNJM), which augments an n -gram target language model with an m -word source window
p3
aVWe follow the standard n -gram LM decomposition of the target, where each target word t i is conditioned on the previous n - 1 target words
p4
aVThe input vector is a 14-word context vector (3 target words, 11 source words), where each word is mapped to a 192-dimensional vector using a shared mapping layer
p5
aVWe treat NULL as a normal target word, and if a source word aligns to multiple target words, it is treated as a single concatenated token
p6
aVThe probability is computed over every source word in the input sentence
p7
aVOne issue with the S2T NNJM is that the
p8
a.