(lp0
VAs an instance of discriminative models, we describe an FFNN-based word alignment model [ 40 ] , which is our baseline
p1
aVIn the lookup layer, each of these words is converted to its word embedding, and then the concatenation of the two embeddings ( x j ) is fed to the hidden layer in the same manner as the FFNN-based model
p2
aVFor the FFNN-based model, we set the word embedding length M to 30, the number of units of a hidden layer z 1 to 100, and the window size of contexts to 5
p3
aVNote that alignments in the FFNN-based model are also governed by first-order Markov dynamics because an alignment score depends on the previous alignment a j - 1
p4
aVThe alignment model based on an FFNN is formed in the same manner as the lexical translation model
p5
aVNote that the development data was not used in the alignment tasks, i.e.,, B u'\u005cu2062' T u'\u005cu2062' E u'\u005cu2062' C and H u'\u005cu2062' a u'\u005cu2062' n u'\u005cu2062' s u'\u005cu2062' a u'\u005cu2062' r u'\u005cu2062' d u'\u005cu2062' s , because the hyperparameters of the alignment models were set by preliminary small-scale experiments
p6
aVFor the RNN-based models, we set M to 30 and
p7
a.