(lp0
VWe compare our model to MST and Turbo parsers on non-projective dependency parsing
p1
aVFrom a computational perspective, adding non-sparse vectors directly as features, including their combinations, can significantly increase the number of active features for scoring syntactic structures (e.g.,, dependency arc
p2
aVIn contrast, we represent words as vectors in a manner that is directly optimized for parsing
p3
aVEnglish has 50 dimensional word vectors, while German and Swedish have 25 dimensional word vectors
p4
aVBy taking the cross-product of all these component feature vectors, we obtain the full feature representation for arc h u'\u005cu2192' m as a rank-1 tensor
p5
aVWe begin by representing high-dimensional feature vectors as multi-way cross-products of smaller feature vectors that represent words and their syntactic relations (arcs
p6
aVThis framework enables us to learn new syntactically guided embeddings while also leveraging separately estimated word vectors as starting features, leading to improved parsing performance
p7
aVFinally, we demonstrate that the model can successfully leverage word vector representations, in contrast to the baselines
p8
aVTo assess the ability of our model to incorporate a range of features, we add unsupervised word vectors to
p9
a.