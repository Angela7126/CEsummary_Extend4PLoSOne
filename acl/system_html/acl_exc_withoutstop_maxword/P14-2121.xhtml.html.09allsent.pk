(lp0
VThe second experiment asks participants to label metaphoricity, this time including a distinction between slightly metaphoric and highly metaphoric sentences
p1
aVThe metaphoricity values for this experiment were calculated in the same way the percentage of participants who rated a sentence as highly metaphoric
p2
aVFor the first task, the binary identification task, the metaphoricity of a sentence was computed by taking the percentage of participants who identified it as metaphoric
p3
aVThe metaphoricity value was computed by taking the percentage of participants who identified a sentence as the most metaphoric of the three given sentences
p4
aVEach experiment had 100 participants and operationalized the task of rating metaphoricity in different ways across a representative section of domains, verbs, and metaphoricity levels
p5
aVThe participants were asked to order the sentences from the least metaphoric to the most metaphoric
p6
aVThe purpose of this is not to test a three-way distinction in metaphoricity values, but rather to improve the scale by moving intermediate sentences out of the Literal or Metaphoric categories
p7
aVRather, the purpose is to have a representative selection of metaphors rated for metaphoricity against which to test scalar measurements of metaphoricity
p8
aVThe idea here is that high metaphoricity is consciously available to participants, so that the more agreement there is about metaphor the more the participants are aware of the sentence u'\u005cu2019' s metaphoricity and thus the higher its metaphoricity value should be
p9
aVParticipants were given a sentence and asked to identify it as u'\u005cu201c' Literal u'\u005cu201d' or u'\u005cu201c' Metaphoric u'\u005cu201d' The second task tested speakers u'\u005cu2019' ability to consistently label a given sentence as u'\u005cu201c' Not Metaphoric u'\u005cu201d' , u'\u005cu201c' Slightly Metaphoric u'\u005cu201d' , and u'\u005cu201c' Very Metaphoric u'\u005cu201d' The additional label was added in order to provide participants with a middle ground between metaphoric and literal
p10
aVHowever, because sentences with the same main verb were forced into a three-way ordering, participants could not, for example, label two of the sentences as equally metaphoric
p11
aVAn experiment was conducted to set a standard for evaluating scalar measurements of metaphoricity
p12
aVIt should be noted that the purpose of the experiment is not to (1) test a three-way distinction between metaphoricity levels (which is simply used to ensure a representative selection of metaphors) or (2) test the author u'\u005cu2019' s intuitions of metaphoricity
p13
aVThe third task gathered ordering information by presenting participants with three sentences, all of which contained the same main verb
p14
aVThis measurement, summarized in Table 2, is more accurate at the lower end of the scale, with many sentences receiving a 0 because participants were able to choose a category other than metaphoric
p15
aVThis paper introduces a system for producing a scalar measurement of metaphoricity which places sentences anywhere between 0 (literal) and 1 (highly metaphoric
p16
aVThe third task tested speakers u'\u005cu2019' ability to consistently rank three sentences according to their metaphoricity
p17
aVThe first tested speakers u'\u005cu2019' ability to consistently separate metaphoric and non-metaphoric sentences
p18
aVThus, this measurement also is based on the idea that more participants will be consciously aware of highly metaphoric sentences, with a third category available to allow an extra distinction to be made
p19
aVThe resulting highly correlated measures show that we have a good standard of metaphoricity against which to evaluate computational models which produce scalar measurements of metaphoricity
p20
aVThe results of this first experiment are summarized in Table 1 with the mean, standard deviation, and range of the metaphoricity measurements
p21
aVEach task had 100 unique participants who gave valid answers, for a total of 300 participants
p22
aVThus, for the number x of metaphors in the genre, the x sentences with the top metaphoricity values were identified as metaphoric
p23
aVIn order to ensure comparability, each set of three sentences contained a literal, a slightly metaphoric, and a very metaphoric use of a single verb (e.g.,, three uses of u'\u005cu201c' butcher u'\u005cu201d'
p24
aVThis reflects a distinction in metaphoricity, although the extreme top and bottom of the scale are problematic
p25
aVParticipants did not see any domain information for the sentence prompts
p26
aVThis section has put forward a robust series of scalar measurements of metaphoricity
p27
aVAll participants were asked if they had attended a primary or elementary school conducted in English in order to ensure consistent language ability
p28
aVFurther, a test question was positioned part way through the survey to ensure that participants read the prompts correctly
p29
aVThe purpose of this task was to allow participants to directly compare different uses of the same verb
p30
aVThe results are strong on the low end of the scale, with every domain having sentences with either 0 values or close to 0 values
p31
aVThus, if all participants agreed that a sentence was metaphoric, then it receives a 1, while if half of the participants agreed, then it receives a 0.5
p32
aVThe purpose of this experiment was to give participants context in the form of other uses of a given verb against which to make their judgments
p33
aVParticipants were given eight questions for the identification and labeling tasks and four questions for the ranking task
p34
aVThis was done in order to keep the survey short and prevent participants from losing interest
p35
aVThe selection of various domains, verbs, and hypothesized metaphoricity levels helps to control for other factors, like abstractness, which might be only indirectly related to metaphoricity
p36
aVA corpus of 60 sentences of varying metaphoricity, drawn equally from four top-level domains ( physical, mental, social , and abstract ), was created using the Corpus of Contemporary American English
p37
aVFor example, it assigns the metaphoricity value of 0.833 to the sentence in (1), but a metaphoricity value of only 0.153 to the sentence in (2
p38
aVA scalar measurement of metaphoricity allows the threshold for metaphor in metaphor identification tasks to be fitted for specific purposes and datasets
p39
aVEach domain was represented by five verbs and each verb by three sentences one literal, one slightly metaphoric, and one very metaphoric (as judged by the author
p40
aVThese features were computed for each of the sentences used in the experiments and then the correlation between the features and the metaphoricity measurements were computed using Pearson u'\u005cu2019' s R
p41
aVThis measurement, shown in Table 3, has similar averages across domains, unlike the previous measurements
p42
aVThe high end is more problematic, with the highest values in each domain being below 0.9
p43
aVThis is a result of not having perfect agreement across all participants
p44
aVAt the same time, the values tend to be further from 1 at the upper end of the scale
p45
aVGiven these three experiments for measuring the metaphoricity of sentences, Table 4 shows the correlations between each measure using Pearson u'\u005cu2019' s R
p46
aVPrevious evaluations using this corpus (Dunn, 2013b) concluded that prepositions annotated as metaphoric in the corpus should not be considered metaphoric for computational purposes
p47
aVThe identification or detection task has been approached as a binary classification problem for a given unit of language (e.g.,, word, phrase, sentence) decide whether it is metaphoric or non-metaphoric
p48
aVFurther, we have also untagged the ambiguously metaphoric sentences
p49
aVThus, while the measurement makes distinctions at the top of the scale, it does not approach 1
p50
aVHowever, in spite of this, the measure makes a good distinction between utterances
p51
aVEach participant took a particular survey only once and the sentences to be rated were drawn randomly from the corpus
p52
aVThe goal is to produce a computationally derived measurement that models the gradient nature of metaphoricity, with the result that metaphors which are clearly and consciously seen as metaphors score closer to 1 and metaphors which are not realized by speakers to be metaphoric score further from 1
p53
aVIn other words, it seems clear that 18.5% of the BNC is not highly metaphoric, but rather is the sort of slightly metaphoric language that speakers are not consciously aware of because it is used so frequently
p54
aVThe sentence in (2) above, for example, received a 0; however, the sentence in (1) above received only a 0.571, which, while high given the range of values, is still far from 1
p55
aVThe single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language
p56
aVIt also ensures that the experiment covers a wide-range of metaphors
p57
aVThree survey tasks were used
p58
aVThis binary distinction assumes a clear boundary between the two; in other words, it assumes that metaphoricity is a discrete property
p59
aVFor the purposes of this evaluation, the threshold for metaphor was set independently for each genre and tied to the number of sentences containing metaphorically used words, as rated by the annotators of the corpus
p60
aVThe scalar system, however, was trained only on the experimental data and was not influenced by the evaluation corpus (except, of course, that it had access to the number of metaphoric sentences in the dataset, which is a parameter and not part of the model itself
p61
aVThus, it is possible that some of this advantage on the upper bound is a result of the task itself
p62
aVThose features which had a significant positive relationship with the experimental results, shown in Table 5, were added together to create a rough computational measure of metaphoricity and then converted so that they fall between 0 and 1
p63
aVThe most plausible interpretation of this psycholinguistic evidence is that most linguistic units fall somewhere between metaphoric and literal, so that metaphoricity is a scalar value which influences processing gradually (and is difficult to uncover because of related factors like salience; Giora, 2002
p64
aVThe binary classification system, with access to the full range of features, out-performs the scalar measurement in most cases
p65
aVThe evaluation dataset thus consists of 6,893 sentences, distributed as shown in Table 6
p66
aVThus, the scalar approach performs competitively on a binary task (0.608 vs
p67
aVThe surveys were conducted using the MechanicalTurk platform
p68
aVThis scalar measurement approach has two advantages
p69
aVHowever, three strands of theoretical research show that metaphoricity is not a discrete property
p70
aVIt is important to note, however, that the binary classification system requires labelled training data and is restricted to a single threshold of metaphoricity, in this case the threshold embedded in the corpus by the raters
p71
aVThus, metaphorically used prepositions have been untagged as metaphoric
p72
aV1) it adheres more closely to the current theoretical understanding of metaphor, thus being more cognitively accurate; (2) it allows applications to control the threshold of metaphoricity when identifying metaphor, thus allowing the treatment of metaphor to be optimized for a given task
p73
aVThe scalar system was evaluated on the VU Amsterdam Metaphor Corpus (Steen, et al., 2010) which consists of 200,000 words from the British National Corpus divided into four genres (academic, news, fiction, and spoken; performance on the spoken genre was not evaluated for this task because it consists of many short fragmentary utterances) and manually annotated for metaphor by five raters
p74
aVStarting with Wilks (1978), the problem of metaphor has been approached as an identification task first identify or detect metaphoric expressions and then (1) prevent them from interfering with computational treatments of literal expressions and (2) use them to gain additional insight about a text (e.g.,, Carbonell, 1980; Neuman Nave, 2009
p75
aVThe highest correlation is between the first and second tasks, at 0.819
p76
aVWe approach the problem by starting with an existing binary identification system and converting it to a scalar system
p77
aVThis illustrates the flexibility of such a scalar approach to metaphor identification
p78
aVThis gives a total of 41 features for each sentence
p79
aVOnly answers valid according to these two tests are considered in the following results
p80
aVHowever, this is still a high correlation
p81
aVFirst, the relative frequency of each value of each concept property in the sentence is determined; Second, the number of instances of the most common value for each property is determined, as well as the number of instances of all other values (both relativized to the number of concepts present in the sentence
p82
aVSentences with an insufficiently robust conceptual representation were removed (e.g.,, fragments
p83
aVFirst, psycholinguistic studies of metaphor processing show that there is no difference between the processing of metaphoric and non-metaphoric language (Coulson Matlock, 2001; Gibbs, 2002; Evans, 2010
p84
aVSecond, linguistic studies of metaphor have found that the metaphoricity of a linguistic unit can be predicted given certain factors (Dunn, 2011, 2013c
p85
aVIt tends to be better than the previous measures on the upper bound, likely because of the contextual comparison it allows
p86
aVThe next section introduces such a system
p87
aVThe baseline results are taken from a binary classification evaluation of the corpus using the full set of 41 features produced by the system and evaluated using the logistic regression algorithm with 100-fold cross-validation
p88
aVThe first step is to increase the robustness of the system u'\u005cu2019' s representation of sentences by adding additional properties
p89
aVThe most comprehensive non-computational study of metaphoric expressions in large corpora (Steen, et al., 2010) found that up to 18.5% of words in the British National Corpus were used metaphorically
p90
aVThird, the high frequency of metaphorically used language implies that it is hard to set a boundary beyond which a word is used metaphorically
p91
aVMetaphor is a cognitive phenomenon (Lakoff Johnson, 1980, 1999) which has a significant impact on human reasoning abilities (Casasanto Jasmin, 2012; Johansson Falk Gibbs, 2012) and which, as a result, commonly appears in language in the form of metaphoric expressions (e.g.,, Deignan, 2005
p92
aVA second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li Sporleder, 2010; Sporleder Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language
p93
aVThird, the number of types of values for each concept property is determined, relative to the number of possible types
p94
aVWe split the original system u'\u005cu2019' s domain membership feature into two the domain of a word u'\u005cu2019' s referent and the domain of a word u'\u005cu2019' s sense
p95
aVA third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013
p96
aVThe scalar version of the system will have to evaluate the features in a different way
p97
aV0.638 F-Measure) but can also produce scalar identifications, which binary systems cannot produce
p98
aVThe lowest is between the first and third (which differ in the number of distinctions allowed) at 0.699
p99
aVEach correlation is significant at the 0.01 level (2-tailed
p100
aVThus, each sentence is represented by the sumo concepts which it contains and each concept is represented by its six concept properties
p101
aVThe resulting computationally-derived measure correlates significantly with each of the experiments
p102
aVThe original system uses the properties of domain-membership and event-status of concepts to identify metaphors at the sentence-level using a logistic regression classifier
p103
aVThe features used are computed as follows
p104
aV1) u'\u005cu201c' A lady on high heels clacked along, the type my mother says invests all of her brainpower in her looks u'\u005cu201d'
p105
aVFirst, animacy-status allows a distinction to be made between inanimate objects like rocks and stones and animate or human objects
p106
aVWe have chosen to start with the domain interaction system (Dunn, 2013a, 2013b), which performed competitively in an evaluation with other systems (Dunn, 2013b
p107
aVWilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g.,, Shutova, et al
p108
aVA finer distinction within the function-status property distinguishes social functions (e.g.,, laws) from physical-use functions (e.g.,, screwdrivers
p109
aVThird, the function-status property allows a distinction to be made between objects which encode a function (e.g.,, a screwdriver is specifically an object meant to turn screws) and those which do not encode a function (e.g.,, rocks are simply objects
p110
aVSecond, the fact-status property allows a distinction to be made between objects which exist as such independently of humans (e.g.,, rocks and stones) and those which exist to some degree dependent on human consciousness (e.g.,, laws and ideas
p111
aV2) u'\u005cu201c' The banks and the corporations in America today have lots of money that they can invest right now u'\u005cu201d'
p112
aVSeveral additional properties are added; these properties were not used in the original system
p113
aVThe idea is to capture cases like minister , in which a physical object (a human) is defined by its social role (being a minister
p114
aVFurther, it can be applied to any English text without the need for labelled training data
p115
aVThis means that metaphorically used words not only have very different interpretations than literally used words, but they are also common enough to pose a significant challenge for computational linguistics
p116
aVFollowing the original system, these properties are taken from a knowledge-base and used to create feature vectors
p117
aVThe event-status property is unchanged
p118
aVThe text is first processed using Apache OpenNLP for tokenization, named entity recognition, and part of speech tagging
p119
aVAt this point word sense disambiguation is performed using SenseRelate (Pedersen Kolhatkar, 2009), mapping the lexical words to the corresponding WordNet senses
p120
aVIn principle any of the property-based systems listed above could be converted in this way
p121
aVMorpha (Minnen, et al., 2001) is used for lemmatization
p122
aVThese WordNet senses are first mapped to SynSets and then to concepts in the sumo ontology, using existing mappings (Niles Pease, 2001, 2003
p123
aV2013; Shutova Sun, 2013
p124
aV0.450, 0.416, and 0.337
p125
a.