(lp0
VThe tree edit distance (TED) problem is defined analogously to the more familiar problem of string edit distance what is the minimum number of edit operations required to transform one tree into the other
p1
aVInstead, we base our work on tree edit distance
p2
aVFor large data sets such as the PCEDT set used in this work, computing u'\u005cu0391' with tree edit distance as the distance measure can take a very long time
p3
aVIn this article we propose a family of chance-corrected measures of agreement, applicable to both dependency- and constituency-based syntactic annotation, based on Krippendorff u'\u005cu2019' s u'\u005cu0391' and tree edit distance
p4
aVTree edit distance has previously been used in the TedEval software [] for parser evaluation agnostic to both annotation scheme and theoretical framework, but this by itself is still an uncorrected accuracy measure and thus unsuitable for our purposes
p5
aVInstead, we propose to use an agreement measure based on Krippendorff u'\u005cu2019' s u'\u005cu0391' [] and tree edit distance
p6
aVSee \u005cciteN Bille05 for a thorough introduction to the tree edit distance problem and other related problems
p7
aVHowever that work used a boundary edit distance as the basis of a metric for the task of text segmentation
p8
aVThe idea of using edit distance as the basis for an inter-annotator agreement metric has previously been explored by \u005cciteN Fournier13
p9
aVIn future work, we would like to investigate the use of other distance functions, in particular the use of approximate tree edit distance functions such as the p u'\u005cu2062' q -gram algorithm []
p10
aVThe only work we know of using chance-corrected metrics is \u005cciteN Rag:Dic13, who use MASI [] to measure agreement on dependency relations and head selection in multi-headed dependency syntax, and \u005cciteN Bha:Sha12, who compute Cohen u'\u005cu2019' s u'\u005cu039a' [] on dependency relations in single-headed dependency syntax
p11
aVThe data studied in this work has previously been used by \u005cciteN Skjaerholt13 to study agreement, but using simple accuracy measures (UAS, LAS) rather than chance-corrected measures
p12
aVNext, we present a number of synthetic experiments performed in order to find the best distance function for this kind of annotation; finally we contrast our new metric and simple accuracy scores as applied to real-world corpora before concluding and presenting some potential avenues for future work
p13
aVThe definitive reference for agreement measures in computational linguistics is \u005cciteN Art:Poe08, who argue forcefully in favour of the use of chance-corrected measures of agreement over simple accuracy measures
p14
a.