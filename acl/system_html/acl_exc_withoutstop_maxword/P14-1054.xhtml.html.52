<html>
<head>
<title>P14-1054.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>[] also pointed out that, due to the inaccuracy of Chinese word segmentation and parsing, the tree kernel based approach is inappropriate for Chinese relation extraction</a>
<a name="1">[1]</a> <a href="#1" id=1>Aiming at the Chinese inattentive structure, we utilize the soft constraint to capture the local dependency in a relation instance</a>
<a name="2">[2]</a> <a href="#2" id=2>The reason of the tree kernel based approach not achieve the same level of accuracy as that from English may be that segmenting and parsing Chinese are more difficult and less accurate than processing English</a>
<a name="3">[3]</a> <a href="#3" id=3>Based on massive and heterogeneous corpora, the ORE systems deal with millions or billions of documents</a>
<a name="4">[4]</a> <a href="#4" id=4>In order to give a better comparison with the state-of-the-art methods, based on our experiment settings and data, we implement the two feature based methods proposed by Che et al</a>
<a name="5">[5]</a> <a href="#5" id=5>However, even in English, u'\u201c' deeper u'\u201d' analysis (e.g., logical syntactic relations or predicate-argument structure) may suffer from a worse performance caused by inaccurate chunking or parsing</a>
<a name="6">[6]</a> <a href="#6" id=6>Head noun and adjacent entity POS tag are employed to combine with positional information</a>
<a name="7">[7]</a> <a href="#7" id=7>No subjective or priori judgement is adopted to delete any potential determinative constraint (except for the reason of dimensionality reduction</a>
<a name="8">[8]</a> <a href="#8" id=8>The errors caused by segmentation and</a>
</body>
</html>