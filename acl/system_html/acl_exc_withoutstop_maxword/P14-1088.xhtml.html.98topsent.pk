(lp0
VFor this reason efforts to gauge the quality of syntactic annotation are hampered by the need to fall back to simple accuracy measures
p1
aVThe definitive reference for agreement measures in computational linguistics is \u005cciteN Art:Poe08, who argue forcefully in favour of the use of chance-corrected measures of agreement over simple accuracy measures
p2
aVTree edit distance has previously been used in the TedEval software [] for parser evaluation agnostic to both annotation scheme and theoretical framework, but this by itself is still an uncorrected accuracy measure and thus unsuitable for our purposes
p3
aVHowever, no such measure is in widespread use for the task of syntactic annotation
p4
aVThis is due to a mismatch between the formulation of the agreement measures, which assumes that the annotations have no or relatively little internal structure, and syntactic annotation where structure is the entire point of the annotation
p5
aVIn this article we propose a family of chance-corrected measures of agreement, applicable to both dependency- and constituency-based syntactic annotation, based on Krippendorff u'\u005cu2019' s u'\u005cu0391' and tree edit distance
p6
aVThus, inserting and deleting nodes is a central part of the task of tectogrammatical annotation, unlike the more surface-oriented annotation of our other treebanks, where the tokenisation is fixed before the text is annotated
p7
aVInstead, we propose to use an agreement measure based on Krippendorff u'\u005cu2019' s u'\u005cu0391' [] and tree edit distance
p8
aVThe data studied in this work has previously been used by \u005cciteN Skjaerholt13 to study agreement, but using simple accuracy measures (UAS, LAS) rather than chance-corrected measures
p9
aVAs shown in \u005cciteN Art:Poe08, such measures are biased in favour of annotation schemes with fewer categories and do not account for skewed distributions between classes, which can give high observed agreement, even if the annotations are inconsistent
p10
aVThus we have to reject this way of assessing the reliability of dependency syntax annotation
p11
aVA distinguishing feature of the tectogrammatical analyses, vis a vis the other treebanks we are using, is that semantically empty words only take part in the analytical annotation layer and nodes are inserted at the tectogrammatical layer to represent covert elements of the sentence not present in the surface syntax of the analytical layer
p12
aVThe ERG is an HPSG-based grammar, and as such its analyses are attribute-value matrices (AVMs); an AVM is not a tree but a directed acyclic graph however, and for this reason we compute agreement not on the AVM but the so-called
p13
a.