(lp0
VReferring to Figure 1 , whose timeline is shown in Figure 2 , we see that the time span with the most number of events is when the latest cyclone made landfall
p1
aVThe importance of a time span T u'\u005cu2062' S i is computed by normalizing the number of events in T u'\u005cu2062' S i against the number of events in T u'\u005cu2062' S L
p2
aVTwo events are said to be in the same time span if one happens within the time period the other happens in
p3
aVFormally, if a sentence s contains events u'\u005cud835' u'\u005cudd3c' s = { e 1 , u'\u005cu2026' , e n } , where each event is associated with a time span T u'\u005cu2062' S i , then T u'\u005cu2062' C u'\u005cu2062' D is computed using
p4
aVAssigning higher scores for sentences which contain events in this time span will help us to select more relevant sentences if we want a summary about the cyclone
p5
aVThen the temporal coverage of a sentence is defined as the number of time spans between the earliest time span T u'\u005cu2062' S a and the latest time span T u'\u005cu2062' S c
p6
aVBy doing so, we are able to make better use of the available temporal information, taking into account all known events and the time in which they occur
p7
aVSince ( u'\u005cu211d' 1) and ( u'\u005cu211d' 3) talk about the same time span, TimeMMR down-weights ( u'\u005cu211d' 3
p8
aVAs a simplifying assumption, events are laid out on the timeline based on the starting time of their time span
p9
aVIn this work we construct timelines (as a representation of temporal information) automatically and incorporate them into a state-of-the-art multi-document summarization system
p10
aVTCD parallels this idea with the use of temporal information, i.e., if two sentences are of the same temporal coverage, then the one with more events should carry more useful facts
p11
aVwhere S u'\u005cu2062' c u'\u005cu2062' o u'\u005cu2062' r u'\u005cu2062' e u'\u005cu2062' ( s ) is the score of s , S is the set of sentences already selected to be in the summary from previous iterations, and R u'\u005cu2062' 2 is the predicted ROUGE-2 score of s with respect to the already selected sentences ( S u'\u005cu0393' is a weighting parameter which is empirically set to 0.9 after tuning over a development dataset u'\u005cud835' u'\u005cudcaf' is the proportion of events in s which happen in the same time span as another event in any other sentence in S
p12
aVIn this case time span importance is able to correctly guide summary generation by favoring time spans containing events related to the actual toppling
p13
aVThus, we propose further penalizing the score of s if it contains events that happen in similar time spans as those contained in sentences within S
p14
aVThus, temporal information does assist in identifying which sentences are more relevant to the final summary
p15
aVThe timelines built in the earlier temporal processing can be incorporated into this pipeline by deriving a set of features used to score sentences in Sentence Scoring , and as input to the MMR algorithm when computing similarity in Sentence Re-ordering
p16
aVThis is achieved with 1) three novel features derived from timelines to help measure the saliency of sentences, as well as 2) TimeMMR , a modification to the traditional Maximal Marginal Relevance (MMR) [ 3 ]
p17
aVAt these higher thresholds, temporal information is still able to help get an improvement in R-2
p18
aVSince the focus of this paper is on multi-document summarization, we employ only the three generic features, i.e.,, 1) sentence position, 2) sentence length, and 3) interpolated n-gram document frequency in our experiments below
p19
aVWhile TimeMMR is proposed here as an improvement over MMR, the premise is that incorporating temporal information can be helpful to minimize redundancy in summaries
p20
aVOur work is significant as it addresses an important gap in the exploitation of temporal information
p21
aVSWING is a supervised, extractive summarization system which ranks sentences based on scores computed using a set of features in the Sentence Scoring phase
p22
aVAs the threshold increases from 0 to 40 u'\u005cu2013' 50, summarization performance improves while the number of document sets where temporal information is used is reduced
p23
aVWe hope to improve the quality of the summaries that are generated by considering temporal information found in the input text
p24
aVAfter laying out these events onto a timeline by making use of these timestamps, the number of events that happen within the same day is used to influence sentence scoring
p25
aVIt is easy to see why ( u'\u005cud835' u'\u005cudd43' 1) scores higher for R-2 u'\u005cu2014' it describes the cause of the accident just as it occurred u'\u005cu211d' 1) however talks about events which happened before the accident itself (e.g.,, how much of the tower had already been erected
p26
aVThe intuition for this is that for longer timelines (which contain more events), possible errors are spread over the entire timeline, and do not overpower any useful signal that can be obtained from the timeline features outlined earlier
p27
aVWe assume that the various input document sets to be summarized are available at the time of processing
p28
aVRecall that TimeMMR seeks to eliminate redundancy based on time span similarities and not lexical likeness
p29
aVIn each iteration, s is penalized if it is lexically similar to other sentences that have already been selected to form the eventual summary S = { s 1 , s 2 , u'\u005cu2026' }
p30
aVThe use of recency as an indicator of saliency is useful, yet disregards other accessible temporal information
p31
aVIn sentence re-ordering, final summaries are re-arranged so that the extracted sentences that form the summary are in a chronological order
p32
aVGeneralizing, we refer to the time period an event takes place in as its time span (vertical dotted lines
p33
aVIf a summary of a whole sequence of events is desired, recency becomes less useful
p34
aVTemporal processing is imperfect
p35
aVRecognizing that sentence (3) is about a storm that had happened in the past is important when writing a summary about the recent storm, as it is not relevant and can likely be excluded
p36
aVTo help visualize what the differences in these ROUGE scores mean, Figure 7 shows two summaries 1 1 The produced summaries are truncated to fit within a 100-word limit imposed by the TAC-2011 guidelines generated for document set D1117C of the TAC-2011 dataset
p37
aVHence in these experiments, the threshold for filtering is set to be the average of all the timeline sizes over the whole input dataset
p38
aV[2]
p39
aVBeyond 60, the R-2 scores are still higher than that obtained by SWING , but no longer significantly different
p40
aVT =0 means that timelines are used for all input document sets, whereas T =100 means that no timelines are used, as the length of the longest timeline is less than 100
p41
aVWe postulate that the length of a timeline can serve as a simple reliability filtering metric
p42
aVThe constraint on the number of sentences that can be included in a summary requires us to select compact sentences which contain as many relevant facts as possible
p43
aVLooking at Rows 1 to 8, and Rows 9 to 16, we see the importance of reliability filtering
p44
aVThere are fewer events which talk about the previous storm
p45
aVThis can be done by computing a metric which can be used to decide whether or not timelines should be used for a particular input document collection
p46
aVThey indicate the temporal relationships between two basic temporal units
p47
aVHowever as this affects only very few out of the 44 document sets, statistical variances mean that these R-2 scores are no longer significant from that produced by SWING
p48
aVHowever it is not trivial for the lexically-motivated MMR algorithm to detect that events like u'\u005cu201c' passed u'\u005cu201d' , u'\u005cu201c' uprooted u'\u005cu201d' or u'\u005cu201c' damaged u'\u005cu201d' are in fact repetitive
p49
aVIn this work, we have simplified this idea by dropping the need for event co-referencing (removing a source of propagated error), and augmented it with two additional features derived from timelines
p50
aVA summary about the hurricane need not contain all of these sentences as they are all describing the same thing
p51
aVThis work additionally proposes the use of the lengths of timelines as a metric to gauge the usefulness of timelines
p52
aVAs the state-of-the-art improves, these workshops have moved away from the piecemeal evaluation of individual temporal processing tasks and towards the evaluation of complete end-to-end systems in TempEval-3
p53
aVThis affirms our use of the average length of timelines as the threshold value in our earlier experiments
p54
aVThe motivating idea is to reduce repeated information by preferring sentences which bring in new facts
p55
aVTimeMMR penalizes ( u'\u005cu211d' 3 u'\u005cu211d' 3) reports that the shoe-throwing incident happened as the U.S
p56
aVFor the analysis on timeline features, we only present an analysis for TSI and CTSI due to space constraints
p57
aVThese indicate that all the proposed features are important and need to be used together to be effective
p58
aVTraditional lexical measures may attempt to achieve this by computing the ratio of keyphrases to the number of words in a sentence [ 11 ]
p59
aVu'\u005cu211d' 3) The incident occurred as Bush was appearing with Iraqi Prime Minister Nouri al-Maliki
p60
aVWe chose to use MMR here as a proof-of-concept to demonstrate the viability of such a technique, and to easily integrate our work into SWING
p61
aVSummarization evaluation is done using ROUGE-2 (R-2) [ 13 ] , as it has previously been shown to correlate well with human assessment [ 14 ] and is often used to evaluate automatic text summarization
p62
aVTogether with the earlier described contributions, this metric further improves summarization, yielding an overall 5.9% performance increase
p63
aV2) More than 100,000 coastal villagers have been evacuated before the cyclone made landfall
p64
aVThe same drop occurs even when reliability filtering is used (Rows 9 to 12
p65
aVCLASSY and POLYCOM are top performing systems at TAC-2011 (ranked 2nd and 3rd by R-2 in TAC 2011, respectively; the full version of SWING was ranked 1st with a R-2 score of 0.1380
p66
aVStated equivalently, when two sentences are of the same length, if one contains more keyphrases, it should contain more useful facts
p67
aVDepending on the style of writing or journalistic guidelines, a summary can arguably be written in a number of ways
p68
aVu'\u005cu211d' 2) A top Army general vowed to personally oversee the upgrading of Walter Reed Army Medical Center u'\u005cu2019' s Building 18, a dilapidated former hotel that houses wounded soldiers as outpatients
p69
aVHowever we believe it is because the ROUGE measures that are used for evaluation are not suited for this purpose
p70
aVWe also show the results of two reference systems, CLASSY [ 5 ] and POLYCOM [ 30 ] , as benchmarks
p71
aV1) A fierce cyclone packing extreme winds and torrential rain smashed into Bangladesh u'\u005cu2019' s southwestern coast Thursday, wiping out homes and trees in what officials described as the worst storm in years
p72
aV1) An official in Barisal, 120 kilometres south of Dhaka, spoke of severe destruction as the 500 kilometre-wide mass of cloud passed overhead
p73
aVPresident Bush appeared together with the Iraqi Prime Minister Nouri al-Maliki
p74
aVBesides the increasing availability of annotation standards (e.g.,, TimeML [ 21 ] ) and corpora (e.g.,, TIDES [ 9 ] , TimeBank [ 22 ] ), the community has also organized three successful evaluation workshops u'\u005cu2014' TempEval-1 [ 25 ] , -2 [ 26 ] , and -3 [ 24 ]
p75
a.