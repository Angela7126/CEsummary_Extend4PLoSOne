(lp0
VUnlike most previous work, our model is defined at a finer level of granularity u'\u005cu2014' it computes meaning representations for individual words and is unique in its use of attributes as a means of representing the textual and visual modalities
p1
aVUnlike previous efforts such as the widely used WordSim353 collection () , our dataset contains ratings for visual and textual similarity, thus allowing to study the two modalities (and their contribution to meaning representation) together and in isolation
p2
aVAs our input consists of natural language attributes, the model would infer textual attributes given visual attributes and vice versa
p3
aVFor that purpose, the autoencoders are pre-trained layer by layer, with the current layer being fed the latent representation of the previous autoencoder as input
p4
aVAs shown in Figure 1 , our model takes as input two (real-valued) vectors representing the visual and textual modalities
p5
aVThese models learn the meaning of words based on textual and perceptual input
p6
aVThe third row in the table presents three variants of our model trained on
p7
a.