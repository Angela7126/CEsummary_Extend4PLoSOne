(lp0
VAs for improving distributional thesauri, outside of numerous alternate approaches to the construction, there is a body of work focusing on improving an existing resource, for instance reweighting context features once an initial thesaurus is built [] , or post-processing the resource to filter bad neighbours or re-ranking neighbours of a given target []
p1
aVThey are not suitable for the evaluation of the whole range of semantic relatedness that is exhibited by distributional similarities, which exceeds the limits of classical lexical relations, even though researchers have tried to collect equivalent resources manually, to be used as a gold standard []
p2
aVThe filtering approach we propose seems to yield good results, by augmenting the similarity built on the whole corpus with signals from the local contexts and documents where related lexical items appear together
p3
aVIntrinsic evaluations try to measure the resource itself with respect to some human standard or judgment, for instance by comparing a distributional resource with respect to an existing synonym dictionary or similarity judgment produced by human subjects []
p4
aVThe method we propose here has been designed as an intrinsic evaluation with a view to validate semantic proximity links in a broad perspective, to cover what [] call u'\u005cu201c' non classical lexical semantic relations u'\u005cu201d'
p5
aVOther popular methods (maximum entropy, SVM) have shown slightly inferior combined F-score, even though precision and recall might yield more important variations
p6
aVThe outcome of the contextual annotation presented above is a rather sizeable dataset of validated semantic links, and we showed these linguistic judgments to be reliable
p7
aVWe chose the following settings for the different models naive bayes uses a kernel density estimation for numerical features, as this generally improves performance
p8
aVFinally, we took into account the network of related lexical items, by considering the largest
p9
a.