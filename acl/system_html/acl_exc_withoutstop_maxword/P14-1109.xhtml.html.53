<html>
<head>
<title>P14-1109.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Finally, we investigate the robustness of the proposed semiparametric Gaussian copula regression model by varying the amount of features in the covariate space</a>
<a name="1">[1]</a> <a href="#1" id=1>To do this, we formulate the problem as a text regression task, and use a Gaussian copula with probability integral transform to model the uniform marginals and their dependencies</a>
<a name="2">[2]</a> <a href="#2" id=2>Note that since the kernel density estimation in the proposed copula model is nonparametric, and we only need to learn the u'\u03a3' in the Gaussian copula, there is no hyperparameters that need to be tuned</a>
<a name="3">[3]</a> <a href="#3" id=3>Therefore, by modeling the correlations among marginal CDFs, the copula model has gained the insights on the dependency structures of the random variables, and thus, the performance of the regression task is boosted</a>
<a name="4">[4]</a> <a href="#4" id=4>In NLP, many of the probabilistic text models work in the discrete space [ 9 , 2 ] , but our model is different since the text features are sparse, we first perform kernel density estimates to smooth out the zeroing items, and then calculate the empirical cumulative distribution function (CDF) of the random variables</a>
<a name="5">[5]</a> <a href="#5" id=5>On one hand, copula models [ 31 ] seek to explicitly model the dependency of random variables by separating the marginals and their correlations</a>
<a name="6">[6]</a> <a href="#6" id=6>One advantage we see from the copula model is that it does not require any assumptions on the marginal distributions</a>
<a name="7">[7]</a> <a href="#7" id=7>Last but not</a>
</body>
</html>