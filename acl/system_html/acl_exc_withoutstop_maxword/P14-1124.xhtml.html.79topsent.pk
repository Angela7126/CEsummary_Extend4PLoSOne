(lp0
VThe first illustration of word burstiness can be seen by plotting observed inverse document frequency, IDF w , versus f w in the log domain (Figure 7
p1
aVLooking close to the y -axis in Figure 9 , we observe a second class of exclusively low frequency words whose burstiness ranges from highly concentrated to singletons
p2
aVIn general, we can think of using word repetitions to re-score term detection as applying a limited form of adaptive or cache language model []
p3
aVAs it turns out this u'\u005cu2018' burstiness u'\u005cu2019' of words within documents, as the term is defined by Church and Gale in their work on Poisson mixtures (1995), provides a more reliable framework for successfully exploiting document context
p4
aVIn applying the burstiness quantity to term detection, we recall that the task requires us to locate a particular instance of a term, not estimate a count, hence the utility of N-gram language models predicting words in sequence
p5
aVClose examination of DF statistics by Church and Gale in their work on Poisson Mixtures (1995) resulted in an analysis of the burstiness of content words
p6
aVThe typical
p7
a.