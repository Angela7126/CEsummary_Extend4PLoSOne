<html>
<head>
<title>P14-1048.xhtml_1.pickle</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Therefore, our model incorporates the strengths of both HILDA and Joty et al u'\u2019' s model, i.e.,, the efficiency of a greedy parsing algorithm, and the ability to incorporate sequential information with CRFs</a>
<a name="1">[1]</a> <a href="#1" id=1>First, with a greedy bottom-up strategy, we develop a discourse parser with a time complexity linear in the total number of sentences in the document</a>
<a name="2">[2]</a> <a href="#2" id=2>First, as shown in Table 2 , the average number of sentences in a document is 26.11, which is already too large for optimal parsing models, e.g.,, the CKY-like parsing algorithm in j CRF, let alone the fact that the largest document contains several hundred of EDUs and sentences</a>
<a name="3">[3]</a> <a href="#3" id=3>While research in discourse parsing can be partitioned into several directions according to different theories and frameworks, Rhetorical Structure Theory (RST) [ 12 ] is probably the most ambitious one, because it aims to identify not only the discourse relations in a small local context, but also the hierarchical tree structure for the full text from the relations relating the smallest discourse units (called elementary discourse units, EDUs), to the ones connecting paragraphs</a>
<a name="4">[4]</a> <a href="#4" id=4>It is possible to optimize Joty et al u'\u2019' s CKY-like parsing by replacing their CRF-based computation for upper-level constituents with some local computation based on the probabilities of lower-level constituents</a>
<a name="5">[5]</a> <a href="#5" id=5>In addition to efficiency, our use of a single CRF chain for all constituents can better capture the sequential dependencies among context, by taking into account</a>
</body>
</html>