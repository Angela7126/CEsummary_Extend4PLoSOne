(lp0
VThe simplest model, ddCRP uniform , uses a uniform prior that sets the distance between any two words equal to one
p1
aV1) the distributional similarity between all words in the proposed partition containing w 1 and w 2 , which is encoded using a Gaussian likelihood function over the word embeddings; and 2) the morphological similarity between w 1 and w 2 , which acts as a prior distribution on the induced clustering
p2
aVWe can create an infinite mixture model by combining the ddCRP prior with a likelihood function defining the probability of the data given the cluster assignments
p3
aVThe final model, ddCRP exp , adds the prior exponentiation
p4
aVIn contrast, we use pairwise morphological similarity as a prior in a non-parametric clustering model
p5
aVExponentiating the prior reduces the number of induced clusters and
p6
a.