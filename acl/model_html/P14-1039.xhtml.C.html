<html>
<head>
<title>P14-1039.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We investigate whether parsers can be used for self-monitoring in surface realization in order to avoid egregious errors involving vicious ambiguities, namely those where the intended interpretation fails to be considerably more likely than alternative ones.</a>
<a name="1">[1]</a> <a href="#1" id=1>Using parse accuracy in a simple reranking strategy for self-monitoring, we find that with a state-of-the-art averaged perceptron realization ranking model, BLEU scores cannot be improved with any of the well-known Treebank parsers we tested, since these parsers too often make errors that human readers would be unlikely to make.</a>
<a name="2">[2]</a> <a href="#2" id=2>However, by using an SVM ranker to combine the realizer s model score together with features from multiple parsers, including ones designed to make the ranker more robust to parsing mistakes, we show that significant increases in BLEU scores can be achieved.</a>
<a name="3">[3]</a> <a href="#3" id=3>Moreover, via a targeted manual analysis, we demonstrate that the SVM reranker frequently manages to avoid vicious ambiguities, while its ranking errors tend to affect fluency much more often than adequacy.</a>
<a name="4">[4]</a> <a href="#4" id=4>In this paper, we have shown that while using parse accuracy in a simple reranking strategy for self-monitoring fails to improve BLEU scores over a state-of-the-art averaged perceptron realization ranking model, it is possible to significantly increase BLEU scores using an SVM ranker that combines the realizer s model score together with features from multiple parsers, including ones designed to make the ranker more robust to parsing mistakes that human readers would be unlikely to make.</a>
<a name="5">[5]</a> <a href="#5" id=5>Additionally, via a targeted manual analysis, we showed that the SVM reranker frequently manages to avoid egregious errors involving vicious ambiguities, of the kind that would mislead human readers as to the intended meaning.</a>
<a name="6">[6]</a> <a href="#6" id=6>As noted in Reiter s [ 30 ] survey, many NLG systems use surface realizers as off-the-shelf components.</a>
<a name="7">[7]</a> <a href="#7" id=7>In this paper, we have focused on broad coverage surface realization using widely-available PTB data where there are many sentences of varying complexity with gold-standard annotations following the common assumption that experiments with broad coverage realization are (or eventually will be) relevant for NLG applications.</a>
<a name="8">[8]</a> <a href="#8" id=8>Of course, the kinds of ambiguity that can be problematic in news text may or may not be the same as the ones encountered in particular applications.</a>
<a name="9">[9]</a> <a href="#9" id=9>Moreover, for certain applications (e.g., ones with medical or legal implications), it may be better to err on the side of ambiguity avoidance, even at some expense to fluency, thereby requiring training data reflecting the desired trade-off to adapt the methods described here.</a>
<a name="10">[10]</a> <a href="#10" id=10>We leave these application-centered issues for investigation in future work.</a>
<a name="11">[11]</a> <a href="#11" id=11>The current approach is primarily suitable for offline use, for example in report generation where there are no real-time interaction demands.</a>
<a name="12">[12]</a> <a href="#12" id=12>In future work, we also plan to investigate ways that self-monitoring might be implemented more efficiently as a combined process, rather than running independent parsers as a post-process following realization.</a>
</body>
</html>