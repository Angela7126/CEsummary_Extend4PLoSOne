<html>
<head>
<title>P14-2088.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Unsupervised domain adaptation often relies on transforming the instance representation.</a>
<a name="1">[1]</a> <a href="#1" id=1>However, most such approaches are designed for bag-of-words models, and ignore the structured features present in many problems in NLP.</a>
<a name="2">[2]</a> <a href="#2" id=2>We propose a new technique called marginalized structured dropout , which exploits feature structure to obtain a remarkably simple and efficient feature projection.</a>
<a name="3">[3]</a> <a href="#3" id=3>Applied to the task of fine-grained part-of-speech tagging on a dataset of historical Portuguese, marginalized structured dropout yields state-of-the-art accuracy while increasing speed by more than an order-of-magnitude over previous work.</a>
<a name="4">[4]</a> <a href="#4" id=4>Denoising autoencoders provide an intuitive solution for domain adaptation transform the features into a representation that is resistant to the noise that may characterize the domain adaptation process.</a>
<a name="5">[5]</a> <a href="#5" id=5>The original implementation of this idea produced this noise directly [ 12 ] ; later work showed that dropout noise could be analytically marginalized [ 4 ].</a>
<a name="6">[6]</a> <a href="#6" id=6>We take another step towards simplicity by showing that structured dropout can make marginalization even easier, obtaining dramatic speedups without sacrificing accuracy.</a>
<a name="7">[7]</a> <a href="#7" id=7>We thank the reviewers for useful feedback.</a>
<a name="8">[8]</a> <a href="#8" id=8>This research was supported by National Science Foundation award 1349837.</a>
</body>
</html>