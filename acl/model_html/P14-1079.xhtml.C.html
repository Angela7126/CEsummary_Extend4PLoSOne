<html>
<head>
<title>P14-1079.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The essence of distantly supervised relation extraction is that it is an incomplete multi-label classification problem with sparse and noisy features.</a>
<a name="1">[1]</a> <a href="#1" id=1>To tackle the sparsity and noise challenges, we propose solving the classification problem using matrix completion on factorized matrix of minimized rank.</a>
<a name="2">[2]</a> <a href="#2" id=2>We formulate relation classification as completing the unknown labels of testing items (entity pairs) in a sparse matrix that concatenates training and testing textual features with training labels.</a>
<a name="3">[3]</a> <a href="#3" id=3>Our algorithmic framework is based on the assumption that the rank of item-by-feature and item-by-label joint matrix is low.</a>
<a name="4">[4]</a> <a href="#4" id=4>We apply two optimization models to recover the underlying low-rank matrix leveraging the sparsity of feature-label matrix.</a>
<a name="5">[5]</a> <a href="#5" id=5>The matrix completion problem is then solved by the fixed point continuation (FPC) algorithm, which can find the global optimum.</a>
<a name="6">[6]</a> <a href="#6" id=6>Experiments on two widely used datasets with different dimensions of textual features demonstrate that our low-rank matrix completion approach significantly outperforms the baseline and the state-of-the-art methods.</a>
<a name="7">[7]</a> <a href="#7" id=7>In this paper, we contributed two noise-tolerant optimization models 17 17 The source code can be downloaded from https://github.com/nlpgeek/DRMC/tree/master , DRMC-b and DRMC-1, for distantly supervised relation extraction task from a novel perspective.</a>
<a name="8">[8]</a> <a href="#8" id=8>Our models are based on matrix completion with low-rank criterion.</a>
<a name="9">[9]</a> <a href="#9" id=9>Experiments demonstrated that the low-rank representation of the feature-label matrix can exploit the underlying semantic correlated information for relation classification and is effective to overcome the difficulties incurred by sparse and noisy features and incomplete labels, so that we achieved significant improvements on performance.</a>
<a name="10">[10]</a> <a href="#10" id=10>Our proposed models also leave open questions for distantly supervised relation extraction task.</a>
<a name="11">[11]</a> <a href="#11" id=11>First, they can not process new coming testing items efficiently, as we have to reconstruct the data matrix containing not only the testing items but also all the training items for relation classification, and compute in iterative fashion again.</a>
<a name="12">[12]</a> <a href="#12" id=12>Second, the volume of the datasets we adopt are relatively small.</a>
<a name="13">[13]</a> <a href="#13" id=13>For the future work, we plan to improve our models so that they will be capable of incremental learning on large-scale datasets [ 6 ].</a>
</body>
</html>