<html>
<head>
<title>P14-2135.xhtml.B</title>
</head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>We presented a novel method, image dispersion-based filtering, that improves multi-modal representations by approximating conceptual concreteness from images and filtering model input..</a>
<a name="2">[2]</a> <a href="#2" id=2> The results clearly show that including more perceptual input in multi-modal models is not always better..</a>
<a name="3">[3]</a> <a href="#3" id=3> Motivated by this fact, our approach provides an intuitive and straightforward metric to determine whether or not to include such information..</a>
<a name="4">[4]</a> <a href="#4" id=4> In addition to improving multi-modal representations, we have shown the applicability of the image dispersion metric to several other tasks..</a>
<a name="5">[5]</a> <a href="#5" id=5> To our knowledge, our algorithm constitutes the first unsupervised method for quantifying conceptual concreteness as applied to NLP, although it does, of course, rely on the Google Images retrieval algorithm..</a>
<a name="6">[6]</a> <a href="#6" id=6> Moreover, we presented a method to classify adjective-noun pairs according to modification type that exploits the link between image dispersion and concreteness..</a>
<a name="7">[7]</a> <a href="#7" id=7> It is striking that this apparently linguistic problem can be addressed solely using the raw data encoded in images..</a>
<a name="8">[8]</a> <a href="#8" id=8> In future work, we will investigate the precise quantity of perceptual information to be included for best performance, as well as the optimal filtering threshold..</a>
<a name="9">[9]</a> <a href="#9" id=9> In addition, we will explore whether the application of image data, and the interaction between images and language, can yield improvements on other tasks in semantic processing and representation..</a>
</body>
</html>