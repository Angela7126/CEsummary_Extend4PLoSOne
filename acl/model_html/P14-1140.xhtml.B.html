<html>
<head>
<title>P14-1140.xhtml.B</title>
</head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>In this paper, we propose a Recursive Recurrent Neural Network(R 2 NN) to combine the recurrent neural network and recursive neural network..</a>
<a name="2">[2]</a> <a href="#2" id=2> Our proposed R 2 NN cannot only integrate global input information during each combination, but also can generate the tree structure in a recursive way..</a>
<a name="3">[3]</a> <a href="#3" id=3> We apply our model to SMT decoding, and propose a three-step semi-supervised training method..</a>
<a name="4">[4]</a> <a href="#4" id=4> In addition, we explore phrase pair embedding method, which models translation confidence directly..</a>
<a name="5">[5]</a> <a href="#5" id=5> We conduct experiments on a Chinese-to-English translation task, and our method outperforms a state-of-the-art baseline about 1.5 points BLEU..</a>
<a name="6">[6]</a> <a href="#6" id=6> From the experiments, we find that, phrase pair embedding is crucial to the performance of SMT..</a>
<a name="7">[7]</a> <a href="#7" id=7> In the future, we will explore better methods for phrase pair embedding to model the translation equivalent between source and target phrases..</a>
<a name="8">[8]</a> <a href="#8" id=8> We will apply our proposed R 2 NN to other tree structure learning tasks, such as natural language parsing..</a>
</body>
</html>