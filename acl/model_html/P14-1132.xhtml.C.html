<html>
<head>
<title>P14-1132.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Following up on recent work on establishing a mapping between vector-based semantic embeddings of words and the visual representations of the corresponding objects from natural images, we first present a simple approach to cross-modal vector-based semantics for the task of zero-shot learning , in which an image of a previously unseen object is mapped to a linguistic representation denoting its word.</a>
<a name="1">[1]</a> <a href="#1" id=1>We then introduce fast mapping , a challenging and more cognitively plausible variant of the zero-shot task, in which the learner is exposed to new objects and the corresponding words in very limited linguistic contexts.</a>
<a name="2">[2]</a> <a href="#2" id=2>By combining prior linguistic and visual knowledge acquired about words and their objects, as well as exploiting the limited new evidence available, the learner must learn to associate new objects with words.</a>
<a name="3">[3]</a> <a href="#3" id=3>Our results on this task pave the way to realistic simulations of how children or robots could use existing knowledge to bootstrap grounded semantic knowledge about new concepts.</a>
<a name="4">[4]</a> <a href="#4" id=4>At the outset of this work, we considered the problem of linking purely language-based distributional semantic spaces with objects in the visual world by means of cross-modal mapping.</a>
<a name="5">[5]</a> <a href="#5" id=5>We compared recent models for this task both on a benchmark object recognition dataset and on a more realistic and noisier dataset covering a wide range of concepts.</a>
<a name="6">[6]</a> <a href="#6" id=6>The neural network architecture emerged as the best performing approach, and our qualitative analysis revealed that it induced a categorical organization of concepts.</a>
<a name="7">[7]</a> <a href="#7" id=7>Most importantly, our results suggest the viability of cross-modal mapping for grounded word-meaning acquisition in a simulation of fast mapping.</a>
<a name="8">[8]</a> <a href="#8" id=8>Given the success of NN , we plan to experiment in the future with more sophisticated neural network architectures inspired by recent work in machine translation [ 19 ] and multimodal deep learning [ 51 ].</a>
<a name="9">[9]</a> <a href="#9" id=9>Furthermore, we intend to adopt visual attributes [ 14 , 44 ] as visual representations, since they should allow a better understanding of how cross-modal mapping works, thanks to their linguistic interpretability.</a>
<a name="10">[10]</a> <a href="#10" id=10>The error analysis in Section 5.3 suggests that automated localization techniques [ 54 ] , distinguishing an object from its surroundings, might drastically improve mapping accuracy.</a>
<a name="11">[11]</a> <a href="#11" id=11>Similarly, in the textual domain, models that extract collocates of a word that are more likely to denote conceptual properties [ 28 ] might lead to more informative and discriminative linguistic vectors.</a>
<a name="12">[12]</a> <a href="#12" id=12>Finally, the lack of large child-directed speech corpora constrained the experimental design of fast mapping simulations; we plan to run more realistic experiments with true nonce words and using source corpora (e.g.,, the Simple Wikipedia, child stories, portions of CHILDES) that contain sentences more akin to those a child might effectively hear or read in her word-learning years.</a>
</body>
</html>