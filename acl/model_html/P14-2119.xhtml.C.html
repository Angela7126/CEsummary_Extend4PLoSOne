<html>
<head>
<title>P14-2119.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Distant supervision usually utilizes only unlabeled data and existing knowledge bases to learn relation extraction models.</a>
<a name="1">[1]</a> <a href="#1" id=1>However, in some cases a small amount of human labeled data is available.</a>
<a name="2">[2]</a> <a href="#2" id=2>In this paper, we demonstrate how a state-of-the-art multi-instance multi-label model can be modified to make use of these reliable sentence-level labels in addition to the relation-level distant supervision from a database.</a>
<a name="3">[3]</a> <a href="#3" id=3>Experiments show that our approach achieves a statistically significant increase of 13.5% in F-score and 37% in area under the precision recall curve.</a>
<a name="4">[4]</a> <a href="#4" id=4>We show that relation extractors trained with distant supervision can benefit significantly from a small number of human labeled examples.</a>
<a name="5">[5]</a> <a href="#5" id=5>We propose a strategy to generate and select guidelines so that they are more generalized forms of labeled instances.</a>
<a name="6">[6]</a> <a href="#6" id=6>We show how to incorporate these guidelines into an existing state-of-art model for relation extraction.</a>
<a name="7">[7]</a> <a href="#7" id=7>Our approach significantly improves performance in practice and thus opens up many opportunities for further research in RE where only a very limited amount of labeled training data is available.</a>
</body>
</html>