<html>
<head>
<title>P14-1117.xhtml.A</title>
</head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>Sentence compression has been shown to benefit from joint inference involving both n-gram and dependency-factored objectives but this typically requires expensive integer programming..</a>
<a name="2">[2]</a> <a href="#2" id=2> We explore instead the use of Lagrangian relaxation to decouple the two subproblems and solve them separately..</a>
<a name="3">[3]</a> <a href="#3" id=3> While dynamic programming is viable for bigram-based sentence compression, finding optimal compressed trees within graphs is NP-hard..</a>
<a name="4">[4]</a> <a href="#4" id=4> We recover approximate solutions to this problem using LP relaxation and maximum spanning tree algorithms, yielding techniques that can be combined with the efficient bigram-based inference approach using Lagrange multipliers..</a>
<a name="5">[5]</a> <a href="#5" id=5> Experiments show that these approximation strategies produce results comparable to a state-of-the-art integer linear programming formulation for the same joint inference task along with a significant improvement in runtime..</a>
</body>
</html>