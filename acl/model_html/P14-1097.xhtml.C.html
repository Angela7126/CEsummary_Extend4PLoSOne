<html>
<head>
<title>P14-1097.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We present an unsupervised method for inducing verb classes from verb uses in giga-word corpora.</a>
<a name="1">[1]</a> <a href="#1" id=1>Our method consists of two clustering steps verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames.</a>
<a name="2">[2]</a> <a href="#2" id=2>By taking this step-wise approach, we can not only generate verb classes based on a massive amount of verb uses in a scalable manner, but also deal with verb polysemy, which is bypassed by most of the previous studies on verb clustering.</a>
<a name="3">[3]</a> <a href="#3" id=3>In our experiments, we acquire semantic frames and verb classes from two giga-word corpora, the larger comprising 20 billion words.</a>
<a name="4">[4]</a> <a href="#4" id=4>The effectiveness of our approach is verified through quantitative evaluations based on polysemy-aware gold-standard data.</a>
<a name="5">[5]</a> <a href="#5" id=5>We presented a step-wise unsupervised method for inducing verb classes from instances in giga-word corpora.</a>
<a name="6">[6]</a> <a href="#6" id=6>This method first clusters predicate-argument structures to induce verb-specific semantic frames and then clusters these semantic frames across verbs to induce verb classes.</a>
<a name="7">[7]</a> <a href="#7" id=7>Both clustering steps are performed with exactly the same method, which is based on the Chinese Restaurant Process.</a>
<a name="8">[8]</a> <a href="#8" id=8>The resulting semantic frames and verb classes are open to the public and also can be searched via our web interface.</a>
<a name="9">[9]</a> <a href="#9" id=9>10 10 http://nlp.ist.i.kyoto-u.ac.jp/member/kawahara/cf/crp.en/.</a>
<a name="10">[10]</a> <a href="#10" id=10>From the results, we can see that the combination of the slot-word pair features for clustering verb-specific frames and the slot-only features for clustering across verbs is the most effective and outperforms the baselines by approximately 10 points.</a>
<a name="11">[11]</a> <a href="#11" id=11>This indicates that slot distributions are more effective than lexical information in slot-word pairs for the induction of verb classes, when Levin-style classes are used for evaluation.</a>
<a name="12">[12]</a> <a href="#12" id=12>This is consistent with Levin s principle of organizing verb classes according to the syntactic behavior of verbs.</a>
<a name="13">[13]</a> <a href="#13" id=13>As applications of the resulting semantic frames and verb classes, we plan to integrate them into syntactic parsing, semantic role labeling and verb sense disambiguation.</a>
<a name="14">[14]</a> <a href="#14" id=14>For instance, Kawahara and Kurohashi ( 2006 ) improved accuracy of dependency parsing based on Japanese semantic frames automatically induced from a raw corpus.</a>
<a name="15">[15]</a> <a href="#15" id=15>It is also valuable and promising to apply the induced verb classes to NLP applications as used in metaphor identification [ 34 ] and argumentative zoning [ 8 ].</a>
</body>
</html>