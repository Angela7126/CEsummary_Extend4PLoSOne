<html>
<head>
<title>P14-2073.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Previous research has established several methods of online learning for latent Dirichlet allocation (LDA.</a>
<a name="1">[1]</a> <a href="#1" id=1>However, streaming learning for LDA allowing only one pass over the data and constant storage complexity is not as well explored.</a>
<a name="2">[2]</a> <a href="#2" id=2>We use reservoir sampling to reduce the storage complexity of a previously-studied online algorithm, namely the particle filter, to constant.</a>
<a name="3">[3]</a> <a href="#3" id=3>We then show that a simpler particle filter implementation performs just as well, and that the quality of the initialization dominates other factors of performance.</a>
<a name="4">[4]</a> <a href="#4" id=4>We have proposed reservoir sampling for reducing the storage complexity of a particle filter from linear to constant.</a>
<a name="5">[5]</a> <a href="#5" id=5>This work was motivated as an expected improvement on the model of Canini et al.</a>
<a name="6">[6]</a> <a href="#6" id=6>2009.</a>
<a name="7">[7]</a> <a href="#7" id=7>However, in the process of establishing an empirical baseline we discovered that rejuvenation does not play a significant role in the experiments of Canini et al.</a>
<a name="8">[8]</a> <a href="#8" id=8>2009.</a>
<a name="9">[9]</a> <a href="#9" id=9>Moreover, we found that performance of the particle filter was strongly affected by the random initialization of the model, and suggested a simple approach to reduce the variability therein without using additional data.</a>
<a name="10">[10]</a> <a href="#10" id=10>In conclusion, it is now an open question whether and if so, under what assumptions rejuvenation benefits particle filters for LDA and similar static Bayesian models.</a>
<a name="11">[11]</a> <a href="#11" id=11>We thank Frank Ferraro, Keith Levin, and Mark Dredze for discussions.</a>
</body>
</html>