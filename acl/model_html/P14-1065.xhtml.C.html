<html>
<head>
<title>P14-1065.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We present experiments in using discourse structure for improving machine translation evaluation.</a>
<a name="1">[1]</a> <a href="#1" id=1>We first design two discourse-aware similarity measures, which use all-subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory.</a>
<a name="2">[2]</a> <a href="#2" id=2>Then, we show that these measures can help improve a number of existing machine translation evaluation metrics both at the segment- and at the system-level.</a>
<a name="3">[3]</a> <a href="#3" id=3>Rather than proposing a single new metric, we show that discourse information is complementary to the state-of-the-art evaluation metrics, and thus should be taken into account in the development of future richer evaluation metrics.</a>
<a name="4">[4]</a> <a href="#4" id=4>In this paper we have shown that discourse structure can be used to improve automatic MT evaluation.</a>
<a name="5">[5]</a> <a href="#5" id=5>First, we defined two simple discourse-aware similarity metrics (lexicalized and un-lexicalized), which use the all-subtree kernel to compute similarity between discourse parse trees in accordance with the Rhetorical Structure Theory.</a>
<a name="6">[6]</a> <a href="#6" id=6>Then, after extensive experimentation on WMT12 and WMT11 data, we showed that a variety of existing evaluation metrics can benefit from our discourse-based metrics, both at the segment- and the system-level, especially when the discourse information is incorporated in an informed way (i.e., using supervised tuning.</a>
<a name="7">[7]</a> <a href="#7" id=7>Our results show that discourse-based metrics can improve the state-of-the-art MT metrics, by increasing correlation with human judgments, even when only sentence-level discourse information is used.</a>
<a name="8">[8]</a> <a href="#8" id=8>Addressing discourse-level phenomena in MT is a relatively new research direction.</a>
<a name="9">[9]</a> <a href="#9" id=9>Yet, many of the ongoing efforts have been moderately successful according to traditional evaluation metrics.</a>
<a name="10">[10]</a> <a href="#10" id=10>There is a consensus in the MT community that more discourse-aware metrics need to be proposed for this area to move forward.</a>
<a name="11">[11]</a> <a href="#11" id=11>We believe this work is a valuable contribution towards this longer-term goal.</a>
<a name="12">[12]</a> <a href="#12" id=12>The tuned combined metrics tested in this paper are just an initial proposal, i.e., a simple adjustment of the relative weights for the individual metrics in a linear combination.</a>
<a name="13">[13]</a> <a href="#13" id=13>In the future, we plan to work on integrated representations of syntactic, semantic and discourse-based structures, which would allow us to train evaluation metrics based on more fine-grained features.</a>
<a name="14">[14]</a> <a href="#14" id=14>Additionally, we propose to use the discourse information for MT in two different ways.</a>
<a name="15">[15]</a> <a href="#15" id=15>First, at the sentence-level, we can use discourse information to re-rank alternative MT hypotheses; this could be applied either for MT parameter tuning, or as a post-processing step for the MT output.</a>
<a name="16">[16]</a> <a href="#16" id=16>Second, we propose to move in the direction of using discourse information beyond the sentence-level.</a>
</body>
</html>