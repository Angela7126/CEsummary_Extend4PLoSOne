<html>
<head>
<title>P14-1045.xhtml.A</title>
</head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>Using distributional analysis methods to compute semantic proximity links between words has become commonplace in NLP..</a>
<a name="2">[2]</a> <a href="#2" id=2> The resulting relations are often noisy or difficult to interpret in general..</a>
<a name="3">[3]</a> <a href="#3" id=3> This paper focuses on the issues of evaluating a distributional resource and filtering the relations it contains, but instead of considering it in abstracto, we focus on pairs of words in context..</a>
<a name="4">[4]</a> <a href="#4" id=4> In a discourse, we are interested in knowing if the semantic link between two items is a by-product of textual coherence or is irrelevant..</a>
<a name="5">[5]</a> <a href="#5" id=5> We first set up a human annotation of semantic links with or without contextual information to show the importance of the textual context in evaluating the relevance of semantic similarity, and to assess the prevalence of actual semantic relations between word tokens..</a>
<a name="6">[6]</a> <a href="#6" id=6> We then built an experiment to automatically predict this relevance, evaluated on the reliable reference data set which was the outcome of the first annotation..</a>
<a name="7">[7]</a> <a href="#7" id=7> We show that in-document information greatly improve the prediction made by the similarity level alone..</a>
</body>
</html>