<html>
<head>
<title>P14-1122.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Large-scale knowledge bases are important assets in NLP.</a>
<a name="1">[1]</a> <a href="#1" id=1>Frequently, such resources are constructed through automatic mergers of complementary resources, such as WordNet and Wikipedia.</a>
<a name="2">[2]</a> <a href="#2" id=2>However, manually validating these resources is prohibitively expensive, even when using methods such as crowdsourcing.</a>
<a name="3">[3]</a> <a href="#3" id=3>We propose a cost-effective method of validating and extending knowledge bases using video games with a purpose.</a>
<a name="4">[4]</a> <a href="#4" id=4>Two video games were created to validate concept-concept and concept-image relations.</a>
<a name="5">[5]</a> <a href="#5" id=5>In experiments comparing with crowdsourcing, we show that video game-based validation consistently leads to higher-quality annotations, even when players are not compensated.</a>
<a name="6">[6]</a> <a href="#6" id=6>Two video games have been presented for validating and extending knowledge bases.</a>
<a name="7">[7]</a> <a href="#7" id=7>The first game, Infection, validates concept-concept relations, and the second, The Knowledge Towers, validates image-concept relations.</a>
<a name="8">[8]</a> <a href="#8" id=8>In experiments involving online players, we demonstrate three contributions.</a>
<a name="9">[9]</a> <a href="#9" id=9>First, games were released in two conditions whereby players either saw financial incentives for playing or a personal satisfaction incentive where they were thanked by us.</a>
<a name="10">[10]</a> <a href="#10" id=10>We demonstrated that both conditions produced nearly identical numbers of annotations and, moreover, that players were disinterested in the satisfaction incentive, suggesting they played out of interest in the game itself.</a>
<a name="11">[11]</a> <a href="#11" id=11>Furthermore, we demonstrated the effectiveness of a novel design for games with a purpose which does not require two players for validation and instead reinforces behavior only using true negative items that required no manual annotation.</a>
<a name="12">[12]</a> <a href="#12" id=12>Second, in a comparison with crowdsourcing, we demonstrate that video game-based annotations consistently generated higher-quality annotations.</a>
<a name="13">[13]</a> <a href="#13" id=13>Last, we demonstrate that video game-based annotation can be more cost-effective than crowdsourcing or annotation tasks with game-like features.</a>
<a name="14">[14]</a> <a href="#14" id=14>The significant number of annotations generated by the satisfaction incentive condition shows that a fun game can generate high-quality annotations at virtually no cost.</a>
<a name="15">[15]</a> <a href="#15" id=15>All annotated resources, demos of the games, and a live version of the top-ranking items for each concept are currently available online.</a>
<a name="16">[16]</a> <a href="#16" id=16>5 5 http://lcl.uniroma1.it/games/.</a>
<a name="17">[17]</a> <a href="#17" id=17>In the future we will apply our video games to the validation of more data, such as the new Wikipedia bitaxonomy [ 11 ].</a>
</body>
</html>