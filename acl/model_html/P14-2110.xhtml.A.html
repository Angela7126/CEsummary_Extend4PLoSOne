<html>
<head>
<title>P14-2110.xhtml.A</title>
</head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>Code-switched documents are common in social media, providing evidence for polylingual topic models to infer aligned topics across languages..</a>
<a name="2">[2]</a> <a href="#2" id=2> We present Code-Switched LDA (csLDA), which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis..</a>
<a name="3">[3]</a> <a href="#3" id=3> We experiment on two code-switching corpora (English-Spanish Twitter data and English-Chinese Weibo data) and show that csLDA improves perplexity over LDA, and learns semantically coherent aligned topics as judged by human annotators..</a>
<a name="4">[4]</a> <a href="#4" id=4> heightadjust=object,valign=t..</a>
</body>
</html>