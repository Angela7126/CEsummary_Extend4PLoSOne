<html>
<head>
<title>P14-1013.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Statistical Machine Translation (SMT) usually utilizes contextual information to disambiguate translation candidates.</a>
<a name="1">[1]</a> <a href="#1" id=1>However, it is often limited to contexts within sentence boundaries, hence broader topical information cannot be leveraged.</a>
<a name="2">[2]</a> <a href="#2" id=2>In this paper, we propose a novel approach to learning topic representation for parallel data using a neural network architecture, where abundant topical contexts are embedded via topic relevant monolingual data.</a>
<a name="3">[3]</a> <a href="#3" id=3>By associating each translation rule with the topic representation, topic relevant rules are selected according to the distributional similarity with the source text during SMT decoding.</a>
<a name="4">[4]</a> <a href="#4" id=4>Experimental results show that our method significantly improves translation accuracy in the NIST Chinese-to-English translation task compared to a state-of-the-art baseline.</a>
<a name="5">[5]</a> <a href="#5" id=5>1] LeiCui 2] DongdongZhang 2] ShujieLiu 3] QimingChen 2] MuLi 2] MingZhou 1] MuyunYang \affil [1]SchoolofComputerScienceandTechnology,HarbinInstituteofTechnology,Harbin,P.R.China \authorcr leicui@hit.edu.cn,ymy@mtlab.hit.edu.cn \affil [2]MicrosoftResearch,Beijing,P.R.China \authorcr { dozhang,shujliu,muli,mingzhou } @microsoft.com \affil [3]ShanghaiJiaoTongUniversity,Shanghai,P.R.China \authorcr simoncqm@gmail.com.</a>
<a name="6">[6]</a> <a href="#6" id=6>UTF8gkai.</a>
<a name="7">[7]</a> <a href="#7" id=7>In this paper, we propose a neural network based approach to learning bilingual topic representation for SMT.</a>
<a name="8">[8]</a> <a href="#8" id=8>We enrich contexts of parallel sentence pairs with topic related monolingual data and obtain a set of documents to represent sentences.</a>
<a name="9">[9]</a> <a href="#9" id=9>These documents are converted to a bag-of-words input and fed into neural networks.</a>
<a name="10">[10]</a> <a href="#10" id=10>The learned low-dimensional vector is used to obtain the topic representations of synchronous rules.</a>
<a name="11">[11]</a> <a href="#11" id=11>In SMT decoding, appropriate rules are selected to best match source texts according to their similarity in the topic space.</a>
<a name="12">[12]</a> <a href="#12" id=12>Experimental results show that our approach is promising for SMT systems to learn a better translation model.</a>
<a name="13">[13]</a> <a href="#13" id=13>It is a significant improvement over the state-of-the-art Hiero system, as well as a conventional LDA-based method.</a>
<a name="14">[14]</a> <a href="#14" id=14>In the future research, we will extend our neural network methods to address document-level translation, where topic transition between sentences is a crucial problem to be solved.</a>
<a name="15">[15]</a> <a href="#15" id=15>Since the translation of the current sentence is usually influenced by the topic of previous sentences, we plan to leverage recurrent neural networks to model this phenomenon, where the history translation information is naturally combined in the model.</a>
</body>
</html>