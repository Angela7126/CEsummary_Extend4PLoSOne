<html>
<head>
<title>P14-2010.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Supervised text classification algorithms require a large number of documents labeled by humans, that involve a labor-intensive and time consuming process.</a>
<a name="1">[1]</a> <a href="#1" id=1>In this paper, we propose a weakly supervised algorithm in which supervision comes in the form of labeling of Latent Dirichlet Allocation (LDA) topics.</a>
<a name="2">[2]</a> <a href="#2" id=2>We then use this weak supervision to sprinkle artificial words to the training documents to identify topics in accordance with the underlying class structure of the corpus based on the higher order word associations.</a>
<a name="3">[3]</a> <a href="#3" id=3>We evaluate this approach to improve performance of text classification on three real world datasets.</a>
<a name="4">[4]</a> <a href="#4" id=4>In this paper we propose a novel algorithm that classifies documents based on class labels over few topics.</a>
<a name="5">[5]</a> <a href="#5" id=5>This reduces the need to label a large collection of documents.</a>
<a name="6">[6]</a> <a href="#6" id=6>We have used the idea of sprinkling originally proposed in the context of supervised Latent Semantic Analysis, but the setting here is quite different.</a>
<a name="7">[7]</a> <a href="#7" id=7>Unlike the work in (Chakraborti et al., 2007), we do not assume that we have class labels over the set of training documents.</a>
<a name="8">[8]</a> <a href="#8" id=8>Instead, to realize our goal of reducing knowledge acquisition overhead, we propose a way of propagating knowledge of few topic labels to the words and inducing a new topic distribution that has its topics more closely aligned to the class labels.</a>
<a name="9">[9]</a> <a href="#9" id=9>The results show that the approach can yield performance comparable to entirely supervised settings.</a>
<a name="10">[10]</a> <a href="#10" id=10>In future work, we also envision the possibility of sprinkling knowledge from background knowledge sources like Wikipedia (Gabrilovich and Markovitch, 2007) to realize an alignment of topics to Wikipedia concepts.</a>
<a name="11">[11]</a> <a href="#11" id=11>We would like to study effect of change in number of topics on the text classification performance.</a>
<a name="12">[12]</a> <a href="#12" id=12>We will also explore techniques which will help annotators to encode their domain knowledge efficiently when the topics are not well aligned to the class labels.</a>
</body>
</html>