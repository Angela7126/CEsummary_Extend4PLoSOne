<html>
<head>
<title>P14-1132.xhtml.A</title>
</head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>Following up on recent work on establishing a mapping between vector-based semantic embeddings of words and the visual representations of the corresponding objects from natural images, we first present a simple approach to cross-modal vector-based semantics for the task of zero-shot learning , in which an image of a previously unseen object is mapped to a linguistic representation denoting its word..</a>
<a name="2">[2]</a> <a href="#2" id=2> We then introduce fast mapping , a challenging and more cognitively plausible variant of the zero-shot task, in which the learner is exposed to new objects and the corresponding words in very limited linguistic contexts..</a>
<a name="3">[3]</a> <a href="#3" id=3> By combining prior linguistic and visual knowledge acquired about words and their objects, as well as exploiting the limited new evidence available, the learner must learn to associate new objects with words..</a>
<a name="4">[4]</a> <a href="#4" id=4> Our results on this task pave the way to realistic simulations of how children or robots could use existing knowledge to bootstrap grounded semantic knowledge about new concepts..</a>
</body>
</html>