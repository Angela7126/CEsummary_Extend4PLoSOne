<html>
<head>
<title>P14-2127.xhtml.A</title>
</head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>Large-scale discriminative training has become promising for statistical machine translation by leveraging the huge training corpus; for example the recent effort in phrase-based MT [ 21 ] significantly outperforms mainstream methods that only train on small tuning sets..</a>
<a name="2">[2]</a> <a href="#2" id=2> However, phrase-based MT suffers from limited reorderings, and thus its training can only utilize a small portion of the bitext due to the distortion limit..</a>
<a name="3">[3]</a> <a href="#3" id=3> To address this problem, we extend \newcite yu+:2013 to syntax-based MT by generalizing their latent variable violation-fixing perceptron from graphs to hypergraphs..</a>
<a name="4">[4]</a> <a href="#4" id=4> Experiments confirm that our method leads to up to +1.2 Bleu improvement over mainstream methods such as Mert and Pro..</a>
<a name="5">[5]</a> <a href="#5" id=5> 1.5em..</a>
<a name="6">[6]</a> <a href="#6" id=6> 1em..</a>
<a name="7">[7]</a> <a href="#7" id=7> algorithmAlgorithm..</a>
</body>
</html>