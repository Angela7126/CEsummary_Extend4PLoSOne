<html>
<head>
<title>P14-1116.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We present a novel approach for automatic report generation from time-series data, in the context of student feedback generation.</a>
<a name="1">[1]</a> <a href="#1" id=1>Our proposed methodology treats content selection as a multi-label (ML) classification problem, which takes as input time-series data and outputs a set of templates, while capturing the dependencies between selected templates.</a>
<a name="2">[2]</a> <a href="#2" id=2>We show that this method generates output closer to the feedback that lecturers actually generated, achieving 3.5% higher accuracy and 15% higher F-score than multiple simple classifiers that keep a history of selected templates.</a>
<a name="3">[3]</a> <a href="#3" id=3>Furthermore, we compare a ML classifier with a Reinforcement Learning (RL) approach in simulation and using ratings from real student users.</a>
<a name="4">[4]</a> <a href="#4" id=4>We show that the different methods have different benefits, with ML being more accurate for predicting what was seen in the training data, whereas RL is more exploratory and slightly preferred by the students.</a>
<a name="5">[5]</a> <a href="#5" id=5>We have shown that ML classification for summarisation of our time-series data has an accuracy of 76.95% and that this approach significantly outperforms other classification methods as it is able to capture dependencies in the data when making content selection decisions.</a>
<a name="6">[6]</a> <a href="#6" id=6>ML classification was also directly compared to a RL method.</a>
<a name="7">[7]</a> <a href="#7" id=7>It was found that although ML classification is almost 20% more accurate than RL, both methods perform comparably when rated by humans.</a>
<a name="8">[8]</a> <a href="#8" id=8>This may be due to the fact that the RL optimisation method is able to provide more varied responses over time rather than just emulating the training data as with standard supervised learning approaches.</a>
<a name="9">[9]</a> <a href="#9" id=9>Foster \shortcite Foster2008 found similar results when performing a study on generation of emphatic facial displays.</a>
<a name="10">[10]</a> <a href="#10" id=10>A previous study by Belz and Reiter \shortcite Belz2006 has demonstrated that automatic metrics can correlate highly with human ratings if the training dataset is of high quality.</a>
<a name="11">[11]</a> <a href="#11" id=11>In our study, the human ratings correlate well to the average scores achieved by the reward function.</a>
<a name="12">[12]</a> <a href="#12" id=12>However, the human ratings do not correlate well to the accuracy scores.</a>
<a name="13">[13]</a> <a href="#13" id=13>It is interesting that the two methods that score differently on various automatic metrics, such as accuracy, reward, precision, recall and F-score, are evaluated similarly by users.</a>
<a name="14">[14]</a> <a href="#14" id=14>The comparison shows that each method can serve different goals.</a>
<a name="15">[15]</a> <a href="#15" id=15>Multi-label classification generates output closer to gold standard whereas RL can optimise the output according to a reward function.</a>
<a name="16">[16]</a> <a href="#16" id=16>ML classification could be used when the goal of the generation is to replicate phenomena seen in the dataset, because it achieves high accuracy, precision and recall.</a>
<a name="17">[17]</a> <a href="#17" id=17>However, optimisation methods can be more flexible, provide more varied output and can be trained for different goals, e.g., for capturing preferences of different users.</a>
</body>
</html>