<html>
<head>
<title>P14-2050.xhtml.B</title>
</head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>We presented a generalization of the SkipGram embedding model in which the linear bag-of-words contexts are replaced with arbitrary ones, and experimented with dependency-based contexts, showing that they produce markedly different kinds of similarities..</a>
<a name="2">[2]</a> <a href="#2" id=2> These results are expected, and follow similar findings in the distributional semantics literature..</a>
<a name="3">[3]</a> <a href="#3" id=3> We also demonstrated how the resulting embedding model can be queried for the discriminative contexts for a given word, and observed that the learning procedure seems to favor relatively local syntactic contexts, as well as conjunctions and objects of preposition..</a>
<a name="4">[4]</a> <a href="#4" id=4> We hope these insights will facilitate further research into improved context modeling and better, possibly task-specific, embedded representations..</a>
<a name="5">[5]</a> <a href="#5" id=5> Our software, allowing for experimentation with arbitrary contexts, together with the embeddings described in this paper, are available for download at the authors websites..</a>
</body>
</html>