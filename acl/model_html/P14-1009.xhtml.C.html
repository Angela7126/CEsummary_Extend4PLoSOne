<html>
<head>
<title>P14-1009.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Distributional semantic methods to approximate word meaning with context vectors have been very successful empirically, and the last years have seen a surge of interest in their compositional extension to phrases and sentences.</a>
<a name="1">[1]</a> <a href="#1" id=1>We present here a new model that, like those of Coecke et al.</a>
<a name="2">[2]</a> <a href="#2" id=2>2010 ) and Baroni and Zamparelli ( 2010 ) , closely mimics the standard Montagovian semantic treatment of composition in distributional terms.</a>
<a name="3">[3]</a> <a href="#3" id=3>However, our approach avoids a number of issues that have prevented the application of the earlier linguistically-motivated models to full-fledged, real-life sentences.</a>
<a name="4">[4]</a> <a href="#4" id=4>We test the model on a variety of empirical tasks, showing that it consistently outperforms a set of competitive rivals.</a>
<a name="5">[5]</a> <a href="#5" id=5>We introduced an approach to compositional distributional semantics based on a linguistically-motivated syntax-to-semantics type mapping, but simple and flexible enough that it can produce representations of English sentences of arbitrary size and structure.</a>
<a name="6">[6]</a> <a href="#6" id=6>We showed that our approach is competitive against the more complex lexical function model when evaluated on the simple constructions the latter can be applied to, and it outperforms the additive and multiplicative compositionality models when tested on more realistic benchmarks (where the full-fledged lexical function approach is difficult or impossible to use), even in presence of strong noise in its syntactic input.</a>
<a name="7">[7]</a> <a href="#7" id=7>While our results are encouraging, no current benchmark combines large-scale, real-life data with the syntactic variety on which a syntax-driven approach to semantics such as ours could truly prove its worth.</a>
<a name="8">[8]</a> <a href="#8" id=8>The recently announced SemEval 2014 Task 1 7 7 http://alt.qcri.org/semeval2014/task1/ is filling exactly this gap, and we look forward to apply our method to this new benchmark, as soon as it becomes available.</a>
<a name="9">[9]</a> <a href="#9" id=9>One of the strengths of our framework is that it allows for incremental improvement focused on specific constructions.</a>
<a name="10">[10]</a> <a href="#10" id=10>For example, one could add representations for different conjunctions ( and vs or ), train matrices for verb arguments other than subject and direct object, or include new types of modifiers into the model, etc.</a>
<a name="11">[11]</a> <a href="#11" id=11>While there is potential for local improvements, our framework, which extends and improves on existing compositional semantic vector models, has demonstrated its ability to account for full sentences in a principled and elegant way.</a>
<a name="12">[12]</a> <a href="#12" id=12>Our implementation of the model relies on simple and efficient training, works fast, and shows good empirical results.</a>
</body>
</html>