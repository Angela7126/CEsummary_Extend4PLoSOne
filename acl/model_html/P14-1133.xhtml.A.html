<html>
<head>
<title>P14-1133.xhtml.A</title>
</head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>A central challenge in semantic parsing is handling the myriad ways in which knowledge base predicates can be expressed..</a>
<a name="2">[2]</a> <a href="#2" id=2> Traditionally, semantic parsers are trained primarily from text paired with knowledge base information..</a>
<a name="3">[3]</a> <a href="#3" id=3> Our goal is to exploit the much larger amounts of raw text not tied to any knowledge base..</a>
<a name="4">[4]</a> <a href="#4" id=4> In this paper, we turn semantic parsing on its head..</a>
<a name="5">[5]</a> <a href="#5" id=5> Given an input utterance, we first use a simple method to deterministically generate a set of candidate logical forms with a canonical realization in natural language for each..</a>
<a name="6">[6]</a> <a href="#6" id=6> Then, we use a paraphrase model to choose the realization that best paraphrases the input, and output the corresponding logical form..</a>
<a name="7">[7]</a> <a href="#7" id=7> We present two simple paraphrase models, an association model and a vector space model, and train them jointly from question-answer pairs..</a>
<a name="8">[8]</a> <a href="#8" id=8> Our system ParaSempre improves state-of-the-art accuracies on two recently released question-answering datasets..</a>
<a name="9">[9]</a> <a href="#9" id=9> leftmargin=0cm,labelindent=0cm..</a>
</body>
</html>