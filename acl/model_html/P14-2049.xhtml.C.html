<html>
<head>
<title>P14-2049.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We show that asymmetric models based on Tversky [ 19 ] improve correlations with human similarity judgments and nearest neighbor discovery for both frequent and middle-rank words.</a>
<a name="1">[1]</a> <a href="#1" id=1>In accord with Tversky s discovery that asymmetric similarity judgments arise when comparing sparse and rich representations, improvement on our two tasks can be traced to heavily weighting the feature bias toward the rarer word when comparing high- and mid-frequency words.</a>
<a name="2">[2]</a> <a href="#2" id=2>We have shown that Tversky s asymmetric ratio models can improve performance in capturing human judgments and produce better nearest neighbors.</a>
<a name="3">[3]</a> <a href="#3" id=3>To validate these very preliminary results, we need to explore applications compatible with asymmetry, such as the TOEFL-like synonym discovery task in Freitag et al.</a>
<a name="4">[4]</a> <a href="#4" id=4>[ 7 ] , and the PP-attachment task in Dagan et al.</a>
<a name="5">[5]</a> <a href="#5" id=5>[ 4 ].</a>
</body>
</html>