<html>
<head>
<title>P14-2110.xhtml</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Code-switched documents are common in social media, providing evidence for polylingual topic models to infer aligned topics across languages.</a>
<a name="1">[1]</a> <a href="#1" id=1>We present Code-Switched LDA (csLDA), which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis.</a>
<a name="2">[2]</a> <a href="#2" id=2>We experiment on two code-switching corpora (English-Spanish Twitter data and English-Chinese Weibo data) and show that csLDA improves perplexity over LDA, and learns semantically coherent aligned topics as judged by human annotators.</a>
<a name="3">[3]</a> <a href="#3" id=3>heightadjust=object,valign=t.</a>
</body>
</html>