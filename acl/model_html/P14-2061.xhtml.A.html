<html>
<head>
<title>P14-2061.xhtml.A</title>
</head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>Prior research on language identification focused primarily on text and speech..</a>
<a name="2">[2]</a> <a href="#2" id=2> In this paper, we focus on the visual modality and present a method for identifying sign languages solely from short video samples..</a>
<a name="3">[3]</a> <a href="#3" id=3> The method is trained on unlabelled video data (unsupervised feature learning) and using these features, it is trained to discriminate between six sign languages (supervised learning..</a>
<a name="4">[4]</a> <a href="#4" id=4> We ran experiments on short video samples involving 30 signers (about 6 hours in total..</a>
<a name="5">[5]</a> <a href="#5" id=5> Using leave-one-signer-out cross-validation, our evaluation shows an average best accuracy of 84 %..</a>
<a name="6">[6]</a> <a href="#6" id=6> Given that sign languages are under-resourced, unsupervised feature learning techniques are the right tools and our results indicate that this is realistic for sign language identification..</a>
</body>
</html>