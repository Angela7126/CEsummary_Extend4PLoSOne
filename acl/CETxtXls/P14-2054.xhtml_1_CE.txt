************************************************************
P14-2054.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Sentence compression aims to shorten a sentence by removing uninformative words to reduce reading time
	Cause: [(0, 8), (0, 14)]
	Effect: [(0, 0), (0, 6)]

CASE: 1
Stag: 3 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Recent studies used a subtree deletion model for compression [ 1 , 13 , 15 ] , which deletes a word only if its modifier in the parse tree is deleted
	Cause: [(0, 23), (0, 30)]
	Effect: [(0, 0), (0, 21)]

CASE: 2
Stag: 7 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Trevor et al.Â proposed synchronous tree substitution grammar [ 5 ] , which allows local distortion of the tree topology and can thus naturally capture structural mismatches
	Cause: [(0, 0), (0, 21)]
	Effect: [(0, 23), (0, 26)]

CASE: 3
Stag: 9 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: However, the time complexity greatly increases since the parse tree dynamically depends on the compression
	Cause: [(0, 8), (0, 15)]
	Effect: [(0, 4), (0, 6)]

CASE: 4
Stag: 12 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Our method extends Eisner u'\u2019' s cubic time parsing algorithm by adding signatures to each span, which indicate the number of deleted words and the rightmost kept word within the span, resulting in O u'\u2062' ( n 6 ) time complexity and O u'\u2062' ( n 4 ) space complexity
	Cause: [(0, 15), (0, 63)]
	Effect: [(0, 0), (0, 13)]

CASE: 5
Stag: 13 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: We further propose a faster approximate algorithm based on Lagrangian relaxation, which has T u'\u2062' O u'\u2062' ( n 4 ) running time and O u'\u2062' ( n 3 ) space complexity ( T is the iteration number in the subgradient decent algorithm
	Cause: [(0, 9), (0, 10)]
	Effect: [(0, 12), (0, 55)]

CASE: 6
Stag: 15 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: We define the sentence compression task as given a sentence composed of n words, u'\ud835' u'\udc31' = x 1 , u'\u2026' , x n , and a length L u'\u2264' n , we need to remove ( n - L ) words from u'\ud835' u'\udc31' , so that the sum of the weights of the dependency tree and word bigrams of the remaining part is maximized
	Cause: [(0, 0), (0, 70)]
	Effect: [(0, 73), (0, 90)]

CASE: 7
Stag: 17 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: where u'\ud835' u'\udc33' is a binary vector, z i indicates x i is kept or not u'\ud835' u'\udc32' is a square matrix denoting the projective dependency parse tree over the remaining words, y i u'\u2062' j indicates if x i is the head of x j (note that each word has exactly one head w i tok is the informativeness of x i , w i u'\u2062' j bgr is the score of bigram x i u'\u2062' x j in an n-gram model, w dep is the score of dependency arc x i u'\u2192' x j in an arc-factored dependency parsing model
	Cause: [(0, 60), (0, 85)]
	Effect: [(0, 87), (0, 124)]

CASE: 8
Stag: 17 18 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: where u'\ud835' u'\udc33' is a binary vector, z i indicates x i is kept or not u'\ud835' u'\udc32' is a square matrix denoting the projective dependency parse tree over the remaining words, y i u'\u2062' j indicates if x i is the head of x j (note that each word has exactly one head w i tok is the informativeness of x i , w i u'\u2062' j bgr is the score of bigram x i u'\u2062' x j in an n-gram model, w dep is the score of dependency arc x i u'\u2192' x j in an arc-factored dependency parsing model Hence, the first part of the objective function is the total score of the kept words, the second and third parts are the scores of the parse tree and bigrams of the compressed sentence, z i u'\u2062' z j u'\u2062' u'\u220f' i k j ( 1 - z k ) = 1 indicates both x i and x j are kept, and are adjacent after compression
	Cause: [(0, 2), (0, 137)]
	Effect: [(1, 2), (1, 81)]

CASE: 9
Stag: 22 23 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: A span is a subtree over a number of consecutive words, with the leftmost or the rightmost word as its root An incomplete span denoted as I j i is a subtree inside a single arc x i u'\u2192' x j , with root x i
	Cause: [(0, 20), (1, 26)]
	Effect: [(0, 0), (0, 18)]

CASE: 10
Stag: 27 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: There are two rules for merging spans one merges two complete spans into an incomplete span, the other merges an incomplete span and a complete span into a large complete span
	Cause: [(0, 5), (0, 31)]
	Effect: [(0, 0), (0, 3)]

CASE: 11
Stag: 29 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: The scores of unigrams w i tok can be transfered to the dependency arcs, so that we can remove all linear terms w i tok u'\u2062' z i from the objective function
	Cause: [(0, 0), (0, 14)]
	Effect: [(0, 17), (0, 36)]

CASE: 12
Stag: 32 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: If z j = 0 , then in both equations, all terms having z j are zero; If z j = 1 , i.e.,, x j is kept, since it has exactly one head word x k in the compressed sentence, the sum of the terms having z j is w j tok + w k u'\u2062' j dep for both equations
	Cause: [(0, 34), (0, 46)]
	Effect: [(0, 13), (0, 31)]

CASE: 13
Stag: 32 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: If z j = 0 , then in both equations, all terms having z j are zero; If z j = 1 , i.e.,, x j is kept, since it has exactly one head word x k in the compressed sentence, the sum of the terms having z j is w j tok + w k u'\u2062' j dep for both equations
	Cause: [(0, 0), (0, 2)]
	Effect: [(0, 3), (0, 5)]

CASE: 14
Stag: 32 33 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: If z j = 0 , then in both equations, all terms having z j are zero; If z j = 1 , i.e.,, x j is kept, since it has exactly one head word x k in the compressed sentence, the sum of the terms having z j is w j tok + w k u'\u2062' j dep for both equations Therefore, we only need to consider the scores of arcs
	Cause: [(0, 0), (0, 71)]
	Effect: [(1, 2), (1, 10)]

CASE: 15
Stag: 34 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: For any compressed sentence, we could augment its dependency tree by adding a virtual arc i - 1 u'\u2192' i for each deleted word x i
	Cause: [(0, 12), (0, 30)]
	Effect: [(0, 0), (0, 10)]

CASE: 16
Stag: 35 36 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If the first word x 1 is deleted, we connect it to the root of the parse tree x 0 , as shown in Figure 3 In this way, we derive a full parse tree of the original sentence
	Cause: [(0, 23), (1, 13)]
	Effect: [(0, 0), (0, 20)]

CASE: 17
Stag: 38 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We can reversely get the the compressed parse tree by removing all virtual arcs from the full parse tree
	Cause: [(0, 10), (0, 18)]
	Effect: [(0, 0), (0, 8)]

CASE: 18
Stag: 39 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: We restrict the score of all the virtual arcs to be zero, so that scores of the two parse trees are equivalent
	Cause: [(0, 0), (0, 12)]
	Effect: [(0, 15), (0, 22)]

CASE: 19
Stag: 46 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The two complete spans must be single words, as the length of the virtual arc is 1
	Cause: [(0, 10), (0, 17)]
	Effect: [(0, 0), (0, 7)]

CASE: 20
Stag: 52 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: The number of the virtual arcs within C j i + 1 must be j - i - 1 , since the descendants of the modifier of a virtual arc x j must be removed
	Cause: [(0, 21), (0, 34)]
	Effect: [(0, 0), (0, 18)]

CASE: 21
Stag: 58 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The root node is allowed to have two modifiers one is the modifier in the compressed sentence, the other is the first word if it is removed
	Cause: [(0, 25), (0, 27)]
	Effect: [(0, 0), (0, 23)]

CASE: 22
Stag: 59 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: For each combination, the algorithm enumerates the number of virtual arcs in the left and right spans, and the split position (e.g.,, k u'\u2032' , k u'\u2032' u'\u2032' , r in case 2), thus it takes O u'\u2062' ( n 3 ) running time
	Cause: [(0, 1), (0, 50)]
	Effect: [(0, 53), (0, 66)]

CASE: 23
Stag: 64 65 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Suppose x j is removed, there must be a virtual arc j - 1 u'\u2192' j which is a conflict with the fact that x j is the leftmost word As x j is a descendant of x i , x i must be kept u'\u220e'
	Cause: [(1, 1), (1, 19)]
	Effect: [(0, 14), (0, 34)]

CASE: 24
Stag: 67 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: According to the proposition above, if the right span is right-headed, its leftmost word is kept
	Cause: [(0, 7), (0, 11)]
	Effect: [(0, 13), (0, 17)]

CASE: 25
Stag: 68 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the right span is left-headed, there are two cases its leftmost word is kept, or no word in the span is kept
	Cause: [(0, 1), (0, 5)]
	Effect: [(0, 7), (0, 17)]

CASE: 26
Stag: 71 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to the proposition above, we have, for any right-headed span p = i
	Cause: [(0, 2), (0, 4)]
	Effect: [(0, 6), (0, 15)]

CASE: 27
Stag: 82 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Fixing u'\u039b' , the optimal u'\ud835' u'\udc33' , u'\ud835' u'\udc32' can be found using a simpler version of the algorithm above
	Cause: [(0, 0), (0, 10)]
	Effect: [(0, 11), (0, 40)]

CASE: 28
Stag: 83 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We drop the signature of the virtual arc number from each span, and thus obtain an O u'\u2062' ( n 4 ) time algorithm
	Cause: [(0, 0), (0, 11)]
	Effect: [(0, 15), (0, 28)]

CASE: 29
Stag: 85 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Fixing u'\ud835' u'\udc33' , u'\ud835' u'\udc32' , the dual variable is updated by
	Cause: [(0, 0), (0, 21)]
	Effect: [(0, 23), (0, 28)]

CASE: 30
Stag: 90 91 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use the same partitions as [ 10 ] , i.e.,, 1,188 sentences for training and 441 for testing Our model is discriminative u'\u2013' the scores of the unigrams, bigrams and dependency arcs are the linear functions of features, that is, w i tok = u'\ud835' u'\udc2f' T u'\u2062' u'\ud835' u'\udc1f' u'\u2062' ( x i ) , where u'\ud835' u'\udc1f' is the feature vector of x i , and u'\ud835' u'\udc2f' is the weight vector of features
	Cause: [(0, 6), (1, 98)]
	Effect: [(0, 0), (0, 4)]

CASE: 31
Stag: 92 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The learning task is to estimate the feature weight vector based on the manually compressed sentences
	Cause: [(0, 12), (0, 15)]
	Effect: [(0, 0), (0, 9)]

CASE: 32
Stag: 94 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Then we augment these parse trees by adding virtual arcs and get the full parse trees of their corresponding original sentences
	Cause: [(0, 7), (0, 9)]
	Effect: [(0, 10), (0, 20)]

CASE: 33
Stag: 100 101 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The first is linear chain CRFs, where the compression task is casted as a binary sequence labeling problem It usually achieves high unigram F1 score but low grammatical relation F1 score since it only considers the local interdependence between adjacent words
	Cause: [(0, 14), (1, 21)]
	Effect: [(0, 0), (0, 12)]

CASE: 34
Stag: 101 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: It usually achieves high unigram F1 score but low grammatical relation F1 score since it only considers the local interdependence between adjacent words
	Cause: [(0, 14), (0, 22)]
	Effect: [(0, 0), (0, 12)]

CASE: 35
Stag: 102 103 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The second is the subtree deletion model [ 1 ] which is solved by integer linear programming (ILP) 2 2 We use Gurobi as the ILP solver in the paper http://www.gurobi.com/ The third one is the bigram model proposed by McDonald [ 12 ] which adopts dynamic programming for efficient inference
	Cause: [(0, 26), (1, 18)]
	Effect: [(0, 0), (0, 24)]

CASE: 36
Stag: 109 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: As expected, the joint models (ours and TM13) consistently outperform the subtree deletion model, since the joint models do not suffer from the subtree restriction
	Cause: [(0, 19), (0, 28)]
	Effect: [(0, 0), (0, 16)]

CASE: 37
Stag: 111 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: It is not surprising that CRFs achieve high unigram F scores but low syntactic F scores as they do not consider the fluency of the compressed sentence
	Cause: [(0, 17), (0, 26)]
	Effect: [(0, 0), (0, 15)]

CASE: 38
Stag: 112 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: Compared with TM13 u'\u2019' s system, our model with exact decoding is not significantly faster due to the high order of the time complexity
	Cause: [(0, 22), (0, 28)]
	Effect: [(0, 0), (0, 19)]

