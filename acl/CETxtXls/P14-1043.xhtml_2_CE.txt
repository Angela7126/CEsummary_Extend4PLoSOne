************************************************************
P14-1043.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 1 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This paper proposes a simple yet effective framework for semi-supervised dependency parsing at entire tree level , referred to as ambiguity-aware ensemble training Instead of only using 1-best parse trees in previous work , our core idea is to utilize parse forest -LRB- ambiguous labelings -RRB- to combine multiple 1-best parse trees generated from diverse parsers on unlabeled data
	Cause: ambiguity-aware ensemble training Instead of only using 1-best parse trees in previous work , our core idea is to utilize parse forest -LRB- ambiguous labelings -RRB- to combine multiple 1-best parse trees generated from diverse parsers on unlabeled
	Effect: This paper proposes a simple yet effective framework for semi-supervised dependency parsing at entire tree level , referred to

CASE: 1
Stag: 14 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: All above work leads to significant improvement on parsing accuracy
	Cause: All above work
	Effect: significant improvement on parsing accuracy

CASE: 2
Stag: 19 20 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Both work employs two parsers to process the unlabeled data , and only select as extra training data sentences on which the 1-best parse trees of the two parsers are identical In this way , the auto-parsed unlabeled data becomes more reliable
	Cause: extra training data sentences on which the 1-best parse trees of the two parsers are identical In this way , the auto-parsed unlabeled data becomes more
	Effect: Both work employs two parsers to process the unlabeled data , and only select

CASE: 3
Stag: 26 27 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To solve above issues , this paper proposes a more general and effective framework for semi-supervised dependency parsing , referred to as ambiguity-aware ensemble training Different from traditional self/co/tri-training which only use 1-best parse trees on unlabeled data , our approach adopts ambiguous labelings , represented by parse forest , as gold-standard for unlabeled sentences
	Cause: ambiguity-aware ensemble training Different from traditional self/co/tri-training which only use 1-best parse trees on unlabeled data , our approach adopts ambiguous labelings , represented by parse forest , as gold-standard for unlabeled
	Effect: To solve above issues , this paper proposes a more general and effective framework for semi-supervised dependency parsing , referred to

CASE: 4
Stag: 27 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Different from traditional self/co/tri-training which only use 1-best parse trees on unlabeled data , our approach adopts ambiguous labelings , represented by parse forest , as gold-standard for unlabeled sentences
	Cause: Different from traditional self/co/tri-training which only use 1-best parse trees on unlabeled data
	Effect: our approach adopts ambiguous labelings , represented by parse forest , as gold-standard for unlabeled sentences

CASE: 5
Stag: 31 32 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The upper tree take u ' \ u201c ' deer u ' \ u201d ' as the subject of u ' \ u201c ' riding u ' \ u201d ' , whereas the lower one indicates that u ' \ u201c ' he u ' \ u201d ' rides the bicycle The other difference is where the preposition phrase -LRB- PP -RRB- u ' \ u201c ' in the park u ' \ u201d ' should be attached , which is also known as the PP attachment problem , a notorious challenge for parsing
	Cause: the subject of u ' \ u201c ' riding u ' \ u201d ' , whereas the lower one indicates that u ' \ u201c ' he u ' \ u201d ' rides the bicycle The other difference is where the preposition phrase -LRB- PP -RRB- u ' \ u201c ' in the park u ' \ u201d ' should be attached , which is also known as the PP attachment problem ,
	Effect: The upper tree take u ' \ u201c ' deer u ' \ u201d '

CASE: 6
Stag: 32 33 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The other difference is where the preposition phrase -LRB- PP -RRB- u ' \ u201c ' in the park u ' \ u201d ' should be attached , which is also known as the PP attachment problem , a notorious challenge for parsing Reserving such uncertainty has three potential advantages
	Cause: the PP attachment problem , a notorious challenge for parsing Reserving such uncertainty has three potential
	Effect: The other difference is where the preposition phrase -LRB- PP -RRB- u ' \ u201c ' in the park u ' \ u201d ' should be attached , which is also known

CASE: 7
Stag: 34 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: First , noise in unlabeled data is largely alleviated , since parse forest encodes only a few highly possible parse trees with high oracle score
	Cause: parse forest encodes only a few highly possible parse trees
	Effect: First , noise in unlabeled data is largely alleviated

CASE: 8
Stag: 37 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Finally , with sufficient unlabeled data , it is possible that the parser can learn to resolve such uncertainty by biasing to more reasonable parse trees
	Cause: biasing to more reasonable parse trees
	Effect: Finally , with sufficient unlabeled data , it is possible that the parser can learn to resolve such uncertainty

CASE: 9
Stag: 38 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: To construct parse forest on unlabeled data , we employ three supervised parsers based on different paradigms , including our baseline graph-based dependency parser , a transition-based dependency parser -LSB- -RSB- , and a generative constituent parser -LSB- -RSB-
	Cause: different paradigms
	Effect: To construct parse forest on unlabeled data , we employ three supervised parsers

CASE: 10
Stag: 41 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Finally , using a conditional random field -LRB- CRF -RRB- based probabilistic parser , we train a better model by maximizing mixed likelihood of labeled data and auto-parsed unlabeled data with ambiguous labelings
	Cause: maximizing mixed likelihood of labeled data and auto-parsed unlabeled data with ambiguous labelings
	Effect: Finally , using a conditional random field -LRB- CRF -RRB- based probabilistic parser , we train a better model

CASE: 11
Stag: 46 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Experiments show that the constituent parser is very helpful since it produces more divergent structures for our semi-supervised parser than discriminative dependency parsers
	Cause: it produces more divergent structures for our semi-supervised parser than discriminative dependency parsers
	Effect: Experiments show that the constituent parser is very helpful

CASE: 12
Stag: 48 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using the probabilistic parser , we benchmark and conduct systematic comparisons among ours and all previous bootstrapping methods , including self/co/tri-training
	Cause: Using the probabilistic parser
	Effect: we benchmark and conduct systematic comparisons among ours and all previous bootstrapping methods , including self/co/tri-training

CASE: 13
Stag: 49 50 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Given an input sentence u ' \ ud835 ' u ' \ udc31 ' = w 0 u ' \ u2062 ' w 1 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' w n , the goal of dependency parsing is to build a dependency tree as depicted in Figure 1 , denoted by u ' \ ud835 ' u ' \ udc1d ' = -LCB- -LRB- h , m 0 u ' \ u2264 ' h u ' \ u2264 ' n , 0 m u ' \ u2264 ' n -RCB- , where -LRB- h , m -RRB- indicates a directed arc from the head word w h to the modifier w m , and w 0 is an artificial node linking to the root of the sentence
	Cause: depicted in Figure 1 , denoted by u ' \ ud835 ' u ' \ udc1d ' = -LCB- -LRB- h , m 0 u ' \ u2264 ' h u ' \ u2264 ' n , 0 m u ' \ u2264 '
	Effect: an input sentence u ' \ ud835 ' u ' \ udc31 ' = w 0 u ' \ u2062 ' w 1 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' w n , the goal of dependency parsing is to build a dependency tree

CASE: 14
Stag: 52 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: The graph-based method views the problem as finding an optimal tree from a fully-connected directed graph -LSB- -RSB- , while the transition-based method tries to find a highest-scoring transition sequence that leads to a legal dependency tree -LSB- -RSB-
	Cause: The graph-based method views the problem as finding an optimal tree from a fully-connected directed graph -LSB- -RSB- , while the transition-based method tries to find a highest-scoring transition sequence
	Effect: a legal dependency tree -LSB- -RSB-

CASE: 15
Stag: 53 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: In this work , we adopt the graph-based paradigm because it allows us to naturally derive conditional probability of a dependency tree u ' \ ud835 ' u ' \ udc1d ' given a sentence u ' \ ud835 ' u ' \ udc31 ' , which is required to compute likelihood of both labeled and unlabeled data
	Cause: it allows us to naturally derive conditional probability of a dependency tree u ' \ ud835 ' u ' \ udc1d ' given a sentence u ' \ ud835 ' u ' \ udc31 '
	Effect: which is required to compute likelihood of both labeled and unlabeled data

CASE: 16
Stag: 55 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We adopt the second-order graph-based dependency parsing model of as our core parser , which incorporates features from the two kinds of subtrees in Fig
	Cause: our core parser , which incorporates features from the two kinds of subtrees in
	Effect: We adopt the second-order graph-based dependency parsing model of

CASE: 17
Stag: 75 76 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: where the first term is the empirical counts and the second term is the model expectations Since u ' \ ud835 ' u ' \ udcb4 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc31 ' i -RRB- contains exponentially many dependency trees , direct calculation of the second term is prohibitive
	Cause: u ' \ ud835 ' u ' \ udcb4 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc31 ' i -RRB- contains exponentially many dependency trees ,
	Effect: is the model expectations

CASE: 18
Stag: 81 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Intuitively , if several parsers disagree on an unlabeled sentence , it implies that the unlabeled sentence contains some difficult syntactic phenomena which are not sufficiently covered in manually labeled data
	Cause: several parsers disagree on an unlabeled sentence
	Effect: it implies that the unlabeled sentence contains some difficult syntactic phenomena which are not sufficiently covered in manually labeled data

CASE: 19
Stag: 81 82 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Intuitively , if several parsers disagree on an unlabeled sentence , it implies that the unlabeled sentence contains some difficult syntactic phenomena which are not sufficiently covered in manually labeled data Therefore , exploiting such unlabeled data may introduce more discriminative syntactic knowledge , largely compensating labeled training data
	Cause: Intuitively , if several parsers disagree on an unlabeled sentence , it implies that the unlabeled sentence contains some difficult syntactic phenomena which are not sufficiently covered in manually labeled data
	Effect: exploiting such unlabeled data may introduce more discriminative syntactic knowledge , largely compensating labeled training data

CASE: 20
Stag: 83 84 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To address above issues , we propose ambiguity-aware ensemble training , which can be interpreted as a generalized tri-training framework The key idea is the use of ambiguous labelings for the purpose of aggregating multiple 1-best parse trees produced by several diverse parsers
	Cause: a generalized tri-training framework The key idea is the use of ambiguous labelings for the purpose of aggregating multiple 1-best parse trees produced
	Effect: To address above issues , we propose ambiguity-aware ensemble training , which can be interpreted

CASE: 21
Stag: 85 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Here , u ' \ u201c ' ambiguous labelings u ' \ u201d ' mean an unlabeled sentence may have multiple parse trees as gold-standard reference , represented by parse forest -LRB- see Figure 1
	Cause: gold-standard reference , represented by parse forest -LRB- see Figure
	Effect: Here , u ' \ u201c ' ambiguous labelings u ' \ u201d ' mean an unlabeled sentence may have multiple parse trees

CASE: 22
Stag: 100 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: 3 -RRB- can be efficiently computed by running the inside-outside algorithm in the constrained search space u ' \ ud835 ' u ' \ udcb1 ' i
	Cause: running the inside-outside algorithm
	Effect: -RRB- can be efficiently computed

CASE: 23
Stag: 104 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Moreover , it is very convenient to parallel SGD since computations among examples in the same batch is mutually independent
	Cause: computations among examples in the same batch is mutually independent
	Effect: Moreover , it is very convenient to parallel SGD

CASE: 24
Stag: 105 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Training with the combined labeled and unlabeled data , the objective is to maximize the mixed likelihood
	Cause: Training with the combined labeled and unlabeled data
	Effect: the objective is to maximize the mixed likelihood

CASE: 25
Stag: 105 106 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Training with the combined labeled and unlabeled data , the objective is to maximize the mixed likelihood Since u ' \ ud835 ' u ' \ udc9f ' u ' \ u2032 ' contains much more instances than u ' \ ud835 ' u ' \ udc9f ' -LRB- 1.7 M vs
	Cause: u ' \ ud835 ' u ' \ udc9f ' u ' \ u2032 ' contains much more instances than u ' \ ud835 ' u ' \ udc9f ' -LRB- 1.7 M
	Effect: Training with the combined labeled and unlabeled data , the objective is to maximize the mixed likelihood

CASE: 26
Stag: 108 109 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: 16K for Chinese -RRB- , it is likely that the unlabeled data may overwhelm the labeled data during SGD training Therefore , we propose a simple corpus-weighting strategy , as shown in Algorithm 3.2 , where u ' \ ud835 ' u ' \ udc9f ' i , k b is the subset of training data used in k t u ' \ u2062 ' h update and b is the batch size ; u ' \ u0397 ' k is the update step , which is adjusted following the simulated annealing procedure -LSB- -RSB-
	Cause: 16K for Chinese -RRB- , it is likely that the unlabeled data may overwhelm the labeled data during SGD training
	Effect: we propose a simple corpus-weighting strategy , as shown in Algorithm 3.2 , where u ' \ ud835 ' u ' \ udc9f ' i , k b is the subset of training data used in k t u ' \ u2062 ' h update and b is the batch size ; u ' \ u0397 ' k is the update step , which is adjusted following the simulated annealing procedure -LSB- -RSB-

CASE: 27
Stag: 112 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Once the feature weights u ' \ ud835 ' u ' \ udc30 ' are learnt , we can parse the test data to find the optimal parse tree
	Cause: the feature weights u ' \ ud835 ' u ' \ udc30 ' are learnt
	Effect: we can parse the test data to find the optimal parse tree

CASE: 28
Stag: 136 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: For the semi-supervised parsers trained with Algorithm 3.2 , we use N 1 = 20 K and M 1 = 50 K for English , and N 1 = 15 K and M 1 = 50 K for Chinese , based on a few preliminary experiments
	Cause: a few preliminary experiments
	Effect: For the semi-supervised parsers trained with Algorithm 3.2 , we use N 1 = 20 K and M 1 = 50 K for English , and N 1 = 15 K and M 1 = 50 K for Chinese

CASE: 29
Stag: 141 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: For Berkeley Parser , we use the model after 5 split-merge iterations to avoid over-fitting the training data according to the manual
	Cause: the manual
	Effect: For Berkeley Parser , we use the model after 5 split-merge iterations to avoid over-fitting the training data

CASE: 30
Stag: 143 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using three supervised parsers , we have many options to construct parse forest on unlabeled data
	Cause: Using three supervised parsers
	Effect: we have many options to construct parse forest on unlabeled data

CASE: 31
Stag: 152 153 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: When using the outputs of GParser itself -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' G u ' \ u201d ' -RRB- , the experiment reproduces traditional self-training The results on both English and Chinese re-confirm that self-training may not work for dependency parsing , which is consistent with previous studies -LSB- -RSB-
	Cause: When using the outputs of GParser itself -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' G u ' \ u201d ' -RRB- , the experiment reproduces traditional self-training
	Effect: consistent with previous studies -LSB- -RSB-

CASE: 32
Stag: 159 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: We believe the reason is that being a generative model designed for constituent parsing , Berkeley Parser is more different from discriminative dependency parsers , and therefore can provide more divergent syntactic structures
	Cause: We believe the reason is that being a generative model designed for constituent parsing , Berkeley Parser is more different from discriminative dependency parsers
	Effect: can provide more divergent syntactic structures

CASE: 33
Stag: 159 
	Pattern: 1 [['reason'], [['that', 'because']]]---- [['&R', '(,/./;/--)', '&ONE', '(&ADJ)'], ['(for &THIS (&NP))', '&BE'], ['&C']]
	sentTXT: We believe the reason is that being a generative model designed for constituent parsing , Berkeley Parser is more different from discriminative dependency parsers
	Cause: being a generative model designed for constituent parsing , Berkeley Parser is more different from discriminative dependency parsers
	Effect: We believe

CASE: 34
Stag: 159 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: being a generative model designed for constituent parsing , Berkeley Parser is more different from discriminative dependency parsers
	Cause: being a generative model designed for constituent parsing
	Effect: Berkeley Parser is more different from discriminative dependency parsers

CASE: 35
Stag: 160 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This kind of syntactic divergence is helpful because it can provide complementary knowledge from a different perspective also show that the diversity of parsers is important for performance improvement when integrating different parsers in the supervised track
	Cause: it can provide complementary knowledge from a different perspective also show that the diversity of parsers is important for performance improvement when integrating different parsers in the supervised track
	Effect: This kind of syntactic divergence is helpful

CASE: 36
Stag: 160 161 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: This kind of syntactic divergence is helpful because it can provide complementary knowledge from a different perspective also show that the diversity of parsers is important for performance improvement when integrating different parsers in the supervised track Therefore , we can conclude that co-training helps dependency parsing , especially when using a more divergent parser
	Cause: This kind of syntactic divergence is helpful because it can provide complementary knowledge from a different perspective also show that the diversity of parsers is important for performance improvement when integrating different parsers in the supervised track
	Effect: we can conclude that co-training helps dependency parsing , especially when using a more divergent parser

CASE: 37
Stag: 162 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The last experiment in the second major row is known as tri-training , which only uses unlabeled sentences on which Berkeley Parser and ZPar produce identical outputs -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B = Z u ' \ u201d '
	Cause: tri-training , which only uses unlabeled sentences on which Berkeley Parser and ZPar produce identical outputs -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B = Z u ' \ u201d
	Effect: The last experiment in the second major row is known

CASE: 38
Stag: 175 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Combining the outputs of Berkeley Parser and GParser -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B+G u ' \ u201d ' -RRB- , we get higher oracle score -LRB- 96.37 % on English and 89.72 % on Chinese -RRB- and higher syntactic divergence -LRB- 1.085 candidate heads per word on English , and 1.188 on Chinese -RRB- than u ' \ u201c ' Unlabeled u ' \ u2190 ' Z+G u ' \ u201d ' , which verifies our earlier discussion that Berkeley Parser produces more different structures than ZPar
	Cause: Combining the outputs of Berkeley Parser and GParser -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B+G u ' \ u201d ' -RRB-
	Effect: we get higher oracle score -LRB- 96.37 % on English and 89.72 % on Chinese -RRB- and higher syntactic divergence -LRB- 1.085 candidate heads per word on English , and 1.188 on Chinese -RRB- than u ' \ u201c ' Unlabeled u ' \ u2190 ' Z+G u ' \ u201d ' , which verifies our earlier discussion that Berkeley Parser produces more different structures than ZPar

CASE: 39
Stag: 176 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: However , it leads to slightly worse accuracy than co-training with Berkeley Parser -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B u ' \ u201d '
	Cause: it
	Effect: slightly worse accuracy than co-training with Berkeley Parser -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B u ' \ u201d '

CASE: 40
Stag: 178 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Combining the outputs of Berkeley Parser and ZPar -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B+Z u ' \ u201d ' -RRB- , we get the best performance on English , which is also significantly better than both co-training -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B u ' \ u201d ' -RRB- and tri-training -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B = Z u ' \ u201d ' -RRB- on both English and Chinese
	Cause: Combining the outputs of Berkeley Parser and ZPar -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B+Z u ' \ u201d ' -RRB-
	Effect: we get the best performance on English , which is also significantly better than both co-training -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B u ' \ u201d ' -RRB- and tri-training -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B = Z u ' \ u201d ' -RRB- on both English and Chinese

CASE: 41
Stag: 181 182 
	Pattern: 2 [[['explanation', 'motivation'], 'is', 'that']]---- [['&R', '(,/./;/--)', '&ONE', '(&adj)'], ['&C']]
	sentTXT: During experimental trials , we find that u ' \ u201c ' Unlabeled u ' \ u2190 ' B + -LRB- Z u ' \ u2229 ' G -RRB- u ' \ u201d ' can further boost performance on Chinese A possible explanation is that by using the intersection of the outputs of GParser and ZPar , the size of the parse forest is better controlled , which is helpful considering that ZPar performs worse on this data than both Berkeley Parser and GParser
	Cause: by using the intersection of the outputs of GParser and ZPar , the size of the parse forest is better controlled , which is helpful considering that ZPar performs worse on this data than both Berkeley Parser and GParser
	Effect: During experimental trials , we find that u ' \ u201c ' Unlabeled u ' \ u2190 ' B + -LRB- Z u ' \ u2229 ' G -RRB- u ' \ u201d ' can further boost performance on Chinese

CASE: 42
Stag: 183 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Adding the output of GParser itself -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B+Z+G u ' \ u201d ' -RRB- leads to accuracy drop , although the oracle score is higher -LRB- 96.95 % on English and 91.50 % on Chinese -RRB- than u ' \ u201c ' Unlabeled u ' \ u2190 ' B+Z u ' \ u201d '
	Cause: Adding the output of GParser itself -LRB- u ' \ u201c ' Unlabeled u ' \ u2190 ' B+Z+G u ' \ u201d ' -RRB-
	Effect: accuracy drop , although the oracle score is higher -LRB- 96.95 % on English and 91.50 % on Chinese -RRB- than u ' \ u201c ' Unlabeled u ' \ u2190 ' B+Z u ' \ u201d '

CASE: 43
Stag: 184 
	Pattern: 1 [['reason'], [['that', 'because']]]---- [['&R', '(,/./;/--)', '&ONE', '(&ADJ)'], ['(for &THIS (&NP))', '&BE'], ['&C']]
	sentTXT: We suspect the reason is that the model is likely to distribute the probability mass to these parse trees produced by itself instead of those by Berkeley Parser or ZPar under this setting
	Cause: the model is likely to distribute the probability mass to these parse trees produced by itself instead of those by Berkeley Parser or ZPar under this setting
	Effect: We suspect

CASE: 44
Stag: 186 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Appropriately composing the forest parse , our approach outperforms the best results of co-training or tri-training by 0.28 % -LRB- 93.78-93 .50 -RRB- on English and 0.92 % -LRB- 84.26-83 .34 -RRB- on Chinese
	Cause: Appropriately composing the forest parse
	Effect: our approach outperforms the best results of co-training or tri-training by 0.28 % -LRB- 93.78-93 .50 -RRB- on English and 0.92 % -LRB- 84.26-83 .34 -RRB- on Chinese

CASE: 45
Stag: 194 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Moreover , our method may be combined with other semi-supervised approaches , since they are orthogonal in methodology and utilize unlabeled data from different perspectives
	Cause: they are orthogonal in methodology and utilize unlabeled data from different perspectives
	Effect: Moreover , our method may be combined with other semi-supervised approaches

CASE: 46
Stag: 201 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: We divide the unlabeled data into three sets according to the divergence of the 1-best outputs of Berkeley Parser and ZPar
	Cause: the divergence of the 1-best outputs of Berkeley Parser and ZPar
	Effect: We divide the unlabeled data into three sets

CASE: 47
Stag: 203 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: Other sentences are split into two sets according to averaged number of heads per word in parse forests , denoted by u ' \ u201c ' low divergence u ' \ u201d ' and u ' \ u201c ' high divergence u ' \ u201d ' respectively
	Cause: averaged number of heads per word in parse forests
	Effect: denoted by u ' \ u201c ' low divergence u ' \ u201d ' and u ' \ u201c ' high divergence u ' \ u201d ' respectively

CASE: 48
Stag: 208 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Especially , the unlabeled data with highly divergent structures leads to slightly higher improvement
	Cause: the unlabeled data with highly divergent structures
	Effect: slightly higher improvement

CASE: 49
Stag: 217 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: They first apply the idea of ambiguous labelings to multilingual parser transfer in the unsupervised parsing field , which aims to build a dependency parser for a resource-poor target language by making use of source-language treebanks
	Cause: making use of source-language treebanks
	Effect: They first apply the idea of ambiguous labelings to multilingual parser transfer in the unsupervised parsing field , which aims to build a dependency parser for a resource-poor target language

CASE: 50
Stag: 222 223 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Stacked learning uses one parser u ' \ u2019 ' s outputs as guide features for another parser , leading to improved performance -LSB- -RSB- Re-parsing merges the outputs of several parsers into a dependency graph , and then apply Viterbi decoding to find a better tree -LSB- -RSB-
	Cause: guide features for another parser , leading to improved performance -LSB- -RSB- Re-parsing merges the outputs of several parsers into a dependency graph , and then apply Viterbi decoding to find a better tree -LSB-
	Effect: Stacked learning uses one parser u ' \ u2019 ' s outputs

CASE: 51
Stag: 226 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: This paper proposes a generalized training framework of semi-supervised dependency parsing based on ambiguous labelings
	Cause: ambiguous labelings
	Effect: This paper proposes a generalized training framework of semi-supervised dependency parsing

