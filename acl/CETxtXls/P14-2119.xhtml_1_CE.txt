************************************************************
P14-2119.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 2 
	Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
	sentTXT: Recently, distant supervision has emerged as an important technique for relation extraction and has attracted increasing attention because of its effective use of readily available databases [] It automatically labels its own training data by heuristically aligning a knowledge base of facts with an unlabeled corpus
	Cause: [(0, 0), (0, 17)]
	Effect: [(1, 0), (1, 18)]

CASE: 1
Stag: 3 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The intuition is that any sentence which mentions a pair of entities ( e 1 and e 2 ) that participate in a relation, r , is likely to express the fact r u'\u2062' ( e 1 , e 2 ) and thus forms a positive training example of r
	Cause: [(0, 0), (0, 45)]
	Effect: [(0, 48), (0, 54)]

CASE: 2
Stag: 6 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Sophisticated multi-instance learning algorithms [] have been proposed to address the issue by loosening the distant supervision assumption
	Cause: [(0, 14), (0, 18)]
	Effect: [(0, 0), (0, 12)]

CASE: 3
Stag: 8 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: On top of that, researchers further improved performance by explicitly adding preprocessing steps [] or additional layers inside the model [] to reduce the effect of training noise
	Cause: [(0, 10), (0, 30)]
	Effect: [(0, 0), (0, 8)]

CASE: 4
Stag: 10 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this paper, we present the first effective approach, u'\ud835' u'\udc06' u'\u2062' u'\ud835' u'\uddce' u'\ud835' u'\uddc2' u'\ud835' u'\uddbd' u'\ud835' u'\uddbe' u'\ud835' u'\uddbd' u'\u2062' u'\ud835' u'\udda3' u'\ud835' u'\uddb2' (distant supervision), to incorporate labeled data into distant supervision for extracting relations from sentences
	Cause: [(0, 114), (0, 117)]
	Effect: [(0, 0), (0, 112)]

CASE: 5
Stag: 11 12 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In contrast to simply taking the union of the hand-labeled data and the corpus labeled by distant supervision as in the previous work by Zhang et al [] , we generalize the labeled data through feature selection and model this additional information directly in the latent variable approaches
	Cause: [(0, 19), (1, 17)]
	Effect: [(0, 1), (0, 17)]

CASE: 6
Stag: 16 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Simply taking the union of the hand-labeled data and the corpus labeled by distant supervision is not effective since hand-labeled data will be swamped by a larger amount of distantly labeled data
	Cause: [(0, 19), (0, 31)]
	Effect: [(0, 0), (0, 17)]

CASE: 7
Stag: 17 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: An effective approach must recognize that the hand-labeled data is more reliable than the automatically labeled data and so must take precedence in cases of conflict
	Cause: [(0, 0), (0, 16)]
	Effect: [(0, 19), (0, 25)]

CASE: 8
Stag: 18 19 
	Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
	sentTXT: Conflicts cannot be limited to those cases where all the features in two examples are the same; this would almost never occur, because of the dozens of features used by a typical relation extractor [] Instead we propose to perform feature selection to generalize human labeled data into training guidelines , and integrate them into latent variable model
	Cause: [(0, 0), (0, 23)]
	Effect: [(1, 0), (1, 21)]

CASE: 9
Stag: 22 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: We experimentally tested alternative feature sets by building supervised Maximum Entropy (MaxEnt) models using the hand-labeled data (Table 3 ), and selected an effective combination of three features from the full feature set used by Surdeanu et al., []
	Cause: [(0, 7), (0, 22)]
	Effect: [(0, 23), (0, 44)]

CASE: 10
Stag: 32 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We keep only those guidelines which make the correct prediction for a u'\u2062' l u'\u2062' l and at least k =3 examples in the training corpus (threshold 3 was obtained by running experiments on the development dataset
	Cause: [(0, 41), (0, 46)]
	Effect: [(0, 0), (0, 39)]

CASE: 11
Stag: 35 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: To do this, we extend the MIML model [] by adding a new layer as shown in Figure 1
	Cause: [(0, 12), (0, 20)]
	Effect: [(0, 0), (0, 10)]

CASE: 12
Stag: 37 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Given a bag of sentences, u'\ud835' u'\udc31' u'\ud835' u'\udc22' , which mention an i th entity pair ( e 1 , e 2 ), our goal is to correctly predict which relation is mentioned in each sentence, or N u'\u2062' R if none of the relations under consideration are mentioned
	Cause: [(0, 65), (0, 72)]
	Effect: [(0, 1), (0, 63)]

CASE: 13
Stag: 49 50 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We define relabeled relations h i u'\u2062' j as following Thus, relation r u'\u2062' ( g ) is assigned to h i u'\u2062' j iff there exists a unique guideline g u'\u2208' u'\ud835' u'\udc06' , such that the feature vector u'\ud835' u'\udc31' i u'\u2062' j contains all constituents of g , i.e., entity types, a dependency path and maybe a span word, if g has one
	Cause: [(0, 13), (1, 89)]
	Effect: [(0, 0), (0, 11)]

CASE: 14
Stag: 49 50 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We define relabeled relations h i u'\u2062' j as following Thus, relation r u'\u2062' ( g ) is assigned to h i u'\u2062' j iff there exists a unique guideline g u'\u2208' u'\ud835' u'\udc06' , such that the feature vector u'\ud835' u'\udc31' i u'\u2062' j contains all constituents of g , i.e., entity types, a dependency path and maybe a span word, if g has one
	Cause: [(0, 0), (0, 13)]
	Effect: [(1, 1), (1, 91)]

CASE: 15
Stag: 60 
	Pattern: 7 [['due', 'to']]---- [['&V-ing/&NP@R@', '&BE'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: where the last equality is due to conditional independence
	Cause: [(0, 7), (0, 8)]
	Effect: [(0, 1), (0, 3)]

CASE: 16
Stag: 65 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: \State z i u'\u2062' j * = argmax z i u'\u2062' j p ( z i u'\u2062' j u'\ud835' u'\udc31' u'\ud835' u'\udc22' , u'\ud835' u'\udc32' u'\ud835' u'\udc22' , u'\ud835' u'\udc30' u'\ud835' u'\udc33' , u'\ud835' u'\udc30' u'\ud835' u'\udc32' ) \State h i u'\u2062' j * = { r u'\u2062' ( g ) , if u'\u2062' u'\u2203' u'\u2003' g u'\u2208' u'\ud835' u'\udc06'
	Cause: [(0, 0), (0, 14)]
	Effect: [(0, 15), (0, 169)]

CASE: 17
Stag: 76 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This dataset is generated by mapping Wikipedia infoboxes into a large unlabeled corpus that consists of 1.5M documents from KBP source corpus and a complete snapshot of Wikipedia
	Cause: [(0, 5), (0, 28)]
	Effect: [(0, 0), (0, 3)]

CASE: 18
Stag: 78 79 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We used 40 queries as development set and the rest 160 queries (3334 entity pairs that express a relation) as the test set The official KBP evaluation is performed by pooling the system responses and manually reviewing each response, producing a hand-checked assessment data
	Cause: [(0, 5), (1, 20)]
	Effect: [(0, 0), (0, 3)]

CASE: 19
Stag: 79 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The official KBP evaluation is performed by pooling the system responses and manually reviewing each response, producing a hand-checked assessment data
	Cause: [(0, 7), (0, 21)]
	Effect: [(0, 0), (0, 5)]

CASE: 20
Stag: 84 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Training u'\ud835' u'\uddac' u'\ud835' u'\udda8' u'\ud835' u'\uddac' u'\ud835' u'\uddab' on a simple fusion of distantly-labeled and human-labeled datasets does not improve the maximum F-score since this hand-labeled data is swamped by a much larger amount of distant-supervised data of much lower quality
	Cause: [(0, 57), (0, 73)]
	Effect: [(0, 0), (0, 55)]

CASE: 21
Stag: 84 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Training u'\ud835' u'\uddac' u'\ud835' u'\udda8' u'\ud835' u'\uddac' u'\ud835' u'\uddab' on a simple fusion of distantly-labeled and human-labeled datasets does not improve the maximum F-score since this hand-labeled data is swamped by a much larger amount of distant-supervised data of much lower quality
	Cause: [(0, 0), (0, 0)]
	Effect: [(0, 1), (0, 15)]

CASE: 22
Stag: 91 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The difference between u'\ud835' u'\udc06' u'\u2062' u'\ud835' u'\uddce' u'\ud835' u'\uddc2' u'\ud835' u'\uddbd' u'\ud835' u'\uddbe' u'\ud835' u'\uddbd' u'\u2062' u'\ud835' u'\udda3' u'\ud835' u'\uddb2' and all other systems is significant with p -value less than 0.05 according to a paired t -test assuming a normal distribution
	Cause: [(0, 108), (0, 110)]
	Effect: [(0, 0), (0, 105)]

CASE: 23
Stag: 92 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We scored our model against all 41 relations and thus replicated the actual KBP evaluation
	Cause: [(0, 0), (0, 7)]
	Effect: [(0, 10), (0, 14)]

