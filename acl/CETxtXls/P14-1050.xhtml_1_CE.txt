************************************************************
P14-1050.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 13 14 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the previous example, u'\u201d' u'\u7ed9' u'\u529b' (cool; powerful) u'\u201d' is a strong feature for classification models while each single character is not Adding new words as feature in classification models will improve the performance of polarity classification, as demonstrated later in this paper
	Cause: [(1, 4), (1, 21)]
	Effect: [(0, 1), (1, 2)]

CASE: 1
Stag: 19 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Moreover, existing lexical resources never have adequate and timely coverage since new words appear constantly
	Cause: [(0, 12), (0, 15)]
	Effect: [(0, 0), (0, 10)]

CASE: 2
Stag: 19 20 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Moreover, existing lexical resources never have adequate and timely coverage since new words appear constantly People thus resort to statistical methods such as Pointwise Mutual Information [ 6 ] , Symmetrical Conditional Probability [ 7 ] , Mutual Expectation [ 8 ] , Enhanced Mutual Information [ 22 ] , and Multi-word Expression Distance [ 2 ]
	Cause: [(0, 1), (1, 0)]
	Effect: [(1, 2), (1, 41)]

CASE: 3
Stag: 32 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We will describe the proposed method in Section 3, including definitions, the overview of the algorithm, and the statistical measures for addressing the two key issues
	Cause: [(0, 24), (0, 28)]
	Effect: [(0, 0), (0, 22)]

CASE: 4
Stag: 36 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In these works, new word detection is considered as an integral part of segmentation, where new words are identified as the most probable segments inferred by the probabilistic models; and the detected new word can be further used to improve word segmentation
	Cause: [(0, 10), (0, 43)]
	Effect: [(0, 0), (0, 8)]

CASE: 5
Stag: 36 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In these works, new word detection is considered as an integral part of segmentation, where new words are identified as the most probable segments inferred by the probabilistic models; and the detected new word can be further used to improve word segmentation
	Cause: [(0, 12), (0, 19)]
	Effect: [(0, 7), (0, 10)]

CASE: 6
Stag: 37 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Typical models include conditional random fields proposed by [ 14 ] , and a joint model trained with adaptive online gradient descent based on feature frequency information [ 18 ]
	Cause: [(0, 24), (0, 29)]
	Effect: [(0, 0), (0, 21)]

CASE: 7
Stag: 38 39 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Another line is to treat new word detection as a separate task, usually preceded by part-of-speech tagging The first genre of such studies is to leverage complex linguistic rules or knowledge
	Cause: [(0, 9), (1, 12)]
	Effect: [(0, 0), (0, 7)]

CASE: 8
Stag: 44 45 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The second genre of the studies is to treat new word detection as a classification problem Zhou [ 25 ] proposed a discriminative Markov Model to detect new words by chunking one or more separated words
	Cause: [(0, 13), (1, 18)]
	Effect: [(0, 0), (0, 11)]

CASE: 9
Stag: 46 47 
	Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
	sentTXT: In [ 12 ] , new word detection was viewed as a binary classification problem However, these supervised models requires not only heavy engineering of linguistic features, but also expensive annotation of training data
	Cause: [(1, 6), (1, 20)]
	Effect: [(0, 1), (1, 0)]

CASE: 10
Stag: 48 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: User behavior data has recently been explored for finding new words
	Cause: [(0, 8), (0, 10)]
	Effect: [(0, 0), (0, 6)]

CASE: 11
Stag: 53 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: However, both of the work are limited due to the public unavailability of expensive commercial resources
	Cause: [(0, 10), (0, 16)]
	Effect: [(0, 0), (0, 7)]

CASE: 12
Stag: 55 56 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In this setting, new word detection is mostly known as multi-word expression extraction To measure multi-word association, the first model is Pointwise Mutual Information (PMI) [ 6 ]
	Cause: [(0, 11), (1, 4)]
	Effect: [(0, 0), (0, 9)]

CASE: 13
Stag: 56 57 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: To measure multi-word association, the first model is Pointwise Mutual Information (PMI) [ 6 ] Since then, a variety of statistical methods have been proposed to measure b u'\u2062' i -gram association, such as Log-likelihood [ 9 ] and Symmetrical Conditional Probability (SCP) [ 7 ]
	Cause: [(1, 1), (1, 39)]
	Effect: [(0, 0), (0, 17)]

CASE: 14
Stag: 59 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: In order to measure arbitrary n -grams, most common strategies are to separate n -gram into two parts X and Y so that existing b u'\u2062' i -gram methods can be used [ 7 , 8 , 16 ]
	Cause: [(0, 0), (0, 23)]
	Effect: [(0, 26), (0, 46)]

CASE: 15
Stag: 66 67 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: In Chinese, such words are like u'\u201d' u'\u7740' , u'\u4e86' , u'\u5566' , u'\u7684' , u'\u554a' u'\u201d' , and punctuation marks include u'\u201d' u'\uff0c' u'\u3002' u'\uff01' u'\uff1f' u'\uff1b' u'\uff1a' u'\u201d' and so on A lexical pattern is a triplet A D , * , A U , where A u'\u2062' D is an adverbial word, the wildcard * means an arbitrary number of words 1 1 We set the number to 3 words in this work considering computation costs and A u'\u2062' U denotes an auxiliary word
	Cause: [(0, 0), (0, 90)]
	Effect: [(0, 48), (1, 61)]

CASE: 16
Stag: 69 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: In order to obtain lexical patterns, we can define regular expressions with POS tags 2 2 Such expressions are very simple and easy to write because we only need to consider POS tags of adverbial and auxiliary word and apply the regular expressions on POS tagged texts
	Cause: [(0, 27), (0, 47)]
	Effect: [(0, 0), (0, 25)]

CASE: 17
Stag: 70 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the tags of adverbial and auxiliary words are relatively static and can be easily identified, such a method can safely obtain lexical patterns
	Cause: [(0, 1), (0, 15)]
	Effect: [(0, 17), (0, 24)]

CASE: 18
Stag: 75 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Note that we do not augment the pattern set ( u'\ud835' u'\udcab' ) at each iteration, instead, we keep a fixed small number of patterns during iteration because this strategy produces optimal results
	Cause: [(0, 38), (0, 42)]
	Effect: [(0, 0), (0, 36)]

CASE: 19
Stag: 76 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: From linguistic perspectives, new sentiment words are commonly modified by adverbial words and thus can be extracted by lexical patterns
	Cause: [(0, 0), (0, 12)]
	Effect: [(0, 15), (0, 20)]

CASE: 20
Stag: 76 77 
	Pattern: 10 [['the'], [['reason', 'reasons'], 'why']]---- [['&C', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&OF)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: From linguistic perspectives, new sentiment words are commonly modified by adverbial words and thus can be extracted by lexical patterns This is the reason why the algorithm will work
	Cause: [(0, 0), (0, 20)]
	Effect: [(1, 5), (1, 8)]

CASE: 21
Stag: 88 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In our problem, LRT computes a contingency table of a pattern p and a word w , derived from the corpus statistics, as given in Table 3 , where k 1 u'\u2062' ( w , p ) is the number of documents that w matches pattern p , k 2 u'\u2062' ( w , p ¯ ) is the number of documents that w occurs while p does not, k 3 u'\u2062' ( w ¯ , p ) is the number of documents that p occurs while w does not, and k 4 u'\u2062' ( w ¯ , p ¯ ) is the number of documents containing neither p nor w
	Cause: [(0, 25), (0, 102)]
	Effect: [(0, 0), (0, 22)]

CASE: 22
Stag: 89 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on the statistics shown in Table 3 , the likelihood ratio tests (LRT) model captures the statistical association between a pattern p and a word w by employing the following formula
	Cause: [(0, 2), (0, 7)]
	Effect: [(0, 9), (0, 33)]

CASE: 23
Stag: 89 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Based on the statistics shown in Table 3 , the likelihood ratio tests (LRT) model captures the statistical association between a pattern p and a word w by employing the following formula
	Cause: [(0, 21), (0, 24)]
	Effect: [(0, 0), (0, 19)]

CASE: 24
Stag: 91 92 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: L u'\u2062' ( u'\u03a1' , k , n ) = u'\u03a1' k * ( 1 - u'\u03a1' ) n - k ; n 1 = k 1 + k 3 ; n 2 = k 2 + k 4 ; u'\u03a1' 1 = k 1 / n 1 ; u'\u03a1' 2 = k 2 / n 2 ; u'\u03a1' = ( k 1 + k 2 ) / ( n 1 + n 2 ) Thus, the utility of a pattern can be measured as follows
	Cause: [(0, 0), (0, 102)]
	Effect: [(1, 1), (1, 11)]

CASE: 25
Stag: 100 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: This has linguistic interpretations because new sentiment words are commonly modified by adverbial words and thus should have close association with lexical patterns
	Cause: [(0, 0), (0, 13)]
	Effect: [(0, 16), (0, 22)]

CASE: 26
Stag: 100 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This has linguistic interpretations because new sentiment words are commonly modified by adverbial words and thus should have close association with lexical patterns
	Cause: [(0, 5), (0, 13)]
	Effect: [(0, 0), (0, 3)]

CASE: 27
Stag: 102 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: If a candidate word is a new word, it will be more commonly used with diversified lexical patterns since the non-compositionality of new word means that the word can be used in many different linguistic scenarios
	Cause: [(0, 20), (0, 36)]
	Effect: [(0, 0), (0, 18)]

CASE: 28
Stag: 102 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If a candidate word is a new word, it will be more commonly used with diversified lexical patterns since the non-compositionality of new word means that the word can be used in many different linguistic scenarios
	Cause: [(0, 1), (0, 7)]
	Effect: [(0, 9), (0, 18)]

CASE: 29
Stag: 105 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Note that we use u'\ud835' u'\udcab' c , instead of u'\ud835' u'\udcab' , because the latter set is very small while computing entropy needs a large number of patterns
	Cause: [(0, 30), (0, 44)]
	Effect: [(0, 0), (0, 27)]

CASE: 30
Stag: 108 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: For example, u'\u201d' u'\u7231' u'\u5403' (love to eat) u'\u201d' and u'\u201d' u'\u7231' u'\u8bf4' (love to talk) u'\u201d' can be matched by many lexical patterns, however, they are not new words due to the lack of non-compositionality
	Cause: [(0, 71), (0, 74)]
	Effect: [(0, 0), (0, 68)]

CASE: 31
Stag: 109 110 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In such words, each single character has high probability to be a word Thus, we design the following measure to favor this observation
	Cause: [(0, 0), (0, 13)]
	Effect: [(1, 1), (1, 10)]

CASE: 32
Stag: 111 112 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where w = w 1 u'\u2062' w 2 u'\u2062' u'\u2026' u'\u2062' w n , each w i is a single character, and p u'\u2062' ( w i ) is the probability of the character w i being a word, as computed as follows where a u'\u2062' l u'\u2062' l u'\u2062' ( w i ) is the total frequency of w i , and s u'\u2062' ( w i ) is the frequency of w i being a single character word
	Cause: [(0, 62), (1, 30)]
	Effect: [(0, 4), (0, 59)]

CASE: 33
Stag: 115 116 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: New words are usually multi-word expressions, where a variety of statistical measures have been proposed to detect multi-word expressions Thus, such measures can be naturally incorporated into our algorithm
	Cause: [(0, 0), (0, 19)]
	Effect: [(1, 1), (1, 10)]

CASE: 34
Stag: 122 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where u'\u039c' u'\u2062' ( w ) is the set of documents in which all single words in w = w 1 u'\u2062' w 2 u'\u2062' u'\u2026' u'\u2062' w n co-occur, u'\u03a6' u'\u2062' ( w ) is the set of documents in which word w occurs as a whole, and N is the total number of documents
	Cause: [(0, 79), (0, 88)]
	Effect: [(0, 1), (0, 77)]

CASE: 35
Stag: 123 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Different from EMI, this measure is a strict distance metric, meaning that a smaller value indicates a larger possibility of being a multi-word expression
	Cause: [(0, 0), (0, 2)]
	Effect: [(0, 4), (0, 25)]

CASE: 36
Stag: 123 124 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Different from EMI, this measure is a strict distance metric, meaning that a smaller value indicates a larger possibility of being a multi-word expression As can be seen from the formula, the key idea of this metric is to compute the ratio of the co-occurrence of all words in a multi-word expressions to the occurrence of the whole expression
	Cause: [(1, 1), (1, 35)]
	Effect: [(0, 0), (0, 25)]

CASE: 37
Stag: 125 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Taking into account the aforementioned factors, we have different settings to score a new word, as follows
	Cause: [(0, 0), (0, 5)]
	Effect: [(0, 7), (0, 18)]

CASE: 38
Stag: 132 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If there is a disagreement on either of the two tasks, discussions are required to make the final decision
	Cause: [(0, 1), (0, 10)]
	Effect: [(0, 12), (0, 19)]

CASE: 39
Stag: 133 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: The annotation led to 323 new words, among which there are 116 positive words, 112 negative words, and 95 neutral words 3 3 All the resources are available upon request
	Cause: [(0, 0), (0, 1)]
	Effect: [(0, 4), (0, 32)]

CASE: 40
Stag: 133 134 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The annotation led to 323 new words, among which there are 116 positive words, 112 negative words, and 95 neutral words 3 3 All the resources are available upon request As our algorithm outputs a ranked list of words, we adapt average precision to evaluate the performance of new sentiment word detection
	Cause: [(1, 1), (1, 22)]
	Effect: [(0, 0), (0, 32)]

CASE: 41
Stag: 136 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: where P u'\u2062' ( k ) is the precision at cut-off k , r u'\u2062' e u'\u2062' l u'\u2062' ( k ) is 1 if the word at position k is a new word and 0 otherwise, and K is the number of words in the ranked list
	Cause: [(0, 41), (0, 54)]
	Effect: [(0, 0), (0, 39)]

CASE: 42
Stag: 138 139 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First, we assess the influence of likelihood ratio test, which measures the association of a word to the pattern set As can be seen from Table 4 , the association model (LRT) remarkably boosts the performance of new word detection, indicating LRT is a key factor for new sentiment word extraction
	Cause: [(1, 1), (1, 33)]
	Effect: [(0, 0), (0, 21)]

CASE: 43
Stag: 140 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: From linguistic perspectives, new sentiment words are commonly modified by adverbial words and thus should have close association with lexical patterns
	Cause: [(0, 0), (0, 12)]
	Effect: [(0, 15), (0, 21)]

CASE: 44
Stag: 143 144 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The results are shown in Figure 1 As can be seen, all the proposed measures outperform the two baselines ( E u'\u2062' M u'\u2062' I and N u'\u2062' M u'\u2062' E u'\u2062' D ) remarkably and consistently
	Cause: [(1, 1), (1, 19)]
	Effect: [(0, 0), (0, 6)]

CASE: 45
Stag: 146 147 
	Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
	sentTXT: Adding N u'\u2062' M u'\u2062' E u'\u2062' D or E u'\u2062' M u'\u2062' I leads to remarkable improvements because of their capability of measuring non-compositionality of new words Only using L u'\u2062' R u'\u2062' T can obtain a fairly good results when K is small, however, the performance drops sharply because it u'\u2019' s unable to measure non-compositionality
	Cause: [(0, 0), (0, 37)]
	Effect: [(1, 0), (1, 43)]

CASE: 46
Stag: 147 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Only using L u'\u2062' R u'\u2062' T can obtain a fairly good results when K is small, however, the performance drops sharply because it u'\u2019' s unable to measure non-compositionality
	Cause: [(0, 33), (0, 43)]
	Effect: [(0, 0), (0, 31)]

CASE: 47
Stag: 153 154 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The measure setting we take here is F N u'\u2062' M u'\u2062' E u'\u2062' D u'\u2062' ( w ) , as shown in Formula ( 12 Again, we choose only one seed word u'\u201d' u'\u5751' u'\u7239' (reverse one u'\u2019' s expectation) u'\u201d' , and the number of words returned is set to K = 300
	Cause: [(0, 37), (1, 50)]
	Effect: [(0, 0), (0, 34)]

CASE: 48
Stag: 156 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Note that at the early stage of Algorithm 1, larger k p (perhaps with noisy patterns) may lead to lower quality of new words; while larger k w (perhaps with noisy seed words) may lead to lower quality of lexical patterns
	Cause: [(0, 29), (0, 38)]
	Effect: [(0, 42), (0, 46)]

CASE: 49
Stag: 156 157 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Note that at the early stage of Algorithm 1, larger k p (perhaps with noisy patterns) may lead to lower quality of new words; while larger k w (perhaps with noisy seed words) may lead to lower quality of lexical patterns Therefore, we choose the optimal setting to small numbers, as k p = 5 , k w = 10
	Cause: [(0, 0), (0, 46)]
	Effect: [(1, 2), (1, 20)]

CASE: 50
Stag: 163 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By looking into the pattern set and the selected words at each iteration, we found that the pattern set ( u'\ud835' u'\udcab' ) converges soon to the same set after a few iterations; and at the beginning several iterations, the selected words are almost the same although the order of adding the words is different
	Cause: [(0, 1), (0, 12)]
	Effect: [(0, 13), (0, 65)]

CASE: 51
Stag: 164 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the algorithm will finally sort the words at step (11) and u'\ud835' u'\udcab' is the same, the ranking of the words becomes all the same
	Cause: [(0, 1), (0, 26)]
	Effect: [(0, 28), (0, 36)]

CASE: 52
Stag: 165 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Lastly, we need to decide the optimal number of patterns in u'\ud835' u'\udcab' c (that is, k c in Algorithm 1) because the set has been used in computing left pattern entropy, see Formula ( 4
	Cause: [(0, 34), (0, 43)]
	Effect: [(0, 45), (0, 48)]

CASE: 53
Stag: 166 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Too small size of u'\ud835' u'\udcab' c may lead to insufficient estimation of left pattern entropy
	Cause: [(0, 0), (0, 14)]
	Effect: [(0, 18), (0, 23)]

CASE: 54
Stag: 167 168 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Results in Table 7 shows that larger u'\ud835' u'\udcab' c decrease the performance, particularly when the number of words returned ( K ) becomes larger Therefore, we set u'\ud835' u'\udcab' c
	Cause: [(0, 0), (0, 33)]
	Effect: [(1, 2), (1, 14)]

CASE: 55
Stag: 175 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The polarity is judged according to this rule if M u'\u2062' V u'\u2062' ( w ) t u'\u2062' h 1 , the word w is positive; if M u'\u2062' V u'\u2062' ( w ) - t u'\u2062' h 1 the word negative; otherwise neutral
	Cause: [(0, 9), (0, 69)]
	Effect: [(0, 0), (0, 7)]

CASE: 56
Stag: 175 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The polarity is judged according to this rule if M u'\u2062' V u'\u2062' ( w ) t u'\u2062' h 1 , the word w is positive; if M u'\u2062' V u'\u2062' ( w ) - t u'\u2062' h 1 the word negative; otherwise neutral
	Cause: [(0, 31), (0, 60)]
	Effect: [(0, 0), (0, 29)]

CASE: 57
Stag: 175 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The polarity is judged according to this rule if M u'\u2062' V u'\u2062' ( w ) t u'\u2062' h 1 , the word w is positive; if M u'\u2062' V u'\u2062' ( w ) - t u'\u2062' h 1 the word negative; otherwise neutral
	Cause: [(0, 6), (0, 7)]
	Effect: [(0, 0), (0, 3)]

CASE: 58
Stag: 179 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The polarity is judged according to the rule if P u'\u2062' M u'\u2062' I u'\u2062' ( w ) t u'\u2062' h 2 , w is positive; if P u'\u2062' M u'\u2062' I u'\u2062' ( w ) - t u'\u2062' h 2 negative; otherwise neutral
	Cause: [(0, 9), (0, 55)]
	Effect: [(0, 0), (0, 7)]

CASE: 59
Stag: 179 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The polarity is judged according to the rule if P u'\u2062' M u'\u2062' I u'\u2062' ( w ) t u'\u2062' h 2 , w is positive; if P u'\u2062' M u'\u2062' I u'\u2062' ( w ) - t u'\u2062' h 2 negative; otherwise neutral
	Cause: [(0, 6), (0, 7)]
	Effect: [(0, 0), (0, 3)]

CASE: 60
Stag: 180 181 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The threshold t u'\u2062' h 2 is manually tuned As for the resources P u'\u2062' W and N u'\u2062' W , we have three settings
	Cause: [(1, 1), (1, 23)]
	Effect: [(0, 0), (0, 12)]

CASE: 61
Stag: 188 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We conjecture that this may be because new sentiment words are more frequently co-occurring with emoticons than with these opinion words
	Cause: [(0, 7), (0, 20)]
	Effect: [(0, 0), (0, 5)]

CASE: 62
Stag: 189 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The second observation is that three-class polarity classification is much more difficult than two-class polarity classification because many extracted new words are nouns such as u'\u201d' u'\u57fa' u'\u53cb' (gay) u'\u201d' , u'\u201d' u'\u83c7' u'\u51c9' (girl) u'\u201d' , and u'\u201d' u'\u76c6' u'\u53cb' (friend) u'\u201d'
	Cause: [(0, 17), (0, 96)]
	Effect: [(0, 0), (0, 15)]

CASE: 63
Stag: 194 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The first model is a lexicon-based model (denoted by L u'\u2062' e u'\u2062' x u'\u2062' i u'\u2062' c u'\u2062' o u'\u2062' n ) that counts the number of positive and negative opinion words in a post respectively, and classifies a post to be positive if there are more positive words than negative ones, and to be negative otherwise
	Cause: [(0, 71), (0, 84)]
	Effect: [(0, 0), (0, 69)]

CASE: 64
Stag: 195 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The second model is a SVM model in which opinion words are used as feature, and 5-fold cross validation is conducted
	Cause: [(0, 14), (0, 20)]
	Effect: [(0, 0), (0, 12)]

CASE: 65
Stag: 203 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: All words in the top 100 words can be used as feature we thus manually label the polarity of all top 100 words (we did NOT remove incorrect new word
	Cause: [(0, 0), (0, 12)]
	Effect: [(0, 14), (0, 30)]

CASE: 66
Stag: 208 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: Note, that T u'\u2062' 100 is automatically obtained from Algorithm 1 so that it may contain words that are not new sentiment words, but the resource also improves performance remarkably
	Cause: [(0, 0), (0, 15)]
	Effect: [(0, 18), (0, 35)]

