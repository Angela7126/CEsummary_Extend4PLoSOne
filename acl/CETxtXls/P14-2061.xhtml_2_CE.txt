************************************************************
P14-2061.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this paper , we focus on the visual modality and present a method for identifying sign languages solely from short video samples
	Cause: identifying sign languages solely from short video samples
	Effect: In this paper , we focus on the visual modality and present a method

CASE: 1
Stag: 4 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using leave-one-signer-out cross-validation , our evaluation shows an average best accuracy of 84 %
	Cause: Using leave-one-signer-out cross-validation
	Effect: our evaluation shows an average best accuracy of 84 %

CASE: 2
Stag: 11 
	Pattern: 47 [['so'], ['that']]---- [['&C'], ['&adj/&adv@C@'], ['&R']]
	sentTXT: This accuracy is so high that current research has shifted to related more challenging problems language variety identification -LSB- 26 -RSB- , native language identification -LSB- 24 -RSB- and identification at the extremes of scales ; many more languages , smaller training data , shorter document lengths -LSB- 1 -RSB-
	Cause: This accuracy is so high
	Effect: current research has shifted to related more challenging problems language variety identification -LSB- 26 -RSB- , native language identification -LSB- 24 -RSB- and identification at the extremes of scales ; many more languages , smaller training data , shorter document lengths -LSB- 1 -RSB-

CASE: 3
Stag: 31 32 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The same holds for the rich use of non-manual articulators in sentences and the limited role of facial expressions in the lexicon these too make sign languages across the world very similar in appearance , even though the meaning of specific articulations may differ -LSB- 7 -RSB- Just as speakers have different voices unique to each individual , signers have also different signing styles that are likely unique to each individual
	Cause: speakers have different voices unique to each individual , signers have also different signing styles that are likely unique to each individual
	Effect: same holds for the rich use of non-manual articulators in sentences and the limited role of facial expressions in the lexicon these too make sign languages across the world very similar in appearance , even though the meaning of specific articulations may differ -LSB- 7 -RSB- Just

CASE: 4
Stag: 53 54 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: There is evidence that normalization and whitening -LSB- 13 -RSB- improve performance in unsupervised feature learning -LSB- 4 -RSB- We therefore normalize every patch x -LRB- i -RRB- by subtracting the mean and dividing by the standard deviation of its elements
	Cause: is evidence that normalization and whitening -LSB- 13 -RSB- improve performance in unsupervised feature learning -LSB- 4 -RSB- We
	Effect: normalize every patch x -LRB- i -RRB- by subtracting the mean and dividing by the standard deviation of its elements

CASE: 5
Stag: 70 71 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We call both the centroids and filters as the learned features Given the learned features , the feature mapping functions and a set of labeled training videos , we extract features as follows
	Cause: the learned features Given the learned features ,
	Effect: We call both the centroids and filters

CASE: 6
Stag: 84 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Part of the other half , involving 5 signers , is used along with the other sign language videos for learning and testing classifiers
	Cause: learning and testing classifiers
	Effect: Part of the other half , involving 5 signers , is used along with the other sign language videos

CASE: 7
Stag: 91 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: For example , if the background of the videos is different across sign languages , then classifying the sign languages could be done with perfection by using signals from the background
	Cause: the background of the videos is different across sign languages
	Effect: classifying the sign languages could be done with perfection by using signals from the

CASE: 8
Stag: 92 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: To avoid this problem , we removed the background by using background subtraction techniques and manually selected thresholds
	Cause: using background subtraction techniques
	Effect: and manually selected thresholds

CASE: 9
Stag: 93 
	Pattern: 0 [['the'], [['reason', 'reasons'], 'for']]---- [['(&OF)'], ['(&ADJ)'], ['&V-ing/&NP@R@', '&BE', '&NP/&TODO@C@']]
	sentTXT: The second reason for data preprocessing is to make the input size smaller and uniform
	Cause: to make the input size smaller and uniform
	Effect: data preprocessing

