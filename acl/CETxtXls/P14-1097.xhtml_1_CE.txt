************************************************************
P14-1097.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 2 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Capturing the sense of a verb is essential for natural language processing (NLP), and thus lexical resources for verbs play an important role in NLP Verb classes are one such lexical resource
	Cause: [(0, 0), (0, 14)]
	Effect: [(0, 18), (1, 5)]

CASE: 1
Stag: 7 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This monosemous assumption, however, is not realistic because many frequent verbs actually have multiple senses
	Cause: [(0, 10), (0, 16)]
	Effect: [(0, 0), (0, 8)]

CASE: 2
Stag: 9 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this paper, we propose an unsupervised method for inducing verb classes that is aware of verb polysemy
	Cause: [(0, 10), (0, 18)]
	Effect: [(0, 0), (0, 8)]

CASE: 3
Stag: 10 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Our method consists of two clustering steps verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames
	Cause: [(0, 14), (0, 19)]
	Effect: [(0, 20), (0, 29)]

CASE: 4
Stag: 10 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Our method consists of two clustering steps verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames
	Cause: [(0, 7), (0, 9)]
	Effect: [(0, 3), (0, 5)]

CASE: 5
Stag: 11 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By taking this step-wise approach, we can not only induce verb classes with frequency information from a massive amount of verb uses in a scalable manner, but also deal with verb polysemy
	Cause: [(0, 1), (0, 4)]
	Effect: [(0, 5), (0, 33)]

CASE: 6
Stag: 23 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2009 ) proposed a Dirichlet process mixture model (DPMM; Neal ( 2000 ) ) to cluster verbs based on subcategorization frame distributions
	Cause: [(0, 21), (0, 23)]
	Effect: [(0, 0), (0, 18)]

CASE: 7
Stag: 26 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: 2006 ) ) model to jointly learn argument structures (subcategorization frames) and verb classes by using syntactic features
	Cause: [(0, 17), (0, 19)]
	Effect: [(0, 0), (0, 15)]

CASE: 8
Stag: 27 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Parisien and Stevenson ( 2011 ) extended their model by adding semantic features
	Cause: [(0, 10), (0, 12)]
	Effect: [(0, 0), (0, 8)]

CASE: 9
Stag: 30 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: 2012 ) extended the model of Titov and Klementiev ( 2012 ) , which is an unsupervised model for inducing semantic roles, to jointly induce semantic roles and frames across verbs using the Chinese Restaurant Process [ 1 ]
	Cause: [(0, 19), (0, 21)]
	Effect: [(0, 0), (0, 17)]

CASE: 10
Stag: 41 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: In particular, they tried to consider verb polysemy by using the IB method, which is a soft clustering method [ 43 ]
	Cause: [(0, 10), (0, 23)]
	Effect: [(0, 0), (0, 8)]

CASE: 11
Stag: 42 43 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However, the verb itself is still represented as a single data point After performing soft clustering, they noted that most verbs fell into a single class, and they decided to assign a single class to each verb by hardening the clustering
	Cause: [(0, 9), (1, 13)]
	Effect: [(0, 0), (0, 7)]

CASE: 12
Stag: 43 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: After performing soft clustering, they noted that most verbs fell into a single class, and they decided to assign a single class to each verb by hardening the clustering
	Cause: [(0, 28), (0, 30)]
	Effect: [(0, 12), (0, 26)]

CASE: 13
Stag: 46 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Lapata and Brew ( 2004 ) and Li and Brew ( 2007 ) proposed probabilistic models for calculating prior probabilities of verb classes for a verb
	Cause: [(0, 17), (0, 25)]
	Effect: [(0, 0), (0, 15)]

CASE: 14
Stag: 47 48 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: These models are approximated to condition not on verbs but on subcategorization frames As mentioned in Li and Brew ( 2007 ) , it is desirable to extend the model to depend on verbs to further improve accuracy
	Cause: [(1, 1), (1, 24)]
	Effect: [(0, 0), (0, 12)]

CASE: 15
Stag: 51 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2008 ) also applied probabilistic soft clustering to verbs by incorporating subcategorization frames and selectional preferences based on WordNet
	Cause: [(0, 18), (0, 18)]
	Effect: [(0, 0), (0, 15)]

CASE: 16
Stag: 51 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: 2008 ) also applied probabilistic soft clustering to verbs by incorporating subcategorization frames and selectional preferences based on WordNet
	Cause: [(0, 10), (0, 12)]
	Effect: [(0, 13), (0, 15)]

CASE: 17
Stag: 52 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: This model is based on the Expectation-Maximization algorithm and the Minimum Description Length principle
	Cause: [(0, 5), (0, 13)]
	Effect: [(0, 0), (0, 1)]

CASE: 18
Stag: 53 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since they focused on the incorporation of selectional preferences, they did not evaluate verb classes but evaluated only selectional preferences using a language model-based measure
	Cause: [(0, 1), (0, 8)]
	Effect: [(0, 10), (0, 25)]

CASE: 19
Stag: 56 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: He used a model based on latent Dirichlet allocation (LDA; Blei et al
	Cause: [(0, 6), (0, 14)]
	Effect: [(0, 0), (0, 3)]

CASE: 20
Stag: 58 59 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Both of these are represented as a probabilistic distribution of words across verbs He applied this method to the BNC and acquired 1,200 frames and 400 roles [ 21 ]
	Cause: [(0, 6), (1, 14)]
	Effect: [(0, 0), (0, 4)]

CASE: 21
Stag: 63 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Although Bayesian approaches are a possible solution to simultaneously induce frames and verb classes from a corpus as used in previous studies, it has prohibitive computational cost
	Cause: [(0, 18), (0, 27)]
	Effect: [(0, 1), (0, 16)]

CASE: 22
Stag: 70 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this paper, we propose a two-step approach for inducing semantic frames and verb classes
	Cause: [(0, 10), (0, 15)]
	Effect: [(0, 0), (0, 8)]

CASE: 23
Stag: 71 72 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First, we make multiple data points for each verb to deal with verb polysemy (cf polysemy-aware previous studies still represented a verb as one data point [ 14 , 23 ] To do that, we induce verb-specific semantic frames by clustering verb uses
	Cause: [(0, 25), (1, 12)]
	Effect: [(0, 0), (0, 23)]

CASE: 24
Stag: 73 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Then, we induce verb classes by clustering these verb-specific semantic frames across verbs
	Cause: [(0, 7), (0, 13)]
	Effect: [(0, 0), (0, 5)]

CASE: 25
Stag: 76 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: induce verb-specific semantic frames by clustering predicate-argument structures for each verb extracted from automatic parses as shown in the lower part of Figure 1 , and
	Cause: [(0, 5), (0, 14)]
	Effect: [(0, 15), (0, 25)]

CASE: 26
Stag: 77 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: induce verb classes by clustering the induced semantic frames across verbs as shown in the upper part of Figure 1
	Cause: [(0, 4), (0, 10)]
	Effect: [(0, 11), (0, 19)]

CASE: 27
Stag: 79 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We induce verb-specific semantic frames from verb uses based on the method of Kawahara et al
	Cause: [(0, 10), (0, 15)]
	Effect: [(0, 0), (0, 7)]

CASE: 28
Stag: 84 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: merge the predicate-argument structures that have presumably the same meaning based on the assumption of one sense per collocation [ 46 ] to get a set of initial frames, and
	Cause: [(0, 12), (0, 30)]
	Effect: [(0, 0), (0, 9)]

CASE: 29
Stag: 85 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: apply clustering to the initial frames based on the Chinese Restaurant Process [ 1 ] to produce verb-specific semantic frames
	Cause: [(0, 8), (0, 19)]
	Effect: [(0, 0), (0, 5)]

CASE: 30
Stag: 99 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We select an argument in the following order by considering the degree of effect on the verb sense
	Cause: [(0, 9), (0, 17)]
	Effect: [(0, 0), (0, 7)]

CASE: 31
Stag: 100 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: 3 3 If a predicate-argument structure has multiple prepositional phrases, one of them is randomly selected
	Cause: [(0, 3), (0, 9)]
	Effect: [(0, 11), (0, 16)]

CASE: 32
Stag: 108 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: P ( f i c j ) is defined based on the Dirichlet-Multinomial distribution as follows
	Cause: [(0, 11), (0, 15)]
	Effect: [(0, 0), (0, 8)]

CASE: 33
Stag: 110 111 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The original method in Kawahara et al 2014 ) defined w as pairs of slots and words, e.g.,, u'\u201c' nsubj:child u'\u201d' and u'\u201c' dobj:bird, u'\u201d' but does not consider slot-only features, e.g.,, u'\u201c' nsubj u'\u201d' and u'\u201c' dobj, u'\u201d' which ignore lexical information
	Cause: [(1, 5), (1, 79)]
	Effect: [(0, 4), (1, 3)]

CASE: 34
Stag: 117 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We regard each output cluster as a semantic frame, by merging the initial frames in a cluster into a semantic frame
	Cause: [(0, 11), (0, 21)]
	Effect: [(0, 0), (0, 9)]

CASE: 35
Stag: 121 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We can use exactly the same clustering method as described in Section 3.2.3 by using semantic frames for multiple verbs as an input instead of initial frames for a single verb
	Cause: [(0, 14), (0, 30)]
	Effect: [(0, 0), (0, 12)]

CASE: 36
Stag: 122 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: This is because an initial frame has the same structure as a semantic frame, which is produced by merging initial frames
	Cause: [(0, 3), (0, 13)]
	Effect: [(0, 15), (0, 21)]

CASE: 37
Stag: 123 124 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We regard each output cluster as a verb class this time For the features, w , in equation ( 2 ), we try the two representations again slot-only features and slot-word pair features
	Cause: [(0, 6), (1, 22)]
	Effect: [(0, 0), (0, 4)]

CASE: 38
Stag: 126 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The other representation using the slot-word pairs means that semantic similarity based on word overlap is naturally considered by looking at lexical information
	Cause: [(0, 13), (0, 22)]
	Effect: [(0, 0), (0, 10)]

CASE: 39
Stag: 126 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The other representation using the slot-word pairs means that semantic similarity based on word overlap is naturally considered by looking at lexical information
	Cause: [(0, 6), (0, 9)]
	Effect: [(0, 0), (0, 4)]

CASE: 40
Stag: 130 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: These two levels of evaluations are performed by considering the work of Reichart et al
	Cause: [(0, 8), (0, 14)]
	Effect: [(0, 0), (0, 6)]

CASE: 41
Stag: 134 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: To prepare a web corpus, we extracted sentences from crawled web pages that are judged to be written in English based on the encoding information
	Cause: [(0, 23), (0, 25)]
	Effect: [(0, 0), (0, 20)]

CASE: 42
Stag: 148 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: However, since these measures are only applicable to a hard clustering, it is necessary to extend them to be applicable to a soft clustering, because in our task a verb can belong to multiple clusters or classes
	Cause: [(0, 3), (0, 11)]
	Effect: [(0, 13), (0, 39)]

CASE: 43
Stag: 148 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: However, since these measures are only applicable to a hard clustering, it is necessary to extend them to be applicable to a soft clustering, because in our task a verb can belong to multiple clusters or classes
	Cause: [(0, 15), (0, 26)]
	Effect: [(0, 0), (0, 12)]

CASE: 44
Stag: 150 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2003 ) evaluated hard clusterings based on a gold standard with multiple classes per verb
	Cause: [(0, 7), (0, 14)]
	Effect: [(0, 0), (0, 4)]

CASE: 45
Stag: 161 162 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In addition, to penalize clusters that consist of only one verb, such singleton clusters in K are considered as errors, as is usual with modified purity The normalized modified purity (nmPU) can then be written as follows
	Cause: [(0, 21), (1, 11)]
	Effect: [(0, 0), (0, 19)]

CASE: 46
Stag: 164 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: K i denotes the number of positive components in K i , and c i u'\u2062' v denotes the v -th component of K i u'\u0394' K i u'\u2062' ( K i u'\u2229' G j ) means the total mass of the set of verbs in K i u'\u2229' G j , given by summing up the values in K i
	Cause: [(0, 75), (0, 81)]
	Effect: [(0, 3), (0, 73)]

CASE: 47
Stag: 166 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: K i u'\u2229' G j because all the values of c i u'\u2062' v are equal to 1
	Cause: [(0, 10), (0, 25)]
	Effect: [(0, 0), (0, 8)]

CASE: 48
Stag: 166 167 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: K i u'\u2229' G j because all the values of c i u'\u2062' v are equal to 1 As usual, the following normalized inverse purity (niPU) is used to measure the recall of a clustering
	Cause: [(1, 1), (1, 19)]
	Effect: [(0, 0), (0, 25)]

CASE: 49
Stag: 168 169 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Finally, we use the harmonic mean (F 1 ) of nmPU and niPU as a single measure of clustering quality We first evaluate our induced verb classes on the test set created by Korhonen et al
	Cause: [(0, 16), (1, 14)]
	Effect: [(0, 0), (0, 14)]

CASE: 50
Stag: 170 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: 2003 ) (Table 1 of their paper) which was created by considering verb polysemy on the basis of Levin u'\u2019' s classes and the LCS database [ 6 ]
	Cause: [(0, 13), (0, 18)]
	Effect: [(0, 19), (0, 28)]

CASE: 51
Stag: 173 174 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: An excerpt from this data is shown in Table 1 As our baselines, we adopt two previously proposed methods
	Cause: [(1, 1), (1, 9)]
	Effect: [(0, 0), (0, 9)]

CASE: 52
Stag: 182 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 2003 ) , prepositional phrases (pp) are parameterized for two frequent subcategorization frames (NP and NP_PP), and the unfiltered raw frequencies of subcategorization frames are used as features to represent a verb
	Cause: [(0, 32), (0, 34)]
	Effect: [(0, 10), (0, 30)]

CASE: 53
Stag: 183 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: It is necessary to specify the number of clusters, k , for the IB method beforehand, and we adopt 35 and 42 clusters according to their reported high accuracies
	Cause: [(0, 27), (0, 30)]
	Effect: [(0, 0), (0, 24)]

CASE: 54
Stag: 195 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The results of the IB baseline and our methods are obtained by averaging five runs
	Cause: [(0, 12), (0, 14)]
	Effect: [(0, 0), (0, 10)]

CASE: 55
Stag: 196 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We can see that u'\u201c' web/SW-S u'\u201d' achieved the best performance and obtained a higher F 1 than the baselines by more than nine points u'\u201c' Web/SW-S u'\u201d' uses the combination of slot-word pair features for clustering verb-specific frames and slot-only features for clustering across verbs
	Cause: [(0, 52), (0, 54)]
	Effect: [(0, 0), (0, 50)]

CASE: 56
Stag: 196 197 
	Pattern: 0 [[['imply', 'implies', 'implied', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(that)', '&R@Complete@']]
	sentTXT: We can see that u'\u201c' web/SW-S u'\u201d' achieved the best performance and obtained a higher F 1 than the baselines by more than nine points u'\u201c' Web/SW-S u'\u201d' uses the combination of slot-word pair features for clustering verb-specific frames and slot-only features for clustering across verbs Interestingly, this result indicates that slot distributions are more effective than lexical information in slot-word pairs for inducing verb classes similar to the gold standard
	Cause: [(0, 1), (1, 0)]
	Effect: [(1, 6), (1, 25)]

CASE: 57
Stag: 198 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: This result is consistent with expectations, given a gold standard based on Levin u'\u2019' s verb classes, which are organized according to the syntactic behavior of verbs
	Cause: [(0, 13), (0, 21)]
	Effect: [(0, 23), (0, 32)]

CASE: 58
Stag: 198 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: This result is consistent with expectations, given a gold standard based on Levin u'\u2019' s verb classes, which are organized according to the syntactic behavior of verbs
	Cause: [(0, 5), (0, 9)]
	Effect: [(0, 0), (0, 2)]

CASE: 59
Stag: 203 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since we focus on the handling of verb polysemy, predominant class induction for each verb is not our main objective
	Cause: [(0, 1), (0, 8)]
	Effect: [(0, 10), (0, 20)]

CASE: 60
Stag: 205 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: To output a single class for each verb by using our proposed method, we skip the induction of verb-specific semantic frames and instead create a single frame for each verb by merging all predicate-argument structures of the verb
	Cause: [(0, 9), (0, 12)]
	Effect: [(0, 13), (0, 38)]

CASE: 61
Stag: 208 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: We evaluate the single-class output for each verb based on the predominant gold-standard classes, which are defined for each verb in the test set of Korhonen et al
	Cause: [(0, 10), (0, 13)]
	Effect: [(0, 15), (0, 28)]

CASE: 62
Stag: 212 213 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 2003 ) , using the gold standard with multiple classes, which we also use for our multi-class evaluations As we did with the multi-class evaluations, we adopt modified purity (mPU), inverse purity (iPU) and their harmonic mean (F 1 ) as the metrics for the evaluation with predominant classes
	Cause: [(1, 1), (1, 37)]
	Effect: [(0, 12), (0, 18)]

CASE: 63
Stag: 214 215 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: It is not necessary to normalize these metrics when we treat verbs as monosemous, and evaluate against the predominant sense When we evaluate against the multiple classes in the gold standard, we do normalize the inverse purity
	Cause: [(0, 13), (1, 17)]
	Effect: [(0, 0), (0, 11)]

CASE: 64
Stag: 218 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The clusterings with the NN and IB methods are obtained by using the VALEX subcategorization lexicon
	Cause: [(0, 11), (0, 15)]
	Effect: [(0, 0), (0, 9)]

CASE: 65
Stag: 222 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Note that our results of the NN and IB methods are different from those reported in their paper since the data source is different
	Cause: [(0, 19), (0, 23)]
	Effect: [(0, 0), (0, 17)]

CASE: 66
Stag: 228 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: From the result, we can see that the induced verb classes based on slot-only features did not achieve a higher F 1 than those based on slot-word pair features in many cases
	Cause: [(0, 27), (0, 32)]
	Effect: [(0, 0), (0, 24)]

CASE: 67
Stag: 228 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: From the result, we can see that the induced verb classes based on slot-only features did not achieve a higher F 1 than those based on slot-word pair features in many cases
	Cause: [(0, 14), (0, 24)]
	Effect: [(0, 0), (0, 11)]

CASE: 68
Stag: 230 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We speculate that slot distributions are not so different among verbs when all uses of a verb are merged into one frame, and thus their discrimination power is lower than that in the intermediate construction of semantic frames
	Cause: [(0, 0), (0, 21)]
	Effect: [(0, 25), (0, 38)]

CASE: 69
Stag: 230 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: We speculate that slot distributions are not so different among verbs when all uses of a verb are merged into one frame, and thus their discrimination power is lower than that in the intermediate construction of semantic frames
	Cause: [(0, 0), (0, 6)]
	Effect: [(0, 8), (0, 20)]

CASE: 70
Stag: 237 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: It is not necessary to normalize these metrics because the clustering of these instances is hard
	Cause: [(0, 9), (0, 15)]
	Effect: [(0, 0), (0, 7)]

CASE: 71
Stag: 239 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The results of these methods are obtained by averaging five runs
	Cause: [(0, 8), (0, 10)]
	Effect: [(0, 0), (0, 6)]

CASE: 72
Stag: 246 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: 9 9 Since FrameNet frames are not assigned to all verbs of SemLink, the number of verbs is different from the evaluations against VerbNet classes
	Cause: [(0, 3), (0, 12)]
	Effect: [(0, 14), (0, 25)]

CASE: 73
Stag: 250 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on the best results in the above evaluations, we induced semantic frames using slot-word pair features, and then induced verb classes using slot-only features
	Cause: [(0, 2), (0, 8)]
	Effect: [(0, 10), (0, 26)]

CASE: 74
Stag: 255 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: For instance, u'\u201c' Class 2 u'\u201d' consists of the semantic frames u'\u201c' need:2 u'\u201d' and u'\u201c' say:2 u'\u201d' These frames were merged due to the high syntactic similarity of constituting slot distributions, which are comprised of a subject and a sentential complement
	Cause: [(0, 51), (0, 58)]
	Effect: [(0, 60), (0, 69)]

