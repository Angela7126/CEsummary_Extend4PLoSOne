************************************************************
P14-2070.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this paper , we present a novel approach for extracting u ' \ u2013 ' in a totally automated way u ' \ u2013 ' a high-coverage and high-precision lexicon of roughly 37 thousand terms annotated with emotion scores , called DepecheMood
	Cause: extracting u ' \ u2013 ' in a totally automated way u ' \ u2013 ' a high-coverage and high-precision lexicon of roughly 37 thousand terms annotated with emotion scores , called DepecheMood
	Effect: In this paper , we present a novel approach

CASE: 1
Stag: 3 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By providing new state-of-the-art performances in unsupervised settings for regression and classification tasks , even using a na ve approach , our experiments show the beneficial impact of harvesting social media data for affective lexicon building
	Cause: providing new state-of-the-art performances in unsupervised settings for regression and classification tasks , even using a na ve approach
	Effect: , our experiments show the beneficial impact of harvesting social media data for affective lexicon building

CASE: 2
Stag: 6 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The simple division in u ' \ u2018 ' positive u ' \ u2019 ' vs u ' \ u2018 ' negative u ' \ u2019 ' comments may not suffice , as in these examples u ' \ u2018 ' I u ' \ u2019 ' m so miserable , I dropped my IPhone in the water and now it u ' \ u2019 ' s not working anymore u ' \ u2019 ' -LRB- sadness -RRB- vs u ' \ u2018 ' I am very upset , my new IPhone keeps not working u ' \ u2019 ' -LRB- anger
	Cause: The simple division in u ' \ u2018 ' positive u ' \ u2019 ' vs u ' \ u2018 ' negative u ' \ u2019 ' comments may not suffice , as in these examples u ' \ u2018 ' I u ' \ u2019 ' m
	Effect: miserable , I dropped my IPhone in the water and now it u ' \ u2019 ' s not working anymore u ' \ u2019 ' -LRB- sadness -RRB- vs u ' \ u2018 ' I am very upset , my new IPhone keeps not working u ' \ u2019 ' -LRB- anger

CASE: 3
Stag: 7 8 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: While both texts express a negative sentiment , the latter , connected to anger , is more relevant for buzz monitoring Thus , emotion analysis represents a natural evolution of sentiment analysis
	Cause: While both texts express a negative sentiment , the latter , connected to anger , is more relevant for buzz monitoring
	Effect: , emotion analysis represents a natural evolution of sentiment analysis

CASE: 4
Stag: 15 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This calls for a role of compositionality , where the score of a sentence is computed by composing the scores of the words up in the syntactic tree
	Cause: composing the scores of the words up in the syntactic tree
	Effect: This calls for a role of compositionality , where the score of a sentence is computed

CASE: 5
Stag: 17 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: In this respect , compositional approaches represent a new promising trend , since all other approaches , either using semantic similarity or Bag-of-Words -LRB- BOW -RRB- based machine-learning , can not handle , for example , cases of texts with same wording but different words order u ' \ u201c ' The dangerous killer escaped one month ago , but recently he was arrested u ' \ u201d ' -LRB- relief , happyness -RRB- vs u ' \ u201c ' The dangerous killer was arrested one month ago , but recently he escaped u ' \ u201d ' -LRB- fear
	Cause: all other approaches , either using semantic similarity or Bag-of-Words -LRB- BOW -RRB- based machine-learning , can not handle , for example , cases of texts with same wording but different words order u ' \ u201c ' The dangerous killer escaped one
	Effect: In this respect , compositional approaches represent a new promising trend

CASE: 6
Stag: 21 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In such cases no context is given and the brand name alone , with its perceived prior polarity , is responsible for stating the area of competition and evoking semantic associations
	Cause: stating the area of competition and evoking semantic associations
	Effect: In such cases no context is given and the brand name alone , with its perceived prior polarity , is responsible

CASE: 7
Stag: 22 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: For example Mitsubishi changed the name of one of its SUVs for the Spanish market , since the original name Pajero had a very negative prior polarity , as it means u ' \ u2018 ' wanker u ' \ u2019 ' in Spanish -LSB- -RSB-
	Cause: the original name Pajero had a very negative prior polarity
	Effect: as it means u ' \ u2018 ' wanker u ' \ u2019 ' in Spanish -LSB- -RSB-

CASE: 8
Stag: 25 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: To this end , we take advantage in an original way of massive crowd-sourced affective annotations associated with news articles , obtained by crawling the rappler.com social news network
	Cause: crawling the rappler.com social news network
	Effect: To this end , we take advantage in an original way of massive crowd-sourced affective annotations associated with news articles , obtained

CASE: 9
Stag: 27 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Results indicate that the use of our resource , even if automatically acquired , is highly beneficial in affective text recognition
	Cause: automatically acquired ,
	Effect: Results indicate that the use of our resource , even

CASE: 10
Stag: 42 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Interestingly , this resource annotates the most frequent words in English , so , even if lexicon coverage is still far lower than SWN-prior , it grants a high coverage , with human precision , of language use
	Cause: Interestingly , this resource annotates the most frequent words in English
	Effect: even if lexicon coverage is still far lower than SWN-prior , it grants a high coverage , with human precision , of language use

CASE: 11
Stag: 42 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: even if lexicon coverage is still far lower than SWN-prior , it grants a high coverage , with human precision , of language use
	Cause: lexicon coverage is still far lower than SWN-prior
	Effect: it grants a high coverage , with human precision , of language use

CASE: 12
Stag: 54 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To build our emotion lexicon we harvested all the news articles from rappler.com , as of June 3rd 2013 the final dataset consists of 13.5 M words over 25.3 K documents , with an average of 530 words per document
	Cause: of June 3rd 2013 the final dataset consists of 13.5 M words over 25.3 K
	Effect: we harvested all the news articles from rappler.com

CASE: 13
Stag: 57 58 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: This way , hundreds of thousands votes have been collected since the launch of the service In our novel approach to u ' \ u2018 ' crowdsourcing u ' \ u2019 ' , as compared to other NLP tasks that rely on tools like Amazon u ' \ u2019 ' s Mechanical Turk -LSB- -RSB- , the subjects are aware of the u ' \ u2018 ' implicit annotation task u ' \ u2019 ' but they are not paid
	Cause: the launch of the service In our novel approach to u ' \ u2018 ' crowdsourcing u ' \ u2019 ' , as compared to other NLP tasks that rely on tools like Amazon u ' \ u2019 ' s Mechanical Turk -LSB- -RSB- , the subjects are aware of the u ' \ u2018 ' implicit annotation task u ' \ u2019 ' but they are not
	Effect: This way , hundreds of thousands votes have been collected

CASE: 14
Stag: 58 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In our novel approach to u ' \ u2018 ' crowdsourcing u ' \ u2019 ' , as compared to other NLP tasks that rely on tools like Amazon u ' \ u2019 ' s Mechanical Turk -LSB- -RSB- , the subjects are aware of the u ' \ u2018 ' implicit annotation task u ' \ u2019 ' but they are not paid
	Cause: compared to other NLP tasks that rely on tools like Amazon u ' \ u2019 ' s Mechanical Turk -LSB- -RSB- , the subjects are aware of the u ' \ u2018 ' implicit annotation task u ' \ u2019 ' but they are not paid
	Effect: novel approach to u ' \ u2018 ' crowdsourcing u ' \ u2019 '

CASE: 15
Stag: 63 
	Pattern: 1 [['it', 'is'], ['due', 'to'], ['that']]---- [[], ['(&ADV)'], ['&NP@C@'], ['&R']]
	sentTXT: There are several possible explanations , out of the scope of the present paper , for this bias i -RRB- it is due to cultural characteristics of the audience -LRB- ii -RRB- the bias is in the dataset itself , being formed mainly by u ' \ u2018 ' positive u ' \ u2019 ' news ; -LRB- iii -RRB- it is a psychological phenomenon due to the fact that people tend to express more positive moods on social networks -LSB- -RSB-
	Cause: the fact
	Effect: people tend to express more positive moods on social networks -LSB- -RSB-

CASE: 16
Stag: 66 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: As a next step we built a word-by-emotion matrix starting from M D u ' \ u2062 ' E using an approach based on compositional semantics
	Cause: compositional semantics
	Effect: As a next step we built a word-by-emotion matrix starting from M D u ' \ u2062 ' E using an approach

CASE: 17
Stag: 67 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: To do so , we first lemmatized and PoS tagged all the documents -LRB- where PoS can be adj. , nouns , verbs , adv. -RRB- and kept only those lemma #PoS present also in WordNet , similar to SWN-prior and WordNetAffect resources , to which we want to align
	Cause: To do
	Effect: we first lemmatized and PoS tagged all the documents -LRB- where PoS can be adj. , nouns , verbs , adv. -RRB- and kept only those lemma #PoS present also in WordNet , similar to SWN-prior and WordNetAffect resources , to which we want to align

CASE: 18
Stag: 68 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: We then computed the term-by-document matrices using raw frequencies , normalized frequencies , and tf-idf -LRB- M W u ' \ u2062 ' D , f , M W u ' \ u2062 ' D , n u ' \ u2062 ' f and M W u ' \ u2062 ' D , t u ' \ u2062 ' f u ' \ u2062 ' i u ' \ u2062 ' d u ' \ u2062 ' f respectively -RRB- , so to test which of the three weights is better
	Cause: We then computed the term-by-document matrices using raw frequencies , normalized frequencies , and tf-idf -LRB- M W u ' \ u2062 ' D , f , M W u ' \ u2062 ' D , n u ' \ u2062 ' f and M W u ' \ u2062 ' D , t u ' \ u2062 ' f u ' \ u2062 ' i u ' \ u2062 ' d u ' \ u2062 ' f respectively -RRB-
	Effect: to test which of the three weights is better

CASE: 19
Stag: 70 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This method allows us to u ' \ u2018 ' merge u ' \ u2019 ' words with emotions by summing the products of the weight of a word with the weight of the emotions in each document
	Cause: summing the products of the weight of a word with the weight of the emotions in each document
	Effect: This method allows us to u ' \ u2018 ' merge u ' \ u2019 ' words with emotions

CASE: 20
Stag: 71 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Finally , we transformed M W u ' \ u2062 ' E by first applying normalization column-wise -LRB- so to eliminate the over representation for happiness as discussed in Section 3 -RRB- and then scaling the data row-wise so to sum up to one
	Cause: Finally , we transformed M W u ' \ u2062 ' E by first applying normalization column-wise -LRB-
	Effect: to eliminate the over representation for happiness as discussed in Section 3 -RRB- and then scaling the data row-wise so to sum up to one

CASE: 21
Stag: 71 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: to eliminate the over representation for happiness as discussed in Section 3 -RRB- and then scaling the data row-wise so to sum up to one
	Cause: to eliminate the over representation for happiness as discussed in Section 3 -RRB- and then scaling the data row-wise
	Effect: to sum up to one

CASE: 22
Stag: 72 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: An excerpt of the final Matrix M W u ' \ u2062 ' E is presented in Table 3 , and it can be interpreted as a list of words with scores that represent how much weight a given word has in the affective dimensions we consider
	Cause: a list of words with scores that represent how much weight a given word has in the affective dimensions we
	Effect: ' \ u2062 ' E is presented in Table 3 , and it can be interpreted

CASE: 23
Stag: 72 73 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: An excerpt of the final Matrix M W u ' \ u2062 ' E is presented in Table 3 , and it can be interpreted as a list of words with scores that represent how much weight a given word has in the affective dimensions we consider So , for example , awe #n has a predominant weight in inspired -LRB- 0.38 -RRB- , comical #a has a predominant weight in amused -LRB- 0.51 -RRB- , while kill #v has a predominant weight in afraid , angry and sad -LRB- 0.23 , 0.21 and 0.27 respectively
	Cause: An excerpt of the final Matrix M W u ' \ u2062 ' E is presented in Table 3 , and it can be interpreted as a list of words with scores that represent how much weight a given word has in the affective dimensions we consider
	Effect: for example , awe #n has a predominant weight in inspired -LRB- 0.38 -RRB- , comical #a has a predominant weight in amused -LRB- 0.51 -RRB- , while kill #v has a predominant weight in afraid , angry and sad -LRB- 0.23 , 0.21 and 0.27 respectively

CASE: 24
Stag: 77 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Headlines typically consist of a few words and are often written with the intention to u ' \ u2018 ' provoke u ' \ u2019 ' emotions so to attract the readers u ' \ u2019 ' attention
	Cause: Headlines typically consist of a few words and are often written with the intention to u ' \ u2018 ' provoke u ' \ u2019 ' emotions
	Effect: to attract the readers u ' \ u2019 ' attention

CASE: 25
Stag: 80 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: This dataset is of interest to us since the u ' \ u2018 ' compositional u ' \ u2019 ' problem is less prominent given the simplified syntax of news headlines , containing , for example , fewer adverbs -LRB- like negations or intensifiers -RRB- than normal sentences -LSB- -RSB-
	Cause: the u ' \ u2018 ' compositional u ' \ u2019 ' problem is less prominent given the simplified syntax of news headlines
	Effect: containing , for example , fewer adverbs -LRB- like negations or intensifiers -RRB- than normal sentences -LSB- -RSB-

CASE: 26
Stag: 82 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Finally , this dataset was meant for unsupervised approaches -LRB- just a small trial sample was provided -RRB- , so to avoid simple text categorization approaches
	Cause: Finally , this dataset was meant for unsupervised approaches -LRB- just a small trial sample was provided -RRB-
	Effect: to avoid simple text categorization approaches

CASE: 27
Stag: 82 83 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Finally , this dataset was meant for unsupervised approaches -LRB- just a small trial sample was provided -RRB- , so to avoid simple text categorization approaches As the affective dimensions present in the test set u ' \ u2013 ' based on the six basic emotions model -LSB- -RSB- u ' \ u2013 ' do not exactly match with the ones provided by Rappler u ' \ u2019 ' s Mood Meter , we first define a mapping between the two when possible , see Table 4
	Cause: the affective dimensions present in the test set u ' \ u2013 ' based on the six basic emotions model -LSB- -RSB- u ' \ u2013 ' do not exactly match with the ones provided by Rappler u ' \ u2019 ' s Mood Meter , we first define a mapping between the two when possible , see Table 4
	Effect: Finally , this dataset was meant for unsupervised approaches -LRB- just a small trial sample was provided -RRB- , so to avoid simple text categorization approaches

CASE: 28
Stag: 88 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: 2013 -RRB- , we observe that even if the number of entries of our lexicon is far lower than SWN-prior approaches , the fact that we extracted and annotated words from documents grants a high coverage of language use
	Cause: the number of entries of our lexicon is far lower than SWN-prior approaches , the fact that we extracted and annotated words from documents grants a high coverage of language use
	Effect: 2013 -RRB- , we observe that even

CASE: 29
Stag: 92 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: We do so by using a very na ve approach , similar to u ' \ u201c ' WordNetAffect presence u ' \ u201d ' discussed in -LSB- -RSB- for each headline , we simply compute a value , for any affective dimension , by averaging the corresponding affective scores u ' \ u2013 ' obtained from DepecheMood - of all lemma #PoS present in the headline
	Cause: We do
	Effect: by using a very na ve approach , similar to u ' \ u201c ' WordNetAffect presence u ' \ u201d ' discussed in -LSB- -RSB- for each headline , we simply compute a value , for any affective dimension , by averaging the corresponding affective scores u ' \ u2013 ' obtained from DepecheMood - of all lemma #PoS present in the headline

CASE: 30
Stag: 92 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: by using a very na ve approach , similar to u ' \ u201c ' WordNetAffect presence u ' \ u201d ' discussed in -LSB- -RSB- for each headline , we simply compute a value , for any affective dimension , by averaging the corresponding affective scores u ' \ u2013 ' obtained from DepecheMood - of all lemma #PoS present in the headline
	Cause: using a very na ve approach , similar to u ' \ u201c ' WordNetAffect presence
	Effect: u ' \ u201d ' discussed in -LSB- -RSB- for each headline , we simply compute a value , for any affective dimension , by averaging the corresponding affective scores u ' \ u2013 ' obtained from DepecheMood - of all lemma #PoS present in the headline

CASE: 31
Stag: 92 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: u ' \ u201d ' discussed in -LSB- -RSB- for each headline , we simply compute a value , for any affective dimension , by averaging the corresponding affective scores u ' \ u2013 ' obtained from DepecheMood - of all lemma #PoS present in the headline
	Cause: averaging the corresponding affective scores u ' \ u2013 ' obtained from DepecheMood
	Effect: - of all lemma #PoS present in the headline

CASE: 32
Stag: 97 98 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Considering the na ve approach we used , we can reasonably conclude that the quality and coverage of our resource are the reason of such results , and that adopting more complex approaches -LRB- i.e. , compositionality -RRB- can possibly further improve performances in text-based emotion recognition As a final test , we evaluate our resource in the classification task
	Cause: a final test , we evaluate our resource in the classification task
	Effect: Considering the na ve approach we used , we can reasonably conclude that the quality and coverage of our resource are the reason of such results , and that adopting more complex approaches -LRB- i.e. , compositionality -RRB- can possibly further improve performances in text-based emotion recognition

CASE: 33
Stag: 103 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We presented DepecheMood , an emotion lexicon built in a novel and totally automated way by harvesting crowd-sourced affective annotation from a social news network
	Cause: harvesting crowd-sourced affective annotation from a social news network
	Effect: We presented DepecheMood , an emotion lexicon built in a novel and totally automated way

CASE: 34
Stag: 104 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Our experimental results indicate high-coverage and high-precision of the lexicon , showing significant improvements over state-of-the-art unsupervised approaches even when using the resource with very na ve classification and regression strategies
	Cause: Our experimental results
	Effect: high-coverage and high-precision of the lexicon , showing significant improvements over state-of-the-art unsupervised approaches even when using the resource with very na ve classification and regression strategies

CASE: 35
Stag: 106 
	Pattern: 0 [['owing', 'to'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Our future work will include testing Singular Value Decomposition on the word-by-document matrices , allowing to propagate emotions values for a document to similar words non present in the document itself , and the study of perceived mood effects on virality indices and readers engagement by exploiting tweets , likes , reshares and comments
	Cause: propagate emotions values for a document to similar words non present in the document itself
	Effect: and the study of perceived mood effects on virality indices and readers engagement by exploiting tweets , likes , reshares and comments

CASE: 36
Stag: 106 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: and the study of perceived mood effects on virality indices and readers engagement by exploiting tweets , likes , reshares and comments
	Cause: exploiting tweets , likes , reshares and comments
	Effect: the study of perceived mood effects on virality indices and readers engagement

