************************************************************
P14-1057.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 1 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: With the increasing use of electronic health records, it becomes urgent to leverage this rich information resource about patients u'\u2019' health conditions to transform research in health and medicine As an example, when developing a cohort for a clinical trial, researchers need to identify patients matching a set of clinical criteria based on their medical records during their hospital visits [ 22 , 8 ]
	Cause: [(1, 1), (1, 37)]
	Effect: [(0, 0), (0, 33)]

CASE: 1
Stag: 3 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Intuitively, to better solve this domain-specific retrieval problem, we need to understand the requirements specified in a query and identify the documents satisfying these requirements based on their semantic meanings
	Cause: [(0, 29), (0, 31)]
	Effect: [(0, 0), (0, 26)]

CASE: 2
Stag: 7 8 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The basic idea is to represent both queries and documents as u'\u201c' bags of concepts u'\u201d' , where the concepts are identified based on the information from the knowledge bases This method has been shown to be more effective than traditional term-based representation in the medical record retrieval because of its ability to handle the ambiguity in the medical terminology
	Cause: [(0, 11), (1, 28)]
	Effect: [(0, 0), (0, 9)]

CASE: 3
Stag: 8 9 
	Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
	sentTXT: This method has been shown to be more effective than traditional term-based representation in the medical record retrieval because of its ability to handle the ambiguity in the medical terminology However, this method also suffers the limitation that its effectiveness depends on the accuracy of the concept mapping results
	Cause: [(0, 0), (0, 17)]
	Effect: [(1, 0), (1, 19)]

CASE: 4
Stag: 10 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: As a result, directly applying existing weighting strategies might lead to non-optimal retrieval performance
	Cause: [(0, 6), (0, 8)]
	Effect: [(0, 12), (0, 14)]

CASE: 5
Stag: 12 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Specifically, by applying the axiomatic approaches [ 7 ] , we analyze the retrieval functions with concept-based representation and find that they may violate some reasonable retrieval constraints
	Cause: [(0, 3), (0, 9)]
	Effect: [(0, 10), (0, 28)]

CASE: 6
Stag: 13 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: We then propose two concept-based weighting regularization methods so that the regularized retrieval functions would satisfy the retrieval constraints and achieve better retrieval performance
	Cause: [(0, 0), (0, 7)]
	Effect: [(0, 10), (0, 23)]

CASE: 7
Stag: 16 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: However, due to the inherent ambiguity of natural languages, the results of NLP tools are not perfect
	Cause: [(0, 4), (0, 9)]
	Effect: [(0, 11), (0, 18)]

CASE: 8
Stag: 17 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: One of our contributions is to present a general methodology that can be used to adjust existing IR techniques based on the inaccurate NLP results
	Cause: [(0, 21), (0, 24)]
	Effect: [(0, 0), (0, 18)]

CASE: 9
Stag: 21 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: To further improve the performance, Limsopatham et al proposed a task-specific representation, i.e.,, using only four types of concepts (symptom, diagnostic test, diagnosis and treatment) in the concept-based representation and a query expansion method based on the relationships among the medical concepts [ 12 , 13 ]
	Cause: [(0, 44), (0, 54)]
	Effect: [(0, 0), (0, 41)]

CASE: 10
Stag: 25 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: However, none of the previous work has studied how to regularize the weight of concepts based on their relations
	Cause: [(0, 18), (0, 19)]
	Effect: [(0, 0), (0, 15)]

CASE: 11
Stag: 33 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since each visit can be associated with multiple medical records, the relevance of a visit is related to the relevance of individual associated medical records
	Cause: [(0, 1), (0, 9)]
	Effect: [(0, 11), (0, 25)]

CASE: 12
Stag: 34 35 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Existing studies computed the relevance scores at either visit-level, where all the medical records of a visit are merged into a visit document [ 5 , 15 ] , or record-level, where we can first compute the relevance score of individual records and then aggregate their scores as the relevance score of a visit [ 15 , 30 , 12 ] In this paper, we focus on the visit-level relevance because of its simplicity
	Cause: [(0, 50), (1, 12)]
	Effect: [(0, 0), (0, 48)]

CASE: 13
Stag: 35 36 
	Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
	sentTXT: In this paper, we focus on the visit-level relevance because of its simplicity In particular, given a patient u'\u2019' s visit, all the medical records generated from this visit are merged as a document
	Cause: [(0, 0), (0, 9)]
	Effect: [(1, 2), (1, 26)]

CASE: 14
Stag: 36 37 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In particular, given a patient u'\u2019' s visit, all the medical records generated from this visit are merged as a document Note that our proposed concept-weighting strategies can also be easily applied to record-level relevance modeling
	Cause: [(0, 25), (1, 14)]
	Effect: [(0, 0), (0, 23)]

CASE: 15
Stag: 38 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the goal is to retrieve medical records of patients that satisfying requirements specified in a query, the relevance of medical records should be modeled based on how well they match all the requirements (i.e.,, aspects) specified in the queries
	Cause: [(0, 1), (0, 16)]
	Effect: [(0, 18), (0, 44)]

CASE: 16
Stag: 43 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In particular, MetaMap [ 3 ] can take a text string as the input, segment it into phrases, and then map each phrase to multiple UMLS CUIs with confidence scores
	Cause: [(0, 13), (0, 30)]
	Effect: [(0, 0), (0, 11)]

CASE: 17
Stag: 51 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Traditional retrieval models are based on u'\u201c' bag of terms u'\u201d' representation
	Cause: [(0, 6), (0, 19)]
	Effect: [(0, 0), (0, 2)]

CASE: 18
Stag: 52 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: One limitation of this representation is that relevance scores are computed based on the matching of terms rather than the meanings
	Cause: [(0, 13), (0, 20)]
	Effect: [(0, 0), (0, 10)]

CASE: 19
Stag: 52 53 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: One limitation of this representation is that relevance scores are computed based on the matching of terms rather than the meanings As a result, the system may fail to retrieve the relevant documents that do not contain any query terms
	Cause: [(0, 0), (0, 20)]
	Effect: [(1, 4), (1, 19)]

CASE: 20
Stag: 55 56 
	Pattern: 3 [[[',', '.', ';', 'and']], ['as', 'a'], ['result']]---- [['&C'], ['&R'], ['(&ADJ)']]
	sentTXT: In particular, MetaMap is used to map terms from queries and documents (e.g.,, medical records) to the semantic concepts from biomedical knowledge bases such as UMLS Within the concept-based representation, the query can then be represented as a bag of all the generated CUIs in the MetaMap results
	Cause: [(0, 1), (1, 3)]
	Effect: [(1, 5), (1, 10)]

CASE: 21
Stag: 61 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Although existing retrieval functions can be directly applied to concept-based representation, they may lead to non-optimal performance
	Cause: [(0, 12), (0, 12)]
	Effect: [(0, 16), (0, 17)]

CASE: 22
Stag: 64 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Under such a situation, traditional retrieval functions would likely work well and generate satisfying retrieval performance since the relations among concepts are independent which is consistent with the assumptions made in traditional IR [ 18 ]
	Cause: [(0, 18), (0, 36)]
	Effect: [(0, 0), (0, 16)]

CASE: 23
Stag: 67 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: In particular, our preliminary results show that turning on the disambiguation functionality provided by MetaMap (i.e.,, returning only the most likely concept for each query) could lead to worse retrieval performance than using all the candidate mappings
	Cause: [(0, 8), (0, 29)]
	Effect: [(0, 33), (0, 41)]

CASE: 24
Stag: 67 68 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In particular, our preliminary results show that turning on the disambiguation functionality provided by MetaMap (i.e.,, returning only the most likely concept for each query) could lead to worse retrieval performance than using all the candidate mappings Thus, we use the one-to-many mapping results generated by MetaMap, in which each aspect can be mapped to multiple concepts
	Cause: [(0, 0), (0, 41)]
	Effect: [(1, 1), (1, 21)]

CASE: 25
Stag: 70 71 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The multiple concepts generated from the same aspect are related, which is inconsistent with the independence assumption made in the existing retrieval functions [ 18 ] For example, as shown in Figure 1 , u'\u201c' dental caries u'\u201d' is mapped to three concepts
	Cause: [(1, 4), (1, 25)]
	Effect: [(0, 1), (1, 1)]

CASE: 26
Stag: 73 74 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The one-to-many mapping results generated by MetaMap could arbitrarily inflate the weights of some query aspects For example, as shown in Figure 1 , query aspect u'\u201c' children u'\u201d' is mapped to 2 concepts while u'\u201c' dental caries u'\u201d' is mapped to 3 concepts
	Cause: [(1, 4), (1, 44)]
	Effect: [(0, 1), (1, 1)]

CASE: 27
Stag: 76 77 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: However, when converting the text to concepts representation using MetaMap, the occurrences of the concepts are determined by not only the original term occurrences, a good indicator of relevance, but also the number of mapped concepts, which is determined by MetaMap and has nothing to do with the relevance status As a result, the occurrences of concepts might not be a very accurate indicator of importance of the corresponding query aspect
	Cause: [(0, 0), (0, 54)]
	Effect: [(1, 4), (1, 21)]

CASE: 28
Stag: 82 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: S u'\u2062' ( Q , D ) is the relevance score of D with respect to Q e i denotes a concept, and u'\ud835' u'\udc9c' u'\u2062' ( e ) denotes the query aspect associated with e , i.e.,, a set of concepts that are mapped to the same phrases as e by using MetaMap i u'\u2062' ( e ) is the normalized confidence score of the mapping for concept e generated by MetaMap c u'\u2062' ( e , D ) denotes the occurrences of concept e in document D , d u'\u2062' f u'\u2062' ( e ) denotes the number of documents containing e
	Cause: [(0, 71), (0, 81)]
	Effect: [(0, 82), (0, 138)]

CASE: 29
Stag: 85 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: We now discuss how to address the first challenge, i.e how to regularize the weighting strategy so that we can take into consideration the fact that concepts associated with the same query aspect are not independent
	Cause: [(0, 0), (0, 16)]
	Effect: [(0, 19), (0, 36)]

CASE: 30
Stag: 86 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: We call a concept is a variant of another one if both of them are associated with the same aspect
	Cause: [(0, 11), (0, 19)]
	Effect: [(0, 0), (0, 9)]

CASE: 31
Stag: 94 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If we know that c u'\u2062' ( e 1 , D 1 ) = c u'\u2062' ( e 3 , D 2 ) 0 , c u'\u2062' ( e 1 , D 2 ) = c u'\u2062' ( e 3 , D 1 ) = 0 and c u'\u2062' ( e 2 , D 1 ) = c u'\u2062' ( e 2 , D 2 ) 0 , then S u'\u2062' ( Q , D 1 ) S u'\u2062' ( Q , D 2 )
	Cause: [(0, 1), (0, 12)]
	Effect: [(0, 14), (0, 47)]

CASE: 32
Stag: 95 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: It is clear that existing retrieval functions would violate this constraint since they ignore the relations among concepts
	Cause: [(0, 12), (0, 17)]
	Effect: [(0, 0), (0, 10)]

CASE: 33
Stag: 97 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: By merging the concepts together, we are aiming to purify the concepts and make the similar concepts centralized so that the assumption that all the concepts are independent would hold
	Cause: [(0, 0), (0, 18)]
	Effect: [(0, 21), (0, 30)]

CASE: 34
Stag: 97 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By merging the concepts together, we are aiming to purify the concepts and make the similar concepts centralized so that the assumption that all the concepts are independent would hold
	Cause: [(0, 1), (0, 4)]
	Effect: [(0, 5), (0, 18)]

CASE: 35
Stag: 99 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where c u'\u2062' ( e , D ) is the original occurrence of concept e in document D , E u'\u2062' C u'\u2062' ( e ) denotes a set of all the variants of e including itself (i.e.,, all the concepts with the same preferred name as e ), and R u'\u2062' e u'\u2062' p u'\u2062' ( E u'\u2062' C u'\u2062' ( e ) ) denotes the representative concept from E u'\u2062' C u'\u2062' ( e )
	Cause: [(0, 62), (0, 120)]
	Effect: [(0, 2), (0, 60)]

CASE: 36
Stag: 100 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: It is trivial to prove that, with such changes, existing retrieval functions would satisfy the above constraint since the constraint implies TFC2 constraint defined in the previous study [ 6 ]
	Cause: [(0, 20), (0, 32)]
	Effect: [(0, 0), (0, 18)]

CASE: 37
Stag: 100 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: It is trivial to prove that, with such changes, existing retrieval functions would satisfy the above constraint since the constraint implies TFC2 constraint defined in the previous study [ 6 ]
	Cause: [(0, 0), (0, 1)]
	Effect: [(0, 3), (0, 12)]

CASE: 38
Stag: 107 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: It is clear that the right plot (i.e.,, selecting the concept with the maximum IDF as the representative concept) is the best choice since the changes make the points less scattered
	Cause: [(0, 28), (0, 34)]
	Effect: [(0, 0), (0, 26)]

CASE: 39
Stag: 108 109 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In fact, this can also be confirmed by experimental results as reported in Table 5 Thus, we use the concept with the maximum IDF value as the representative concept of all the variants
	Cause: [(0, 12), (1, 18)]
	Effect: [(0, 0), (0, 10)]

CASE: 40
Stag: 108 109 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In fact, this can also be confirmed by experimental results as reported in Table 5 Thus, we use the concept with the maximum IDF value as the representative concept of all the variants
	Cause: [(0, 0), (0, 15)]
	Effect: [(1, 1), (1, 18)]

CASE: 41
Stag: 111 112 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The arbitrary inflation could impact the importance of the query aspects For example, as shown in Figure 1 , one aspect is mapped to two concepts while the other is mapped to three
	Cause: [(1, 4), (1, 22)]
	Effect: [(0, 1), (1, 1)]

CASE: 42
Stag: 116 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: To fix the negative impact on query aspects, we could leverage the findings in the previous study [ 28 ] and regularize the weighting strategy based on the length of query aspects to favor documents covering more query aspects
	Cause: [(0, 28), (0, 39)]
	Effect: [(0, 0), (0, 25)]

CASE: 43
Stag: 117 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since each concept mapping is associated with a confidence score, we can incorporate them into the regularization function as follows
	Cause: [(0, 1), (0, 9)]
	Effect: [(0, 11), (0, 20)]

CASE: 44
Stag: 120 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: This regularization function aims to penalize the weight of concept e based on its variants as well as the concepts from other aspects
	Cause: [(0, 13), (0, 22)]
	Effect: [(0, 1), (0, 10)]

CASE: 45
Stag: 122 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: To fix the negative impact on the concept IDF values, we propose to regularize the weighting based on the importance of the query aspect
	Cause: [(0, 19), (0, 24)]
	Effect: [(0, 0), (0, 16)]

CASE: 46
Stag: 129 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If we know I u'\u2062' m u'\u2062' p c u'\u2062' ( e 1 ) = I u'\u2062' m u'\u2062' p c u'\u2062' ( e 2 ) and I u'\u2062' m u'\u2062' p A u'\u2062' ( u'\ud835' u'\udc9c' u'\u2062' ( e 1 ) ) I u'\u2062' m u'\u2062' p A u'\u2062' ( u'\ud835' u'\udc9c' u'\u2062' ( e 2 ) ) , then we have S u'\u2062' ( Q , D 1 ) S u'\u2062' ( Q , D 2 )
	Cause: [(0, 1), (0, 130)]
	Effect: [(0, 132), (0, 157)]

CASE: 47
Stag: 131 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In a way, the constraint aims to counteract the arbitrary statistics inflation caused by MetaMap results and balance the weight among concepts based on the importance of the associated query aspects
	Cause: [(0, 25), (0, 31)]
	Effect: [(0, 0), (0, 22)]

CASE: 48
Stag: 135 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Note that I u'\u2062' m u'\u2062' p A u'\u2062' ( u'\ud835' u'\udc9c' u'\u2062' ( e ) ) is the importance of a query aspect and can be estimated based on the terms from the query aspect
	Cause: [(0, 54), (0, 59)]
	Effect: [(0, 0), (0, 51)]

CASE: 49
Stag: 142 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: With the unified concept weighting regularization, the revised function based on F2-EXP function, i.e.,, Unified , is shown as follows
	Cause: [(0, 12), (0, 13)]
	Effect: [(0, 15), (0, 23)]

CASE: 50
Stag: 151 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the task is to retrieve relevant visits, we merged all the records from a visit to form a single document for the visit, which leads to 17,198 documents in the collection
	Cause: [(0, 1), (0, 7)]
	Effect: [(0, 9), (0, 33)]

CASE: 51
Stag: 153 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: These queries were developed by domain experts based on the u'\u201c' inclusion criteria u'\u201d' of a clinical study [ 25 , 24 ]
	Cause: [(0, 9), (0, 30)]
	Effect: [(0, 0), (0, 6)]

CASE: 52
Stag: 155 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since documents are often much longer, we can first segment them into sentences, get the mapping results for each sentence, and then merge them together to generate the concept-based representation for the documents
	Cause: [(0, 1), (0, 5)]
	Effect: [(0, 7), (0, 35)]

CASE: 53
Stag: 162 163 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Following the evaluation methodology used in the medical record track, we use MAP@1000 as the primary measure for Med11 and also report bpref For Med12 , we take infNDCG@100 as the primary measure and also report infAP@100
	Cause: [(0, 15), (1, 13)]
	Effect: [(0, 0), (0, 13)]

CASE: 54
Stag: 164 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Different measures were chosen for these two sets mainly because different pooling strategies were used to create the judgment pools [ 24 ]
	Cause: [(0, 10), (0, 22)]
	Effect: [(0, 0), (0, 8)]

CASE: 55
Stag: 167 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Note that T , C and T u'\u2062' S indicate improvement over Term-BL, Concept-BL and TSConcept-BL is statistically significant at 0.05 level based on Wilcoxon signed-rank test, respectively
	Cause: [(0, 29), (0, 31)]
	Effect: [(0, 0), (0, 26)]

CASE: 56
Stag: 170 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: It is not surprising to see that Balanced method is more effective than Unified since the former satisfies both of the proposed retrieval constraints while the latter satisfies only one
	Cause: [(0, 15), (0, 29)]
	Effect: [(0, 0), (0, 13)]

CASE: 57
Stag: 179 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Moreover, our performance might be further improved if we apply the result filtering methods used by many TREC participants [ 11 ]
	Cause: [(0, 9), (0, 22)]
	Effect: [(0, 0), (0, 7)]

CASE: 58
Stag: 180 181 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the Unified method, we chose the concept with the maximum IDF as the representative concept among all the variants We now conduct experiments on Med11 to compare its performance with those of using average IDF and minimum IDF ones as the representative concept
	Cause: [(0, 14), (1, 22)]
	Effect: [(0, 0), (0, 12)]

CASE: 59
Stag: 186 187 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Table 6 summarizes the results, and shows that using the maximum IDF value performs better than the other choices As shown in Equation ( 3 ), the Balanced method regularizes the weights through two components
	Cause: [(1, 1), (1, 16)]
	Effect: [(0, 0), (0, 19)]

