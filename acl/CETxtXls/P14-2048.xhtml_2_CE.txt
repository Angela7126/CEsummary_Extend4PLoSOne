************************************************************
P14-2048.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We show further that the accuracy with which a learned classifier can detect text as machine translated is strongly correlated with the translation quality of the machine translation system that generated it
	Cause: machine translated is strongly correlated with the translation quality of the machine translation system that generated it
	Effect: We show further that the accuracy with which a learned classifier can detect text

CASE: 1
Stag: 2 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Finally , we offer a generic machine translation quality estimation technique based on this approach , which does not require reference sentences
	Cause: this approach
	Effect: which does not require reference sentences

CASE: 2
Stag: 4 5 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Prominent among these are how to evaluate the quality of such a system efficiently and how to detect the output of such systems -LRB- for example , to avoid using it circularly as input for refining MT systems In this paper , we will answer both these questions
	Cause: input for refining MT systems In this paper , we will answer both these
	Effect: Prominent among these are how to evaluate the quality of such a system efficiently and how to detect the output of such systems -LRB- for example , to avoid using it circularly

CASE: 3
Stag: 9 10 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Specifically , given a corpus consisting of both machine-translated English text -LRB- English being the target language -RRB- and native English text -LRB- not necessarily the reference translation of the machine-translated text -RRB- , we measure the accuracy of the system in classifying the sentences in the corpus as machine-translated or not This accuracy will be shown to decrease as the quality of the underlying MT system increases
	Cause: machine-translated or not This accuracy will be shown to decrease as the quality of the
	Effect: target language -RRB- and native English text -LRB- not necessarily the reference translation of the machine-translated text -RRB- , we measure the accuracy of the system in classifying the sentences in the corpus

CASE: 4
Stag: 10 11 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This accuracy will be shown to decrease as the quality of the underlying MT system increases In fact , the correlation is strong enough that we propose that this accuracy measure itself can be used as a measure of MT system quality , obviating the need for a reference corpus , as for example is necessary for BLEU -LSB- -RSB-
	Cause: the quality of the underlying MT system increases In fact , the correlation is strong enough that we propose that this accuracy measure itself can be used as a measure of MT system quality , obviating the need for a reference corpus , as for example is necessary for BLEU -LSB-
	Effect: This accuracy will be shown to decrease

CASE: 5
Stag: 11 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In fact , the correlation is strong enough that we propose that this accuracy measure itself can be used as a measure of MT system quality , obviating the need for a reference corpus , as for example is necessary for BLEU -LSB- -RSB-
	Cause: a measure of MT system quality , obviating the need for a reference corpus , as for example is necessary for BLEU -LSB- -RSB-
	Effect: In fact , the correlation is strong enough that we propose that this accuracy measure itself can be used

CASE: 6
Stag: 14 15 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the third section , we describe experiments regarding the detection of machine translation and in the fourth section we discuss the use of detection techniques as a machine translation quality estimation method In the final section we offer conclusions and suggestions for future work
	Cause: a machine translation quality estimation method In the final section we offer conclusions and suggestions for future
	Effect: In the third section , we describe experiments regarding the detection of machine translation and in the fourth section we discuss the use of detection techniques

CASE: 7
Stag: 19 20 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Using automatic text classification methods in the field of translation studies had many use cases in recent years , mainly as an empirical method of measuring , proving or contradicting translation universals Several works -LSB- -RSB- used text classification techniques in order to distinguish human translated text from native language text at document or paragraph level , using features like word and POS n-grams , proportion of grammatical words in the text , nouns , finite verbs , auxiliary verbs , adjectives , adverbs , numerals , pronouns , prepositions , determiners , conjunctions etc
	Cause: an empirical method of measuring , proving or contradicting translation universals Several works -LSB- -RSB- used text classification techniques in order to distinguish human translated text from native language text at document or paragraph level , using features like word and POS
	Effect: automatic text classification methods in the field of translation studies had many use cases in recent years , mainly

CASE: 8
Stag: 24 25 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Regarding the detection of machine translated text , Carter and Inkpen -LSB- -RSB- translated the Hansards of the 36th Parliament of Canada using the Microsoft Bing MT web service , and conducted three detection experiments at document level , using unigrams , average token length , and type-token ratio as features Arase and Zhou -LSB- -RSB- trained a sentence-level classifier to distinguish machine translated text from human generated text on English and Japanese web-page corpora , translated by Google Translate , Bing and an in-house SMT system
	Cause: features Arase and Zhou -LSB- -RSB- trained a sentence-level classifier to distinguish machine translated text from human generated text on English and Japanese web-page corpora , translated by Google Translate , Bing and an in-house SMT
	Effect: machine translated text , Carter and Inkpen -LSB- -RSB- translated the Hansards of the 36th Parliament of Canada using the Microsoft Bing MT web service , and conducted three detection experiments at document level , using unigrams , average token length , and type-token ratio

CASE: 9
Stag: 27 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: While Arase and Zhou -LSB- -RSB- considered MT detection at sentence level , as we do in this paper , they did not study the correlation between the translation quality of the machine translated text and the ability to detect it
	Cause: we do in this paper , they did not study the correlation between the translation quality of the machine translated text and the ability to detect it
	Effect: Arase and Zhou -LSB- -RSB- considered MT detection at sentence level

CASE: 10
Stag: 31 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: Due to the sparseness of the data at the sentence level , we use common content-independent linguistic features for the classification task
	Cause: the sparseness of the data at the sentence level
	Effect: we use common content-independent linguistic features for the classification task

CASE: 11
Stag: 33 34 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We consider only those entries that appear at least ten times in the entire corpus , in order to reduce sparsity in the data As our learning algorithm we use SVM with sequential minimal optimization -LRB- SMO -RRB- , taken from the WEKA machine learning toolkit -LSB- -RSB-
	Cause: our learning algorithm we use SVM with sequential minimal optimization -LRB- SMO -RRB- , taken from the WEKA machine learning toolkit -LSB- -RSB-
	Effect: We consider only those entries that appear at least ten times in the entire corpus , in order to reduce sparsity in the data

CASE: 12
Stag: 39 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: After translating the sentences , we take 20,000 sentences from each engine output and conduct the detection experiment by labeling those sentences as MT sentences , and another 20,000 sentences , which are the human reference translations , labeled as reference sentences
	Cause: MT sentences , and another 20,000 sentences , which are the human reference translations , labeled as reference
	Effect: After translating the sentences , we take 20,000 sentences from each engine output and conduct the detection experiment by labeling those sentences

CASE: 13
Stag: 42 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using simple linear regression , we also obtain an R 2 value -LRB- coefficient of determination -RRB- over the measurements of detection accuracy and BLEU score , for each of three feature set combinations -LRB- function words , POS tags and mixed -RRB- and the two data combinations -LRB- MT vs reference and MT vs non reference sentences
	Cause: Using simple linear regression
	Effect: we also obtain an R 2 value -LRB- coefficient of determination -RRB- over the measurements of detection accuracy and BLEU score , for each of three feature set combinations -LRB- function words , POS tags and mixed -RRB- and the two data combinations -LRB- MT vs reference and MT vs non reference sentences

CASE: 14
Stag: 52 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: It can also be seen that , as might be expected , it is easier to distinguish machine-translated sentences from a non-reference set than from the reference set
	Cause: might be expected , it is easier to distinguish machine-translated sentences from a non-reference set than from the reference set
	Effect: It can also be seen that

CASE: 15
Stag: 53 54 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In Figure 1 , we show the relationship of the observed detection accuracy for each system with the BLEU score of that system As is evident , regardless of the feature set or non-MT sentences used , the correlation between detection accuracy and BLEU score is very high , as we can also see from the R 2 values in Table 1
	Cause: is evident , regardless of the feature set or non-MT sentences used , the correlation between detection accuracy and BLEU score is very high , as we can also see from the R 2 values in
	Effect: In Figure 1 , we show the relationship of the observed detection accuracy for each system with the BLEU score of that system

CASE: 16
Stag: 56 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: In order to do so , we use the Moses statistical machine translation toolkit -LSB- -RSB-
	Cause: In order to do
	Effect: we use the Moses statistical machine translation toolkit -LSB- -RSB-

CASE: 17
Stag: 59 60 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For purposes of classification , we use the same content independent features as in the previous experiment , based on function words and POS tags , again with SMO-based SVM as the classifier For data , we use 20,000 random , non reference sentences from the Hansard corpus , against 20,000 sentences from one MT system per experiment , again resulting in 40,000 sentence instances per experiment
	Cause: in the previous experiment , based on function words and POS tags , again with SMO-based SVM as the classifier For data , we use 20,000 random , non reference sentences from the Hansard corpus , against 20,000 sentences from one MT system per experiment , again resulting in 40,000 sentence instances per
	Effect: For purposes of classification , we use the same content independent features

CASE: 18
Stag: 63 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: -LSB- color = black , mark = none , style = dashed -RSB- table -LSB- y = create col/linear regression = y = Y -RSB- X Y 29.18 72.33 28.54 73.10 27.76 73.90 24.34 74.12 23.83 73.59 22.46 74.78 20.72 75.98 ;
	Cause: -LSB- color = black
	Effect: mark = none , style = dashed -RSB- table -LSB- y = create col/linear regression = y = Y -RSB- X Y 29.18 72.33 28.54 73.10 27.76 73.90 24.34 74.12 23.83 73.59 22.46 74.78 20.72 75.98 ;

CASE: 19
Stag: 65 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: -LSB- color = black , mark = none , style = dashed -RSB- table -LSB- y = create col/linear regression = y = Y -RSB- X Y 0.638 58.58 0.604 58.61 0.591 57.63 0.573 58.78 0.562 59.38 0.541 58.63 0.512 59.86 0.486 58.53 0.439 60.46 0.429 61.65 0.420 62.66 0.389 60.83 0.322 64.10 ;
	Cause: -LSB- color = black
	Effect: mark = none , style = dashed -RSB- table -LSB- y = create col/linear regression = y = Y -RSB- X Y 0.638 58.58 0.604 58.61 0.591 57.63 0.573 58.78 0.562 59.38 0.541 58.63 0.512 59.86 0.486 58.53 0.439 60.46 0.429 61.65 0.420 62.66 0.389 60.83 0.322 64.10 ;

CASE: 20
Stag: 67 68 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: -LSB- title = R 2 = 0.829 , width = 7.5 cm , height = 7.5 cm , xlabel = human evaluation score , ylabel = detection accuracy -LRB- % -RRB- -RSB- \ addplot -LSB- color = black , mark =*] coordinates -LRB- 0.638,60.92 -RRB- -LRB- 0.604,61.54 -RRB- -LRB- 0.591,62.41 -RRB- -LRB- 0.573,62.87 -RRB- -LRB- 0.562,62.46 -RRB- -LRB- 0.541,62.97 -RRB- -LRB- 0.512,63.81 -RRB- -LRB- 0.486,62.87 -RRB- -LRB- 0.439,64.09 -RRB- -LRB- 0.429,64.72 -RRB- -LRB- 0.420,66.81 -RRB- -LRB- 0.389,65.24 -RRB- -LRB- 0.322,65.87 -RRB- ; \ addplot -LSB- color = black , mark = none , style = dashed -RSB- table -LSB- y = create col/linear regression = y = Y -RSB- X Y 0.638 60.92 0.604 61.54 0.591 62.41 0.573 62.87 0.562 62.46 0.541 62.97 0.512 63.81 0.486 62.87 0.439 64.09 0.429 64.72 0.420 66.81 0.389 65.24 0.322 65.87 ; As can be seen in the above experiments , there is a strong correlation between the BLEU score and the MT detection accuracy of our method
	Cause: can be seen in the above experiments , there is a strong correlation between the BLEU score and the MT detection accuracy of our method
	Effect: -LSB- title = R 2 = 0.829 , width = 7.5 cm , height = 7.5 cm , xlabel = human evaluation score , ylabel = detection accuracy -LRB- % -RRB- -RSB- \ addplot -LSB- color = black , mark =*] coordinates -LRB- 0.638,60.92 -RRB- -LRB- 0.604,61.54 -RRB- -LRB- 0.591,62.41 -RRB- -LRB- 0.573,62.87 -RRB- -LRB- 0.562,62.46 -RRB- -LRB- 0.541,62.97 -RRB- -LRB- 0.512,63.81 -RRB- -LRB- 0.486,62.87 -RRB- -LRB- 0.439,64.09 -RRB- -LRB- 0.429,64.72 -RRB- -LRB- 0.420,66.81 -RRB- -LRB- 0.389,65.24 -RRB- -LRB- 0.322,65.87 -RRB- ; \ addplot -LSB- color = black , mark = none , style = dashed -RSB- table -LSB- y = create col/linear regression = y = Y -RSB- X Y 0.638 60.92 0.604 61.54 0.591 62.41 0.573 62.87 0.562 62.46 0.541 62.97 0.512 63.81 0.486 62.87 0.439 64.09 0.429 64.72 0.420 66.81 0.389 65.24 0.322 65.87 ;

CASE: 21
Stag: 72 73 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We conduct the same classification experiment as above , with features based on function words and POS tags , and SMO-based SVM as the classifier We first use 3000 reference sentences from the WMT13 u ' \ u2019 ' English reference translations , against the matching 3000 output sentences from one MT system at a time , resulting in 6000 sentence instances per experiment
	Cause: above , with features based on function words and POS tags , and SMO-based SVM as the classifier We first use 3000 reference sentences from the WMT13 u ' \ u2019 ' English reference translations , against the matching 3000 output sentences from one MT system at a time ,
	Effect: We conduct the same classification experiment

CASE: 22
Stag: 73 74 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We first use 3000 reference sentences from the WMT13 u ' \ u2019 ' English reference translations , against the matching 3000 output sentences from one MT system at a time , resulting in 6000 sentence instances per experiment As can be seen in Figure 3 , the detection accuracy is strongly correlated with the evaluations scores , yielding R 2 = 0.774
	Cause: can be seen in Figure 3 , the detection accuracy is strongly correlated with the evaluations scores , yielding R 2 = 0.774
	Effect: We first use 3000 reference sentences from the WMT13 u ' \ u2019 ' English reference translations , against the matching 3000 output sentences from one MT system at a time , resulting in 6000 sentence instances per experiment

CASE: 23
Stag: 76 77 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the second experiment , we use 3000 random , non reference sentences from the newstest 2011-2012 corpora published in WMT12 u ' \ u2019 ' -LSB- -RSB- against 3000 output sentences from one MT system at a time , again resulting in 6000 sentence instances per experiment While applying the same classification method as with the reference sentences , the detection accuracy rises , while the correlation with the translation quality yields R 2 = 0.556 , as can be seen in Figure 4
	Cause: with the reference sentences , the detection accuracy rises , while the correlation with the translation quality yields R 2 = 0.556 , as can be seen in Figure 4
	Effect: we use 3000 random , non reference sentences from the newstest 2011-2012 corpora published in WMT12 u ' \ u2019 ' -LSB- -RSB- against 3000 output sentences from one MT system at a time , again resulting in 6000 sentence instances per experiment While applying the same classification method

CASE: 24
Stag: 83 84 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To verify this intuition , we create parse trees using the Berkeley parser -LSB- -RSB- and extract the one-level CFG rules as features Again , we represent each sentence as a boolean vector , in which each entry represents the presence or absence of the CFG rule in the parse-tree of the sentence
	Cause: features Again , we represent each sentence as a boolean vector , in which each entry represents the presence or absence of the CFG rule in the parse-tree of the
	Effect: To verify this intuition , we create parse trees using the Berkeley parser -LSB- -RSB- and extract the one-level CFG rules

CASE: 25
Stag: 84 85 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Again , we represent each sentence as a boolean vector , in which each entry represents the presence or absence of the CFG rule in the parse-tree of the sentence Using these features alone , without the FW and POS tag based features presented above , we obtain an R 2 = 0.829 with a proportion of identically ordered pairs at 0.923 -LRB- 72 of 78 -RRB- , as shown in Figure 5
	Cause: a boolean vector , in which each entry represents the presence or absence of the CFG rule in the parse-tree of the sentence Using these features alone , without the FW and POS tag based features presented above , we obtain an R 2 = 0.829 with a proportion of identically ordered pairs at 0.923 -LRB- 72 of 78 -RRB- , as shown in Figure
	Effect: Again , we represent each sentence

CASE: 26
Stag: 85 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using these features alone , without the FW and POS tag based features presented above , we obtain an R 2 = 0.829 with a proportion of identically ordered pairs at 0.923 -LRB- 72 of 78 -RRB- , as shown in Figure 5
	Cause: Using these features alone , without the FW and POS tag based features presented above
	Effect: we obtain an R 2 = 0.829 with a proportion of identically ordered pairs at 0.923 -LRB- 72 of 78 -RRB- , as shown in Figure 5

CASE: 27
Stag: 89 90 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This suggests that our method might be used as an unsupervised quality estimation method when no reference sentences are available , such as for resource-poor source languages Further work might include applying our methods to other language pairs and domains , acquiring word-level quality estimation or integrating our method in a machine translation system
	Cause: an unsupervised quality estimation method when no reference sentences are available , such as for resource-poor source languages Further work might include applying our methods to other language pairs and domains , acquiring word-level quality estimation or integrating our method in a machine translation
	Effect: This suggests that our method might be used

CASE: 28
Stag: 91 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Furthermore , additional features and feature selection techniques can be applied , both for improving detection accuracy and for strengthening the correlation with human quality estimation
	Cause: improving detection accuracy
	Effect: Furthermore , additional features and feature selection techniques can be applied , both

