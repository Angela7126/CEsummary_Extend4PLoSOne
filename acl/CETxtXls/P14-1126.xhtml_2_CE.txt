************************************************************
P14-1126.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We present a novel approach for inducing unsupervised dependency parsers for languages that have no labeled training data , but have translated text in a resource-rich language
	Cause: inducing unsupervised dependency parsers for languages that have no labeled training data , but have translated text in a resource-rich language
	Effect: We present a novel approach

CASE: 1
Stag: 1 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We train probabilistic parsing models for resource-poor languages by transferring cross-lingual knowledge from resource-rich language with entropy regularization
	Cause: transferring cross-lingual knowledge from resource-rich language with entropy regularization
	Effect: We train probabilistic parsing models for resource-poor languages

CASE: 2
Stag: 2 3 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Our method can be used as a purely monolingual dependency parser , requiring no human translations for the test data , thus making it applicable to a wide range of resource-poor languages We perform experiments on three Data sets u ' \ u2014 ' Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks , across ten languages
	Cause: Our method can be used as a purely monolingual dependency parser , requiring no human translations for the test data
	Effect: making it applicable to a wide range of resource-poor languages We perform experiments on three Data sets u ' \ u2014 ' Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks , across ten languages

CASE: 3
Stag: 5 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: In recent years , dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation -LSB- 43 -RSB- , relation extraction -LSB- 37 -RSB- and machine translation -LSB- 21 , 51 -RSB-
	Cause: its usefulness in a wide range of applications such as synonym generation -LSB- 43 -RSB- , relation extraction -LSB- 37 -RSB- and machine translation -LSB- 21 , 51
	Effect: In recent years , dependency parsing has gained universal interest

CASE: 4
Stag: 7 8 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: However , the manually annotated treebanks that these parsers rely on are highly expensive to create , in particular when we want to build treebanks for resource-poor languages This led to a vast amount of research on unsupervised grammar induction -LSB- 9 , 22 , 47 , 12 , 48 , 4 , 29 , 49 -RSB- , which appears to be a natural solution to this problem , as unsupervised methods require only unannotated text for training parsers
	Cause: However , the manually annotated treebanks that these parsers rely on are highly expensive to create , in particular when we want to build treebanks for resource-poor languages
	Effect: a vast amount of research on unsupervised grammar induction -LSB- 9 , 22 , 47 , 12 , 48 , 4 , 29 , 49 -RSB- , which appears to be a natural solution to this problem , as unsupervised methods require only unannotated text for training parsers

CASE: 5
Stag: 12 
	Pattern: 2 [['for', 'the', 'sake', 'of'], [',']]---- [[], ['&V-ing/&NP@C@'], ['&R']]
	sentTXT: 1 1 For the sake of simplicity , we refer to the resource-poor language as the u ' \ u201c ' target language u ' \ u201d ' , and resource-rich language as the u ' \ u201c ' source language u ' \ u201d '
	Cause: simplicity
	Effect: we refer to the resource-poor language as the u ' \ u201c ' target language u ' \ u201d ' , and resource-rich language as the u ' \ u201c ' source language u ' \ u201d '

CASE: 6
Stag: 12 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: we refer to the resource-poor language as the u ' \ u201c ' target language u ' \ u201d ' , and resource-rich language as the u ' \ u201c ' source language u ' \ u201d '
	Cause: the u ' \ u201c ' target language u ' \ u201d
	Effect: we refer to the resource-poor language

CASE: 7
Stag: 13 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In addition , in this study we use English as the source resource-rich language , but our methodology can be applied to any resource-rich languages
	Cause: the source resource-rich language , but our methodology can be applied to any resource-rich
	Effect: In addition , in this study we use English

CASE: 8
Stag: 17 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Obviously , bilingual treebanks are much more difficult to acquire than the resources required in our scenario , since the labeled training data and the parallel text in our case are completely separated
	Cause: the labeled training data and the parallel text in our case are completely separated
	Effect: Obviously , bilingual treebanks are much more difficult to acquire than the resources required in our scenario

CASE: 9
Stag: 28 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this work , we propose a learning framework for transferring dependency grammars from a resource-rich language to resource-poor languages via parallel text
	Cause: transferring dependency grammars from a resource-rich language to resource-poor languages via parallel text
	Effect: In this work , we propose a learning framework

CASE: 10
Stag: 29 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We train probabilistic parsing models for resource-poor languages by maximizing a combination of likelihood on parallel data and confidence on unlabeled data
	Cause: maximizing a combination of likelihood on parallel data and confidence on unlabeled data
	Effect: We train probabilistic parsing models for resource-poor languages

CASE: 11
Stag: 30 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Our work is based on the learning framework used in Smith and Eisner -LSB- 44 -RSB- , which is originally designed for parser bootstrapping
	Cause: the learning framework used in Smith and Eisner -LSB- 44 -RSB-
	Effect: which is originally designed for parser bootstrapping

CASE: 12
Stag: 31 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: We extend this learning framework so that it can be used to transfer cross-lingual knowledge between different languages
	Cause: We extend this learning framework
	Effect: it can be used to transfer cross-lingual knowledge between different languages

CASE: 13
Stag: 32 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Throughout this paper , English is used as the source language and we evaluate our approach on ten target languages u ' \ u2014 ' Danish -LRB- da -RRB- , Dutch -LRB- nl -RRB- , French -LRB- fr -RRB- , German -LRB- de -RRB- , Greek -LRB- el -RRB- , Italian -LRB- it -RRB- , Korean -LRB- ko -RRB- , Portuguese -LRB- pt -RRB- , Spanish -LRB- es -RRB- and Swedish -LRB- sv
	Cause: the source language and we evaluate our approach on ten target languages u ' \ u2014 ' Danish -LRB- da -RRB- , Dutch -LRB- nl -RRB- , French -LRB- fr -RRB- , German -LRB- de -RRB- , Greek -LRB- el -RRB- , Italian -LRB- it -RRB- , Korean -LRB- ko -RRB- , Portuguese -LRB- pt -RRB- , Spanish -LRB- es -RRB- and Swedish -LRB-
	Effect: Throughout this paper , English is used

CASE: 14
Stag: 35 36 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For example , Figure 1 shows a dependency tree for the sentence , Economic news had little effect on financial markets , with the sentence u ' \ u2019 ' s root-symbol as its root The focus of this work is on building dependency parsers for target languages , assuming that an accurate English dependency parser and some parallel text between the two languages are available
	Cause: its root The focus of this work is on building dependency parsers for target languages ,
	Effect: For example , Figure 1 shows a dependency tree for the sentence , Economic news had little effect on financial markets , with the sentence u ' \ u2019 ' s root-symbol

CASE: 15
Stag: 38 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: Another advantage of the learning framework is that it combines both the likelihood on parallel data and confidence on unlabeled data , so that both parallel text and unlabeled data can be utilized in our approach
	Cause: Another advantage of the learning framework is that it combines both the likelihood on parallel data and confidence on unlabeled data ,
	Effect: both parallel text and unlabeled data can be utilized in our approach

CASE: 16
Stag: 42 43 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where F j are feature functions , u ' \ u039b ' = -LRB- u ' \ u039b ' 1 , u ' \ u039b ' 2 , u ' \ u2026 ' -RRB- are parameters of the model , and Z u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- is a normalization factor , which is commonly referred to as the partition function A common strategy to make this parsing model efficiently computable is to factor dependency trees into sets of edges
	Cause: the partition function A common strategy to make this parsing model efficiently computable is to factor dependency trees into sets of
	Effect: ' \ u039b ' = -LRB- u ' \ u039b ' 1 , u ' \ u039b ' 2 , u ' \ u2026 ' -RRB- are parameters of the model , and Z u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- is a normalization factor , which is commonly referred to

CASE: 17
Stag: 44 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: That is , dependency tree y is treated as a set of edges e and each feature function F j u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc9a ' , u ' \ ud835 ' u ' \ udc99 ' -RRB- is equal to the sum of all the features f j u ' \ u2062 ' -LRB- e , u ' \ ud835 ' u ' \ udc99 ' -RRB-
	Cause: a set of edges e and each feature function F j u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc9a ' , u ' \ ud835 ' u ' \ udc99 ' -RRB- is equal to the sum of all the features f j u ' \ u2062 ' -LRB- e , u ' \ ud835 ' u ' \ udc99 '
	Effect: That is , dependency tree y is treated

CASE: 18
Stag: 66 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: First , by transferring the weight function to the corresponding weight in the well-developed English parsing model , we can project syntactic information across language boundaries
	Cause: transferring the weight function to the corresponding weight in the well-developed English parsing model
	Effect: , we can project syntactic information across language boundaries

CASE: 19
Stag: 69 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By reducing unaligned edges to their delexicalized forms , we can still use those delexicalized features , such as part-of-speech tags , for those unaligned edges , and can address problem that automatically generated word alignments include errors
	Cause: reducing unaligned edges to their delexicalized forms
	Effect: , we can still use those delexicalized features , such as part-of-speech tags , for those unaligned edges , and can address problem that automatically generated word alignments include errors

CASE: 20
Stag: 72 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: Due to the normalizing factor Z ~ u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- , the transferring distribution is a valid one
	Cause: the normalizing factor Z ~ u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB-
	Effect: the transferring distribution is a valid one

CASE: 21
Stag: 72 73 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Due to the normalizing factor Z ~ u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- , the transferring distribution is a valid one We introduce a multiplier u ' \ u0393 ' as a trade-off between the two contributions -LRB- parallel and unsupervised -RRB- of the objective function K , and the final objective function K u ' \ u2032 ' has the following form
	Cause: a trade-off between the two contributions -LRB- parallel and unsupervised -RRB- of the objective function K , and the final objective function K u ' \ u2032 ' has the following form
	Effect: Due to the normalizing factor Z ~ u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- , the transferring distribution is a valid one We introduce a multiplier u ' \ u0393 '

CASE: 22
Stag: 75 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: One may regard u ' \ u0393 ' as a Lagrange multiplier that is used to constrain the parser u ' \ u2019 ' s uncertainty H to be low , as presented in several studies on entropy regularization -LSB- 5 , 17 , 20 -RSB-
	Cause: a Lagrange multiplier that is used to constrain the parser u ' \ u2019 ' s uncertainty H to be low , as presented in several studies on entropy regularization -LSB- 5 , 17 ,
	Effect: One may regard u ' \ u0393 '

CASE: 23
Stag: 80 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: According to equation -LRB- 9 -RRB- , p ~ -LRB- u ' \ ud835 ' u ' \ udc9a ' u ' \ ud835 ' u ' \ udc99 ' -RRB- can also be factored into the multiplication of the weight of each edge , so both K P and its gradient can be calculated by running the O u ' \ u2062 ' -LRB- n 3 -RRB- inside-outside algorithm -LSB- 2 , 41 -RSB- for projective parsing
	Cause: According to equation -LRB- 9 -RRB- , p ~ -LRB- u ' \ ud835 ' u ' \ udc9a ' u ' \ ud835 ' u ' \ udc99 ' -RRB- can also be factored into the multiplication of the weight of each edge
	Effect: both K P and its gradient can be calculated by running the O u ' \ u2062 ' -LRB- n 3 -RRB- inside-outside algorithm -LSB- 2 , 41 -RSB- for projective parsing

CASE: 24
Stag: 80 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to equation -LRB- 9 -RRB- , p ~ -LRB- u ' \ ud835 ' u ' \ udc9a ' u ' \ ud835 ' u ' \ udc99 ' -RRB- can also be factored into the multiplication of the weight of each edge
	Cause: equation -LRB- 9 -RRB-
	Effect: p ~ -LRB- u ' \ ud835 ' u ' \ udc9a ' u ' \ ud835 ' u ' \ udc99 ' -RRB- can also be factored into the multiplication of the weight of each edge

CASE: 25
Stag: 80 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: both K P and its gradient can be calculated by running the O u ' \ u2062 ' -LRB- n 3 -RRB- inside-outside algorithm -LSB- 2 , 41 -RSB- for projective parsing
	Cause: running the O u ' \ u2062 ' -LRB- n 3 -RRB- inside-outside algorithm -LSB- 2 , 41 -RSB- for projective parsing
	Effect: both K P and its gradient can be calculated

CASE: 26
Stag: 81 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: For non-projective parsing , the analogy to the inside algorithm is the O u ' \ u2062 ' -LRB- n 3 -RRB- matrix-tree algorithm based on Kirchhoff u ' \ u2019 ' s Matrix-Tree Theorem , which is dominated asymptotically by a matrix determinant -LSB- 25 , 46 -RSB-
	Cause: Kirchhoff u ' \ u2019 ' s Matrix-Tree Theorem
	Effect: which is dominated asymptotically by a matrix determinant -LSB- 25 , 46 -RSB-

CASE: 27
Stag: 82 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The gradient of a determinant may be computed by matrix inversion , so evaluating the gradient again has the same O u ' \ u2062 ' -LRB- n 3 -RRB- complexity as evaluating the function
	Cause: The gradient of a determinant may be computed by matrix inversion
	Effect: evaluating the gradient again has the same O u ' \ u2062 ' -LRB- n 3 -RRB- complexity as evaluating the

CASE: 28
Stag: 85 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Similar with the calculation of K P , K U can also be computed by running the inside-outside algorithm -LSB- 2 , 41 -RSB- for projective parsing
	Cause: Similar with the calculation of K P
	Effect: K U can also be computed by running the inside-outside algorithm -LSB- 2 , 41 -RSB- for projective parsing

CASE: 29
Stag: 85 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: K U can also be computed by running the inside-outside algorithm -LSB- 2 , 41 -RSB- for projective parsing
	Cause: running the inside-outside algorithm -LSB- 2 , 41 -RSB- for projective parsing
	Effect: K U can also be computed

CASE: 30
Stag: 92 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Prepare parallel text by running word alignment method to obtain word alignments , 3 3 The word alignment methods do not require additional resources besides parallel text and prepare the unlabeled data
	Cause: running word alignment method to obtain word alignments , 3 3 The word alignment methods do not require additional resources besides parallel text
	Effect: and prepare the unlabeled data

CASE: 31
Stag: 96 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We select target languages based on the availability of these resources
	Cause: the availability of these resources
	Effect: We select target languages

CASE: 32
Stag: 97 
	Pattern: 2 [['for', 'the'], ['reason']]---- [['&R', '(,)', '(&ADV)'], ['(&ADJ)'], ['(that)', '&C']]
	sentTXT: The monolingual treebanks in our experiments are from the Google Universal Dependency Treebanks -LSB- 31 -RSB- , for the reason that the treebanks of different languages in Google Universal Dependency Treebanks have consistent syntactic representations
	Cause: the treebanks of different languages in Google Universal Dependency Treebanks have consistent syntactic representations
	Effect: The monolingual treebanks in our experiments are from the Google Universal Dependency Treebanks -LSB- 31 -RSB-

CASE: 33
Stag: 102 
	Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
	sentTXT: However , previous studies -LSB- 34 , 31 -RSB- have demonstrated that a homogeneous representation is critical for multilingual language technologies that require consistent cross-lingual analysis for downstream components , and the heterogenous representations used in CoNLL shared-tasks treebanks weaken any conclusion that can be drawn
	Cause: consistent cross-lingual analysis for downstream components
	Effect: However , previous studies -LSB- 34 , 31 -RSB- have demonstrated that a homogeneous representation is critical for multilingual language technologies

CASE: 34
Stag: 105 106 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The three languages are Danish , Dutch and Greek So totally we have ten target languages
	Cause: The three languages are Danish , Dutch and Greek
	Effect: totally we have ten target languages

CASE: 35
Stag: 114 115 
	Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
	sentTXT: The set of POS tags needs to be consistent across languages and treebanks For this reason we use the universal POS tag set of Petrov et al
	Cause: The set of POS tags needs to be consistent across languages and treebanks
	Effect: we use the universal POS tag set of Petrov et al

CASE: 36
Stag: 119 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: POS tags are not available for parallel data in the Europarl and Kaist corpus , so we need to provide the POS tags for these data
	Cause: POS tags are not available for parallel data in the Europarl and Kaist corpus
	Effect: we need to provide the POS tags for these data

CASE: 37
Stag: 124 125 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For the purpose of evaluation of our approach and comparison with previous work , we need to exploit the gold POS tags to train the POS taggers As part-of-speech tags are also a form of syntactic analysis , this assumption weakens the applicability of our approach
	Cause: part-of-speech tags are also a form of syntactic analysis , this assumption weakens the applicability of our approach
	Effect: For the purpose of evaluation of our approach and comparison with previous work , we need to exploit the gold POS tags to train the POS taggers

CASE: 38
Stag: 128 129 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In this section , we will describe the details of our experiments and compare our results with previous methods As presented in Section 3.1 , we evaluate our parsing approach on both version 1.0 and version 2.0 of Google Univereal Treebanks for seven languages 6 6 Japanese and Indonesia are excluded as no practicable parallel data are available
	Cause: presented in Section 3.1 , we evaluate our parsing approach on both version 1.0 and version 2.0 of Google Univereal Treebanks for seven languages 6 6 Japanese and Indonesia are excluded as no practicable parallel data are available
	Effect: In this section , we will describe the details of our experiments and compare our results with previous methods

CASE: 39
Stag: 140 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: It is based on the transition-based dependency parsing paradigm -LSB- 40 -RSB-
	Cause: the transition-based dependency parsing paradigm -LSB- 40 -RSB-
	Effect: It

CASE: 40
Stag: 143 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In addition to their original results , we also report results by re-implementing the direct transfer parser based on the first-order projective dependency parsing model -LSB- 30 -RSB- -LRB- DTP u ' \ u2020 '
	Cause: the first-order projective dependency parsing model -LSB- 30 -RSB- -LRB- DTP u ' \ u2020
	Effect: In addition to their original results , we also report results by re-implementing the direct transfer parser

CASE: 41
Stag: 152 153 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: One may regard this system as an oracle of transfer parsing Parsing accuracy is measured with unlabeled attachment score -LRB- UAS the percentage of words with the correct head
	Cause: an oracle of transfer parsing Parsing accuracy is measured with unlabeled attachment score -LRB- UAS the percentage of words with the correct
	Effect: One may regard this system

CASE: 42
Stag: 155 156 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Our approaches significantly outperform all the baseline systems across all the seven target languages For the results on Google Universal Treebanks version 1.0 , the improvement on average over the projected transfer paper -LRB- PTP u ' \ u2020 ' -RRB- is 3.96 % and up to 6.22 % for Korean and 4.80 % for German
	Cause: approaches significantly outperform all the baseline systems across all the seven target languages For
	Effect: 3.96 % and up to 6.22 % for Korean and 4.80 % for German

CASE: 43
Stag: 158 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By adding entropy regularization from unlabeled data , our full model achieves average improvement of 0.29 % over the u ' \ u201c ' - U u ' \ u201d ' setting
	Cause: adding entropy regularization from unlabeled data
	Effect: , our full model achieves average improvement of 0.29 % over the u ' \ u201c ' - U u ' \ u201d ' setting

CASE: 44
Stag: 175 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Table 6 gives the results comparing the model without unlabeled data -LRB- - U -RRB- presented in this work to those five baseline systems and the oracle -LRB- OR
	Cause: Table 6 gives
	Effect: work to those five baseline systems and the oracle -LRB- OR

CASE: 45
Stag: 180 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Table 7 shows the results of our system and the results of baseline systems u ' \ u201c ' USR u ' \ u2020 ' u ' \ u201d ' is the weakly supervised system of Naseem et al
	Cause: Table 7 shows the results of our system and
	Effect: the weakly supervised system of Naseem et al

CASE: 46
Stag: 190 191 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: It should be noted that the u ' \ u201c ' NMG u ' \ u201d ' system utilizes more than one helper languages So it is not directly comparable to our work
	Cause: It should be noted that the u ' \ u201c ' NMG u ' \ u201d ' system utilizes more than one helper languages
	Effect: it is not directly comparable to our work

CASE: 47
Stag: 198 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: For example , if we want to make our model capable of utilizing more contextual information , we can extend our transferring weight to higher-order parts
	Cause: we want to make our model capable of utilizing more contextual information
	Effect: we can extend our transferring weight to higher-order parts

CASE: 48
Stag: 204 205 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: By presenting a model training framework , our approach can utilize parallel text to estimate transferring distribution with the help of a well-developed resource-rich language dependency parser , and use unlabeled data as entropy regularization The experimental results on three data sets across ten target languages show that our approach achieves significant improvement over previous studies
	Cause: entropy regularization The experimental results on three data sets across ten target languages show that our approach achieves significant improvement over previous
	Effect: By presenting a model training framework , our approach can utilize parallel text to estimate transferring distribution with the help of a well-developed resource-rich language dependency parser , and use unlabeled data

