************************************************************
P14-2080.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 4 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: This approach is advantageous if large amounts of in-domain sentence-parallel data are available to train SMT systems , but relevance rankings to train retrieval models are not
	Cause: large amounts of in-domain sentence-parallel data are available to train SMT systems
	Effect: but relevance rankings to train retrieval models are not

CASE: 1
Stag: 7 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: For example , in patent prior art search , patents granted at any patent office worldwide are considered relevant if they constitute prior art with respect to the invention claimed in the query patent
	Cause: they constitute prior art with respect to the invention claimed in the query patent
	Effect: For example , in patent prior art search , patents granted at any patent office worldwide are considered relevant

CASE: 2
Stag: 8 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since patent applicants and lawyers are required to list relevant prior work explicitly in the patent application , patent citations can be used to automatically extract large amounts of relevance judgments across languages -LSB- 12 -RSB-
	Cause: patent applicants and lawyers are required to list relevant prior work explicitly in the patent application
	Effect: patent citations can be used to automatically extract large amounts of relevance judgments across languages -LSB- 12 -RSB-

CASE: 3
Stag: 10 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since authors are encouraged to avoid orphan articles and to cite their sources , Wikipedia has a rich linking structure between related articles , which can be exploited to create relevance links between articles across languages -LSB- 2 -RSB-
	Cause: authors are encouraged to avoid orphan articles and to cite their sources
	Effect: Wikipedia has a rich linking structure between related articles , which can be exploited to create relevance links between articles across languages -LSB- 2 -RSB-

CASE: 4
Stag: 13 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2013 -RRB- advocate the use of dense features encoding domain knowledge on inventors , assignees , location and date , together with dense similarity scores based on bag-of-word representations of patents
	Cause: bag-of-word representations of patents
	Effect: 2013 -RRB- advocate the use of dense features encoding domain knowledge on inventors , assignees , location and date , together with dense similarity scores

CASE: 5
Stag: 21 22 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Furthermore , we show that our approach can be seen as supervised model combination that allows to combine SMT-based and ranking-based approaches for further substantial improvements We conjecture that the gains are due to orthogonal information contributed by domain-knowledge , ranking-based word associations , and translation-based information
	Cause: supervised model combination that allows to combine SMT-based and ranking-based approaches for further substantial improvements We conjecture that the gains are due to orthogonal information contributed by domain-knowledge , ranking-based word associations , and translation-based
	Effect: Furthermore , we show that our approach can be seen

CASE: 6
Stag: 28 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: The advantage of this technique is an implicit query expansion effect due to the use of probability distributions over term translations -LSB- 27 -RSB-
	Cause: the use of probability distributions over term translations -LSB- 27 -RSB-
	Effect: The advantage of this technique is an implicit query expansion effect

CASE: 7
Stag: 30 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: 2012 -RRB- brought SMT back into this paradigm by projecting terms from n - best translations from synchronous context-free grammars
	Cause: projecting terms from n
	Effect: - best translations from synchronous context-free grammars

CASE: 8
Stag: 41 42 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We will refer to DT and PSQ as SMT-based models that translate a query , and then perform monolingual retrieval using BM25 Translation is agnostic of the retrieval task
	Cause: SMT-based models that translate a query , and then perform monolingual retrieval using BM25 Translation is agnostic of
	Effect: We will refer to DT and PSQ

CASE: 9
Stag: 48 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We present two methods for optimizing W in the following
	Cause: optimizing W in the following
	Effect: We present two methods

CASE: 10
Stag: 61 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Memory usage was reduced using the same hashing technique as for boosting
	Cause: boosting
	Effect: Memory usage was reduced using the same hashing technique as

CASE: 11
Stag: 62 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Domain knowledge features for patents were inspired by Guo and Gomes -LRB- 2009 a feature fires if two patents share similar aspects , e.g. , a common inventor
	Cause: two patents share similar aspects ,
	Effect: Domain knowledge features for patents were inspired by Guo and Gomes -LRB- 2009 a feature fires

CASE: 12
Stag: 62 63 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Domain knowledge features for patents were inspired by Guo and Gomes -LRB- 2009 a feature fires if two patents share similar aspects , e.g. , a common inventor As we do not have access to address data , we omit geolocation features and instead add features that evaluate similarity w.r.t patent classes extracted from IPC codes
	Cause: we do not have access to address data , we omit geolocation features and instead add features that evaluate similarity w.r.t patent classes
	Effect: knowledge features for patents were inspired by Guo and Gomes -LRB- 2009 a feature fires if two patents share similar aspects , e.g. , a common inventor

CASE: 13
Stag: 69 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The intersection between target set T n and the source category set S reflects the category level similarity between query and document , which we calculate as a mutual containment score s n = 1 2 u ' \ u2062 '
	Cause: a mutual containment score s n = 1 2 u ' \ u2062 '
	Effect: The intersection between target set T n and the source category set S reflects the category level similarity between query and document , which we calculate

CASE: 14
Stag: 77 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Optimization for these additional models including domain knowledge features was done by overloading the vector representation of queries u ' \ ud835 ' u ' \ udc2a ' and documents u ' \ ud835 ' u ' \ udc1d ' in the VW linear learner
	Cause: overloading the vector representation of queries u ' \ ud835 ' u ' \ udc2a ' and documents u ' \ ud835 ' u ' \ udc1d ' in the VW linear learner
	Effect: Optimization for these additional models including domain knowledge features was done

CASE: 15
Stag: 85 86 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In addition to dense domain-knowledge features , we incorporate arbitrary ranking models as dense features whose value is the score of the ranking model Training data was sampled from the dev set and processed with VW
	Cause: dense features whose value is the score of the ranking model Training data was sampled from the dev set and processed with
	Effect: In addition to dense domain-knowledge features , we incorporate arbitrary ranking models

CASE: 16
Stag: 89 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: EN patents are regarded as relevant with level -LRB- 3 -RRB- to a JP query patent , if they are in a family relationship -LRB- e.g. , , same invention -RRB- , cited by the patent examiner -LRB- 2 -RRB- , or cited by the applicant -LRB- 1
	Cause: they are in a family relationship -LRB- e.g. , , same invention -RRB- , cited by the patent examiner -LRB- 2 -RRB- , or cited by the applicant -LRB- 1
	Effect: EN patents are regarded as relevant with level -LRB- 3 -RRB- to a JP query patent ,

CASE: 17
Stag: 96 97 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The information need may be paraphrased as a high-level definition of the topic Since typically the first sentence of any Wikipedia article is such a well-formed definition , this allows us to extract a large set of one sentence queries from Wikipedia articles
	Cause: a high-level definition of the topic Since typically the first sentence of any Wikipedia article is such a well-formed definition , this allows us to extract a large set of one sentence queries from Wikipedia
	Effect: The information need may be paraphrased

CASE: 18
Stag: 97 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since typically the first sentence of any Wikipedia article is such a well-formed definition , this allows us to extract a large set of one sentence queries from Wikipedia articles
	Cause: typically the first sentence of any Wikipedia article is such a well-formed definition
	Effect: this allows us to extract a large set of one sentence queries from Wikipedia articles

CASE: 19
Stag: 105 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since Wikipedia articles vary greatly in length , we restricted EN documents to the first 200 words after extracting the link graph to reduce the number of features for BM and VW models
	Cause: Wikipedia articles vary greatly in length
	Effect: we restricted EN documents to the first 200 words after extracting the link graph to reduce the number of features for BM and VW models

CASE: 20
Stag: 111 112 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: To reduce the EN vocabulary to a comparable size , we applied similar preprocessing and CFH with F = 30k and k = 5 Since for Wikipedia data , the DE and EN vocabularies were both large -LRB- 6.7 M and 6M -RRB- , we used the same filtering and preprocessing as for the patent data before applying CFH with F = 40k and k = 5 on both sides
	Cause: for Wikipedia data , the DE and EN vocabularies were both large -LRB- 6.7 M and 6M -RRB- , we used the same filtering and preprocessing as for the patent data before applying CFH with F = 40k and k = 5 on both sides
	Effect: To reduce the EN vocabulary to a comparable size , we applied similar preprocessing and CFH with F = 30k and k = 5

CASE: 21
Stag: 138 139 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: LinLearn denotes model combination by overloading the vector representation of queries u ' \ ud835 ' u ' \ udc2a ' and documents u ' \ ud835 ' u ' \ udc1d ' in the VW linear learner by incorporating arbitrary ranking models as dense features In difference to grid search for Borda , optimal weights for the linear combination of incorporated ranking models can be learned automatically
	Cause: dense features In difference to grid search for Borda , optimal weights for the linear combination of incorporated ranking models can be learned
	Effect: LinLearn denotes model combination by overloading the vector representation of queries u ' \ ud835 ' u ' \ udc2a ' and documents u ' \ ud835 ' u ' \ udc1d ' in the VW linear learner by incorporating arbitrary ranking models

CASE: 22
Stag: 141 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: We do not report combination results including the sparse BM model since they were consistently lower than the ones with the sparse VW model
	Cause: they were consistently lower than the ones with the sparse VW model
	Effect: We do not report combination results including the sparse BM model

CASE: 23
Stag: 153 154 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: As can be seen from inspecting the two blocks of results , one for patents , one for Wikipedia , we find the same system rankings on both datasets In both cases , as standalone systems , DT and PSQ are very close and far better than any ranking approach , irrespective of the objective function or the choice of sparse or dense features
	Cause: standalone systems , DT and PSQ are very close and far better than any ranking approach , irrespective of the objective function or the choice of sparse or dense features
	Effect: can be seen from inspecting the two blocks of results , one for patents , one for Wikipedia , we find the same system rankings on both datasets In both cases

CASE: 24
Stag: 156 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The best result is achieved by combining DT and PSQ with DK and VW
	Cause: combining DT and PSQ with DK and VW
	Effect: The best result is achieved

CASE: 25
Stag: 156 157 
	Pattern: 5 [['due', 'to']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: The best result is achieved by combining DT and PSQ with DK and VW This is due to the already high scores of the combined models , but also to the combination of yet other types of orthogonal information
	Cause: the already high scores of the combined models , but
	Effect: The best result is achieved by combining DT and PSQ with DK and VW

CASE: 26
Stag: 158 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: Borda voting gives the best result under MAP which is probably due to the adjustment of the interpolation parameter for MAP on the development set
	Cause: the adjustment of the interpolation parameter for MAP on the development set
	Effect: Borda voting gives the best result under MAP which is probably

CASE: 27
Stag: 159 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: Under NDCG and PRES , LinLearn achieves the best results , showing the advantage of automatically learning combination weights that leads to stable results across various metrics
	Cause: Under NDCG and PRES , LinLearn achieves the best results , showing the advantage of automatically learning combination weights
	Effect: stable results across various metrics

CASE: 28
Stag: 163 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: We conjecture that if these types of information sources are available , a supervised ranking approach will yield superior results in other retrieval scenarios as well
	Cause: these types of information sources are available
	Effect: a supervised ranking approach will yield superior results in other retrieval scenarios as well

