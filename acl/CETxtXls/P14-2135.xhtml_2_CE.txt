************************************************************
P14-2135.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 13 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since perceptual data sources typically contain information about both abstract and concrete concepts , such information is included for both concept types
	Cause: perceptual data sources typically contain information about both abstract and concrete concepts
	Effect: such information is included for both concept types

CASE: 1
Stag: 14 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The potential effect of this design decision on performance is significant because the vast majority of meaning-bearing words in everyday language correspond to abstract concepts
	Cause: the vast majority of meaning-bearing words in everyday language correspond to abstract concepts
	Effect: The potential effect of this design decision on performance is significant

CASE: 2
Stag: 16 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In light of these considerations , we propose a novel algorithm for approximating conceptual concreteness
	Cause: approximating conceptual concreteness
	Effect: In light of these considerations , we propose a novel algorithm

CASE: 3
Stag: 17 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: Multi-modal models in which perceptual input is filtered according to our algorithm learn higher-quality semantic representations than previous approaches , resulting in a significant performance improvement of up to 17 % in capturing the semantic similarity of concepts
	Cause: our algorithm
	Effect: resulting in a significant performance improvement of up to 17 % in capturing the semantic similarity of concepts

CASE: 4
Stag: 22 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: They are also more scalable since high-quality tagged images are freely available in several web-scale image datasets
	Cause: high-quality tagged images are freely available in several web-scale image datasets
	Effect: They are also more scalable

CASE: 5
Stag: 23 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use Google Images as our image source , and extract the first n image results for each concept word
	Cause: our image source , and extract the first n image results for
	Effect: We use Google Images

CASE: 6
Stag: 29 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By exploiting this connection , the method approximates the concreteness of concepts , and provides a basis to filter the corresponding perceptual information
	Cause: exploiting this connection
	Effect: , the method approximates the concreteness of concepts , and provides a basis to filter the corresponding perceptual information

CASE: 7
Stag: 30 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Formally , we propose a measure , image dispersion d of a concept word w , defined as the average pairwise cosine distance between all the image representations -LCB- w 1 u ' \ u2192 ' u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' w n u ' \ u2192 ' -RCB- in the set of images for that concept
	Cause: the average pairwise cosine distance between all the image representations -LCB- w 1 u ' \ u2192 ' u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' w n u ' \ u2192 '
	Effect: Formally , we propose a measure , image dispersion d of a concept word w , defined

CASE: 8
Stag: 31 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We use an average pairwise distance-based metric because this emphasizes the total variation more than e.g. , the mean distance from the centroid
	Cause: this emphasizes the total variation more than e.g. , the mean distance from the centroid
	Effect: We use an average pairwise distance-based metric

CASE: 9
Stag: 35 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Previous NLP-related work uses SIFT -LSB- 11 , 6 -RSB- or SURF -LSB- 22 -RSB- descriptors for identifying points of interest in an image , quantified by 128-dimensional local descriptors
	Cause: identifying points of interest in an image , quantified by 128-dimensional local descriptors
	Effect: Previous NLP-related work uses SIFT -LSB- 11 , 6 -RSB- or SURF -LSB- 22 -RSB- descriptors

CASE: 10
Stag: 36 37 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We apply Pyramid Histogram Of visual Words -LRB- PHOW -RRB- descriptors , which are particularly well-suited for object categorization , a key component of image similarity and thus dispersion -LSB- 5 -RSB- PHOW is roughly equivalent to running SIFT on a dense grid of locations at a fixed scale and orientation and at multiple scales -LRB- see Fig 2 -RRB- , but is both more efficient and more accurate than regular -LRB- dense -RRB- SIFT approaches -LSB- 5 -RSB-
	Cause: We apply Pyramid Histogram Of visual Words -LRB- PHOW -RRB- descriptors , which are particularly well-suited for object categorization , a key component of image similarity
	Effect: dispersion -LSB- 5 -RSB- PHOW is roughly equivalent to running SIFT on a dense grid of locations at a fixed scale and orientation and at multiple scales -LRB- see Fig 2 -RRB- , but is both more efficient and more accurate than regular -LRB- dense -RRB- SIFT approaches -LSB- 5

CASE: 11
Stag: 42 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: This model learns high quality lexical semantic representations based on the distributional properties of words in text , and has been shown to outperform simple distributional models on applications such as semantic composition and analogical mapping -LSB- 19 -RSB-
	Cause: the distributional properties of words in text
	Effect: and has been shown to outperform simple distributional models on applications such as semantic composition and analogical mapping -LSB- 19 -RSB-

CASE: 12
Stag: 43 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We evaluate models by measuring the Spearman correlation of model output with two well-known gold-standards reflecting semantic proximity u ' \ u2013 ' a standard measure for evaluating the quality of representations -LRB- see e.g. , Agirre et al
	Cause: evaluating the quality of representations -LRB- see e.g. , Agirre et al
	Effect: We evaluate models by measuring the Spearman correlation of model output with two well-known gold-standards reflecting semantic proximity u ' \ u2013 ' a standard measure

CASE: 13
Stag: 46 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: WordSim has been used as a benchmark for distributional semantic models in numerous studies -LRB- see e.g. , -LSB- 15 , 6 -RSB-
	Cause: a benchmark for distributional semantic models in numerous studies -LRB- see
	Effect: WordSim has been used

CASE: 14
Stag: 46 47 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: WordSim has been used as a benchmark for distributional semantic models in numerous studies -LRB- see e.g. , -LSB- 15 , 6 -RSB- As a complementary gold-standard , we use the University of South Florida Norms -LRB- USF -RRB- -LSB- 20 -RSB-
	Cause: a complementary gold-standard , we use the University of South Florida Norms -LRB- USF -RRB- -LSB- 20 -RSB-
	Effect: WordSim has been used as a benchmark for distributional semantic models in numerous studies -LRB- see e.g. , -LSB- 15 , 6 -RSB-

CASE: 15
Stag: 50 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The USF evaluation set is particularly appropriate in the present context because concepts in the dataset are also rated for conceptual concreteness by at least 10 human annotators
	Cause: concepts in the dataset are also rated for conceptual concreteness by at least 10 human annotators
	Effect: The USF evaluation set is particularly appropriate in the present context

CASE: 16
Stag: 57 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: We apply image dispersion-based filtering as follows if both concepts in an evaluation pair have an image dispersion below a given threshold , both the linguistic and the visual representations are included
	Cause: both concepts in an evaluation pair have an image dispersion below a given threshold
	Effect: both the linguistic and the visual representations are included

CASE: 17
Stag: 59 60 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For both datasets , we set the threshold as the median image dispersion , although performance could in principle be improved by adjusting this parameter We compare dispersion filtered representations with linguistic , perceptual and standard multi-modal representations -LRB- concatenated linguistic and perceptual representations
	Cause: the median image dispersion , although performance could in principle be improved by adjusting this parameter We compare dispersion filtered representations with linguistic , perceptual and standard multi-modal representations -LRB- concatenated
	Effect: For both datasets , we set the threshold

CASE: 18
Stag: 61 62 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Similarity between concept pairs is calculated using cosine similarity As Figure 3 shows , dispersion-filtered multi-modal representations significantly outperform standard multi-modal representations on both evaluation datasets
	Cause: Figure 3 shows , dispersion-filtered multi-modal representations significantly outperform standard multi-modal representations on
	Effect: Similarity between concept pairs is calculated using cosine similarity

CASE: 19
Stag: 64 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on the correlation comparison method of Steiger -LRB- 1980 -RRB- , both represent significant improvements -LRB- WordSim353 , t = 2.42 , p 0.05 ; USF , t = 1.86 , p 0.1
	Cause: the correlation comparison method of Steiger -LRB- 1980 -RRB-
	Effect: both represent significant improvements -LRB- WordSim353 , t = 2.42 , p 0.05 ; USF , t = 1.86 , p 0.1

CASE: 20
Stag: 67 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The filtering approach described thus far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts
	Cause: The filtering approach described
	Effect: far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts

CASE: 21
Stag: 67 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts
	Cause: image dispersion provides a means to distinguish concrete concepts from more abstract concepts
	Effect: far improves multi-modal representations

CASE: 22
Stag: 68 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since research has demonstrated the applicability of concreteness to a range of other NLP tasks -LSB- 28 , 16 -RSB- , it is important to examine the connection between image dispersion and concreteness in more detail
	Cause: research has demonstrated the applicability of concreteness to a range of other NLP tasks -LSB- 28
	Effect: 16 -RSB- , it is important to examine the connection between image dispersion and concreteness in more detail

CASE: 23
Stag: 68 69 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Since research has demonstrated the applicability of concreteness to a range of other NLP tasks -LSB- 28 , 16 -RSB- , it is important to examine the connection between image dispersion and concreteness in more detail To evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u ' \ u222a ' C introduced in Section 2
	Cause: a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u ' \ u222a ' C introduced in Section
	Effect: Since research has demonstrated the applicability of concreteness to a range of other NLP tasks -LSB- 28 , 16 -RSB- , it is important to examine the connection between image dispersion and concreteness in more detail To evaluate the effectiveness of image dispersion

CASE: 24
Stag: 73 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to the Dual Coding Theory , however , concrete concepts are precisely those with a salient perceptual representation
	Cause: the Dual Coding Theory
	Effect: however , concrete concepts are precisely those with a salient perceptual representation

CASE: 25
Stag: 73 74 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: According to the Dual Coding Theory , however , concrete concepts are precisely those with a salient perceptual representation As illustrated in Figure 4 , our binary classification conforms to this characterization
	Cause: illustrated in Figure 4 , our binary classification conforms to
	Effect: According to the Dual Coding Theory , however , concrete concepts are precisely those with a salient perceptual representation

CASE: 26
Stag: 75 76 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The importance of the visual modality is significantly greater when evaluating on pairs for which both concepts are classified as concrete than on pairs of two abstract concepts Image dispersion is also an effective predictor of concreteness on samples for which the abstract/concrete distinction is less clear
	Cause: concrete than on pairs of two abstract concepts Image dispersion is also an effective predictor of concreteness on samples for which the abstract/concrete distinction is less
	Effect: The importance of the visual modality is significantly greater when evaluating on pairs for which both concepts are classified

CASE: 27
Stag: 78 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: On this more diverse sample , which reflects the range of concepts typically found in linguistic corpora , image dispersion is a particularly useful diagnostic for identifying the very abstract or very concrete concepts
	Cause: identifying the very abstract or very concrete concepts
	Effect: On this more diverse sample , which reflects the range of concepts typically found in linguistic corpora , image dispersion is a particularly useful diagnostic

CASE: 28
Stag: 78 79 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: On this more diverse sample , which reflects the range of concepts typically found in linguistic corpora , image dispersion is a particularly useful diagnostic for identifying the very abstract or very concrete concepts As Table 1 illustrates , the concepts with the lowest dispersion in this sample are , without exception , highly concrete , and the concepts of highest dispersion are clearly very abstract
	Cause: Table 1 illustrates , the concepts with the lowest dispersion in this sample are , without exception , highly concrete , and the concepts of highest dispersion
	Effect: On this more diverse sample , which reflects the range of concepts typically found in linguistic corpora , image dispersion is a particularly useful diagnostic for identifying the very abstract or very concrete concepts

CASE: 29
Stag: 81 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Kwong -LRB- 2008 -RRB- proposes a method based on the presence of hard-coded phrasal features in dictionary entries corresponding to each concept
	Cause: Kwong
	Effect: -LRB- 2008 -RRB- proposes a method

CASE: 30
Stag: 83 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2011 -RRB- present an approach based on the position of word senses corresponding to each concept in the WordNet ontology -LSB- 10 -RSB-
	Cause: the position of word senses corresponding to each concept in the WordNet ontology -LSB- 10 -RSB-
	Effect: 2011 -RRB- present an approach

CASE: 31
Stag: 86 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The Turney et al algorithm quantifies the concreteness of concepts that lack such a rating based on their proximity to rated concepts in a semantic vector space
	Cause: their proximity to rated concepts in a semantic vector space
	Effect: The Turney et al algorithm quantifies the concreteness of concepts that lack such a rating

CASE: 32
Stag: 88 89 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: It is therefore more scalable , and instantly applicable to a wide range of languages Finally , we explored whether image dispersion can be applied to specific NLP tasks as an effective proxy for concreteness
	Cause: It is
	Effect: more scalable , and instantly applicable to a wide range of languages Finally , we explored whether image dispersion can be applied to specific NLP tasks as an effective proxy for

CASE: 33
Stag: 91 92 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 2011 -RRB- showed that concreteness is applicable to the classification of adjective-noun modification as either literal or non-literal By applying a logistic regression with noun concreteness as the predictor variable , Turney et al achieved a classification accuracy of 79 % on this task
	Cause: either literal or non-literal By applying a logistic regression with noun concreteness as the predictor variable , Turney et al achieved a classification accuracy of 79 % on this
	Effect: -RRB- showed that concreteness is applicable to the classification of adjective-noun modification

CASE: 34
Stag: 91 92 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 2011 -RRB- showed that concreteness is applicable to the classification of adjective-noun modification as either literal or non-literal By applying a logistic regression with noun concreteness as the predictor variable , Turney et al achieved a classification accuracy of 79 % on this task
	Cause: the predictor variable , Turney et al achieved a classification accuracy of 79 % on this task
	Effect: -RRB- showed that concreteness is applicable to the classification of adjective-noun modification as either literal or non-literal By applying a logistic regression with noun concreteness

CASE: 35
Stag: 98 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We presented a novel method , image dispersion-based filtering , that improves multi-modal representations by approximating conceptual concreteness from images and filtering model input
	Cause: approximating conceptual concreteness from images and filtering model input
	Effect: We presented a novel method , image dispersion-based filtering , that improves multi-modal representations

CASE: 36
Stag: 102 103 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To our knowledge , our algorithm constitutes the first unsupervised method for quantifying conceptual concreteness as applied to NLP , although it does , of course , rely on the Google Images retrieval algorithm Moreover , we presented a method to classify adjective-noun pairs according to modification type that exploits the link between image dispersion and concreteness
	Cause: applied to NLP , although it does , of course , rely on the Google Images retrieval algorithm Moreover , we presented a method to classify adjective-noun pairs according to modification type that exploits the link between image dispersion and
	Effect: To our knowledge , our algorithm constitutes the first unsupervised method for quantifying conceptual concreteness

CASE: 37
Stag: 103 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: Moreover , we presented a method to classify adjective-noun pairs according to modification type that exploits the link between image dispersion and concreteness
	Cause: modification type that exploits the link between image dispersion and concreteness
	Effect: Moreover , we presented a method to classify adjective-noun pairs

