************************************************************
P14-1029.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 6 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In this paper, we refer to a negation word as the negator (e.g.,, isn u'\u2019' t ), a text span being modified by and composed with a negator as the argument (e.g.,, very good ), and entire phrase (e.g.,, isn u'\u2019' t very good ) as the negated phrase
	Cause: [(0, 11), (0, 62)]
	Effect: [(0, 0), (0, 9)]

CASE: 1
Stag: 8 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This corpus provides us with the data to further understand the quantitative behavior of negators, as the effect of negators can now be studied with arguments of rich syntactic and semantic variety
	Cause: [(0, 17), (0, 32)]
	Effect: [(0, 0), (0, 14)]

CASE: 2
Stag: 18 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We regard the negators u'\u2019' behavior as an underlying function embedded in annotated data; we aim to model this function from different aspects
	Cause: [(0, 11), (0, 16)]
	Effect: [(0, 0), (0, 9)]

CASE: 3
Stag: 19 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By examining sentiment compositions of negators and arguments, we model the quantitative behavior of negators in changing sentiment
	Cause: [(0, 1), (0, 7)]
	Effect: [(0, 8), (0, 18)]

CASE: 4
Stag: 29 30 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Early work on automatic sentiment analysis includes the widely cited work of [] , among others Since then, there has been an explosion of research addressing various aspects of the problem, including detecting subjectivity, rating and classifying sentiment, labeling sentiment-related semantic roles (e.g.,, target of sentiment), and visualizing sentiment (see surveys by and
	Cause: [(1, 1), (1, 46)]
	Effect: [(0, 0), (0, 16)]

CASE: 5
Stag: 34 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For example, not alive has the same meaning as dead , however, not tall does not always mean short
	Cause: [(0, 10), (0, 20)]
	Effect: [(0, 0), (0, 8)]

CASE: 6
Stag: 41 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: For example, in the work of [] , a feature not_good will be created if the word good is encountered within a predefined range after a negator
	Cause: [(0, 17), (0, 28)]
	Effect: [(0, 0), (0, 15)]

CASE: 7
Stag: 44 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The more recent work of [] proposed models based on recursive neural networks that do not rely on any heuristic rules
	Cause: [(0, 11), (0, 21)]
	Effect: [(0, 6), (0, 8)]

CASE: 8
Stag: 45 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Such models work in a bottom-up fashion over the parse tree of a sentence to infer the sentiment label of the sentence as a composition of the sentiment expressed by its constituting parts
	Cause: [(0, 23), (0, 31)]
	Effect: [(0, 0), (0, 21)]

CASE: 9
Stag: 51 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In this paper, we call a model based on such assumptions a non-lexicalized model
	Cause: [(0, 10), (0, 14)]
	Effect: [(0, 0), (0, 7)]

CASE: 10
Stag: 53 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: That is, the model parameters are only based on the sentiment value of the arguments
	Cause: [(0, 10), (0, 15)]
	Effect: [(0, 0), (0, 6)]

CASE: 11
Stag: 56 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: where s i g n is the standard sign function which determines if the constant C should be added to or deducted from s u'\u2062' ( w n the constant is added to a negative s u'\u2062' ( w u'\u2192' ) but deducted from a positive one
	Cause: [(0, 13), (0, 58)]
	Effect: [(0, 1), (0, 11)]

CASE: 12
Stag: 56 57 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where s i g n is the standard sign function which determines if the constant C should be added to or deducted from s u'\u2062' ( w n the constant is added to a negative s u'\u2062' ( w u'\u2192' ) but deducted from a positive one Polarity-based shifting As will be shown in our experiments, negators can have different shifting power when modifying a positive or a negative phrase
	Cause: [(1, 3), (1, 23)]
	Effect: [(0, 2), (1, 1)]

CASE: 13
Stag: 57 58 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Polarity-based shifting As will be shown in our experiments, negators can have different shifting power when modifying a positive or a negative phrase Thus, we explore the use of two different constants for these two situations, i.e.,, f u'\u2062' ( s u'\u2062' ( w u'\u2192' ) ) = s u'\u2062' ( w u'\u2192' ) - s u'\u2062' i u'\u2062' g u'\u2062' n u'\u2062' ( s u'\u2062' ( w u'\u2192' ) ) * C u'\u2062' ( s u'\u2062' i u'\u2062' g u'\u2062' n u'\u2062' ( s u'\u2062' ( w u'\u2192' ) )
	Cause: [(0, 0), (0, 23)]
	Effect: [(1, 1), (1, 143)]

CASE: 14
Stag: 71 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: This shifting model is based on negators and the polarity of the text they modify constants can be different for each negator-polarity pair
	Cause: [(0, 6), (0, 22)]
	Effect: [(0, 0), (0, 2)]

CASE: 15
Stag: 87 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: A recursive neural tensor network (RNTN) is a specific form of feed-forward neural network based on syntactic (phrasal-structure) parse tree to conduct compositional sentiment analysis
	Cause: [(0, 18), (0, 28)]
	Effect: [(0, 0), (0, 15)]

CASE: 16
Stag: 102 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To this end, we make use of the sentiment class information of p 1 , noted as p 1 s u'\u2062' e u'\u2062' n
	Cause: [(0, 18), (0, 28)]
	Effect: [(0, 0), (0, 16)]

CASE: 17
Stag: 102 103 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: To this end, we make use of the sentiment class information of p 1 , noted as p 1 s u'\u2062' e u'\u2062' n As a result, the vector of p 2 is calculated as follows
	Cause: [(0, 0), (0, 32)]
	Effect: [(1, 4), (1, 12)]

CASE: 18
Stag: 103 104 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: As a result, the vector of p 2 is calculated as follows As shown in Equation 6 , for the node vector p 1 u'\u2208' u'\u211d' d × 1 , we employ a matrix, namely W s u'\u2062' e u'\u2062' n u'\u2208' u'\u211d' d × ( d + m ) and a tensor, V s u'\u2062' e u'\u2062' n u'\u2208' u'\u211d' ( d + m ) × ( d + m ) × d , aiming at explicitly capturing the interplays between the sentiment class of p 1 , denoted as p 1 s u'\u2062' e u'\u2062' n ( u'\u2208' u'\u211d' m × 1 ), and the negator a
	Cause: [(1, 1), (1, 146)]
	Effect: [(0, 0), (0, 12)]

CASE: 19
Stag: 106 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Following the idea of , we regard the sentiment of p 1 as a prior sentiment as it has not been affected by the specific context (negators), so we denote our method as prior sentiment-enriched tensor network (PSTN
	Cause: [(0, 0), (0, 28)]
	Effect: [(0, 31), (0, 41)]

CASE: 20
Stag: 110 111 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However, in our current study, we focus on exploring the behavior of negators As we have discussed above, we will use the human annotated sentiment for the arguments, same as in the models discussed in Section 3
	Cause: [(1, 1), (1, 25)]
	Effect: [(0, 0), (0, 14)]

CASE: 21
Stag: 112 113 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: With the new matrix and tensor, we then have u'\u0398' = ( V , V s u'\u2062' e u'\u2062' n , W , W s u'\u2062' e u'\u2062' n , W l u'\u2062' a u'\u2062' b u'\u2062' e u'\u2062' l , L ) as the PSTN model u'\u2019' s parameters Here, L denotes the vector representations of the word dictionary
	Cause: [(0, 81), (1, 9)]
	Effect: [(0, 0), (0, 79)]

CASE: 22
Stag: 120 121 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To minimize E u'\u2062' ( u'\u0398' ) , the gradient of the objective function with respect to each of the parameters in u'\u0398' is calculated efficiently via backpropagation through structure, as proposed by Specifically, we first compute the prediction errors in all tree nodes bottom-up
	Cause: [(0, 44), (1, 12)]
	Effect: [(0, 0), (0, 41)]

CASE: 23
Stag: 126 127 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: During the derivative computation, the two errors will be summed up as the complement incoming error for the node We denote the complete incoming error and the softmax error vector for node i as u'\u0394' i , c u'\u2062' o u'\u2062' m u'\u2208' u'\u211d' d × 1 and u'\u0394' i , s u'\u2208' u'\u211d' d × 1 , respectively
	Cause: [(0, 13), (1, 68)]
	Effect: [(0, 0), (0, 11)]

CASE: 24
Stag: 132 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Now, let u'\u2019' s form the equations for computing the error for the two children of the p 2 node
	Cause: [(0, 13), (0, 22)]
	Effect: [(0, 0), (0, 11)]

CASE: 25
Stag: 134 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We denote the error passing down as u'\u0394' p 2 , d u'\u2062' o u'\u2062' w u'\u2062' n , where the left child and the right child of p 2 take the 1 s u'\u2062' t and 2 n u'\u2062' d half of the error u'\u0394' p 2 , d u'\u2062' o u'\u2062' w u'\u2062' n , namely u'\u0394' p 2 , d u'\u2062' o u'\u2062' w u'\u2062' n [ 1 d ] and u'\u0394' p 2 , d u'\u2062' o u'\u2062' w u'\u2062' n [ d + 1
	Cause: [(0, 7), (0, 140)]
	Effect: [(0, 0), (0, 5)]

CASE: 26
Stag: 141 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The original RNTN and the PSTN predict 5-class sentiment for each negated phrase; we map the output to real-valued scores based on the scale that used to map real-valued sentiment scores to sentiment categories
	Cause: [(0, 23), (0, 34)]
	Effect: [(0, 0), (0, 20)]

CASE: 27
Stag: 143 144 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For example, if y i = [ 0.5 u'\u2004' 0.5 u'\u2004' 0 u'\u2004' 0 u'\u2004' 0 ] , meaning this phrase has a 0.5 probability to be in the first category (strong negative) and 0.5 for the second category (weak negative), the resulting p i r u'\u2062' e u'\u2062' a u'\u2062' l will be 0.2 (0.5*0.1+0.5*0.3 Data As described earlier, the Stanford Sentiment Treebank [] has manually annotated, real-valued sentiment values for all phrases in parse trees
	Cause: [(1, 2), (1, 23)]
	Effect: [(0, 1), (1, 0)]

CASE: 28
Stag: 161 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The table shows that the basic reversing and shifting heuristics do capture negators u'\u2019' behavior to some degree, as their MAE scores are higher than that of the baseline
	Cause: [(0, 24), (0, 33)]
	Effect: [(0, 0), (0, 21)]

CASE: 29
Stag: 167 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This could suggest that additional external knowledge, e.g.,, that from human-built resources or automatically learned from other data (e.g.,, as in [] ), including sentiment that cannot be inferred from its constituent expressions, might be incorporated to benefit the current neural-network-based models as prior knowledge
	Cause: [(0, 26), (0, 54)]
	Effect: [(0, 0), (0, 23)]

CASE: 30
Stag: 168 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Note that the two neural network based models incorporate the syntax and semantics by representing each node with a vector
	Cause: [(0, 14), (0, 19)]
	Effect: [(0, 2), (0, 12)]

CASE: 31
Stag: 170 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: For example, if a phrase very good modified by a negator not appears in the training and test data, the system can simply memorize the sentiment score of not very good in training and use this score at testing
	Cause: [(0, 4), (0, 19)]
	Effect: [(0, 21), (0, 40)]

CASE: 32
Stag: 184 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Alternatively, if the modeling has to be done in groups, one should consider clustering valence shifters by their shifting abilities in training or external data
	Cause: [(0, 3), (0, 10)]
	Effect: [(0, 12), (0, 26)]

CASE: 33
Stag: 190 191 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The depth here is defined as the longest distance between the root of a negator-phrase pair u'\u27e8' w n , w u'\u2192' u'\u27e9' and their descendant leafs Negators appearing at deeper levels of the tree tend to have more complicated syntax and semantics
	Cause: [(0, 6), (1, 14)]
	Effect: [(0, 0), (0, 4)]

CASE: 34
Stag: 196 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The errors made by model 6 is bumpy, as the model considers no semantics and hence its errors are not dependent on the depths
	Cause: [(0, 10), (0, 24)]
	Effect: [(0, 0), (0, 7)]

CASE: 35
Stag: 196 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: The errors made by model 6 is bumpy, as the model considers no semantics and hence its errors are not dependent on the depths
	Cause: [(0, 0), (0, 4)]
	Effect: [(0, 7), (0, 14)]

