************************************************************
P14-2053.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 3 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The vast majority of systems generate questions by selecting one sentence at a time, extracting portions of the source sentence, then applying transformation rules or patterns in order to construct a question
	Cause: [(0, 8), (0, 33)]
	Effect: [(0, 0), (0, 6)]

CASE: 1
Stag: 13 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: These approaches can potentially ask deeper questions due to their focus on semantics
	Cause: [(0, 9), (0, 12)]
	Effect: [(0, 0), (0, 6)]

CASE: 2
Stag: 20 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: First, the source text is divided into sentences which are processed by SENNA 1 1 http://ml.nec-labs.com/senna/ software, described in (Collobert et al., 2011
	Cause: [(0, 13), (0, 17)]
	Effect: [(0, 18), (0, 26)]

CASE: 3
Stag: 26 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Additionally, patterns indicate the semantic arguments that provide the answer to the question, required fields, and filter condition fields
	Cause: [(0, 2), (0, 2)]
	Effect: [(0, 4), (0, 21)]

CASE: 4
Stag: 26 27 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Additionally, patterns indicate the semantic arguments that provide the answer to the question, required fields, and filter condition fields As these patterns are matched, they will be rejected as candidates for generation for a particular sentence if the required arguments are absent or if filter conditions are present
	Cause: [(1, 1), (1, 29)]
	Effect: [(0, 0), (0, 21)]

CASE: 5
Stag: 34 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Patterns specify whether verbs should be included in their lexical form or as they appear in the source text
	Cause: [(0, 13), (0, 18)]
	Effect: [(0, 3), (0, 11)]

CASE: 6
Stag: 36 37 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The lungs take in air The most common use of the verb as it appears in the sentence is with the verb be , as in
	Cause: [(1, 8), (1, 20)]
	Effect: [(0, 1), (1, 6)]

CASE: 7
Stag: 39 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This pattern takes the copular be as it appears in the source text
	Cause: [(0, 7), (0, 12)]
	Effect: [(0, 0), (0, 5)]

CASE: 8
Stag: 49 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: Textbooks were chosen rather than hand-crafted source material so that a more realistic assessment of performance could be achieved
	Cause: [(0, 0), (0, 7)]
	Effect: [(0, 10), (0, 18)]

CASE: 9
Stag: 56 57 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The patterns are designed to match only the arguments used as part of the question or the answer, in order to prevent over generation of questions The system inserted the correct forms of release and do , and ignored the phrase As this occurs since it is not part of the semantic argument
	Cause: [(0, 11), (1, 25)]
	Effect: [(0, 0), (0, 9)]

CASE: 10
Stag: 57 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: The system inserted the correct forms of release and do , and ignored the phrase As this occurs since it is not part of the semantic argument
	Cause: [(0, 19), (0, 26)]
	Effect: [(0, 0), (0, 17)]

CASE: 11
Stag: 57 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The system inserted the correct forms of release and do , and ignored the phrase As this occurs since it is not part of the semantic argument
	Cause: [(0, 16), (0, 17)]
	Effect: [(0, 0), (0, 14)]

CASE: 12
Stag: 61 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Question 3 is from the source sentence u'\u2019' s 3rd predicate-argument set because this matched the pattern requirements
	Cause: [(0, 17), (0, 21)]
	Effect: [(0, 0), (0, 15)]

CASE: 13
Stag: 74 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Annotators were given instructions to read a paragraph, then the questions based on that paragraph
	Cause: [(0, 14), (0, 15)]
	Effect: [(0, 0), (0, 11)]

CASE: 14
Stag: 80 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We compared our system to the H S and LPN W systems because they produce questions that are the most similar to ours, and for the same purpose reading comprehension reinforcement
	Cause: [(0, 13), (0, 31)]
	Effect: [(0, 0), (0, 11)]

CASE: 15
Stag: 84 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The purpose of this evaluation was to determine if any patterns consistently produce poor questions
	Cause: [(0, 9), (0, 14)]
	Effect: [(0, 0), (0, 7)]

CASE: 16
Stag: 86 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: We were also interested to know if first predicates make better questions than later ones
	Cause: [(0, 7), (0, 14)]
	Effect: [(0, 0), (0, 5)]

CASE: 17
Stag: 92 93 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This task utilized a file (Biology the body) with 56 source sentences from which our system generated 102 questions The Heilman and Smith system, as they describe it, takes an over-generate and rank approach
	Cause: [(1, 7), (1, 16)]
	Effect: [(0, 1), (1, 4)]

CASE: 18
Stag: 103 104 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The file has 93 sentences and our system generated 184 questions; the LPN W system generated roughly 4 times as many questions From each system, 100 questions were randomly selected, making sure that the LPN W questions did not include questions generated from domain-specific templates such as
	Cause: [(0, 21), (1, 25)]
	Effect: [(0, 12), (0, 19)]

CASE: 19
Stag: 108 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Interestingly, our system again achieved a 44% reduction in the error rate when averaging over all metrics, just as it did in the Heilman and Smith comparison
	Cause: [(0, 22), (0, 29)]
	Effect: [(0, 0), (0, 20)]

CASE: 20
Stag: 111 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Negation detection is a complicated task because negation can occur at the word, phrase or clause level, and because there are subtle shades of negation between definite positive and negative polarities (Blanco and Moldovan, 2011
	Cause: [(0, 7), (0, 38)]
	Effect: [(0, 0), (0, 5)]

CASE: 21
Stag: 111 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Negation detection is a complicated task because negation can occur at the word, phrase or clause level, and because there are subtle shades of negation between definite positive and negative polarities (Blanco and Moldovan, 2011
	Cause: [(0, 14), (0, 31)]
	Effect: [(0, 0), (0, 12)]

CASE: 22
Stag: 122 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Not having coreference resolution leads to vague questions, some of which can be filtered as discussed previously
	Cause: [(0, 3), (0, 3)]
	Effect: [(0, 6), (0, 17)]

CASE: 23
Stag: 130 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since current state-of-the-art systems do not deal well with relative and possessive pronouns, this will continue to be a limitation of natural language generation systems for the time being
	Cause: [(0, 1), (0, 12)]
	Effect: [(0, 14), (0, 19)]

CASE: 24
Stag: 131 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since our focus is on expository text, system patterns deal primarily with the present and simple past tenses
	Cause: [(0, 1), (0, 6)]
	Effect: [(0, 8), (0, 18)]

CASE: 25
Stag: 132 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Some patterns look for modals and so can handle future tense
	Cause: [(0, 0), (0, 4)]
	Effect: [(0, 7), (0, 10)]

CASE: 26
Stag: 137 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Light verbs pose complications in NLG because they are highly idiosyncratic and subject to syntactic variability (Sag et al., 2002
	Cause: [(0, 7), (0, 21)]
	Effect: [(0, 0), (0, 5)]

CASE: 27
Stag: 141 142 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The catenative construction also potentially adds complexity (Huddleston and Pullum, 2005), as shown in this example As the universe expanded, it became less dense and began to cool
	Cause: [(1, 1), (1, 12)]
	Effect: [(0, 0), (0, 19)]

CASE: 28
Stag: 143 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Care must be taken not to generate questions based on one predicate in the catenative construction
	Cause: [(0, 10), (0, 15)]
	Effect: [(0, 0), (0, 7)]

CASE: 29
Stag: 147 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Plant roots and bacterial decay use carbon dioxide in the process of respiration, the word use was classified as NN, leaving no predicate and no semantic role labels in this sentence
	Cause: [(0, 20), (0, 30)]
	Effect: [(0, 0), (0, 18)]

