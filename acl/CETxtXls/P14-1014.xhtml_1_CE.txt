************************************************************
P14-1014.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 1 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Analysing and extracting useful information from the web has become an increasingly important research direction for the NLP community, where many tasks require part-of-speech (POS) tagging as a fundamental preprocessing step However, state-of-the-art POS taggers in the literature [ 5 , 23 ] are mainly optimized on the the Penn Treebank (PTB), and when shifted to web data, tagging accuracies drop significantly [ 18 ]
	Cause: [(0, 30), (1, 29)]
	Effect: [(0, 3), (0, 28)]

CASE: 1
Stag: 2 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The problem we face here can be considered as a special case of domain adaptation , where we have access to labelled data on the source domain (PTB) and unlabelled data on the target domain (web data
	Cause: [(0, 9), (0, 23)]
	Effect: [(0, 0), (0, 7)]

CASE: 2
Stag: 7 8 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We integrate the learned encoder with a set of well-established features for POS tagging [ 21 , 5 ] in a single neural network, which is applied as a scorer to an easy-first POS tagger We choose the easy-first tagging approach since it has been demonstrated to give higher accuracies than the standard left-to-right POS tagger [ 23 , 15 ]
	Cause: [(0, 29), (1, 24)]
	Effect: [(0, 12), (0, 27)]

CASE: 3
Stag: 8 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: We choose the easy-first tagging approach since it has been demonstrated to give higher accuracies than the standard left-to-right POS tagger [ 23 , 15 ]
	Cause: [(0, 7), (0, 25)]
	Effect: [(0, 0), (0, 5)]

CASE: 4
Stag: 12 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The idea of learning representations from unlabelled data and then fine-tuning a model with such representations according to some supervised criterion has been studied before [ 26 , 6 , 8 ]
	Cause: [(0, 18), (0, 20)]
	Effect: [(0, 0), (0, 15)]

CASE: 5
Stag: 14 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Previous work treats the learned representations either as model parameters that are further optimized in supervised fine-tuning [ 6 ] or as fixed features that are kept unchanged [ 26 , 8 ]
	Cause: [(0, 8), (0, 31)]
	Effect: [(0, 0), (0, 6)]

CASE: 6
Stag: 18 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Our method achieves a 93.27 u'\u2062' % average accuracy across the web-domain, which is the best result reported so far on this data set, higher than those given by ensembled syntactic parsers
	Cause: [(0, 0), (0, 18)]
	Effect: [(0, 27), (0, 36)]

CASE: 7
Stag: 37 38 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: While in our case, each visible variable corresponds to a word, which may take on tens-of-thousands of different values Therefore, the RBM need to be re-factorized to make inference tractable
	Cause: [(0, 0), (0, 20)]
	Effect: [(1, 2), (1, 11)]

CASE: 8
Stag: 55 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By adopting greedy layer-wise training [ 10 , 2 ] , DBNs are capable of modelling higher order non-linear relations between the input, and has been demonstrated to improve performance for many computer vision tasks [ 10 , 2 , 13 ]
	Cause: [(0, 1), (0, 9)]
	Effect: [(0, 10), (0, 42)]

CASE: 9
Stag: 56 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: However, in this work we do not observe further improvement by employing DBNs
	Cause: [(0, 12), (0, 13)]
	Effect: [(0, 2), (0, 10)]

CASE: 10
Stag: 57 
	Pattern: 0 [['due', 'to', 'the', 'fact', 'that']]---- [['&R', '(,)'], ['&C']]
	sentTXT: This may partly be due to the fact that unlike computer vision tasks, the input structure of POS tagging or other sequential labelling tasks is relatively simple, and a single non-linear layer is enough to model the interactions within the input [ 27 ]
	Cause: [(0, 9), (0, 45)]
	Effect: [(0, 0), (0, 3)]

CASE: 11
Stag: 59 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: The main challenge to designing the neural network structure is on the one hand, we hope that the model can take the advantage of information provided by the learned WRRBM, which reflects general properties of web texts, so that the model generalizes well in the web domain; on the other hand, we also hope to improve the model u'\u2019' s discriminative power by utilizing well-established POS tagging features, such as those of Ratnaparkhi ( 1996 )
	Cause: [(0, 0), (0, 39)]
	Effect: [(0, 42), (0, 85)]

CASE: 12
Stag: 60 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Our approach is to leverage the two sources of information in one neural network by combining them though a shared output layer, as shown in Figure 1
	Cause: [(0, 15), (0, 27)]
	Effect: [(0, 0), (0, 13)]

CASE: 13
Stag: 73 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This can be achieved by initializing only the first layer of the web module with the projection matrix u'\ud835' u'\udc03' of the learned WRRBM
	Cause: [(0, 5), (0, 31)]
	Effect: [(0, 0), (0, 3)]

CASE: 14
Stag: 74 75 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Alternatively, we can choose to use the hidden states of the WRRBM, which can be treated as the representations of the input n-gram This can be achieved by also initializing the parameters of the second layer of the web-feature module using the position-dependent weight matrix and hidden bias of the learned WRRBM
	Cause: [(0, 19), (1, 23)]
	Effect: [(0, 0), (0, 17)]

CASE: 15
Stag: 81 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The input for this module is a vector of boolean values u'\u03a6' u'\u2062' ( x ) = ( f 1 u'\u2062' ( x ) , u'\u2026' , f k u'\u2062' ( x ) ) , where x denotes the partially tagged input sentence and f i u'\u2062' ( x ) denotes a feature function, which returns 1 if the corresponding feature fires and 0 otherwise
	Cause: [(0, 83), (0, 89)]
	Effect: [(0, 0), (0, 81)]

CASE: 16
Stag: 88 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Such distribution can be easily obtained by adding a soft-max layer on top of the output layer to perform a local normalization, as done by Collobert et al
	Cause: [(0, 7), (0, 28)]
	Effect: [(0, 0), (0, 5)]

CASE: 17
Stag: 96 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Rather than tagging a sentence from left to right, easy-first tagging is based on a deterministic process, repeatedly selecting the easiest word to tag
	Cause: [(0, 15), (0, 17)]
	Effect: [(0, 19), (0, 25)]

CASE: 18
Stag: 97 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Here u'\u201c' easiness u'\u201d' is evaluated based on a statistical model
	Cause: [(0, 16), (0, 18)]
	Effect: [(0, 0), (0, 13)]

CASE: 19
Stag: 102 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: At each step during the processing of a training example, the algorithm calculates a margin loss based on two word-tag pairs ( w ¯ , t ¯ ) and ( w ^ , t ^ ) (line 4 u'\u223c' line 6 w ¯ , t ¯ ) denotes the word-tag pair that has the highest model score among those that are inconsistent with the gold standard, while ( w ^ , t ^ ) denotes the one that has the highest model score among those that are consistent with the gold standard
	Cause: [(0, 19), (0, 21)]
	Effect: [(0, 25), (0, 94)]

CASE: 20
Stag: 103 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the loss is zero, the algorithm continues to process the next untagged word
	Cause: [(0, 1), (0, 4)]
	Effect: [(0, 6), (0, 14)]

CASE: 21
Stag: 105 106 
	Pattern: 8 [['because']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&ADV)'], ['&C']]
	sentTXT: The standard back-propagation algorithm [ 22 ] cannot be applied directly This is because the standard loss is calculated based on a unique input vector
	Cause: [(1, 3), (1, 13)]
	Effect: [(0, 0), (0, 11)]

CASE: 22
Stag: 107 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: This condition does not hold in our case, because w ^ and w ¯ may refer to different words, which means that the margin loss in line 6 of Algorithm 2 is calculated based on two different input vectors, denoted by u'\u27e8' w ^ u'\u27e9' and u'\u27e8' w ¯ u'\u27e9' , respectively
	Cause: [(0, 10), (0, 18)]
	Effect: [(0, 20), (0, 67)]

CASE: 23
Stag: 107 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: This condition does not hold in our case, because w ^ and w ¯ may refer to different words, which means that the margin loss in line 6 of Algorithm 2 is calculated based on two different input vectors, denoted by u'\u27e8' w ^ u'\u27e9' and u'\u27e8' w ¯ u'\u27e9' , respectively
	Cause: [(0, 16), (0, 19)]
	Effect: [(0, 21), (0, 47)]

CASE: 24
Stag: 115 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: While previous work [ 23 , 29 , 9 ] apply guided learning to train a linear classifier by using variants of the perceptron algorithm, we are the first to combine guided learning with a neural network, by using a margin loss and a modified back-propagation algorithm
	Cause: [(0, 19), (0, 24)]
	Effect: [(0, 25), (0, 48)]

CASE: 25
Stag: 115 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: While previous work [ 23 , 29 , 9 ] apply guided learning to train a linear classifier by using variants of the perceptron algorithm, we are the first to combine guided learning with a neural network, by using a margin loss and a modified back-propagation algorithm
	Cause: [(0, 15), (0, 17)]
	Effect: [(0, 18), (0, 22)]

CASE: 26
Stag: 116 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: [t] Training over one sentence {algorithmic} [1] \REQUIRE ( x , t ) a tagged sentence, neural net n u'\u2062' n \ENSURE updated neural net n u'\u2062' n u'\u2032'
	Cause: [(0, 0), (0, 11)]
	Effect: [(0, 12), (0, 49)]

CASE: 27
Stag: 118 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: u'\ud835' u'\udc14' u'\u2260' [ ] \STATE ( w ¯ , t ¯ ) u'\u2190' arg u'\u2062' max ( w , t ) u'\u2208' ( u'\ud835' u'\udc14' × u'\ud835' u'\udc13' / u'\ud835' u'\udc11' ) u'\u2061' n u'\u2062' n u'\u2062' ( w , t ) \STATE ( w ^ , t ^ ) u'\u2190' arg u'\u2062' max ( w , t ) u'\u2208' u'\ud835' u'\udc11' u'\u2061' n u'\u2062' n u'\u2062' ( w , t
	Cause: [(0, 0), (0, 78)]
	Effect: [(0, 79), (0, 160)]

CASE: 28
Stag: 119 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: l u'\u2062' o u'\u2062' s u'\u2062' s u'\u2190' max u'\u2061' ( 0 , 1 + n u'\u2062' n u'\u2062' ( w ¯ , t ¯ ) - n u'\u2062' n u'\u2062' ( w ^ , t ^ ) ) \IF l u'\u2062' o u'\u2062' s u'\u2062' s 0 \STATE e ^ u'\u2190' n u'\u2062' n
	Cause: [(0, 75), (0, 109)]
	Effect: [(0, 2), (0, 73)]

CASE: 29
Stag: 127 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: While emails and weblogs are used as the development sets, reviews, news groups and Yahoo!Answers are used as the final test sets
	Cause: [(0, 7), (0, 23)]
	Effect: [(0, 1), (0, 5)]

CASE: 30
Stag: 144 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The tagging performance is evaluated according to the official evaluation metrics of SANCL 2012
	Cause: [(0, 7), (0, 13)]
	Effect: [(0, 0), (0, 4)]

CASE: 31
Stag: 145 146 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The tagging accuracy is defined as the percentage of words (punctuations included) that are correctly tagged The averaged accuracies are calculated across the web domain data
	Cause: [(0, 6), (1, 8)]
	Effect: [(0, 0), (0, 4)]

CASE: 32
Stag: 148 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The data sets are generated by first concatenating all the cleaned unlabelled data, then selecting sentences evenly across the concatenated file
	Cause: [(0, 6), (0, 21)]
	Effect: [(0, 0), (0, 4)]

CASE: 33
Stag: 150 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: All these parameters are selected according to the averaged accuracy on the development set
	Cause: [(0, 7), (0, 13)]
	Effect: [(0, 0), (0, 4)]

CASE: 34
Stag: 157 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Feature templates are shown in Table 3, which are based on those of Ratnaparkhi (1996) and Shen et al
	Cause: [(0, 12), (0, 21)]
	Effect: [(0, 0), (0, 9)]

CASE: 35
Stag: 160 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Compared with the performance of the official baseline (row 4 of Table 6), which is evaluated based on the output of BerkeleyParser [ 16 , 17 ] , our baseline tagger achieves comparable accuracies on both the source and target domain data
	Cause: [(0, 21), (0, 25)]
	Effect: [(0, 28), (0, 44)]

CASE: 36
Stag: 162 163 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This is consistent with previous work (Le Roux et al., 2011), which found that for noisy data such as web domain text, data cleaning is a effective and necessary step As mentioned in Section 3.1, the knowledge learned from the WRRBM can be investigated incrementally, using word representation , which corresponds to initializing only the projection layer of web-feature module with the projection matrix of the learned WRRBM, or ngram-level representation , which corresponds to initializing both the projection and sigmoid layers of the web-feature module by the learned WRRBM
	Cause: [(1, 1), (1, 62)]
	Effect: [(0, 0), (0, 34)]

CASE: 37
Stag: 171 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: However, since fine-tuning is conducted with respect to the source domain , adjusting the parameters of the pre-trained representation towards optimizing source domain tagging accuracies would disrupt its ability in modelling the web domain data
	Cause: [(0, 3), (0, 11)]
	Effect: [(0, 13), (0, 35)]

CASE: 38
Stag: 171 172 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: However, since fine-tuning is conducted with respect to the source domain , adjusting the parameters of the pre-trained representation towards optimizing source domain tagging accuracies would disrupt its ability in modelling the web domain data Therefore, a better idea is to keep the representation unchanged so that we can learn a function that maps the general web-text properties to its syntactic categories
	Cause: [(0, 1), (0, 35)]
	Effect: [(1, 2), (1, 27)]

CASE: 39
Stag: 174 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This result illustrates that the ngram-level knowledge captures more complex interactions of the web text, which cannot be recovered by using only word embeddings
	Cause: [(0, 22), (0, 25)]
	Effect: [(0, 0), (0, 20)]

CASE: 40
Stag: 188 189 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The results suggest that using mixed data can achieve almost as good performance as using the target sub-domain data, while using mixed data yields a much more robust tagger across all sub-domains The best result achieved by using a 4-gram WRRBM, ( w i - 2 , u'\u2026' , w i + 1 ) , with 300 hidden units learned on 1,000k web domain sentences are shown in row 3 of Table 6
	Cause: [(0, 11), (1, 45)]
	Effect: [(0, 0), (0, 9)]

CASE: 41
Stag: 189 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: The best result achieved by using a 4-gram WRRBM, ( w i - 2 , u'\u2026' , w i + 1 ) , with 300 hidden units learned on 1,000k web domain sentences are shown in row 3 of Table 6
	Cause: [(0, 5), (0, 38)]
	Effect: [(0, 39), (0, 46)]

CASE: 42
Stag: 192 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Moreover, we achieve the highest tagging accuracy reported so far on this data set, surpassing those achieved using parser combinations based on self-training [ 24 , 12 ]
	Cause: [(0, 24), (0, 29)]
	Effect: [(0, 0), (0, 21)]

CASE: 43
Stag: 215 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2006 ) propose to induce shared representations for domain adaptation, which is based on the alternating structure optimization (ASO) method of Ando and Zhang ( 2005
	Cause: [(0, 15), (0, 28)]
	Effect: [(0, 0), (0, 12)]

CASE: 44
Stag: 217 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The new representations are induced based on the auxiliary tasks defined on unlabelled data together with a dimensionality reduction technique
	Cause: [(0, 7), (0, 19)]
	Effect: [(0, 0), (0, 4)]

