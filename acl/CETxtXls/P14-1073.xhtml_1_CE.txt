************************************************************
P14-1073.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Variation poses a serious challenge for determining who or what a name refers to
	Cause: [(0, 6), (0, 7)]
	Effect: [(0, 0), (0, 4)]

CASE: 1
Stag: 5 
	Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
	sentTXT: Another option is to train a model like stochastic edit distance from known pairs of similar names [] , but this requires supervised data in the test domain
	Cause: [(0, 23), (0, 28)]
	Effect: [(0, 0), (0, 20)]

CASE: 2
Stag: 6 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Even the best model of name similarity is not enough by itself, since two names that are similar u'\u2014' even identical u'\u2014' do not necessarily corefer
	Cause: [(0, 14), (0, 34)]
	Effect: [(0, 0), (0, 11)]

CASE: 3
Stag: 9 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Our model is an evolutionary generative process based on the name variation model of , which stipulates that names are often copied from previously generated names, perhaps with mutation (spelling edits
	Cause: [(0, 9), (0, 13)]
	Effect: [(0, 15), (0, 32)]

CASE: 4
Stag: 15 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Their inference procedure only clustered types (distinct names) rather than tokens (mentions in context), and relied on expensive matrix inversions for learning
	Cause: [(0, 26), (0, 26)]
	Effect: [(0, 1), (0, 24)]

CASE: 5
Stag: 24 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: \todo [author=jason,color=RedOrange,fancyline,size= ,]summarize results and add John Smith here if you do it in the conclusions
	Cause: [(0, 25), (0, 30)]
	Effect: [(0, 0), (0, 23)]

CASE: 6
Stag: 25 26 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Cross-document coreference resolution (CDCR) was first introduced by Most approaches since then are based on the intuitions that coreferent names tend to have u'\u201c' similar u'\u201d' spellings and tend to appear in u'\u201c' similar u'\u201d' contexts
	Cause: [(1, 3), (1, 43)]
	Effect: [(0, 1), (1, 1)]

CASE: 7
Stag: 35 36 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: To apply our model to the CDCR task, we observe that the probability that two name mentions are coreferent is the probability that they arose from a common ancestor in the phylogeny So we design a Monte Carlo sampler to reconstruct likely phylogenies
	Cause: [(0, 0), (0, 32)]
	Effect: [(1, 1), (1, 10)]

CASE: 8
Stag: 38 39 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: While our model is capable of generating each name independently, a phylogeny will generally achieve higher probability if it explains similar names as being similar by mutation (rather than by coincidence Thus, our sampled phylogenies tend to make similar names coreferent u'\u2014' especially long or unusual names that would be expensive to generate repeatedly, and especially in contexts that are topically similar and therefore have a higher prior probability of coreference
	Cause: [(0, 24), (1, 37)]
	Effect: [(0, 0), (0, 22)]

CASE: 9
Stag: 39 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Thus, our sampled phylogenies tend to make similar names coreferent u'\u2014' especially long or unusual names that would be expensive to generate repeatedly, and especially in contexts that are topically similar and therefore have a higher prior probability of coreference
	Cause: [(0, 0), (0, 36)]
	Effect: [(0, 39), (0, 45)]

CASE: 10
Stag: 45 46 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Rather than fixing its parameters before we begin CDCR, we learn them (without supervision) as part of CDCR, by training from samples of reconstructed phylogenies Name similarity is also an important component of within -document coreference resolution, and efforts in that area bear resemblance to our approach describe an u'\u201c' entity-centered u'\u201d' model where a distance-dependent Chinese restaurant process is used to pick previous coreferent mentions within a document
	Cause: [(0, 18), (1, 53)]
	Effect: [(0, 0), (0, 16)]

CASE: 11
Stag: 47 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Similarly, learn a mention similarity model based on labeled data
	Cause: [(0, 9), (0, 10)]
	Effect: [(0, 0), (0, 6)]

CASE: 12
Stag: 50 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Like and we use topics as the contexts, but learn mention topics jointly with other model parameters
	Cause: [(0, 6), (0, 17)]
	Effect: [(0, 0), (0, 4)]

CASE: 13
Stag: 57 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We assume that each document has a (single) known \todo [author=mark,color=RoyalBlue,fancyline,size=,]We got dinged in the last submission for trying to generalize the model to language without any data to back it up
	Cause: [(0, 36), (0, 49)]
	Effect: [(0, 0), (0, 34)]

CASE: 14
Stag: 59 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: \todo [author=jason,color=RedOrange,fancyline,size=,]As you see, I already amplified the footnote to give our defense of this
	Cause: [(0, 18), (0, 31)]
	Effect: [(0, 0), (0, 16)]

CASE: 15
Stag: 62 63 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Our model generates an ordered sequence u'\ud835' u'\udc99' although we do not observe its order Thus each mention x has latent position x i (e.g.,, x 729 i = 729
	Cause: [(0, 0), (0, 22)]
	Effect: [(1, 1), (1, 16)]

CASE: 16
Stag: 64 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The entire corpus, including these entities, is generated according to standard topic model assumptions; we first generate a topic distribution for a document, then sample topics and words for the document [ ]
	Cause: [(0, 12), (0, 15)]
	Effect: [(0, 0), (0, 9)]

CASE: 17
Stag: 68 69 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To mitigate this unrealistic assumption, we allow any ordering u'\ud835' u'\udc99' of the observed mentions, not respecting document timestamps or forcing the mentions from a given document to be generated as a contiguous subsequence of u'\ud835' u'\udc99' Alternatively, the model may manufacture a name for a new person, though the name itself may not be new
	Cause: [(0, 41), (1, 19)]
	Effect: [(0, 0), (0, 39)]

CASE: 18
Stag: 70 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If all previous mentions were equally likely, this would be a Chinese Restaurant Process (CRP) in which frequently mentioned entities are more likely to be mentioned again ( u'\u201c' the rich get richer u'\u201d'
	Cause: [(0, 1), (0, 6)]
	Effect: [(0, 8), (0, 44)]

CASE: 19
Stag: 71 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We refine that idea by saying that the current topic, language, and document influence the choice of which previous mention to copy, similar to the distance-dependent CRP [ ]
	Cause: [(0, 5), (0, 31)]
	Effect: [(0, 0), (0, 3)]

CASE: 20
Stag: 72 73 
	Pattern: 10 [['why']]---- [['&C', '(,/./;/--)', '(&AND)', '&THIS', '&BE'], ['&R']]
	sentTXT: 2 2 Unlike the ddCRP, our generative story is careful to prohibit derivational cycles each mention is copied from a previous mention in the latent ordering This is why our phylogeny is a tree , and why our sampler is more complex
	Cause: [(0, 0), (0, 26)]
	Effect: [(1, 3), (1, 15)]

CASE: 21
Stag: 74 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Also unlike the ddCRP, we permit asymmetric u'\u201c' distances u'\u201d' if a certain topic or language likes to copy mentions from another, the compliment is not necessarily returned
	Cause: [(0, 20), (0, 30)]
	Effect: [(0, 32), (0, 37)]

CASE: 22
Stag: 75 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: This will help distinguish multiple John Smith entities if they tend to appear in different contexts
	Cause: [(0, 9), (0, 15)]
	Effect: [(0, 0), (0, 7)]

CASE: 23
Stag: 83 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: While u'\ud835' u'\udc8a' and u'\ud835' u'\udc9b' are not necessary for creating coref clusters, they are needed to produce u'\ud835' u'\udc91'
	Cause: [(0, 26), (0, 28)]
	Effect: [(0, 0), (0, 24)]

CASE: 24
Stag: 88 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The distributions used to choose these are unimportant because these variables are always observed
	Cause: [(0, 9), (0, 13)]
	Effect: [(0, 0), (0, 7)]

CASE: 25
Stag: 92 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: \todo [author=jason,color=RedOrange,fancyline,size=,]If we u'\u2019' re using [ ] , then don u'\u2019' t we have to say how u'\ud835' u'\udc8e' is sampled
	Cause: [(0, 18), (0, 27)]
	Effect: [(0, 30), (0, 53)]

CASE: 26
Stag: 94 95 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: I simplified it from u'\u03a4' u'\u2062' u'\ud835' u'\udc8e' here and in the main document So now u'\ud835' u'\udc8e' is unnormalized
	Cause: [(0, 0), (0, 29)]
	Effect: [(1, 1), (1, 13)]

CASE: 27
Stag: 102 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: \todo [author=jason,color=RedOrange,fancyline,size=,]if we restore u'\u0391' then it should be mentioned here
	Cause: [(0, 18), (0, 24)]
	Effect: [(0, 26), (0, 30)]

CASE: 28
Stag: 106 107 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Notice that the tokens w d u'\u2062' k in document d are exchangeable by collapsing out u'\ud835' u'\udf4d' d , we can regard them as having been generated from a CRP Thus, for fixed values of the non-mention tokens and their topics, the probability of generating the mention sequence u'\ud835' u'\udc99' is proportional to the product of the probabilities of the choices in step 3 at the positions d u'\u2062' k where mentions were generated
	Cause: [(0, 37), (1, 57)]
	Effect: [(0, 2), (0, 35)]

CASE: 29
Stag: 106 107 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Notice that the tokens w d u'\u2062' k in document d are exchangeable by collapsing out u'\ud835' u'\udf4d' d , we can regard them as having been generated from a CRP Thus, for fixed values of the non-mention tokens and their topics, the probability of generating the mention sequence u'\ud835' u'\udc99' is proportional to the product of the probabilities of the choices in step 3 at the positions d u'\u2062' k where mentions were generated
	Cause: [(0, 1), (0, 42)]
	Effect: [(1, 1), (1, 57)]

CASE: 30
Stag: 110 111 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: To select a parent for a mention x of type t = x e t , a simple model (as mentioned above) would be a CRP each previous mention of the same type is selected with probability proportional to 1, and u'\u2662' is selected with probability proportional to u'\u0391' t 0 A larger choice of u'\u0391' t results in smaller entity clusters, because it prefers to create new entities of type t rather than copying old ones
	Cause: [(1, 17), (1, 30)]
	Effect: [(0, 1), (1, 14)]

CASE: 31
Stag: 112 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: We modify this story by re-weighting u'\u2662' and previous mentions according to their relative suitability as the parent of x
	Cause: [(0, 16), (0, 23)]
	Effect: [(0, 0), (0, 13)]

CASE: 32
Stag: 113 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: \todo [author=noa,color=SeaGreen,fancyline,size=,]I have features on u'\u2662' here since e.g., position in document may be predictive of if a new entity is being started
	Cause: [(0, 28), (0, 43)]
	Effect: [(0, 0), (0, 26)]

CASE: 33
Stag: 113 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: \todo [author=noa,color=SeaGreen,fancyline,size=,]I have features on u'\u2662' here since e.g., position in document may be predictive of if a new entity is being started
	Cause: [(0, 10), (0, 15)]
	Effect: [(0, 0), (0, 8)]

CASE: 34
Stag: 114 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: \todo [author=jason,color=RedOrange,fancyline,size=,]Ok, but then the factors of u'\u0391' t n u'\u2062' ( x ) + u'\u0391' t should no longer be used, so I deleted them and simplified
	Cause: [(0, 0), (0, 50)]
	Effect: [(0, 53), (0, 57)]

CASE: 35
Stag: 116 117 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In fact, we no longer have any u'\u0391' parameter where x p ranges over u'\u2662' and all previous mentions of the same type as x , that is, mentions p such that p i x i and p e t = x e t
	Cause: [(1, 19), (1, 39)]
	Effect: [(0, 0), (1, 17)]

CASE: 36
Stag: 118 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: The normalizing constant Z ( x ) = def u'\u2211' p exp ( u'\u03a6' u'\u22c5' u'\ud835' u'\udc1f' ( x p , x ) ) is chosen so that the probabilities sum to 1
	Cause: [(0, 0), (0, 45)]
	Effect: [(0, 48), (0, 52)]

CASE: 37
Stag: 122 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: This binary feature has a high weight if authors mainly choose mentions from the same topic
	Cause: [(0, 8), (0, 15)]
	Effect: [(0, 0), (0, 6)]

CASE: 38
Stag: 127 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: One could also make more specific versions of any feature by conjoining it with the entity type t
	Cause: [(0, 11), (0, 17)]
	Effect: [(0, 0), (0, 9)]

CASE: 39
Stag: 128 129 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Let x denote a mention with parent p = x p As in , its name x n is a stochastic transduction of its parent u'\u2019' s name p n
	Cause: [(1, 1), (1, 22)]
	Effect: [(0, 1), (0, 10)]

CASE: 40
Stag: 143 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: More generally, the probability ( 2 ) may also be conditioned on other variables such as on the languages p u'\u2113' and x u'\u2113' u'\u2014' this leaves room for a transliteration model when x u'\u2113' u'\u2260' p u'\u2113' u'\u2014' and on the entity type x t
	Cause: [(0, 0), (0, 27)]
	Effect: [(0, 28), (0, 33)]

CASE: 41
Stag: 148 149 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use the same model, taking u'\u2662' n to be the empty string (but with # u'\u2662' rather than # as the end-of-string symbol This yields a feature-based unigram language model (whose character probabilities may differ from usual insertion probabilities because they see # u'\u2662' as the lookahead character
	Cause: [(0, 31), (1, 28)]
	Effect: [(0, 0), (0, 29)]

CASE: 42
Stag: 149 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This yields a feature-based unigram language model (whose character probabilities may differ from usual insertion probabilities because they see # u'\u2662' as the lookahead character
	Cause: [(0, 18), (0, 24)]
	Effect: [(0, 0), (0, 16)]

CASE: 43
Stag: 153 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The edit model thinks that Pr u'\ud835' u'\udf3d' ( u'\ud835' u'\udda2' u'\ud835' u'\udda8' u'\ud835' u'\udda0' u'\u2223' u'\u2662' ) is relatively high (because CIA is a short string) and so is Pr u'\ud835' u'\udf3d' ( u'\ud835' u'\udda2' u'\ud835' u'\udda8' u'\ud835' u'\udda0' u'\u2223' Chuck u'\u2019' s Ice Art
	Cause: [(0, 0), (0, 68)]
	Effect: [(0, 71), (0, 127)]

CASE: 44
Stag: 153 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The edit model thinks that Pr u'\ud835' u'\udf3d' ( u'\ud835' u'\udda2' u'\ud835' u'\udda8' u'\ud835' u'\udda0' u'\u2223' u'\u2662' ) is relatively high (because CIA is a short string) and so is Pr u'\ud835' u'\udf3d' ( u'\ud835' u'\udda2' u'\ud835' u'\udda8' u'\ud835' u'\udda0' u'\u2223' Chuck u'\u2019' s Ice Art
	Cause: [(0, 63), (0, 67)]
	Effect: [(0, 0), (0, 61)]

CASE: 45
Stag: 154 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: But in fact, if CIA has already been frequently used to refer to the Central Intelligence Agency, then an author is unlikely to use it for a different entity
	Cause: [(0, 5), (0, 17)]
	Effect: [(0, 20), (0, 30)]

CASE: 46
Stag: 159 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: We take this to be the probability that a reader who knows our sub-models would guess some parent having the correct entity (or u'\u2662' if x is a first mention u'\u2211' p u'\u2032' p u'\u2032' e = x e w u'\u2062' ( p u'\u2032' , x ) / u'\u2211' p u'\u2032' w u'\u2062' ( p u'\u2032' , x
	Cause: [(0, 30), (0, 60)]
	Effect: [(0, 70), (0, 96)]

CASE: 47
Stag: 168 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Output the current sample s t = ( u'\ud835' u'\udc91' , u'\ud835' u'\udc8a' , u'\ud835' u'\udc9b' )
	Cause: [(0, 0), (0, 3)]
	Effect: [(0, 4), (0, 29)]

CASE: 48
Stag: 169 170 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: It is difficult to draw exact samples at steps 1 and 2 Thus, we sample u'\ud835' u'\udc8a' or u'\ud835' u'\udc9b' from a simpler proposal distribution, but correct the discrepancy using the Independent Metropolis-Hastings (IMH) strategy with an appropriate probability, reject the proposed new value and instead use another copy of the current value [ ]
	Cause: [(0, 0), (0, 11)]
	Effect: [(1, 1), (1, 63)]

CASE: 49
Stag: 172 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: The current phylogeny u'\ud835' u'\udc91' already defines a partial order on u'\ud835' u'\udc99' , since each parent must precede its children
	Cause: [(0, 31), (0, 36)]
	Effect: [(0, 0), (0, 28)]

CASE: 50
Stag: 178 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: We provide details about this procedure in Appendix A .) 7 7 The full version of this paper is available at http://cs.jhu.edu/~noa/publications/phylo-acl-14.pdf However, such orderings are not in fact equiprobable given the other variables u'\u2014' some orderings better explain why that phylogeny was chosen in the first place, according to our competitive parent selection model (§ 4.1
	Cause: [(0, 57), (0, 63)]
	Effect: [(0, 0), (0, 53)]

CASE: 51
Stag: 183 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The topics of context words are assumed exchangeable, and so we resample them using Gibbs sampling [ ]
	Cause: [(0, 0), (0, 7)]
	Effect: [(0, 11), (0, 18)]

CASE: 52
Stag: 187 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This probability is expensive to evaluate because changing x z will change the probability of many edges in the current phylogeny u'\ud835' u'\udc91'
	Cause: [(0, 7), (0, 30)]
	Effect: [(0, 0), (0, 5)]

CASE: 53
Stag: 188 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Equation ( 1 ) puts x is in competition with other parents, so every mention y that follows x must recompute how happy it is with its current parent y p
	Cause: [(0, 0), (0, 11)]
	Effect: [(0, 14), (0, 31)]

CASE: 54
Stag: 194 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: As detailed below, a proposal can be sampled from Q u'\u2062' ( u'\ud835' u'\udc9b' ) in time O u'\u2062' u'\ud835' u'\udc9b' u'\u2062' K 2 ) where K is the number of topics, because the only interactions among topics are along the edges of the tree u'\ud835' u'\udc91'
	Cause: [(0, 63), (0, 83)]
	Effect: [(0, 0), (0, 60)]

CASE: 55
Stag: 203 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We sample from Q using standard methods, \todo [author=jason,color=RedOrange,fancyline,size=,]can we cite a section of Koller Friedman similar to sampling from a linear-chain CRF by running the backward algorithm followed by forward sampling
	Cause: [(0, 41), (0, 48)]
	Effect: [(0, 0), (0, 39)]

CASE: 56
Stag: 207 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: While Pr ( u'\ud835' u'\udc91' , u'\ud835' u'\udc8a' , u'\ud835' u'\udc9b' ^ , u'\ud835' u'\udc99' u'\u2223' u'\ud835' u'\udf3d' , u'\u03a6' ) might seem slow to compute because it contains many factors ( 1 ) with different denominators Z u'\u2062' ( x ) , one can share work by visiting the mentions x in their order u'\ud835' u'\udc8a'
	Cause: [(0, 75), (0, 93)]
	Effect: [(0, 95), (0, 116)]

CASE: 57
Stag: 207 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: While Pr ( u'\ud835' u'\udc91' , u'\ud835' u'\udc8a' , u'\ud835' u'\udc9b' ^ , u'\ud835' u'\udc99' u'\u2223' u'\ud835' u'\udf3d' , u'\u03a6' ) might seem slow to compute because it contains many factors ( 1 ) with different denominators Z u'\u2062' ( x ) , one can share work by visiting the mentions x in their order u'\ud835' u'\udc8a'
	Cause: [(0, 5), (0, 20)]
	Effect: [(0, 0), (0, 3)]

CASE: 58
Stag: 208 209 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Most summands in Z u'\u2062' ( x ) were already included in Z u'\u2062' ( x u'\u2032' ) , where x u'\u2032' is the latest previous mention having the same attributes as x (e.g.,, same topic \todo [author=jason,color=RedOrange,fancyline,size=,]Nick, I assume you use this trick
	Cause: [(0, 48), (1, 23)]
	Effect: [(0, 0), (0, 46)]

CASE: 59
Stag: 210 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: [author=jason,color=RedOrange,fancyline,size=,]cut out a speedup here for space
	Cause: [(0, 0), (0, 12)]
	Effect: [(0, 14), (0, 21)]

CASE: 60
Stag: 213 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the ordering u'\ud835' u'\udc8a' prevents cycles, the resulting phylogeny u'\ud835' u'\udc91' is indeed a tree
	Cause: [(0, 1), (0, 13)]
	Effect: [(0, 16), (0, 31)]

CASE: 61
Stag: 214 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: Given the topics u'\ud835' u'\udc9b' , the ordering u'\ud835' u'\udc8a' , and the observed names, we choose an x p value according to its posterior probability
	Cause: [(0, 40), (0, 42)]
	Effect: [(0, 0), (0, 37)]

CASE: 62
Stag: 218 219 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: With the pragmatic model (section 4.2 ), the parent choices are no longer independent; then the samples of u'\ud835' u'\udc91' should be corrected by IMH as usual The initial sampler state ( u'\ud835' u'\udc9b' 0 , u'\ud835' u'\udc91' 0 , u'\ud835' u'\udc8a' 0 ) is obtained as follows
	Cause: [(0, 37), (1, 43)]
	Effect: [(0, 13), (0, 35)]

CASE: 63
Stag: 220 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: \todo [author=jason,color=RedOrange,fancyline,size=,]nick, a LaTeXnote you can use inline lists with itemize* if you want to compactify like this (we u'\u2019' re already using enumitem package) (1) We fix topics u'\ud835' u'\udc9b' 0 via collapsed Gibbs sampling [ ]
	Cause: [(0, 30), (0, 70)]
	Effect: [(0, 21), (0, 28)]

CASE: 64
Stag: 222 223 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This process treats all topics as exchangeable, including those associated with named entities \todo [author=jason,color=RedOrange,fancyline,size=,]Well, maybe they u'\u2019' re exchangeable if you u'\u2019' re ignoring the names at this step and just treating the types as words
	Cause: [(0, 6), (1, 47)]
	Effect: [(0, 0), (0, 4)]

CASE: 65
Stag: 223 224 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: \todo [author=jason,color=RedOrange,fancyline,size=,]Well, maybe they u'\u2019' re exchangeable if you u'\u2019' re ignoring the names at this step and just treating the types as words Are you
	Cause: [(0, 48), (1, 0)]
	Effect: [(0, 0), (0, 46)]

CASE: 66
Stag: 227 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: The weight w ( x p , x ) is defined as in section 5.3 u'\u2014' except that since we do not yet have an ordering u'\ud835' u'\udc8a' , we do not restrict the possible values of x p to mentions p with p i x p i
	Cause: [(0, 23), (0, 39)]
	Effect: [(0, 41), (0, 59)]

CASE: 67
Stag: 229 230 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Evaluating the likelihood and its partial derivatives with respect to the parameters of the model requires marginalizing over our latent variables As this marginalization is intractable, we resort to Monte Carlo EM procedure [ ] which iterates the following two steps
	Cause: [(1, 1), (1, 20)]
	Effect: [(0, 4), (0, 20)]

CASE: 68
Stag: 234 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Improve u'\ud835' u'\udf3d' and u'\u03a6' to increase 8 8 We actually do MAP-EM, which augments ( 7 ) by adding the log-likelihoods of u'\u0398' and u'\u03a6' under a Gaussian prior
	Cause: [(0, 32), (0, 39)]
	Effect: [(0, 40), (0, 50)]

CASE: 69
Stag: 235 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: It is not necessary to locally maximize u'\u2112' at each M-step, merely to improve it if it is not already at a local maximum [ ]
	Cause: [(0, 21), (0, 30)]
	Effect: [(0, 0), (0, 19)]

CASE: 70
Stag: 238 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Also, should u'\u03a3' t be described as a (diagonal) matrix where u'\u0395' is a fixed scaling term and u'\u03a3' t is an adaptive learning rate given by AdaGrad [ ]
	Cause: [(0, 12), (0, 41)]
	Effect: [(0, 2), (0, 10)]

CASE: 71
Stag: 243 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: That edge explains a mention x as a mutation of some parent p in the context of a particular sample ( u'\ud835' u'\udc91' s , u'\ud835' u'\udc8a' s , u'\ud835' u'\udc9b' s
	Cause: [(0, 7), (0, 54)]
	Effect: [(0, 0), (0, 5)]

CASE: 72
Stag: 244 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: The possible parents p u'\u2032' range over u'\u2662' and the mentions that precede x according to the ordering u'\ud835' u'\udc8a' s , while the features u'\ud835' u'\udc87' and distribution Pr u'\u03a6' depend on the topics u'\ud835' u'\udc9b' s
	Cause: [(0, 24), (0, 36)]
	Effect: [(0, 38), (0, 73)]

CASE: 73
Stag: 249 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: From a single phylogeny u'\ud835' u'\udc91' , we deterministically obtain a clustering u'\ud835' u'\udc86' by removing the root u'\u2662'
	Cause: [(0, 31), (0, 37)]
	Effect: [(0, 0), (0, 29)]

CASE: 74
Stag: 251 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Our model gives a distribution over phylogenies u'\ud835' u'\udc91' (given observations u'\ud835' u'\udc99' and learned parameters u'\u03a6' ) u'\u2014' and thus gives a posterior distribution over clusterings u'\ud835' u'\udc86' , which can be used to answer various queries
	Cause: [(0, 0), (0, 43)]
	Effect: [(0, 46), (0, 70)]

CASE: 75
Stag: 255 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: In practice, we again estimate the expectation by sampling u'\ud835' u'\udc86' values
	Cause: [(0, 9), (0, 20)]
	Effect: [(0, 0), (0, 7)]

CASE: 76
Stag: 257 258 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where the true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) use the clustering u'\ud835' u'\udc86' to evaluate how well u'\ud835' u'\udc86' u'\u2032' classifies the ( N 2 ) mention pairs as coreferent or not More similar clusterings achieve larger R , with R u'\u2062' ( u'\ud835' u'\udc86' u'\u2032' , u'\ud835' u'\udc86' ) = 1 iff u'\ud835' u'\udc86' u'\u2032' = u'\ud835' u'\udc86'
	Cause: [(0, 67), (1, 69)]
	Effect: [(0, 1), (0, 65)]

CASE: 77
Stag: 261 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: where u'\u223c' denotes coreference according to u'\ud835' u'\udc86' u'\u2032'
	Cause: [(0, 10), (0, 24)]
	Effect: [(0, 0), (0, 7)]

CASE: 78
Stag: 261 262 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where u'\u223c' denotes coreference according to u'\ud835' u'\udc86' u'\u2032' As explained above, the s i u'\u2062' j are coreference probabilities s i u'\u2062' j that can be estimated from a sample of clusterings u'\ud835' u'\udc86'
	Cause: [(1, 1), (1, 42)]
	Effect: [(0, 1), (0, 24)]

CASE: 79
Stag: 271 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: For the political blog dataset, the reference does not consist of entity annotations, and so we follow the evaluation procedure of
	Cause: [(0, 0), (0, 13)]
	Effect: [(0, 17), (0, 22)]

CASE: 80
Stag: 281 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Their method uses Jaro-Winkler string similarity to match names, then clusters mentions with matching names (for disambiguation) by comparing their unigram context distributions using the Jenson-Shannon metric
	Cause: [(0, 21), (0, 29)]
	Effect: [(0, 0), (0, 19)]

CASE: 81
Stag: 286 287 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: For our model, we tune only the fixed weight of the root feature, which determines the precision/recall trade-off (larger values of this feature result in more attachments to u'\u2662' and hence more entities We leave other hyperparameters fixed
	Cause: [(0, 0), (0, 35)]
	Effect: [(0, 38), (1, 3)]

CASE: 82
Stag: 298 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The baseline system took the first mention from each (gold) within-document coreference chain as the canonical mention, ignoring other mentions in the chain; we follow the same procedure in our experiments
	Cause: [(0, 16), (0, 27)]
	Effect: [(0, 0), (0, 14)]

CASE: 83
Stag: 301 302 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use the same baselines as in § 8.1 On development data, modeling pragmatics as in § 4.2 gave large improvements for organizations (8 points in F-measure), \todo [author=jason,color=RedOrange,fancyline,size=,]but maybe just for org correcting the tendency to assume that short names like CIA were coincidental homonyms
	Cause: [(0, 6), (1, 54)]
	Effect: [(0, 0), (0, 4)]

CASE: 84
Stag: 302 303 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: On development data, modeling pragmatics as in § 4.2 gave large improvements for organizations (8 points in F-measure), \todo [author=jason,color=RedOrange,fancyline,size=,]but maybe just for org correcting the tendency to assume that short names like CIA were coincidental homonyms Hence we allowed u'\u0393' 0 and tuned it on development data
	Cause: [(0, 0), (0, 55)]
	Effect: [(1, 1), (1, 10)]

CASE: 85
Stag: 306 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: The other results we report do not use pragmatics at all, since we found that it gave only a slight improvement on Twitter
	Cause: [(0, 13), (0, 23)]
	Effect: [(0, 0), (0, 10)]

CASE: 86
Stag: 309 310 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The CMU political blogs dataset consists of 3000 documents about U.S politics [ ] Preprocessed as described in , the data consists of 10647 entity mentions
	Cause: [(1, 2), (1, 11)]
	Effect: [(0, 0), (1, 0)]

CASE: 87
Stag: 315 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Like the output of our model, the output of their hierarchical clustering baseline is a mention clustering, and therefore must be mapped to a table of canonical entity names to compare to the reference table
	Cause: [(0, 0), (0, 17)]
	Effect: [(0, 21), (0, 36)]

CASE: 88
Stag: 317 318 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The tuned model then produced a mention clustering on the full political blog corpus As the mapping from clusters to a table is not fully detailed in , we used a simple heuristic the most frequent name in each cluster is taken as the canonical name, augmented by any titles from a predefined list appearing in any other name in the cluster
	Cause: [(1, 1), (1, 48)]
	Effect: [(0, 0), (0, 13)]

CASE: 89
Stag: 321 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Though not state-of-the-art, this result is close to the score of the u'\u201c' EEA u'\u201d' system of , as reported in Figure 2 of , \todo [author=jason,color=RedOrange,fancyline,size=,]so we lose slightly to EEA but EEA loses big to Yogotama which is specifically designed for the task of canonicalization
	Cause: [(0, 2), (0, 50)]
	Effect: [(0, 52), (0, 71)]

CASE: 90
Stag: 329 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: For instance, we see several instances of variation due to transliteration that were all correctly grouped together, such as Megawati Soekarnoputri and Megawati Sukarnoputri
	Cause: [(0, 11), (0, 25)]
	Effect: [(0, 0), (0, 8)]

CASE: 91
Stag: 331 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: We found that multiple samples tend to give different phylogenies (so the sampler is mobile), but essentially the same clustering into entities (which is why consensus clustering did not improve much over simply using the last sample
	Cause: [(0, 0), (0, 10)]
	Effect: [(0, 12), (0, 40)]

CASE: 92
Stag: 331 
	Pattern: 10 [['why']]---- [['&C', '(,/./;/--)', '(&AND)', '&THIS', '&BE'], ['&R']]
	sentTXT: We found that multiple samples tend to give different phylogenies (so the sampler is mobile), but essentially the same clustering into entities (which is why consensus clustering did not improve much over simply using the last sample
	Cause: [(0, 1), (0, 13)]
	Effect: [(0, 17), (0, 28)]

CASE: 93
Stag: 332 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Random restarts of EM might create more variety by choosing different locally optimal parameter settings
	Cause: [(0, 9), (0, 14)]
	Effect: [(0, 0), (0, 7)]

CASE: 94
Stag: 335 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: However, the true tree must include many names that fall outside our small observed corpora, so our model would be a more appropriate fit for a far larger corpus
	Cause: [(0, 0), (0, 15)]
	Effect: [(0, 18), (0, 30)]

CASE: 95
Stag: 336 
	Pattern: 0 [[['enable', 'enables', 'enabled']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@', '&TODO@R@']]
	sentTXT: Larger corpora also offer stronger signals that might enable our Monte Carlo methods to mix faster and detect regularities more accurately
	Cause: [(0, 0), (0, 5)]
	Effect: [(0, 9), (0, 20)]

CASE: 96
Stag: 345 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Note that in the base case where x is a leaf (so M = 0 ), this procedure terminates immediately, having printed the empty ordering
	Cause: [(0, 0), (0, 11)]
	Effect: [(0, 13), (0, 27)]

CASE: 97
Stag: 347 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using the Twitter 1% streaming API, we collected all tweets during the 2013 Grammy music awards ceremony, which occurred on Feb 10, 2013 between 8pm eastern (1:00am GMT) and 11:30pm (4:30 GMT
	Cause: [(0, 0), (0, 6)]
	Effect: [(0, 8), (0, 40)]

CASE: 98
Stag: 360 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the extracted mention was incorrect or referred to a non-person, it was removed
	Cause: [(0, 1), (0, 10)]
	Effect: [(0, 12), (0, 14)]

CASE: 99
Stag: 361 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If it was mostly correct, but omitted/excluded a token, the annotator corrected it
	Cause: [(0, 1), (0, 4)]
	Effect: [(0, 6), (0, 10)]

