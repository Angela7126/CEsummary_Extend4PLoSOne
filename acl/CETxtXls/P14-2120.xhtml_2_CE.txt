************************************************************
P14-2120.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: While prior works addressed such relationships as an extension to semantic role labeling , our work investigates them in the context of textual inference scenarios
	Cause: an extension to semantic role labeling , our work investigates them in the context of textual inference scenarios
	Effect: prior works addressed such relationships

CASE: 1
Stag: 19 20 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The task is to recognize whether the predicate-argument relationship , as expressed in the Hypothesis , holds implicitly also in the Text To address this task , we provide a large and freely available annotated dataset , and propose methods for coping with it
	Cause: expressed in the Hypothesis , holds implicitly also in the Text To address this task , we provide a large and freely available annotated dataset , and propose methods for coping with
	Effect: The task is to recognize whether the predicate-argument relationship

CASE: 2
Stag: 20 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: To address this task , we provide a large and freely available annotated dataset , and propose methods for coping with it
	Cause: coping with it
	Effect: To address this task , we provide a large and freely available annotated dataset , and propose methods

CASE: 3
Stag: 22 
	Pattern: 47 [['so'], ['that']]---- [['&C'], ['&adj/&adv@C@'], ['&R']]
	sentTXT: While the results reported so far on that annotation task were relatively low , we suggest that the task itself may be more complicated than what is actually required in textual inference scenarios
	Cause: While the results reported so far
	Effect: annotation task were relatively low , we suggest that the task itself may be more complicated than what is actually required in textual inference scenarios

CASE: 4
Stag: 22 23 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: While the results reported so far on that annotation task were relatively low , we suggest that the task itself may be more complicated than what is actually required in textual inference scenarios On the other hand , the results obtained for our task , which does fit textual inference scenarios , are promising , and encourage utilizing algorithms for this task in actual inference systems
	Cause: the results reported so far on that annotation task were relatively low , we suggest that the task itself may be more complicated than what is actually required in textual inference scenarios On the other hand
	Effect: task in actual inference systems

CASE: 5
Stag: 30 31 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Second , each NI should be classified as Definite NI -LRB- DNI -RRB- , meaning that the role filler must exist in the discourse , or Indefinite NI otherwise Third , the DNI fillers should be found -LRB- DNI linking
	Cause: Definite NI -LRB- DNI -RRB- , meaning that the role filler must exist in the discourse , or Indefinite NI otherwise Third , the DNI fillers should be found -LRB-
	Effect: Second , each NI should be classified

CASE: 6
Stag: 36 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Comparing to the implied SRL task , our task may better fit the needs of textual inference
	Cause: Comparing to the implied SRL task
	Effect: our task may better fit the needs of textual inference

CASE: 7
Stag: 37 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: First , some relatively complex steps of the implied SRL task are avoided in our setting , while on the other hand it covers more relevant cases
	Cause: some relatively complex steps of the
	Effect: SRL task are avoided in our setting , while on the other hand it covers more relevant cases

CASE: 8
Stag: 38 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: More concretely , in textual inference the candidate predicate and argument are typically identified , as they are aligned by the RTE system to a predicate and an argument of the Hypothesis
	Cause: they are aligned by the RTE system to a predicate and an argument of the Hypothesis
	Effect: in textual inference the candidate predicate and argument are typically identified

CASE: 9
Stag: 38 39 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: More concretely , in textual inference the candidate predicate and argument are typically identified , as they are aligned by the RTE system to a predicate and an argument of the Hypothesis Thus , the only remaining challenge is to verify that the sought relationship is implied in the text
	Cause: the candidate predicate and argument are typically identified , as they are aligned by the RTE system to a predicate and an argument of the Hypothesis
	Effect: , the only remaining challenge is to verify that the sought relationship is implied in the text

CASE: 10
Stag: 39 40 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Thus , the only remaining challenge is to verify that the sought relationship is implied in the text Therefore , the sub-tasks of identifying and classifying DNIs can be avoided
	Cause: Thus , the only remaining challenge is to verify that the sought relationship is implied in the text
	Effect: the sub-tasks of identifying and classifying DNIs can be avoided

CASE: 11
Stag: 44 45 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Another case is when an implied predicate-argument relationship holds even though the corresponding role is already filled by another argument , hence not an NI Consider example 1 of Table 1
	Cause: Another case is when an implied predicate-argument relationship holds even though the corresponding role is already filled by another argument
	Effect: not an NI Consider example 1 of Table 1

CASE: 12
Stag: 49 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: This section describes a semi-automatic method for extracting candidate instances of implied predicate-argument relationship from an RTE dataset
	Cause: extracting candidate instances of implied predicate-argument relationship from an RTE dataset
	Effect: This section describes a semi-automatic method

CASE: 13
Stag: 53 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Then , a human reader annotates each instance as u ' \ u201c ' Yes u ' \ u201d ' u ' \ u2013 ' meaning that the implied relationship indeed holds in the Text , or u ' \ u201c ' No u ' \ u201d ' otherwise
	Cause: u ' \ u201c ' Yes u ' \ u201d ' u ' \ u2013 ' meaning that the implied relationship indeed holds in the Text , or u '
	Effect: Then , a human reader annotates each instance

CASE: 14
Stag: 59 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By applying this method on the RTE-6 dataset -LSB- 1 -RSB- , we constructed a dataset of 4022 instances , where 2271 -LRB- 56 % -RRB- are annotated as positive instances , and 1751 as negative ones
	Cause: applying this method on the RTE-6 dataset
	Effect: -LSB- 1 -RSB- , we constructed a dataset of 4022 instances , where 2271 -LRB- 56 % -RRB- are annotated as positive instances , and 1751 as negative ones

CASE: 15
Stag: 66 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: These features do not depend on manually built resources , and hence are portable to resource-poor languages
	Cause: These features do not depend on manually built resources
	Effect: are portable to resource-poor languages

CASE: 16
Stag: 78 79 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: For example , example 1 in Table 1 includes the explicit relationship u ' \ u201c ' derailment of train u ' \ u201d ' , which might indicate the implied relationship u ' \ u201c ' crash of train u ' \ u201d ' Hence p = u ' \ u201c ' crash u ' \ u201d ' , a = u ' \ u201c ' train u ' \ u201d ' and p u ' \ u2032 ' = u ' \ u201c ' derailment u ' \ u201d '
	Cause: For example , example 1 in Table 1 includes the explicit relationship u ' \ u201c ' derailment of train u ' \ u201d ' , which might indicate the implied relationship u ' \ u201c ' crash of train u ' \ u201d '
	Effect: p = u ' \ u201c ' crash u ' \ u201d ' , a = u ' \ u201c ' train u ' \ u201d ' and p u ' \ u2032 ' = u ' \ u201c ' derailment u ' \ u201d '

CASE: 17
Stag: 80 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The Co-occurring predicate feature estimates the probability that a document would contain a as an argument of p , given that a appears elsewhere in that document as an argument of p u ' \ u2032 ' , based on explicit predicate-argument relationships in a large corpus
	Cause: an argument of p , given that a appears elsewhere in that document as an argument of p u ' \ u2032 ' , based
	Effect: The Co-occurring predicate feature estimates the probability that a document would contain a

CASE: 18
Stag: 82 83 
	Pattern: 2 [['accordingly']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: This is exemplified in example 1 of Table 1 , where p = u ' \ u201c ' renew u ' \ u201d ' , a = u ' \ u201c ' Patriot Act u ' \ u201d ' and a u ' \ u2032 ' = u ' \ u201c ' law u ' \ u201d ' Accordingly , the feature quantifies the probability that a document including the relationship p - a u ' \ u2032 ' would also include the relationship p - a
	Cause: This is exemplified in example 1 of Table 1 , where p = u ' \ u201c ' renew u ' \ u201d ' , a = u ' \ u201c ' Patriot Act u ' \ u201d ' and a u ' \ u2032 ' = u ' \ u201c ' law u ' \ u201d '
	Effect: the feature quantifies the probability that a document including the relationship p - a u ' \ u2032 ' would also include the relationship p - a

CASE: 19
Stag: 86 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since our task and dataset are novel , there is no direct baseline with which we can compare this result
	Cause: our task and dataset are novel
	Effect: there is no direct baseline with which we can compare this result

CASE: 20
Stag: 86 87 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Since our task and dataset are novel , there is no direct baseline with which we can compare this result As a reference point we mention the majority class proportion , and also report a configuration in which only features adopted from prior works -LRB- G C and S F -RRB- are utilized
	Cause: a reference point we mention the majority class proportion , and also report a configuration in which only features adopted from prior works -LRB- G C and S F -RRB- are utilized
	Effect: Since our task and dataset are novel , there is no direct baseline with which we can compare this result

CASE: 21
Stag: 88 89 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: This comparison shows that the contribution of our new features -LRB- 3 % -RRB- is meaningful , which is also statistically significant with p 0.01 using Bootstrap Resampling test -LSB- 11 -RSB- The high results show that this task is feasible , and its solutions can be adopted as a component in textual inference systems
	Cause: This comparison shows that the contribution of our new features -LRB- 3 % -RRB- is meaningful , which is also statistically significant with p 0.01 using Bootstrap Resampling test -LSB- 11 -RSB-
	Effect: task is feasible , and its solutions can be adopted as a component in textual inference systems

CASE: 22
Stag: 93 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: We ran three configurations for the second feature , where in the first only syntactically expressed relationships are used , in the second all the implied relationships , as detected by a human annotator , are added , and in the third only the implied relationships detected by our algorithm are added
	Cause: We ran three configurations for the second feature , where in the first only syntactically expressed relationships are used , in the second all the
	Effect: relationships , as detected by a human annotator , are added , and in the third only the implied relationships detected by our algorithm are added

CASE: 23
Stag: 104 105 
	Pattern: 2 [['accordingly']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: We point out that in textual inference scenarios the candidate predicate and argument are given by the Hypothesis , while the challenge is only to verify that a predicate-argument relationship between these candidates is implied from the given Text Accordingly , some complex steps necessitated in the SemEval task can be avoided , while additional relevant cases are covered
	Cause: We point out that in textual inference scenarios the candidate predicate and argument are given by the Hypothesis , while the challenge is only to verify that a predicate-argument relationship between these candidates is implied from the given Text
	Effect: some complex steps necessitated in the SemEval task can be avoided , while additional relevant cases are covered

CASE: 24
Stag: 110 111 
	Pattern: 9 [['consequently']]---- [['&C', '(,/;/./--)'], ['(,)', '&R']]
	sentTXT: Similarly , candidate arguments , which match either the expected answer type or other arguments in the question are detected too Consequently , our methods which exploit the availability of the candidate predicate and argument can be adapted to this scenario as well
	Cause: Similarly , candidate arguments , which match either the expected answer type or other arguments in the question are detected too
	Effect: our methods which exploit the availability of the candidate predicate and argument can be adapted to this scenario as well

CASE: 25
Stag: 112 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Similarly , a typical approach for Event Extraction -LRB- a sub task of Information Extraction -RRB- is to start by applying an entity extractor , which identifies argument candidates
	Cause: applying an entity extractor , which identifies argument candidates
	Effect: Similarly , a typical approach for Event Extraction -LRB- a sub task of Information Extraction -RRB- is to start

CASE: 26
Stag: 112 113 
	Pattern: 2 [['accordingly']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Similarly , a typical approach for Event Extraction -LRB- a sub task of Information Extraction -RRB- is to start by applying an entity extractor , which identifies argument candidates Accordingly , candidate predicate and arguments are detected in this scenario too , while the remaining challenge is to assess the likelihood that a predicate-argument relationship holds between them
	Cause: Similarly , a typical approach for Event Extraction -LRB- a sub task of Information Extraction -RRB- is to start by applying an entity extractor , which identifies argument candidates
	Effect: candidate predicate and arguments are detected in this scenario too , while the remaining challenge is to assess the likelihood that a predicate-argument relationship holds between them

CASE: 27
Stag: 115 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: An additional direction for future work is to further develop new methods for our task , possibly by incorporating SRL resources and/or linguistically oriented rules , in order to improve the results we achieved so far
	Cause: incorporating SRL resources and/or linguistically oriented rules
	Effect: , in order to improve the results we achieved so far

