************************************************************
P14-2004.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 4 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To analyze and maintain dialog topics from a more systematic perspective in a given dialog flow, some researchers [ 12 , 8 , 1 ] have considered this dialog topic identification as a separate sub-problem of dialog management and attempted to solve it with text categorization approaches for the recognized utterances in a given turn
	Cause: [(0, 33), (0, 55)]
	Effect: [(0, 0), (0, 31)]

CASE: 1
Stag: 7 8 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: However, the dialog topic at each turn can be determined not only by the user u'\u2019' s intentions captured from the given utterances, but also by the system u'\u2019' s decisions for dialog management purposes Thus, the text categorization approaches can only be effective for the user-initiative cases when users tend to mention the topic-related expressions explicitly in their utterances
	Cause: [(0, 0), (0, 44)]
	Effect: [(1, 1), (1, 25)]

CASE: 2
Stag: 10 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: These knowledge-based methods have an advantage of dealing with system-initiative dialogs, because dialog flows can be controlled by the system based on given resources
	Cause: [(0, 13), (0, 24)]
	Effect: [(0, 0), (0, 10)]

CASE: 3
Stag: 10 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: These knowledge-based methods have an advantage of dealing with system-initiative dialogs, because dialog flows can be controlled by the system based on given resources
	Cause: [(0, 10), (0, 11)]
	Effect: [(0, 0), (0, 7)]

CASE: 4
Stag: 12 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for each specific domain
	Cause: [(0, 23), (0, 35)]
	Effect: [(0, 0), (0, 20)]

CASE: 5
Stag: 12 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for each specific domain
	Cause: [(0, 8), (0, 20)]
	Effect: [(0, 0), (0, 6)]

CASE: 6
Stag: 14 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Composite kernels have been successfully applied to improve the performances in other NLP problems [ 17 , 16 ] by integrating multiple individual kernels, which aim to overcome the errors occurring at one level by information from other levels
	Cause: [(0, 20), (0, 39)]
	Effect: [(0, 0), (0, 18)]

CASE: 7
Stag: 15 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Our composite kernel consists of a history sequence and a domain context tree kernels, both of which are composed based on similar textual units in Wikipedia articles to a given dialog context
	Cause: [(0, 22), (0, 32)]
	Effect: [(0, 0), (0, 19)]

CASE: 8
Stag: 16 17 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Dialog topic tracking can be considered as a classification problem to detect topic transitions The most probable pair of topics at just before and after each turn is predicted by the following classifier f u'\u2062' ( x t ) = ( y t - 1 , y t ) , where x t contains the input features obtained at a turn t , y t u'\u2208' C , and C is a closed set of topic categories
	Cause: [(0, 7), (1, 28)]
	Effect: [(0, 0), (0, 5)]

CASE: 9
Stag: 18 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If a topic transition occurs at t , y t should be different from y t - 1
	Cause: [(0, 1), (0, 6)]
	Effect: [(0, 8), (0, 17)]

CASE: 10
Stag: 21 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: This conversation is divided into three segments, since f detects three topic transitions at t 1 , t 4 and t 6
	Cause: [(0, 9), (0, 22)]
	Effect: [(0, 0), (0, 6)]

CASE: 11
Stag: 24 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Although some fundamental features extracted from the utterances mentioned at a given turn or in a certain number of previous turns can be used for training the model, this information obtained solely from an ongoing dialog is not sufficient to identify not only user-initiative, but also system-initiative topic transitions
	Cause: [(0, 25), (0, 27)]
	Effect: [(0, 0), (0, 23)]

CASE: 12
Stag: 29 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Both represent the current dialog context at a given turn with a set of relevant Wikipedia paragraphs which are selected based on the cosine similarity between the term vectors of the recently mentioned utterances and each paragraph in the Wikipedia collection as follows
	Cause: [(0, 22), (0, 42)]
	Effect: [(0, 0), (0, 19)]

CASE: 13
Stag: 31 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: The term vector for the input x , u'\u03a6' u'\u2062' ( x ) , is computed by accumulating the weights in the previous turns as follows
	Cause: [(0, 25), (0, 30)]
	Effect: [(0, 31), (0, 33)]

CASE: 14
Stag: 32 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: where u'\u0391' i = u'\u2211' j = 0 h ( u'\u039b' j u'\u22c5' t u'\u2062' f u'\u2062' i u'\u2062' d u'\u2062' f u'\u2062' ( w i , u ( t - j ) ) ) , u t is the utterance mentioned in a turn t , t u'\u2062' f u'\u2062' i u'\u2062' d u'\u2062' f u'\u2062' ( w i , u t ) is the product of term frequency of a word w i in u t and inverse document frequency of w i , u'\u039b' is a decay factor for giving more importance to more recent turns
	Cause: [(0, 152), (0, 158)]
	Effect: [(0, 0), (0, 150)]

CASE: 15
Stag: 33 34 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: W is the size of word dictionary, and h is the number of previous turns considered as dialog history features After computing this relatedness between the current dialog context and every paragraph in the Wikipedia collection, two kernel structures are constructed using the information obtained from the highly-ranked paragraphs in the Wikipedia
	Cause: [(0, 18), (1, 32)]
	Effect: [(0, 2), (0, 16)]

CASE: 16
Stag: 38 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since our hypothesis is that the more similar the dialog histories of the two inputs are, the more similar aspects of topic transtions occur for them, we propose a sub-sequence kernel [ 11 ] to map the data into a new feature space defined based on the similarity of each pair of history sequences as follows
	Cause: [(0, 1), (0, 15)]
	Effect: [(0, 17), (0, 43)]

CASE: 17
Stag: 46 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since this constructed tree structure represents semantic, discourse, and structural information extracted from the similar Wikipedia paragraphs to each given instance, we can explore these more enriched features to build the topic tracking model using a subset tree kernel [ 5 ] which computes the similarity between each pair of trees in the feature space as follows
	Cause: [(0, 1), (0, 6)]
	Effect: [(0, 8), (0, 56)]

CASE: 18
Stag: 48 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: In this work, a composite kernel is defined by combining the individual kernels including history sequence and domain context tree kernels, as well as the linear kernel between the vectors representing fundamental features extracted from the utterances themselves and the results of linguistic preprocessors
	Cause: [(0, 10), (0, 45)]
	Effect: [(0, 0), (0, 8)]

CASE: 19
Stag: 54 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since we aim at developing the system which acts as a guide communicating with tourist users, an instance for both training and prediction of topic transition was created for each turn of tourists
	Cause: [(0, 1), (0, 15)]
	Effect: [(0, 17), (0, 33)]

CASE: 20
Stag: 57 58 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Then, the history sequence and tree context structures for our composite kernel were constructed based on 3,155 articles related to Singapore collected from Wikipedia database dump as of February 2013 For the linear kernel baseline, we used the following features n-gram words, previous system actions, and current user acts which were manually annotated
	Cause: [(0, 28), (1, 24)]
	Effect: [(0, 0), (0, 26)]

CASE: 21
Stag: 59 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Finally, 8,318 instances were used for training the model
	Cause: [(0, 7), (0, 9)]
	Effect: [(0, 0), (0, 5)]

CASE: 22
Stag: 60 61 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We trained the SVM models using SVM light 1 1 http://svmlight.joachims.org/ [ 7 ] with the following five different combinations of kernels K l only, K l with u'\ud835' u'\udcab' as features, K l + K s , K l + K t , and K l + K s + K t
	Cause: [(1, 18), (1, 38)]
	Effect: [(0, 1), (1, 16)]

CASE: 23
Stag: 65 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: When just the paragraph IDs were included as additional features, it failed to improve the performances from the baseline without any external features
	Cause: [(0, 8), (0, 23)]
	Effect: [(0, 1), (0, 6)]

CASE: 24
Stag: 69 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The error distributions in Figure 4 indicate that these performance improvements were achieved by resolving the errors not only on user-initiative topic transitions, but also on system-initiative cases, which implies the effectiveness of the structured knowledge from Wikipedia to track the topics in mixed-initiative dialogs
	Cause: [(0, 14), (0, 46)]
	Effect: [(0, 0), (0, 12)]

