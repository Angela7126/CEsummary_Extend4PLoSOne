************************************************************
P14-1103.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Specifically , we propose a non-parametric Bayesian model for learning phonological markedness constraints directly from the distribution of input-output mappings in an Optimality Theory -LRB- OT -RRB- setting
	Cause: learning phonological markedness constraints directly from the distribution of input-output mappings in an Optimality Theory -LRB- OT -RRB- setting
	Effect: Specifically , we propose a non-parametric Bayesian model

CASE: 1
Stag: 2 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: The model uses an Indian Buffet Process prior to learn the feature values used in the log-linear method , and is the first algorithm for learning phonological constraints without presupposing constraint structure
	Cause: learning phonological constraints without presupposing constraint structure
	Effect: The model uses an Indian Buffet Process prior to learn the feature values used in the log-linear method , and is the first algorithm

CASE: 2
Stag: 5 6 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Many aspects of human cognition involve the interaction of constraints that push a decision-maker toward different options , whether in something so trivial as choosing a movie or so important as a fight-or-flight response These constraint-driven decisions can be modeled with a log-linear system
	Cause: Many aspects of human cognition involve the interaction of constraints that push a decision-maker toward different options , whether in something
	Effect: trivial as choosing a movie or so important as a fight-or-flight response These constraint-driven decisions can be modeled with a log-linear

CASE: 3
Stag: 9 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We consider this question by examining the dominant framework in modern phonology , Optimality Theory -LSB- , OT -RSB- , implemented in a log-linear framework , MaxEnt OT -LSB- -RSB- , with output forms u ' \ u2019 ' probabilities based on a weighted sum of constraint violations
	Cause: a weighted sum of constraint violations
	Effect: We consider this question by examining the dominant framework in modern phonology , Optimality Theory -LSB- , OT -RSB- , implemented in a log-linear framework , MaxEnt OT -LSB- -RSB- , with output forms u ' \ u2019 ' probabilities

CASE: 4
Stag: 11 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We propose a new approach to learn constraints with limited innate phonological knowledge by identifying sets of constraint violations that explain the observed distributional data , instead of selecting constraints from an innate set of constraint definitions
	Cause: identifying sets of constraint violations that explain the observed distributional data , instead of selecting constraints from an innate set of constraint definitions
	Effect: We propose a new approach to learn constraints with limited innate phonological knowledge

CASE: 5
Stag: 12 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because the constraints are identified as sets of violations , this also permits constraints specific to a given language to be learned
	Cause: the constraints are identified as sets of violations
	Effect: this also permits constraints specific to a given language to be learned

CASE: 6
Stag: 23 24 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Previous OT work has focused on identifying the appropriate formulation of Eval and the values and acquisition of H , while taking Gen and Con as given Here , we expand the learning task by proposing an acquisition method for Con
	Cause: given Here , we expand the learning task by proposing an acquisition method for Con
	Effect: Previous OT work has focused on identifying the appropriate formulation of Eval and the values and acquisition of H , while taking Gen and Con

CASE: 7
Stag: 24 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Here , we expand the learning task by proposing an acquisition method for Con
	Cause: proposing an acquisition method for Con
	Effect: Here , we expand the learning task

CASE: 8
Stag: 28 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Although all OT systems share the same core structure , different choices of Eval lead to different behaviors
	Cause: different choices of Eval
	Effect: different behaviors

CASE: 9
Stag: 33 34 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Weights are always negative in OT ; a constraint violation can never make a candidate more likely to win . -RRB- For a given input-candidate pair -LRB- x , y -RRB- , f i u ' \ u2062 ' -LRB- y , x -RRB- is the number of violations of constraint C i by the pair As a maximum entropy model , the probability of y given x is proportional to the exponential of the weighted sum of violations , u ' \ u2211 ' i w i u ' \ u2062 ' f i u ' \ u2062 ' -LRB- y , x
	Cause: a maximum entropy model , the probability of y given x is proportional to the exponential of the weighted sum of violations , u ' \ u2211 ' i w i u ' \ u2062 ' f i u ' \ u2062 ' -LRB- y ,
	Effect: given input-candidate pair -LRB- x , y -RRB- , f i u ' \ u2062 ' -LRB- y , x -RRB- is the number of violations of constraint C i by the pair

CASE: 10
Stag: 35 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If u ' \ ud835 ' u ' \ udcb4 ' u ' \ u2062 ' -LRB- x -RRB- is the set of all output candidates for the input x , then the probability of y as the winning output is
	Cause: the winning output is
	Effect: udcb4 ' u ' \ u2062 ' -LRB- x -RRB- is the set of all output candidates for the input x , then the probability of y

CASE: 11
Stag: 40 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If constraints u ' \ u2019 ' weights are close together , multiple violations of lower-weighted constraints can reduce a candidate u ' \ u2019 ' s probability below that of a competitor with a single high-weight violation
	Cause: constraints u ' \ u2019 ' weights are close together
	Effect: multiple violations of lower-weighted constraints can reduce a candidate u ' \ u2019 ' s probability below that of a competitor with a single high-weight violation

CASE: 12
Stag: 41 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: As the distance between weights in MEOT increases , the probability of a suboptimal candidate being chosen approaches zero ; thus the traditional formulation is a limit case of MEOT
	Cause: As the distance between weights in MEOT increases , the probability of a suboptimal candidate being chosen approaches zero
	Effect: the traditional formulation is a limit case of MEOT

CASE: 13
Stag: 55 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: A white cell indicates no violation
	Cause: A white cell
	Effect: no violation

CASE: 14
Stag: 56 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: Grey stripes are overlaid on cells whose value will have a negligible impact on the distribution due to the values of higher-ranked constraint
	Cause: the values of higher-ranked constraint
	Effect: Grey stripes are overlaid on cells whose value will have a negligible impact on the distribution

CASE: 15
Stag: 61 62 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: In the \ textipa ete tableau at top left , output \ textipa ete has no violations , and therefore a score of zero Outputs \ textipa Ete and \ textipa etE violate both Harmony -LRB- weight 16 -RRB- and Parse -LSB- atr -RSB- -LRB- weight 8 -RRB- , so their scores are 24
	Cause: In the \ textipa ete tableau at top left , output \ textipa ete has no violations
	Effect: a score of zero Outputs \ textipa Ete and \ textipa etE violate both Harmony -LRB- weight 16 -RRB- and Parse -LSB- atr -RSB- -LRB- weight 8 -RRB- , so their scores are

CASE: 16
Stag: 62 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Outputs \ textipa Ete and \ textipa etE violate both Harmony -LRB- weight 16 -RRB- and Parse -LSB- atr -RSB- -LRB- weight 8 -RRB- , so their scores are 24
	Cause: Outputs \ textipa Ete and \ textipa etE violate both Harmony -LRB- weight 16 -RRB- and Parse -LSB- atr -RSB- -LRB- weight 8 -RRB-
	Effect: their scores are 24

CASE: 17
Stag: 63 64 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Output \ textipa EtE violates Parse -LSB- atr -RSB- , and has score 8 Thus the log-probability of output \ textipa EtE is 1/8 that of \ textipa ete , and the log-probability of disharmonious \ textipa Ete and \ textipa etE are each 1/24 that of \ textipa ete
	Cause: Output \ textipa EtE violates Parse -LSB- atr -RSB- , and has score 8
	Effect: the log-probability of output \ textipa EtE is 1/8 that of \ textipa ete , and the log-probability of disharmonious \ textipa Ete and \ textipa etE are each 1/24 that of \ textipa ete

CASE: 18
Stag: 64 65 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Thus the log-probability of output \ textipa EtE is 1/8 that of \ textipa ete , and the log-probability of disharmonious \ textipa Ete and \ textipa etE are each 1/24 that of \ textipa ete As the ratio between scores increases , the log-probability ratios can become arbitrarily close to zero , approximating the deterministic situation of traditional OT
	Cause: the ratio between scores increases , the log-probability ratios can become arbitrarily close to zero , approximating the deterministic situation of traditional OT
	Effect: the log-probability of output \ textipa EtE is 1/8 that of \ textipa ete , and the log-probability of disharmonious \ textipa Ete and \ textipa etE are each 1/24 that of \ textipa ete

CASE: 19
Stag: 74 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This version allows language-particular constraints , but it comes with a computational cost , as the learner must be able to generate and evaluate possible constraints while learning the language u ' \ u2019 ' s phonology
	Cause: the learner must be able to generate and evaluate possible constraints while learning the language u ' \ u2019 ' s phonology
	Effect: but it comes with a computational cost

CASE: 20
Stag: 76 77 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Depending on the specific formulation of the constraints , the constraint identification problem may even be NP-hard -LSB- -RSB- Our approach of casting the learning problem as one of identifying violation profiles is an attempt to determine the amount that can be learned about the active constraints in a paradigm without hypothesizing intensional constraint definitions
	Cause: one of identifying violation profiles is an attempt to determine the amount that can be learned about the active constraints in a paradigm without hypothesizing intensional constraint definitions
	Effect: on the specific formulation of the constraints , the constraint identification problem may even be NP-hard -LSB- -RSB- Our approach of casting the learning problem

CASE: 21
Stag: 84 85 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Even well-known constraint types , such as generalized alignment , can have disputed structures -LSB- -RSB- As such , it is unclear where a universal set of markedness constraints would come from
	Cause: such , it is unclear where a universal set of markedness constraints would come from
	Effect: well-known constraint types , such as generalized alignment , can have disputed structures -LSB- -RSB-

CASE: 22
Stag: 86 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The IBPOT model defines a generative process for mappings between input and output forms based on three latent variables the constraint violation matrices F -LRB- faithfulness -RRB- and M -LRB- markedness -RRB- , and the weight vector w
	Cause: three latent variables the constraint violation matrices F -LRB- faithfulness -RRB- and M -LRB- markedness -RRB- , and the weight vector w
	Effect: The IBPOT model defines a generative process for mappings between input and output forms

CASE: 23
Stag: 89 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Note that M is shared across inputs , as M j u ' \ u2062 ' l has the same value for all input-output pairs with output y j
	Cause: M j u ' \ u2062 ' l has the same value for all input-output pairs with output y j
	Effect: M is shared across inputs

CASE: 24
Stag: 95 96 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 2.4 , we assume that F is known as part of the output of Gen -LSB- -RSB- The goal of the IBPOT model is to learn the markedness matrix M and weights w for both the markedness and faithfulness constraints
	Cause: part of the output of Gen -LSB- -RSB- The goal of the IBPOT model is to learn the markedness matrix M and weights w for both the markedness and faithfulness
	Effect: 2.4 , we assume that F is known

CASE: 25
Stag: 96 97 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The goal of the IBPOT model is to learn the markedness matrix M and weights w for both the markedness and faithfulness constraints As for M , we need a non-parametric prior , as there is no inherent limit to the number of markedness constraints a language will use
	Cause: for M , we need a non-parametric prior , as there is no inherent limit to the number of markedness constraints a language will use
	Effect: The goal of the IBPOT model is to learn the markedness matrix M and weights w for both the markedness and faithfulness constraints

CASE: 26
Stag: 112 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: We begin by resampling M j u ' \ u2062 ' l for all represented constraints M u ' \ u22c5 ' l , conditioned on the rest of the violations -LRB- M - -LRB- j u ' \ u2062 ' l -RRB- , F -RRB- and the weights w
	Cause: resampling M j u ' \ u2062 ' l
	Effect: for all represented constraints M u ' \ u22c5 ' l , conditioned on the rest of the violations -LRB- M - -LRB- j u ' \ u2062 ' l -RRB- , F

CASE: 27
Stag: 120 
	Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
	sentTXT: Ideally , this would draw new constraints from the infinite feature matrix ; however , this requires marginalizing the likelihood over possible weights , and we lack an appropriate conjugate prior for doing so
	Cause: marginalizing the likelihood over possible weights
	Effect: , this would draw new constraints from the infinite feature matrix ; however

CASE: 28
Stag: 122 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We consider in each sample at most K * new constraints , with weights based on the auxiliary vector w *
	Cause: the auxiliary vector w *
	Effect: We consider in each sample at most K * new constraints , with weights

CASE: 29
Stag: 123 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This approximation retains the unbounded feature set of the IBP , as repeated sampling can add more and more constraints without limit
	Cause: repeated sampling can add more and more constraints without limit
	Effect: This approximation retains the unbounded feature set of the IBP

CASE: 30
Stag: 125 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the number of constraints removed is less than K * , w * is filled out with draws from the prior distribution over weights
	Cause: the number of constraints removed is less than K *
	Effect: w * is filled out with draws from the prior distribution over weights

CASE: 31
Stag: 133 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We test the model by learning the markedness constraints driving Wolof vowel harmony -LSB- -RSB-
	Cause: learning the markedness constraints driving Wolof vowel harmony -LSB- -RSB-
	Effect: We test the model

CASE: 32
Stag: 134 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Vowel harmony in general refers to a phonological phenomenon wherein the vowels of a word share certain features in the output form even if they do not share them in the input
	Cause: they do not share them in the input
	Effect: Vowel harmony in general refers to a phonological phenomenon wherein the vowels of a word share certain features in the output form even

CASE: 33
Stag: 149 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Under this ranking , Wolof harmony is achieved by changing a disharmonious ATR to an RTR , unless this creates an \ textipa I vowel
	Cause: changing a disharmonious ATR to an RTR
	Effect: , unless this creates an \ textipa I vowel

CASE: 34
Stag: 151 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: As in previous MEOT work , all Wolof candidates are faithful with respect to vowel height , either because height changes are not considered by Gen , or because of a high-ranked faithfulness constraint blocking height changes
	Cause: height changes are not considered by Gen
	Effect: or because of a high-ranked faithfulness constraint blocking height changes

CASE: 35
Stag: 153 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If unfaithful vowel heights were allowed by Gen , these unfaithful candidates would incur a violation approximately as strong as * \ textipa I , as neither unfaithful-height candidates nor \ textipa I candidates are attested in the Wolof data
	Cause: unfaithful vowel heights were allowed by Gen
	Effect: these unfaithful candidates would incur a violation approximately as strong as * \ textipa I , as neither unfaithful-height candidates nor \ textipa I candidates are attested in the Wolof data

CASE: 36
Stag: 154 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: The Wolof constraints provide an interesting testing ground for the model , because it is a small set of constraints to be learned , but contains the Harmony constraint , which can be violated by non-adjacent segments
	Cause: it is a small set of constraints to be learned
	Effect: but contains the Harmony constraint , which can be violated by non-adjacent segments

CASE: 37
Stag: 155 156 
	Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
	sentTXT: Non-adjacent constraints are difficult for string-based approaches because of the exponential number of possible relationships across non-adjacent segments However , the Wolof results show that by learning violations directly , IBPOT does not encounter problems with non-adjacent constraints
	Cause: Non-adjacent constraints are difficult for string-based approaches
	Effect: However , the Wolof results show that by learning violations directly , IBPOT does not encounter problems with non-adjacent constraints

CASE: 38
Stag: 156 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: However , the Wolof results show that by learning violations directly , IBPOT does not encounter problems with non-adjacent constraints
	Cause: learning violations directly
	Effect: , IBPOT does not encounter problems with non-adjacent constraints

CASE: 39
Stag: 159 160 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The outputs appear for multiple inputs , as shown in Figure 1 The candidate outputs are the four combinations of tongue-roots for the given vowel heights ; the inputs and candidates are known to the learner
	Cause: shown in Figure 1 The candidate outputs are the four combinations of tongue-roots for the given vowel heights ;
	Effect: The outputs appear for multiple inputs

CASE: 40
Stag: 161 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We generate simulated data by observing 1000 instances of the winning output for each input
	Cause: observing 1000 instances of the winning output for each input
	Effect: We generate simulated data

CASE: 41
Stag: 161 162 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: We generate simulated data by observing 1000 instances of the winning output for each input 6 6 Since data , matrix , and weight likelihoods all shape the learned constraints , there must be enough data for the model to avoid settling for a simple matrix that poorly explains the data
	Cause: data , matrix , and weight likelihoods all shape the learned constraints , there must be enough data for the model to avoid settling for a simple matrix that poorly explains the
	Effect: generate simulated data by observing 1000 instances of the winning output for each input 6 6

CASE: 42
Stag: 167 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This is necessary in the current model definition because the IBP produces a prior over binary matrices
	Cause: the IBP produces a prior over binary matrices
	Effect: This is necessary in the current model definition

CASE: 43
Stag: 177 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: This is done so that the IBPOT weights and phonological standard weights are learned by the same process and can be compared
	Cause: This is done
	Effect: the IBPOT weights and phonological standard weights are learned by the same process and can be compared

CASE: 44
Stag: 178 179 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: We use the same parameters for this baseline as for the IBPOT tests The results in this section are based on nine runs each of IBPOT and MEOT ; ten MEOT runs were performed but one failed to converge and was removed from analysis
	Cause: We use the same parameters for this baseline as for the IBPOT tests
	Effect: section are based on nine runs each of IBPOT and MEOT ; ten MEOT runs were performed but one failed to converge and was removed from analysis

CASE: 45
Stag: 187 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: All eight differences are significant according to t - tests over the nine runs
	Cause: t
	Effect: All eight differences are significant

CASE: 46
Stag: 189 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The most important differences are those in the data probabilities , as the matrix and weight probabilities are reflective primarily of the choice of prior
	Cause: the matrix and weight probabilities are reflective primarily of the choice of prior
	Effect: The most important differences are those in the data probabilities

CASE: 47
Stag: 196 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Turning to the form of these constraints , Figure 2 shows violation profiles from the last iteration of a representative IBPOT run
	Cause: Turning to the form of these constraints
	Effect: Figure 2 shows violation profiles from the last iteration of a representative IBPOT run

CASE: 48
Stag: 198 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because vowel heights must be faithful between input and output , the Wolof data is divided into nine separate paradigms , each containing the four candidates -LRB- ATR/RTR ATR/RTR -RRB- for the vowel heights in the input
	Cause: vowel heights must be faithful between input and output
	Effect: the Wolof data is divided into nine separate paradigms , each containing the four candidates -LRB- ATR/RTR ATR/RTR -RRB- for the vowel heights in the input

CASE: 49
Stag: 199 200 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: The violations on a given output form only affect probabilities within its paradigm As a result , learned constraints are consistent within paradigms , but across paradigms , the same constraint may serve different purposes
	Cause: The violations on a given output form only affect probabilities within its paradigm
	Effect: learned constraints are consistent within paradigms , but across paradigms , the same constraint may serve different purposes

CASE: 50
Stag: 201 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For instance , the strongest learned markedness constraint , shown as M1 in Figure 2 , has the same violations as the top-ranked constraint that actively distinguishes between candidates in each paradigm
	Cause: M1 in Figure 2 , has the same violations as the top-ranked constraint that actively distinguishes between candidates in each paradigm
	Effect: instance , the strongest learned markedness constraint , shown

CASE: 51
Stag: 204 205 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Instead , it learns that M1 has the same violations as Harmony , which is the highest-weighted constraint that distinguishes between candidates in these paradigms Thus in the high-vowel paradigms , M1 serves as * \ textipa I , while in the low/mid-vowel paradigms , it serves as Harmony
	Cause: Harmony , which is the highest-weighted constraint that distinguishes between candidates in these paradigms Thus in the high-vowel paradigms , M1 serves as * \ textipa I , while in the low/mid-vowel paradigms , it serves as
	Effect: Instead , it learns that M1 has the same violations

CASE: 52
Stag: 204 205 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Instead , it learns that M1 has the same violations as Harmony , which is the highest-weighted constraint that distinguishes between candidates in these paradigms Thus in the high-vowel paradigms , M1 serves as * \ textipa I , while in the low/mid-vowel paradigms , it serves as Harmony
	Cause: Instead , it learns that M1 has the same violations as Harmony , which is the highest-weighted constraint that distinguishes between candidates in these paradigms
	Effect: in the high-vowel paradigms , M1 serves as * \ textipa I , while in the low/mid-vowel paradigms , it serves as Harmony

CASE: 53
Stag: 206 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The lower-weighted M2 is defined noisily , as the higher-ranked M1 makes some values of M2 inconsequential
	Cause: the higher-ranked M1 makes some values of M2 inconsequential
	Effect: The lower-weighted M2 is defined noisily

CASE: 54
Stag: 208 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because M1 has a much higher weight than M2 , a violation of M2 has a negligible effect on a candidate u ' \ u2019 ' s probability
	Cause: M1 has a much higher weight than M2
	Effect: a violation of M2 has a negligible effect on a candidate u ' \ u2019 ' s probability

CASE: 55
Stag: 210 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: 2 , if the losing candidate violates M1 , its probability changes from 10 - 12 when the preferred candidate does not violate M2 to 10 - 8 when it does
	Cause: the losing candidate violates M1
	Effect: its probability changes from 10 - 12 when the preferred candidate does not violate M2 to 10 - 8 when it does

CASE: 56
Stag: 215 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: On the non-high paradigms , the meaning of M2 is unclear , as Harmony is handled by M1 and * \ textipa I is unviolated
	Cause: Harmony is handled by M1 and
	Effect: On the non-high paradigms , the meaning of M2 is unclear

CASE: 57
Stag: 216 217 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In all four paradigms , the model learns that the RTR-RTR candidate violates M2 and the ATR-ATR candidate does not ; this appears to be the model u ' \ u2019 ' s attempt to reinforce a pattern in the lowest-ranked faithfulness constraint -LRB- Parse -LSB- atr -RSB- -RRB- , which the ATR-ATR candidate never violates Thus , while the IBPOT constraints are not identical to the phonologically standard ones , they reflect a version of the standard constraints that is consistent with the IBPOT framework
	Cause: In all four paradigms , the model learns that the RTR-RTR candidate violates M2 and the ATR-ATR candidate does not ; this appears to be the model u ' \ u2019 ' s attempt to reinforce a pattern in the lowest-ranked faithfulness constraint -LRB- Parse -LSB- atr -RSB- -RRB- , which the ATR-ATR candidate never violates
	Effect: , while the IBPOT constraints are not identical to the phonologically standard ones , they reflect a version of the standard constraints that is consistent with the IBPOT framework

CASE: 58
Stag: 218 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 9 9 In fact , it appears this constraint organization is favored by IBPOT as it allows for lower weights , hence the large difference in w log-probability in Table 1
	Cause: it allows for lower weights , hence the large difference in w log-probability in Table 1
	Effect: 9 9 In fact , it appears this constraint organization is favored by IBPOT

CASE: 59
Stag: 223 224 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The model u ' \ u2019 ' s ability to infer constraint violation profiles without theoretical constraint structure provides an alternative solution to the problems of the traditionally innate and universal OT constraint set As it jointly learns constraints and weights , the IBPOT model calls to mind Hayes and Wilson u ' \ u2019 ' s -LSB- -RSB- joint phonotactic learner
	Cause: it jointly learns constraints and weights , the IBPOT model calls to mind Hayes and Wilson u ' \ u2019 '
	Effect: The model u ' \ u2019 ' s ability to infer constraint violation profiles without theoretical constraint structure provides an alternative solution to the problems of the traditionally innate and universal OT constraint set

CASE: 60
Stag: 226 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This limits their learner in practice by the rapid explosion in the number of constraints as the maximum constraint definition size grows
	Cause: the maximum constraint definition size grows
	Effect: This limits their learner in practice by the rapid explosion in the number of constraints

CASE: 61
Stag: 232 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: IBPOT , as proposed here , learns constraints based on binary violation profiles , defined extensionally
	Cause: binary violation profiles
	Effect: defined extensionally

CASE: 62
Stag: 242 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Non-binarity can be handled by using the binary matrix M to indicate whether a candidate violates a constraint , with a second distribution determining the number of violations
	Cause: using the binary matrix M to indicate whether a candidate violates a constraint , with a second distribution determining the number of violations
	Effect: Non-binarity can be handled

CASE: 63
Stag: 243 244 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Alternately , a binary matrix can directly capture non-binary constraints ; converted existing non-binary constraints into a binary OT system by representing non-binary constraints as a set of equally-weighted overlapping constraints , each accounting for one violation The non-binary harmony constraint , for instance , becomes a set -LCB- * -LRB- at least one disharmony -RRB- , * -LRB- at least two disharmonies -RRB- , etc. . -RCB-
	Cause: a set of equally-weighted overlapping constraints , each accounting for one violation The non-binary harmony constraint , for instance , becomes a set -LCB- * -LRB- at least one disharmony -RRB- , * -LRB- at least two disharmonies -RRB- , etc. .
	Effect: Alternately , a binary matrix can directly capture non-binary constraints ; converted existing non-binary constraints into a binary OT system by representing non-binary constraints

