************************************************************
P14-1064.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this work , we present a semi-supervised graph-based approach for generating new translation rules that leverages bilingual and monolingual data
	Cause: generating new translation rules that leverages bilingual and monolingual data
	Effect: In this work , we present a semi-supervised graph-based approach

CASE: 1
Stag: 14 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Our work introduces a new take on the problem using graph-based semi-supervised learning to acquire translation rules and probabilities by leveraging both monolingual and parallel data resources
	Cause: leveraging both monolingual and parallel data resources
	Effect: Our work introduces a new take on the problem using graph-based semi-supervised learning to acquire translation rules and probabilities

CASE: 2
Stag: 15 16 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: On the source side , labeled phrases -LRB- those with known translations -RRB- are extracted from bilingual corpora , and unlabeled phrases are extracted from monolingual corpora ; together they are embedded as nodes in a graph , with the monolingual data determining edge strengths between nodes -LRB- 2.2 Unlike previous work -LSB- 11 , 22 -RSB- , we use higher order n - grams instead of restricting to unigrams , since our approach goes beyond OOV mitigation and can enrich the entire translation model by using evidence from monolingual text
	Cause: nodes in a graph , with the monolingual data determining edge strengths between nodes -LRB- 2.2 Unlike previous work -LSB- 11 , 22 -RSB- , we use higher order n - grams instead of restricting to unigrams , since our approach goes beyond OOV mitigation and can enrich
	Effect: known translations -RRB- are extracted from bilingual corpora , and unlabeled phrases are extracted from monolingual corpora ; together they are embedded

CASE: 3
Stag: 16 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Unlike previous work -LSB- 11 , 22 -RSB- , we use higher order n - grams instead of restricting to unigrams , since our approach goes beyond OOV mitigation and can enrich the entire translation model by using evidence from monolingual text
	Cause: our approach goes beyond OOV mitigation and can enrich the entire translation model by using evidence from monolingual text
	Effect: Unlike previous work -LSB- 11 , 22 -RSB- , we use higher order n - grams instead of restricting to unigrams

CASE: 4
Stag: 16 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: our approach goes beyond OOV mitigation and can enrich the entire translation model by using evidence from monolingual text
	Cause: using evidence from monolingual text
	Effect: our approach goes beyond OOV mitigation and can enrich the entire translation model

CASE: 5
Stag: 29 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If a source phrase is found in the baseline phrase table it is called a labeled phrase its conditional empirical probability distribution over target phrases -LRB- estimated from the parallel data -RRB- is used as the label , and is subsequently never changed
	Cause: the label , and is subsequently never
	Effect: a source phrase is found in the baseline phrase table it is called a labeled phrase its conditional empirical probability distribution over target phrases -LRB- estimated from the parallel data -RRB- is used

CASE: 6
Stag: 31 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The label space is thus the phrasal translation inventory , and like the source side it can also be represented in terms of a graph , initially consisting of target phrase nodes from the parallel corpus
	Cause: The label space is
	Effect: the phrasal translation inventory , and like the source side it can also be represented in terms of a graph , initially consisting of target phrase nodes from the parallel

CASE: 7
Stag: 32 33 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: For the unlabeled phrases , the set of possible target translations could be extremely large -LRB- e.g. , , all target language n - grams Therefore , we first generate and fix a list of possible target translations for each unlabeled source phrase
	Cause: For the unlabeled phrases , the set of possible target translations could be extremely large -LRB- e.g. , , all target language n - grams
	Effect: we first generate and fix a list of possible target translations for each unlabeled source phrase

CASE: 8
Stag: 40 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: The generation component is based on the observation that for structured label spaces , such as translation candidates for source phrases in SMT , even similar phrases have slightly different labels -LRB- target translations
	Cause: the observation that for structured label spaces
	Effect: such as translation candidates for source phrases in SMT , even similar phrases have slightly different labels -LRB- target translations

CASE: 9
Stag: 41 42 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The exponential dependence of the sizes of these spaces on the length of instances is to blame Thus , the target phrase inventory from the parallel corpus may be inadequate for unlabeled instances
	Cause: The exponential dependence of the sizes of these spaces on the length of instances is to blame
	Effect: , the target phrase inventory from the parallel corpus may be inadequate for unlabeled instances

CASE: 10
Stag: 42 43 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Thus , the target phrase inventory from the parallel corpus may be inadequate for unlabeled instances We therefore need to enrich the target or label space for unknown phrases
	Cause: , the target phrase inventory from the parallel corpus may be inadequate for unlabeled instances We
	Effect: need to enrich the target or label space for unknown phrases

CASE: 11
Stag: 44 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: A na ve way to achieve this goal would be to extract all n - grams , from n = 1 to a maximum n - gram order , from the monolingual data , but this strategy would lead to a combinatorial explosion in the number of target phrases
	Cause: na ve way to achieve this goal would be to extract all n - grams , from n = 1 to a maximum n - gram order , from the monolingual data , but
	Effect: a combinatorial explosion in the number of target phrases

CASE: 12
Stag: 47 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We refer to these additional candidates as u ' \ u201c ' generated u ' \ u201d ' candidates
	Cause: u ' \ u201c ' generated u ' \ u201d '
	Effect: We refer to these additional candidates

CASE: 13
Stag: 52 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on these functions , source and target sequences of words can be mapped to sequences of stems
	Cause: these functions
	Effect: source and target sequences of words can be mapped to sequences of stems

CASE: 14
Stag: 53 54 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The morphological generation step adds to the target graph all target word sequences from the monolingual data that map to the same stem sequence as one of the target phrases occurring in the baseline phrase table In other words , this step adds phrases that are morphological variants of existing phrases , differing only in their affixes
	Cause: one of the target phrases occurring in the baseline phrase table In other words , this step adds phrases that are morphological variants of existing phrases ,
	Effect: The morphological generation step adds to the target graph all target word sequences from the monolingual data that map to the same stem sequence

CASE: 15
Stag: 56 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: To determine pairwise phrase similarities in order to embed these nodes in their graphs , we utilize the monolingual corpora on both the source and target sides to extract distributional features based on the context surrounding each phrase
	Cause: the context surrounding each phrase
	Effect: To determine pairwise phrase similarities in order to embed these nodes in their graphs , we utilize the monolingual corpora on both the source and target sides to extract distributional features

CASE: 16
Stag: 62 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 1 1 The q most frequent words in the monolingual corpus were removed as keys from this mapping , as these high entropy features do not provide much information
	Cause: keys from this mapping , as these high entropy features do not provide much
	Effect: 1 1 The q most frequent words in the monolingual corpus were removed

CASE: 17
Stag: 63 64 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The inverted index structure reduces the graph construction cost from u ' \ u0398 ' u ' \ u2062 ' -LRB- n 2 -RRB- , by only computing similarities for a subset of all possible pairs of phrases , namely other phrases that have at least one feature in common As mentioned previously , we construct and fix a set of translation candidates , i.e. , , the label set for each unlabeled source phrase
	Cause: mentioned previously , we construct and fix a set of translation candidates , i.e. , , the label
	Effect: The inverted index structure reduces the graph construction cost from u ' \ u0398 ' u ' \ u2062 ' -LRB- n 2 -RRB- , by only computing similarities for a subset of all possible pairs of phrases , namely other phrases that have at least one feature in common

CASE: 18
Stag: 70 71 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 1 , this source would yield the cat and cat , among others , as candidates The generated candidates for the unlabeled phrase u ' \ u2013 ' the ones from the baseline system u ' \ u2019 ' s decoder output , or from a morphological generator -LRB- e.g. , , a cat and catlike in Fig
	Cause: candidates The generated candidates for the unlabeled phrase u ' \ u2013 ' the ones from the baseline system u ' \ u2019 ' s decoder output ,
	Effect: this source would yield the cat and cat , among others

CASE: 19
Stag: 73 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The morphologically-generated candidates for a given source unlabeled phrase are initially defined as the target word sequences in the monolingual data that have the same stem sequence as one of the baseline u ' \ u2019 ' s target translations for a source phrase which has the same stem sequence as the unlabeled source phrase
	Cause: the target word sequences in the monolingual data that have the same stem sequence as one of the baseline u ' \ u2019 ' s target translations for a source phrase which has the same stem sequence as the unlabeled source phrase
	Effect: The morphologically-generated candidates for a given source unlabeled phrase are initially defined

CASE: 20
Stag: 78 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: A graph propagation algorithm transfers label information from labeled nodes to unlabeled nodes by following the graph u ' \ u2019 ' s structure
	Cause: following the graph u ' \ u2019 ' s structure
	Effect: A graph propagation algorithm transfers label information from labeled nodes to unlabeled nodes

CASE: 21
Stag: 83 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This quantity is also known as the propagation probability , and its exact form will depend on the type of graph propagation algorithm used
	Cause: the propagation probability , and its exact form will depend on the type of graph propagation algorithm
	Effect: This quantity is also known

CASE: 22
Stag: 84 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For our purposes , node f is a source phrasal node , the set u ' \ ud835 ' u ' \ udca9 ' u ' \ u2062 ' -LRB- f -RRB- refers to other source phrases that are neighbors of f -LRB- restricted to the k - nearest neighbors as in 2.2 -RRB- , and the aim is to estimate P -LRB- e f -RRB- , the probability of target phrase e being a phrasal translation of source phrase f
	Cause: in 2.2 -RRB- , and the aim is to estimate P -LRB- e f -RRB- , the probability of
	Effect: our purposes , node f is a source phrasal node , the set u ' \ ud835 ' u ' \ udca9 ' u ' \ u2062 ' -LRB- f -RRB- refers to other source phrases that are neighbors of f -LRB- restricted to the k - nearest neighbors

CASE: 23
Stag: 96 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: As a result , LP is suboptimal for our needs , since it is unable to appropriately handle generated translation candidates for the unlabeled phrases
	Cause: it is unable to appropriately handle generated translation candidates for the unlabeled phrases
	Effect: As a result , LP is suboptimal for our needs

CASE: 24
Stag: 97 98 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: These translation candidates are usually not present as translations for the labeled phrases -LRB- or for the labeled phrases that neighbor the unlabeled one in question When propagating information from the labeled phrases , such candidates will obtain no probability mass since e u ' \ u2260 ' e u ' \ u2032 '
	Cause: translations for the labeled phrases -LRB- or for the labeled phrases that neighbor the unlabeled one in question When propagating information from the labeled phrases , such candidates will obtain no probability mass since e u ' \ u2260 ' e u ' \
	Effect: These translation candidates are usually not present

CASE: 25
Stag: 98 99 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: When propagating information from the labeled phrases , such candidates will obtain no probability mass since e u ' \ u2260 ' e u ' \ u2032 ' Thus , due to the setup of the problem , LP naturally biases away from translation candidates produced during the generation step -LRB- 2.1
	Cause: e u ' \ u2260 ' e u ' \ u2032 ' Thus , due to the setup of the problem , LP naturally biases away from translation candidates produced during the
	Effect: When propagating information from the labeled phrases , such candidates will obtain no probability mass

CASE: 26
Stag: 98 99 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: When propagating information from the labeled phrases , such candidates will obtain no probability mass since e u ' \ u2260 ' e u ' \ u2032 ' Thus , due to the setup of the problem , LP naturally biases away from translation candidates produced during the generation step -LRB- 2.1
	Cause: When propagating information from the labeled phrases , such candidates will obtain no probability mass since e u ' \ u2260 ' e u ' \ u2032 '
	Effect: , due to the setup of the problem , LP naturally biases away from translation candidates produced during the generation step -LRB- 2.1

CASE: 27
Stag: 104 105 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: In particular , the definition of target similarity is similar to that of source similarity Therefore , the final update equation in SLP is
	Cause: In particular , the definition of target similarity is similar to that of source similarity
	Effect: the final update equation in SLP is

CASE: 28
Stag: 106 107 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: With this formulation , even if e u ' \ u2260 ' e u ' \ u2032 ' , the similarity T t -LRB- e u ' \ u2032 ' e -RRB- as determined by the target phrase graph will dictate propagation probability We re-normalize the probability distributions after each propagation step to sum to one over the fixed list of translation candidates , and run the SLP algorithm to convergence
	Cause: determined by the target phrase graph will dictate propagation probability We re-normalize the probability distributions after each propagation step to sum to one over the fixed list of translation candidates ,
	Effect: With this formulation , even if e u ' \ u2260 ' e u ' \ u2032 ' , the similarity T t -LRB- e u ' \ u2032 ' e -RRB-

CASE: 29
Stag: 113 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We utilize the graph propagation-estimated forward phrasal probabilities u ' \ u2119 ' -LRB- e f -RRB- as the forward likelihood probabilities for the acquired phrases ; to obtain the backward phrasal probability for a given phrase pair , we make use of Bayes u ' \ u2019 ' Theorem
	Cause: the forward likelihood probabilities for the acquired phrases ; to obtain the backward phrasal probability for a given phrase pair , we make use of Bayes u ' \ u2019 '
	Effect: We utilize the graph propagation-estimated forward phrasal probabilities u ' \ u2119 ' -LRB- e f -RRB-

CASE: 30
Stag: 126 127 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Baseline phrasal systems are used both for comparison and for generating translation candidates for unlabeled phrases as described in 2.1 The baseline is a state-of-the-art phrase-based system ; we perform word alignment using a lexicalized hidden Markov model , and then the phrase table is extracted using the grow-diag-final heuristic -LSB- 14 -RSB-
	Cause: described in 2.1 The baseline is a state-of-the-art phrase-based system ;
	Effect: Baseline phrasal systems are used both for comparison and for generating translation candidates for unlabeled phrases

CASE: 31
Stag: 133 134 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The NIST MT06 and MT08 Arabic-English evaluation sets -LRB- combining the newswire and weblog domains for both sets -RRB- , with four references each , were used as tuning and testing sets respectively For Urdu-English , the training corpus was provided by the LDC for the NIST Urdu-English MT evaluation , and most of the data was automatically acquired from the web , making it quite noisy
	Cause: tuning and testing sets respectively For Urdu-English , the training corpus was provided by the LDC for the NIST Urdu-English MT evaluation , and most
	Effect: The NIST MT06 and MT08 Arabic-English evaluation sets -LRB- combining the newswire and weblog domains for both sets -RRB- , with four references each , were used

CASE: 32
Stag: 141 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: In addition , we obtained a corpus from the ELRA 5 5 ELRA-W0038 , which contains a mix of parallel and monolingual data ; based on timestamps , we extracted a comparable English corpus for the ELRA Urdu monolingual data to form a roughly 470k-sentence u ' \ u201c ' noisy parallel u ' \ u201d ' set
	Cause: timestamps
	Effect: we extracted a comparable English corpus for the ELRA Urdu monolingual data to form a roughly 470k-sentence u ' \ u201c ' noisy parallel u ' \ u201d ' set

CASE: 33
Stag: 144 145 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In our first set of experiments , we looked at the impact of choosing bigrams over unigrams as our basic unit of representation , along with performance of LP -LRB- Eq 2 -RRB- compared to SLP -LRB- Eq
	Cause: our basic unit of representation , along with performance of LP -LRB- Eq 2 -RRB- compared
	Effect: In our first set of experiments , we looked at the impact of choosing bigrams over unigrams

CASE: 34
Stag: 147 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Recall that LP only takes into account source similarity ; since the vast majority of generated candidates do not occur as labeled neighbors u ' \ u2019 ' labels , restricting propagation to the source graph drastically reduces the usage of generated candidates as labels , but does not completely eliminate it
	Cause: the vast majority of generated candidates do not occur as labeled neighbors u ' \ u2019 ' labels
	Effect: restricting propagation to the source graph drastically reduces the usage of generated candidates as labels , but does not completely eliminate it

CASE: 35
Stag: 147 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: the vast majority of generated candidates do not occur as labeled neighbors u ' \ u2019 ' labels
	Cause: labeled neighbors u ' \ u2019 '
	Effect: the vast majority of generated candidates do not occur

CASE: 36
Stag: 147 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: restricting propagation to the source graph drastically reduces the usage of generated candidates as labels , but does not completely eliminate it
	Cause: restricting propagation to the source graph
	Effect: drastically reduces

CASE: 37
Stag: 149 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Table 4 presents the results of these variations ; overall , by taking into account generated candidates appropriately and using bigrams -LRB- u ' \ u201c ' SLP 2-gram u ' \ u201d ' -RRB- , we obtained a 1.13 BLEU gain on the test set
	Cause: taking into account generated candidates appropriately and using bigrams -LRB- u ' \ u201c ' SLP 2-gram u ' \ u201d ' -RRB-
	Effect: , we obtained a 1.13 BLEU gain on the test set

CASE: 38
Stag: 156 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We used a simple hand-built Arabic morphological analyzer that segments word types based on regular expressions , and an English lexicon-based morphological analyzer
	Cause: regular expressions , and
	Effect: We used a simple hand-built Arabic morphological analyzer that segments word types

CASE: 39
Stag: 157 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The morphological candidates add a small amount of improvement , primarily by targeting genuine OOVs
	Cause: targeting genuine OOVs
	Effect: The morphological candidates add a small amount of improvement , primarily

CASE: 40
Stag: 158 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: In this set of experiments , we examined if the improvements in 3.2 can be explained primarily through the extraction of language model characteristics during the semi-supervised learning phase , or through orthogonal pieces of evidence
	Cause: the improvements in 3.2 can be explained primarily through the extraction of language model characteristics during the semi-supervised learning phase , or through orthogonal pieces of evidence
	Effect: In this set of experiments , we examined

CASE: 41
Stag: 162 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Table 5 presents the results of using this language model
	Cause: Table 5 presents
	Effect: language model

CASE: 42
Stag: 164 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Further examination of the differences between the two systems yielded that most of the improvements are due to better bigrams and trigrams , as indicated by the breakdown of the BLEU score precision per n - gram , and primarily leverages higher quality generated candidates from the baseline system
	Cause: indicated by the breakdown of the BLEU score precision per n - gram , and primarily leverages higher quality generated candidates from the baseline system
	Effect: Further examination of the differences between the two systems yielded that most of the improvements are due to better bigrams and trigrams

CASE: 43
Stag: 164 
	Pattern: 7 [['due', 'to']]---- [['&V-ing/&NP@R@', '&BE'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Further examination of the differences between the two systems yielded that most of the improvements are due to better bigrams and trigrams
	Cause: better bigrams and trigrams
	Effect: most of the improvements

CASE: 44
Stag: 172 173 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: English monolingual u ' \ u201c ' En II Noisy Parallel u ' \ u201d ' + u ' \ u201c ' En II Non-Comparable u ' \ u201d ' The results from this setup are presented as u ' \ u201c ' Baseline u ' \ u201d ' and u ' \ u201c ' SLP+N oisy u ' \ u201d ' in Table 6
	Cause: English monolingual u ' \ u201c ' En II Noisy Parallel u ' \ u201d ' + u ' \ u201c ' En II Non-Comparable u ' \ u201d '
	Effect: setup are presented as u ' \ u201c ' Baseline u ' \ u201d ' and u ' \ u201c ' SLP+N oisy u ' \ u201d ' in Table 6

CASE: 45
Stag: 177 178 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: English monolingual u ' \ u201c ' En II Non-Comparable u ' \ u201d ' The results from this setup are presented as u ' \ u201c ' Baseline + Noisy u ' \ u201d ' and u ' \ u201c ' SLP u ' \ u201d ' in Table 6
	Cause: English monolingual u ' \ u201c ' En II Non-Comparable u ' \ u201d '
	Effect: setup are presented as u ' \ u201c ' Baseline + Noisy u ' \ u201d ' and u ' \ u201c ' SLP u ' \ u201d ' in Table 6

CASE: 46
Stag: 179 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The two setups allow us to examine how effectively our method can learn from the noisy parallel data by treating it as monolingual -LRB- i.e. , , for graph construction -RRB- , compared to treating this data as parallel , and also examines the realistic scenario of using completely non-comparable monolingual text for graph construction as in the second setup
	Cause: monolingual -LRB- i.e. , , for graph construction -RRB- , compared to treating this data as parallel , and also examines the realistic scenario of using completely non-comparable monolingual text for graph construction as in the second setup
	Effect: The two setups allow us to examine how effectively our method can learn from the noisy parallel data by treating it

CASE: 47
Stag: 188 189 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The third and fourth examples represent bigram phrases with much better translations compared to backing off to the lexical translations as in the baseline The fifth Arabic-English example demonstrates the pitfalls of over-reliance on the distributional hypothesis the source bigram corresponding to the name u ' \ u201c ' abd almahmood u ' \ u201d ' is distributional similar to another named entity u ' \ u201c ' mahmood u ' \ u201d ' and the English equivalent is offered as a translation
	Cause: in the baseline The fifth Arabic-English example demonstrates the pitfalls of over-reliance on the distributional hypothesis the source bigram corresponding to the name u ' \ u201c ' abd almahmood u ' \ u201d ' is distributional similar to another named entity u ' \ u201c ' mahmood u ' \ u201d ' and
	Effect: The third and fourth examples represent bigram phrases with much better translations compared to backing off to the lexical translations

CASE: 48
Stag: 191 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The sixth example shows how morphological information can propose novel candidates an OOV word is broken down to its stem via the analyzer and candidates are generated based on the stem
	Cause: the stem
	Effect: The sixth example shows how morphological information can propose novel candidates an OOV word is broken down to its stem via the analyzer and candidates are generated

CASE: 49
Stag: 194 195 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: By leveraging the monolingual corpus to understand the context of this unlabeled bigram , we can utilize the graph structure to propose a syntactically correct form , also resulting in a more fluent and correct sentence as determined by the language model Examples 8 9 show cases where the baseline deletes words or translates them into more common words e.g. , , u ' \ u201c ' conversation u ' \ u201d ' to u ' \ u201c ' the u ' \ u201d ' , while our system proposes reasonable candidates
	Cause: determined by the language model Examples 8 9 show cases where the baseline deletes words or translates them into more common words e.g. , , u ' \ u201c ' conversation u ' \ u201d ' to u ' \ u201c '
	Effect: By leveraging the monolingual corpus to understand the context of this unlabeled bigram , we can utilize the graph structure to propose a syntactically correct form , also resulting in a more fluent and correct sentence

CASE: 50
Stag: 196 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The idea presented in this paper is similar in spirit to bilingual lexicon induction -LRB- BLI -RRB- , where a seed lexicon in two different languages is expanded with the help of monolingual corpora , primarily by extracting distributional similarities from the data using word context
	Cause: extracting distributional similarities from the data using word context
	Effect: The idea presented in this paper is similar in spirit to bilingual lexicon induction -LRB- BLI -RRB- , where a seed lexicon in two different languages is expanded with the help of monolingual corpora , primarily

CASE: 51
Stag: 197 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This line of work , initiated by Rapp -LRB- 1995 -RRB- and continued by others -LSB- 7 , 13 -RSB- -LRB- inter alia -RRB- is limited from a downstream perspective , as translations for only a small number of words are induced and oftentimes for common or frequently occurring ones only
	Cause: translations for only a small number of words are induced and oftentimes for common or frequently occurring ones only
	Effect: This line of work , initiated by Rapp -LRB- 1995 -RRB- and continued by others -LSB- 7 , 13 -RSB- -LRB- inter alia -RRB- is limited from a downstream perspective

CASE: 52
Stag: 198 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Recent improvements to BLI -LSB- 24 , 10 -RSB- have contained a graph-based flavor by presenting label propagation-based approaches using a seed lexicon , but evaluation is once again done on top-1 or top-3 accuracy , and the focus is on unigrams
	Cause: presenting label propagation-based approaches using a seed lexicon
	Effect: , but evaluation is once again done on top-1 or top-3 accuracy , and the focus is on unigrams

CASE: 53
Stag: 200 201 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 2013 -RRB- and Irvine and Callison-Burch -LRB- 2013 -RRB- conduct a more extensive evaluation of their graph-based BLI techniques , where the emphasis and end-to-end BLEU evaluations concentrated on OOVs , i.e. , , unigrams , and not on enriching the entire translation model As with previous BLI work , these approaches only take into account source-side similarity of words ; only moderate gains -LRB- and in the latter work , on a subset of language pairs evaluated -RRB- are obtained
	Cause: with previous BLI work , these approaches only take into account source-side similarity of words ; only moderate gains -LRB- and in the latter work , on a subset of language pairs evaluated -RRB-
	Effect: emphasis and end-to-end BLEU evaluations concentrated on OOVs , i.e. , , unigrams , and not on enriching the entire translation model

CASE: 54
Stag: 201 202 
	Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
	sentTXT: As with previous BLI work , these approaches only take into account source-side similarity of words ; only moderate gains -LRB- and in the latter work , on a subset of language pairs evaluated -RRB- are obtained Additionally , because of our structured propagation algorithm , our approach is better at handling multiple translation candidates and does not need to restrict itself to the top translation
	Cause: with previous BLI work , these approaches only take into account source-side similarity of words ; only moderate gains -LRB- and in the latter work , on a subset of language pairs evaluated -RRB- are obtained Additionally
	Effect: , our approach is better at handling multiple translation candidates and does not need to restrict itself to the top translation

CASE: 55
Stag: 206 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: In our case , we obtain the phrase pairs from the graph structure -LRB- and therefore indirectly from the monolingual data -RRB- and a separate generation step , which plays an important role in good performance of the method
	Cause: In our case , we obtain the phrase pairs from the graph structure -LRB-
	Effect: indirectly from the monolingual data -RRB- and a separate generation step , which plays an important role in good performance of the

CASE: 56
Stag: 212 213 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However , the former work operates only at the level of sentences , and while the latter does extend the framework to sub-spans of sentences , they do not discover new translation pairs or phrasal probabilities for new pairs at all , but instead re-estimate phrasal probabilities using the graph structure and add this score as an additional feature during decoding The goal of leveraging non-parallel data in machine translation has been explored from several different angles
	Cause: an additional feature during decoding The goal of leveraging non-parallel data in machine translation has been explored from several different
	Effect: , and while the latter does extend the framework to sub-spans of sentences , they do not discover new translation pairs or phrasal probabilities for new pairs at all , but instead re-estimate phrasal probabilities using the graph structure and add this score

