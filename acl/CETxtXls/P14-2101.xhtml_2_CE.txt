************************************************************
P14-2101.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: The automatic labelling of such topics derived from social media poses however new challenges since topics may characterise novel events happening in the real world
	Cause: topics may characterise novel events happening in the real world
	Effect: The automatic labelling of such topics derived from social media poses however new challenges

CASE: 1
Stag: 2 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Existing automatic topic labelling approaches which depend on external knowledge sources become less applicable here since relevant articles/concepts of the extracted topics may not exist in external sources
	Cause: relevant articles/concepts of the extracted topics may not exist in external sources
	Effect: Existing automatic topic labelling approaches which depend on external knowledge sources become less applicable here

CASE: 2
Stag: 10 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: This task has been approached by investigating methodologies for identifying meaningful topics through semantic coherence -LSB- 1 , 24 , 27 -RSB- and for characterising the semantic content of a topic through automatic labelling techniques -LSB- 12 , 14 , 22 -RSB-
	Cause: identifying meaningful topics through semantic coherence -LSB- 1 , 24 , 27 -RSB-
	Effect: This task has been approached by investigating methodologies

CASE: 3
Stag: 13 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The most generic approach to automatic labelling has been to use as primitive labels the top - n words in a topic distribution learned by a topic model such as LDA -LSB- 9 , 2 -RSB-
	Cause: primitive labels the top - n words in a topic distribution learned by a topic model such as LDA -LSB- 9 ,
	Effect: The most generic approach to automatic labelling has been to use

CASE: 4
Stag: 15 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This task can be illustrated by considering the following topic derived from social media related to Education
	Cause: considering the following topic derived from social media related to Education
	Effect: This task can be illustrated

CASE: 5
Stag: 17 18 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: where the top 10 words ranked by P -LRB- w i t j -RRB- for this topic are listed Therefore the task is to find the top - n terms which are more representative of the given topic
	Cause: where the top 10 words ranked by P -LRB- w i t j -RRB- for this topic are listed
	Effect: the task is to find the top - n terms which are more representative of the given

CASE: 6
Stag: 20 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: However previous work has shown that top terms are not enough for interpreting the coherent meaning of a topic -LSB- 22 -RSB-
	Cause: interpreting the coherent meaning of a topic
	Effect: However previous work has shown that top terms are not enough

CASE: 7
Stag: 21 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: More recent approaches have explored the use of external sources -LRB- e.g. , Wikipedia , WordNet -RRB- for supporting the automatic labelling of topics by deriving candidate labels by means of lexical -LSB- 14 , 21 , 22 -RSB- or graph-based -LSB- 12 -RSB- algorithms applied on these sources
	Cause: supporting the automatic labelling of topics by deriving candidate labels by means of lexical -LSB- 14 , 21 , 22 -RSB- or graph-based -LSB- 12 -RSB- algorithms applied on these sources
	Effect: More recent approaches have explored the use of external sources -LRB- e.g. , Wikipedia , WordNet -RRB-

CASE: 8
Stag: 26 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: -LSB- 15 -RSB- proposed to label topics by selecting top - n terms to label the overall topic based on different ranking mechanisms including pointwise mutual information and conditional probabilities
	Cause: different ranking mechanisms including pointwise mutual information and conditional probabilities
	Effect: -LSB- 15 -RSB- proposed to label topics by selecting top - n terms to label the overall topic

CASE: 9
Stag: 26 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: -LSB- 15 -RSB- proposed to label topics by selecting top - n terms to label the overall topic
	Cause: selecting top
	Effect: - n terms to label the overall topic

CASE: 10
Stag: 30 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: -LSB- 14 -RSB- generated label candidates for a topic based on top-ranking topic terms and titles of Wikipedia articles
	Cause: top-ranking topic terms and titles of Wikipedia articles
	Effect: -LSB- 14 -RSB- generated label candidates for a topic

CASE: 11
Stag: 31 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: They then built a Support Vector Regression -LRB- SVR -RRB- model for ranking the label candidates
	Cause: ranking the label candidates
	Effect: They then built a Support Vector Regression -LRB- SVR -RRB- model

CASE: 12
Stag: 36 37 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In nature micropost content is sparse and present ill-formed words Moreover , the use of Twitter as the u ' \ u201c ' what u ' \ u2019 ' s-happening-right now u ' \ u201d ' tool , introduces new event-dependent relations between words which might not have a counter part in existing knowledge sources -LRB- e.g. , Wikipedia
	Cause: the u ' \ u201c ' what u ' \ u2019 ' s-happening-right now u ' \ u201d ' tool , introduces new event-dependent relations between words which might not have a counter part in existing knowledge sources -LRB-
	Effect: nature micropost content is sparse and present ill-formed words Moreover , the use of Twitter

CASE: 13
Stag: 38 39 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Our original interest in labelling topics stems from work in topic model based event extraction from social media , in particular from tweets -LSB- 32 , 6 -RSB- As opposed to previous approaches , the research presented in this paper addresses the labelling of topics exposing event-related content that might not have a counter part on existing external sources
	Cause: opposed to previous approaches , the research presented in this paper addresses the labelling of topics
	Effect: Our original interest in labelling topics stems from work in topic model based event extraction from social media , in particular from tweets -LSB- 32 , 6 -RSB-

CASE: 14
Stag: 40 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Based on the observation that a short summary of a collection of documents can serve as a label characterising the collection , we propose to generate topic label candidates based on the summarisation of a topic u ' \ u2019 ' s relevant documents
	Cause: a label characterising the collection , we propose to generate topic label candidates based on the summarisation of a topic u ' \ u2019 ' s relevant documents
	Effect: a short summary of a collection of documents can serve

CASE: 15
Stag: 40 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: a label characterising the collection , we propose to generate topic label candidates based on the summarisation of a topic u ' \ u2019 ' s relevant documents
	Cause: the summarisation of a topic u ' \ u2019 ' s relevant documents
	Effect: a label characterising the collection , we propose to generate topic label candidates

CASE: 16
Stag: 43 44 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We propose to approach the topic labelling problem as a multi-document summarisation task The following describes our proposed framework to characterise documents relevant to a topic
	Cause: a multi-document summarisation task The following describes our proposed framework to characterise documents relevant to a
	Effect: We propose to approach the topic labelling problem

CASE: 17
Stag: 51 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Topics are interpreted using the top N terms ranked based on the marginal probability p -LRB- w i t j -RRB-
	Cause: the marginal probability p -LRB- w i t j -RRB-
	Effect: Topics are interpreted using the top N terms ranked

CASE: 18
Stag: 53 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We propose to generate topic label candidates by summarising topic relevant documents
	Cause: summarising topic relevant documents
	Effect: We propose to generate topic label candidates

CASE: 19
Stag: 55 56 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: In particular , the prominent topic of a document d can be found by Therefore given a topic k , a set of C documents related to this topic can be obtained via equation 1
	Cause: In particular , the prominent topic of a document d can be found by
	Effect: given a topic k , a set of C documents related to this topic can be obtained via equation 1

CASE: 20
Stag: 58 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We compare different summarisation algorithms based on their ability to provide a good label to a given topic
	Cause: their ability to provide a good label to a given topic
	Effect: We compare different summarisation algorithms

CASE: 21
Stag: 59 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: In particular we investigate the use of lexical features by comparing three different well-known multi-document summarisation algorithms against the top - n topic terms baseline
	Cause: comparing three different well-known multi-document summarisation algorithms against the top
	Effect: - n topic terms baseline

CASE: 22
Stag: 62 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: It then weights each sentence in the text -LRB- in our case a micropost -RRB- by computing the average probability of the words in the sentence
	Cause: computing the average probability of the words in the sentence
	Effect: It then weights each sentence in the text -LRB- in our case a micropost -RRB-

CASE: 23
Stag: 65 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: It is similar to SB , however rather than computing the initial word probabilities based on word frequencies it weights terms based on TFIDF
	Cause: TFIDF
	Effect: It is similar to SB , however rather than computing the initial word probabilities based on word frequencies it weights terms

CASE: 24
Stag: 65 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: It is similar to SB , however rather than computing the initial word probabilities based on word frequencies it weights terms
	Cause: word frequencies it weights terms
	Effect: It is similar to SB , however rather than computing the initial word probabilities

CASE: 25
Stag: 66 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In this case the document frequency is computed as the number of times a word appears in a micropost from the collection u ' \ ud835 ' u ' \ udc9e '
	Cause: the number of times a word appears in a micropost from the collection u ' \ ud835 ' u ' \ udc9e '
	Effect: In this case the document frequency is computed

CASE: 26
Stag: 68 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: This is a relevance based ranking algorithm -LSB- 4 -RSB- , which avoids redundancy in the documents used for generating a summary
	Cause: generating a summary
	Effect: This is a relevance based ranking algorithm -LSB- 4 -RSB- , which avoids redundancy in the documents used

CASE: 27
Stag: 71 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The relevance of a vertex -LRB- term -RRB- to the graph is computed based on global information recursively drawn from the whole graph
	Cause: global information recursively drawn from the whole graph
	Effect: The relevance of a vertex -LRB- term -RRB- to the graph is computed

CASE: 28
Stag: 73 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: The final score of a word is therefore not only dependent on the terms immediately connected to it but also on how these terms connect to others
	Cause: The final score of a word is
	Effect: not only dependent on the terms immediately connected to it but also on how these terms connect to

CASE: 29
Stag: 75 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Once a final score is calculated for each vertex of the graph , TextRank sorts the terms in a reverse order and provided the top T vertices in the ranking
	Cause: a final score is calculated for each vertex of the graph
	Effect: TextRank sorts the terms in a reverse order and provided the top T vertices in the ranking

CASE: 30
Stag: 87 88 
	Pattern: 5 [['due', 'to']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: However performing human evaluations of Social Media test sets comprising thousands of inputs become a difficult task This is due to both the corpus size , the diversity of event-related topics and the limited availability of domain experts
	Cause: both the corpus size , the diversity of event-related topics and the limited availability of domain experts
	Effect: However performing human evaluations of Social Media test sets comprising thousands of inputs become a difficult task

CASE: 31
Stag: 92 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since previous research has shown that headlines are good indicators of the main focus of a text , both in structure and content , and that they can act as a human produced abstract -LSB- 26 -RSB- , we used headlines as the GS labels of NW
	Cause: previous research has shown that headlines are good indicators of the main focus of a text
	Effect: both in structure and content , and that they can act as a human produced abstract -LSB- 26 -RSB- , we used headlines as the GS labels of NW

CASE: 32
Stag: 92 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: both in structure and content , and that they can act as a human produced abstract -LSB- 26 -RSB- , we used headlines as the GS labels of NW
	Cause: a human produced abstract -LSB- 26 -RSB- , we used headlines as the GS labels of NW
	Effect: they can act

CASE: 33
Stag: 93 94 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The News Corpus -LRB- NW -RRB- was collected during the same period of time as the TW corpus NW consists of a collection of news articles crawled from traditional news media -LRB- BBC , CNN , and New York Times -RRB- comprising over 77,000 articles which include supplemental metadata -LRB- e.g. , headline , author , publishing date
	Cause: the TW corpus NW consists of a collection of news articles crawled from traditional news media -LRB- BBC , CNN , and New York Times -RRB- comprising over 77,000 articles which include supplemental metadata -LRB- e.g. , headline , author , publishing
	Effect: The News Corpus -LRB- NW -RRB- was collected during the same period of time

CASE: 34
Stag: 96 97 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: The same preprocessing steps were performed on NW Therefore , following a similarity alignment approach we performed the steps oulined in Algorithm 3.2 for generating the GS topic labels of a topic in TW
	Cause: The same preprocessing steps were performed on NW
	Effect: following a similarity alignment approach we performed the steps oulined in Algorithm 3.2 for generating the GS topic labels of a topic in TW

CASE: 35
Stag: 99 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: \ ENSURE Gold standard topic label for each of the LDA topics for TW
	Cause: \
	Effect: Gold standard topic label for each of the LDA topics for TW

CASE: 36
Stag: 103 104 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: \ STATE Extract the headlines of news articles from u ' \ ud835 ' u ' \ udc9e ' N u ' \ u2062 ' W j and select the top x most frequent words as the gold standard label for topic t i in the TW set \ ENDFOR These steps can be outlined as follows
	Cause: the gold standard label for topic t i in the TW set \ ENDFOR These steps can be outlined as
	Effect: ' \ ud835 ' u ' \ udc9e ' N u ' \ u2062 ' W j and select the top x most frequent words

CASE: 37
Stag: 106 107 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The generated label was used as the gold standard label for the corresponding Twitter topic t i in the topic pair We compared the results of the summarisation techniques with the top terms -LRB- TT -RRB- of a topic as our baseline
	Cause: the gold standard label for the corresponding Twitter topic t i in the topic pair We compared the results of the summarisation techniques with the top terms -LRB- TT -RRB- of a topic as our
	Effect: The generated label was used

CASE: 38
Stag: 107 108 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We compared the results of the summarisation techniques with the top terms -LRB- TT -RRB- of a topic as our baseline These TT set corresponds to the top x terms ranked based on the probability of the word given the topic -LRB- p -LRB- w k -RRB- -RRB- from the topic model
	Cause: our baseline These TT set corresponds to the top x terms ranked based on the probability of the word given the topic -LRB- p -LRB- w k -RRB- -RRB- from the topic
	Effect: We compared the results of the summarisation techniques with the top terms -LRB- TT -RRB- of a topic

CASE: 39
Stag: 108 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: These TT set corresponds to the top x terms ranked based on the probability of the word given the topic -LRB- p -LRB- w k -RRB- -RRB- from the topic model
	Cause: the probability of the word given the topic -LRB- p -LRB- w k -RRB- -RRB- from the topic model
	Effect: These TT set corresponds to the top x terms ranked

CASE: 40
Stag: 113 114 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Figure 1 presents the ROUGE-1 performance of the summarisation approaches as the length x of the generated topic label increases We can see in all four categories that the SB and TFIDF approaches provide a better summarisation coverage as the length of the topic label increases
	Cause: the length x of the generated topic label increases We can see in all four categories that the SB and TFIDF approaches provide a better summarisation coverage as the length of the topic label
	Effect: Figure 1 presents the ROUGE-1 performance of the summarisation approaches

CASE: 41
Stag: 114 115 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We can see in all four categories that the SB and TFIDF approaches provide a better summarisation coverage as the length of the topic label increases In particular , in both the Education and Law Crime categories , both SB and TFIDF outperforms TT and TR by a large margin
	Cause: the length of the topic label increases In particular , in both the Education and Law Crime categories , both SB and TFIDF outperforms TT and TR by a large
	Effect: We can see in all four categories that the SB and TFIDF approaches provide a better summarisation coverage

CASE: 42
Stag: 126 127 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We can also notice that the GS labels generated from Newswire media presented in Table 2 appear on their own , to be good labels for the TW topics However as we described in the introduction we want to avoid relaying on external sources for the derivation of topic labels
	Cause: we described in the introduction we want to avoid relaying on external sources for the derivation of topic labels
	Effect: GS labels generated from Newswire media presented in Table 2 appear on their own , to be good labels for the TW topics However

CASE: 43
Stag: 129 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: This is an attractive property for automatically generating topic labels for tweets where their event-related content might not have a counter part on existing external sources
	Cause: automatically generating topic labels for tweets where their event-related content might not have a counter part on existing external sources
	Effect: This is an attractive property

CASE: 44
Stag: 132 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This experiment shows that existing summarisation techniques can be exploited to provide a better label of a topic , extending in this way a topic u ' \ u2019 ' s information by providing a richer context than top-terms
	Cause: providing a richer context than top-terms
	Effect: This experiment shows that existing summarisation techniques can be exploited to provide a better label of a topic , extending in this way a topic u ' \ u2019 ' s information

