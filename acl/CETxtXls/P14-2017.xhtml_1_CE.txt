************************************************************
P14-2017.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 3 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: The wide range of applications in which cognates prove useful attracted more and more attention on methods for detecting such related pairs of words
	Cause: [(0, 18), (0, 23)]
	Effect: [(0, 0), (0, 16)]

CASE: 1
Stag: 4 5 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: This task is most challenging for resource-poor languages, for which etymologically related information is not accessible Therefore, the research [ 17 , 25 , 16 ] focused on automatic identification of cognate pairs, starting from lists of known cognates
	Cause: [(0, 0), (0, 16)]
	Effect: [(1, 2), (1, 24)]

CASE: 2
Stag: 11 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Finally, in Section 5 we draw the conclusions of our study and describe our plans for extending the method
	Cause: [(0, 17), (0, 19)]
	Effect: [(0, 0), (0, 15)]

CASE: 3
Stag: 15 16 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input Various measures were investigated and compared [ 17 , 14 ] ; Levenshtein distance [ 22 ] , XDice [ 3 ] and the longest common subsequence ratio [ 24 ] are among the most frequently used metrics in this field
	Cause: [(0, 25), (1, 8)]
	Effect: [(0, 0), (0, 23)]

CASE: 4
Stag: 17 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Gomes and Lopes ( 2011 ) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words
	Cause: [(0, 14), (0, 25)]
	Effect: [(0, 0), (0, 12)]

CASE: 5
Stag: 18 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic
	Cause: [(0, 12), (0, 14)]
	Effect: [(0, 0), (0, 9)]

CASE: 6
Stag: 20 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Kondrak ( 2000 ) developed the ALINE system, which aligns words u'\u2019' phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming
	Cause: [(0, 21), (0, 30)]
	Effect: [(0, 0), (0, 18)]

CASE: 7
Stag: 26 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2013 ) proposed a method for cognate production relying on statistical character-based machine translation, learning orthographic production patterns, and Mulloni ( 2007 ) introduced an algorithm for cognate production based on edit distance alignment and the identification of orthographic cues when words enter a new language
	Cause: [(0, 33), (0, 47)]
	Effect: [(0, 0), (0, 30)]

CASE: 8
Stag: 30 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: We assume that rules for adapting foreign words to the orthographic system of the target languages might not have been very well defined in their period of early development, but they may have since become complex and probably language-specific
	Cause: [(0, 35), (0, 39)]
	Effect: [(0, 26), (0, 33)]

CASE: 9
Stag: 31 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Detecting pairs of cognates based on etymology is useful and reliable, but, for resource-poor languages, methods which require less linguistic knowledge might be necessary
	Cause: [(0, 6), (0, 10)]
	Effect: [(0, 12), (0, 26)]

CASE: 10
Stag: 32 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to Gusfield ( 1997 ) , an edit transcript (representing the conversion of one string to another) and an alignment are mathematically equivalent ways of describing relationships between strings
	Cause: [(0, 2), (0, 5)]
	Effect: [(0, 7), (0, 31)]

CASE: 11
Stag: 32 33 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: According to Gusfield ( 1997 ) , an edit transcript (representing the conversion of one string to another) and an alignment are mathematically equivalent ways of describing relationships between strings Therefore, because the edit distance was widely used in this research area and produced good results, we are encouraged to employ orthographic alignment for identifying pairs of cognates, not only to compute similarity scores, as was previously done, but to use aligned subsequences as features for machine learning algorithms
	Cause: [(0, 0), (0, 31)]
	Effect: [(1, 2), (1, 53)]

CASE: 12
Stag: 34 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Our intuition is that inferring language-specific rules for aligning words will lead to better performance in the task of cognate identification
	Cause: [(0, 4), (0, 9)]
	Effect: [(0, 13), (0, 20)]

CASE: 13
Stag: 35 36 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: String alignment is closely related to the task of sequence alignment in computational biology Therefore, to align pairs of words we employ the Needleman-Wunsch global alignment algorithm [ 29 ] , which is mainly used for aligning sequences of proteins or nucleotides
	Cause: [(0, 0), (0, 13)]
	Effect: [(1, 2), (1, 28)]

CASE: 14
Stag: 38 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The algorithm uses dynamic programming and, thus, guarantees to find the optimal alignment
	Cause: [(0, 0), (0, 5)]
	Effect: [(0, 8), (0, 14)]

CASE: 15
Stag: 39 40 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Its main idea is that any partial path of the alignment along the optimal path should be the optimal path leading up to that point Therefore, the optimal path can be determined by incremental extension of the optimal subpaths [ 31 ]
	Cause: [(0, 0), (0, 24)]
	Effect: [(1, 2), (1, 17)]

CASE: 16
Stag: 41 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For orthographic alignment, we consider words as input sequences and we use a very simple substitution matrix, which gives equal scores to all substitutions, disregarding diacritics (e.g.,, we ensure that e and Ã¨ are matched
	Cause: [(0, 8), (0, 39)]
	Effect: [(0, 0), (0, 6)]

CASE: 17
Stag: 42 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using aligned pairs of words as input, we extract features around mismatches in the alignments
	Cause: [(0, 0), (0, 6)]
	Effect: [(0, 8), (0, 13)]

CASE: 18
Stag: 50 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The second alternative leads to better performance, so we account for all mismatches
	Cause: [(0, 0), (0, 6)]
	Effect: [(0, 9), (0, 13)]

CASE: 19
Stag: 50 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: The second alternative leads to better performance, so we account for all mismatches
	Cause: [(0, 0), (0, 2)]
	Effect: [(0, 5), (0, 6)]

CASE: 20
Stag: 50 51 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The second alternative leads to better performance, so we account for all mismatches As for the length of the grams, we experiment with n u'\u2208' { 1 , 2 , 3 }
	Cause: [(1, 1), (1, 23)]
	Effect: [(0, 0), (0, 13)]

CASE: 21
Stag: 52 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We achieve slight improvements by combining n -grams, i.e.,, for a given n , we use all i -grams, where i u'\u2208' { 1 , u'\u2026' , n }
	Cause: [(0, 5), (0, 42)]
	Effect: [(0, 0), (0, 3)]

CASE: 22
Stag: 53 54 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In order to provide information regarding the position of the features, we mark the beginning and the end of the word with a $ symbol Thus, for the above-mentioned pair of cognates, (exhaustiv, esaustivo) , we extract the following features when n = 2
	Cause: [(0, 0), (0, 25)]
	Effect: [(1, 1), (1, 23)]

CASE: 23
Stag: 55 56 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: For identical features we account only once Therefore, because there is one feature ( xh s- ) which occurs twice in our example, we have 8 features for the pair (exhaustiv, esaustivo)
	Cause: [(0, 0), (0, 6)]
	Effect: [(1, 2), (1, 30)]

CASE: 24
Stag: 57 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use Naive Bayes as a baseline and we experiment with Support Vector Machines (SVMs) to learn orthographic changes and to discriminate between pairs of cognates and non-cognates
	Cause: [(0, 5), (0, 29)]
	Effect: [(0, 0), (0, 3)]

CASE: 25
Stag: 60 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use the radial basis function kernel (RBF), which can handle the case when the relation between class labels and attributes is non-linear, as it maps samples non-linearly into a higher dimensional space
	Cause: [(0, 28), (0, 31)]
	Effect: [(0, 0), (0, 25)]

CASE: 26
Stag: 69 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We discard pairs of words for which the forms across languages are identical (i.e.,, the Romanian word matrice and its Italian cognate pair matrice , having the same form), because these pairs do not provide any orthographic changes to be learned
	Cause: [(0, 35), (0, 45)]
	Effect: [(0, 0), (0, 32)]

CASE: 27
Stag: 71 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Finally, we obtain 445 pairs of cognates for Romanian-French 2 2 The number of pairs of cognates is much lower for French than for the other languages because there are numerous Romanian words which have French etymology and, in this paper, we do not consider these words to be cognate candidates
	Cause: [(0, 29), (0, 38)]
	Effect: [(0, 40), (0, 52)]

CASE: 28
Stag: 73 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because we need sets of approximately equal size for comparison across languages, we keep 400 pairs of cognates and 400 pairs of non-cognates for each pair of languages
	Cause: [(0, 1), (0, 11)]
	Effect: [(0, 13), (0, 28)]

CASE: 29
Stag: 85 86 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For Portuguese, both Naive Bayes and SVM misclassify more non-cognates as cognates than viceversa A possible explanation might be the occurrence, in the dataset, of more remotely related words, which are not labeled as cognates
	Cause: [(0, 12), (1, 22)]
	Effect: [(0, 0), (0, 10)]

CASE: 30
Stag: 88 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We investigate the performance of the method we propose in comparison to previous approaches for automatic detection of cognate pairs based on orthographic similarity
	Cause: [(0, 22), (0, 23)]
	Effect: [(0, 0), (0, 19)]

CASE: 31
Stag: 91 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In addition, we use SpSim [ 11 ] , which outperformed the longest common subsequence ratio and a similarity measure based on the edit distance in previous experiments
	Cause: [(0, 23), (0, 28)]
	Effect: [(0, 0), (0, 20)]

CASE: 32
Stag: 92 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To evaluate these metrics on our dataset, we use the same train/test sets as we did in our previous experiments and we follow the strategy described in [ 17 ]
	Cause: [(0, 15), (0, 21)]
	Effect: [(0, 0), (0, 13)]

CASE: 33
Stag: 93 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: First, we compute the pairwise distances between pairs of words for each orthographic metric individually, as a single feature 5 5 SpSim cannot be computed directly, as the other metrics, so we introduce an additional step in which we use 1/3 of the training set (only cognates are needed) to learn orthographic changes
	Cause: [(0, 0), (0, 33)]
	Effect: [(0, 36), (0, 59)]

CASE: 34
Stag: 93 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First, we compute the pairwise distances between pairs of words for each orthographic metric individually, as a single feature 5 5 SpSim cannot be computed directly, as the other metrics, so we introduce an additional step in which we use 1/3 of the training set (only cognates are needed) to learn orthographic changes
	Cause: [(0, 18), (0, 29)]
	Effect: [(0, 0), (0, 15)]

CASE: 35
Stag: 96 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In order to detect the best threshold for discriminating between cognates and non-cognates, we run a decision stump classifier (provided by Weka) on the training set for each pair of languages and for each metric
	Cause: [(0, 8), (0, 12)]
	Effect: [(0, 0), (0, 6)]

CASE: 36
Stag: 98 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using the best threshold value selected for each metric and pair of languages, we further classify the pairs of words in our test sets as cognates or non-cognates
	Cause: [(0, 0), (0, 12)]
	Effect: [(0, 14), (0, 28)]

