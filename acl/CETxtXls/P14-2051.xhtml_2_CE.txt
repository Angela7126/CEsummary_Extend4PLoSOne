************************************************************
P14-2051.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By providing an empirical measure of semantic similarity between words derived from lexical co-occurrences , distributional semantics not only reliably captures how the verbs in the distribution of a construction are related , but also enables the use of visualization techniques and statistical modeling to analyze the semantic development of a construction over time and identify the semantic determinants of syntactic productivity in naturally occurring data
	Cause: providing an empirical measure of semantic similarity between words derived from lexical co-occurrences
	Effect: , distributional semantics not only reliably captures how the verbs in the distribution of a construction are related , but also enables the use of visualization techniques and statistical modeling to analyze the semantic development of a construction over time and identify the semantic determinants of syntactic productivity in naturally occurring data

CASE: 1
Stag: 9 10 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: She typed her way to a promotion As reported by Israel , examples like -LRB- 1 -RRB- , in which the main verb describes the physical means whereby motion towards a goal is enabled , are attested as early as the 16 th century , but it was not until the 19 th century that examples like -LRB- 2 -RRB- started to appear , in which the action depicted by the verb provides a more indirect -LRB- and abstract -RRB- way of attaining the agent u ' \ u2019 ' s goal
	Cause: reported by Israel , examples like -LRB- 1 -RRB- , in which the main verb describes the physical means whereby motion towards a goal is enabled , are attested as early as the 16 th century , but it was not until the 19 th century that examples like -LRB- 2 -RRB- started to appear , in which the action depicted by the verb provides a more indirect -LRB- and abstract -RRB- way of attaining the agent u ' \ u2019 '
	Effect: She typed her way to a promotion

CASE: 2
Stag: 13 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Along these lines , Suttle and Goldberg -LSB- Suttle and Goldberg2011 , 1254 -RSB- posit a criterion of coverage , defined as u ' \ u201c ' the degree to which attested instances u ' \ u2018 ' cover u ' \ u2019 ' the category determined jointly by attested instances together with the target coinage u ' \ u201d '
	Cause: u ' \ u201c ' the degree to which attested instances u ' \ u2018 ' cover u ' \ u2019 ' the category determined jointly by attested instances together with the target coinage u ' \ u201d
	Effect: Along these lines , Suttle and Goldberg -LSB- Suttle and Goldberg2011 , 1254 -RSB- posit a criterion of coverage , defined

CASE: 3
Stag: 25 26 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The construction generally conveys an intensifying function -LRB- very broadly defined Thus , scare/surprise the hell out of means u ' \ u201c ' scare/surprise very much u ' \ u201d ' , and kick the hell out of means u ' \ u201c ' kick very hard u ' \ u201d '
	Cause: The construction generally conveys an intensifying function -LRB- very broadly defined
	Effect: , scare/surprise the hell out of means u ' \ u201c ' scare/surprise very much u ' \ u201d ' , and kick the hell out of means u ' \ u201c ' kick very hard u ' \ u201d '

CASE: 4
Stag: 37 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the corpus size varies slightly in each decade , the token frequencies are normalized per million words
	Cause: the corpus size varies slightly in each
	Effect: the token frequencies are normalized per million words

CASE: 5
Stag: 38 39 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: The construction is first attested in the corpus in the 1930s Since then , it has been steadily increasing in token frequency -LRB- to the exception of a sudden decrease in the 1990s
	Cause: then , it has been steadily increasing in token frequency -LRB- to the exception of a sudden decrease in the 1990s
	Effect: The construction is first attested in the corpus in the 1930s

CASE: 6
Stag: 43 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: To answer these questions , I will analyze the distribution of the construction from a semantic point of view by using a measure of semantic similarity derived from distributional information
	Cause: using a measure of semantic similarity derived from distributional information
	Effect: To answer these questions , I will analyze the distribution of the construction from a semantic point of view

CASE: 7
Stag: 45 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: One benefit of the distributional semantics approach is that it allows semantic similarity between words to be quantified by measuring the similarity in their distribution
	Cause: measuring the similarity in their distribution
	Effect: One benefit of the distributional semantics approach is that it allows semantic similarity between words to be quantified

CASE: 8
Stag: 47 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: A wide range of distributional information can be employed in vector-based models ; the present study uses the u ' \ u2018 ' bag of words u ' \ u2019 ' approach , which is based on the frequency of co-occurrence of words within a given context window
	Cause: the frequency of co-occurrence of words within a given context window
	Effect: A wide range of distributional information can be employed in vector-based models ; the present study uses the u ' \ u2018 ' bag of words u ' \ u2019 ' approach , which is

CASE: 9
Stag: 48 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to Sahlgren -LSB- Sahlgren2008 -RSB- , this kind of model captures to what extent words can be substituted for each other , which is a good measure of semantic similarity between verbs
	Cause: Sahlgren
	Effect: this kind of model captures to what extent words can be substituted for each other , which is a good measure of semantic similarity between

CASE: 10
Stag: 48 49 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: According to Sahlgren -LSB- Sahlgren2008 -RSB- , this kind of model captures to what extent words can be substituted for each other , which is a good measure of semantic similarity between verbs As it turns out , even this relatively coarse model captures semantic distinctions in the distribution of the hell - construction that make intuitive sense
	Cause: it turns out , even this relatively coarse model captures semantic distinctions in the distribution of the hell - construction that make intuitive sense
	Effect: words can be substituted for each other , which is a good measure of semantic similarity between verbs

CASE: 11
Stag: 52 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: This is , however , not as problematic as it might sound , since the meaning of the verbs under consideration are not likely to have changed considerably within the time frame of this study
	Cause: the meaning of the verbs under consideration are not likely to have changed considerably within the
	Effect: This is , however , not as problematic as it might sound

CASE: 12
Stag: 57 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Only the nouns , verbs , adjectives , and adverbs listed among the 5,000 most frequent words in the corpus were considered -LRB- to the exclusion of be , have , and do -RRB- , thus ignoring function words -LRB- articles , prepositions , conjunctions , etc. -RRB- and all words that did not make the top 5,000
	Cause: Only the nouns , verbs , adjectives , and adverbs listed among the 5,000 most frequent words in the corpus were considered -LRB- to the exclusion of be , have , and do -RRB-
	Effect: ignoring function words -LRB- articles , prepositions , conjunctions , etc. -RRB- and all words that did not make the top 5,000

CASE: 13
Stag: 58 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The co-occurrence matrix was transformed by applying a Point-wise Mutual Information weighting scheme , using the DISSECT toolkit -LSB- Dinu et al. 2013 -RSB- , to turn the raw frequencies into weights that reflect how distinctive a collocate is for a given target word with respect to the other target words under consideration
	Cause: applying a Point-wise Mutual Information weighting scheme , using the DISSECT toolkit -LSB- Dinu et al. 2013 -RSB- , to turn the raw frequencies into weights that reflect how distinctive a collocate is for a given target word with respect to the other target words under consideration
	Effect: The co-occurrence matrix was transformed

CASE: 14
Stag: 58 59 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: The co-occurrence matrix was transformed by applying a Point-wise Mutual Information weighting scheme , using the DISSECT toolkit -LSB- Dinu et al. 2013 -RSB- , to turn the raw frequencies into weights that reflect how distinctive a collocate is for a given target word with respect to the other target words under consideration The resulting matrix , which contains the distributional information -LRB- in 4,683 columns -RRB- for 92 verbs occurring in the hell - construction , constitutes the semantic space under consideration in this case study
	Cause: The co-occurrence matrix was transformed by applying a Point-wise Mutual Information weighting scheme , using the DISSECT toolkit -LSB- Dinu et al. 2013 -RSB- , to turn the raw frequencies into weights that reflect how distinctive a collocate is for a given target word with respect to the other target words under consideration
	Effect: case study

CASE: 15
Stag: 70 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: For convenience and ease of visualization , the verbs are color-coded according to four broad semantic groupings that were identified inductively by means of hierarchical clustering -LRB- using Ward u ' \ u2019 ' s criterion
	Cause: four broad semantic groupings that were identified inductively by means of hierarchical clustering -LRB- using Ward u ' \ u2019 ' s criterion
	Effect: For convenience and ease of visualization , the verbs are color-coded

CASE: 16
Stag: 71 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: 3 3 Another benefit of combining clustering and MDS stems from the fact that the latter often distorts the data when fitting the objects into two dimensions , in that some objects might have to be slightly misplaced if not all distance relations can be simultaneously complied with
	Cause: not all distance relations can be simultaneously complied with
	Effect: 3 3 Another benefit of combining clustering and MDS stems from the fact that the latter often distorts the data when fitting the objects into two dimensions , in that some objects might have to be slightly misplaced

CASE: 17
Stag: 72 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since cluster analysis operates with all 4,683 dimensions of the distributional space , it is more reliable than MDS , although it lacks the visual appeal of the latter
	Cause: cluster analysis operates with all 4,683 dimensions of the distributional
	Effect: it is more reliable than MDS , although it lacks the visual appeal of the latter

CASE: 18
Stag: 73 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By comparing the plots in Figure 2 , we can follow the semantic development of the hell - construction
	Cause: comparing the plots in Figure 2
	Effect: , we can follow the semantic development of the hell - construction

CASE: 19
Stag: 76 77 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: These two classes also correspond to the regions of the semantic domain that attract the most new members , and they constantly do so in all periods Outside of these two clusters , the semantic space is much more sparsely populated
	Cause: These two classes also correspond to the regions of the semantic domain that attract the most new members , and they constantly do
	Effect: in all periods Outside of these two clusters , the semantic space is much more sparsely

CASE: 20
Stag: 82 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Outside of the two identified domains of predilection , other classes never become important , assumedly because they do not receive a u ' \ u201c ' critical mass u ' \ u201d ' of items , and therefore attract new members more slowly
	Cause: Outside of the two identified domains of predilection , other classes never become important , assumedly because they do not receive a u ' \ u201c ' critical mass u ' \ u201d ' of items
	Effect: attract new members more slowly

CASE: 21
Stag: 82 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Outside of the two identified domains of predilection , other classes never become important , assumedly because they do not receive a u ' \ u201c ' critical mass u ' \ u201d ' of items
	Cause: they do not receive a u ' \ u201c ' critical mass u ' \ u201d ' of items
	Effect: Outside of the two identified domains of predilection , other classes never become important , assumedly

CASE: 22
Stag: 84 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: On the reasonable assumption that the semantic contribution of the construction did not change , and therefore that all verbs ever attested in it are equally plausible from a semantic point of view , the fact that some verbs joined the distribution later than others is in want of an explanation
	Cause: that the semantic contribution of the construction did not change
	Effect: that all verbs ever attested in it are equally plausible from a semantic point of view , the fact that some verbs joined the distribution later than others is in want of an explanation

CASE: 23
Stag: 86 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the semantic space around the novel item is dense , i.e. , , if there is a high number of similar items , the coinage will be very likely
	Cause: there is a high number of similar items
	Effect: the coinage will be very likely

CASE: 24
Stag: 91 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: The latter value decreases with space density -LRB- i.e. , , if there are many close neighbors -RRB- , and is therefore technically a measure of sparsity ; since cosine distances are between 0 and 1 , subtracting the mean distance from one returns a measure of density within the same boundaries
	Cause: The latter value decreases with space density -LRB- i.e. , , if there are many close neighbors -RRB- , and is
	Effect: technically a measure of sparsity ; since cosine distances are between 0 and 1 , subtracting the mean distance from one returns a measure of density within the same boundaries

CASE: 25
Stag: 91 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: The latter value decreases with space density -LRB- i.e. , , if there are many close neighbors -RRB- , and is
	Cause: there are many close neighbors -RRB-
	Effect: and is

CASE: 26
Stag: 91 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: technically a measure of sparsity ; since cosine distances are between 0 and 1 , subtracting the mean distance from one returns a measure of density within the same boundaries
	Cause: technically a measure of sparsity
	Effect: ; since cosine distances are between 0 and 1 , subtracting the mean distance from one returns a measure of density within the same boundaries

CASE: 27
Stag: 92 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This measure of density was used as a factor in logistic regression to predict the first occurrence of a verb in the construction , coded as the binary variable Occurrence , set to 1 for the first period in which the verb is attested in the construction , and to 0 for all preceding periods -LRB- later periods were discarded
	Cause: a factor in logistic regression to predict the first occurrence of a verb in the construction , coded as the binary variable Occurrence , set to 1 for the first period in which the verb is attested in the construction , and to 0 for all preceding periods -LRB- later periods were discarded
	Effect: This measure of density was used

CASE: 28
Stag: 96 
	Pattern: 1 [[['effect', 'effects'], 'of'], [['is', 'was']]]---- [['&ONE', '(&adj)'], ['&NP@C@'], ['&NP@R@']]
	sentTXT: For all values of N , we find a positive effect of Density , i.e. , , there is a positive relation between the measure of density and the probability of first occurrence of a verb in the construction
	Cause: Density , i.e.
	Effect: a positive relation between the measure of density and the probability of first occurrence of a verb in the construction

CASE: 29
Stag: 97 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: However , the effect is only significant for N u ' \ u2265 ' 7 ; hence , the hypothesis that space density increases the odds of a coinage occurs in the construction is supported for measures of density based on these values of N
	Cause: However , the effect is only significant for N u ' \ u2265 ' 7
	Effect: the hypothesis that space density increases the odds of a coinage occurs in the construction is supported for measures of density based on these values of N

CASE: 30
Stag: 97 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: the hypothesis that space density increases the odds of a coinage occurs in the construction is supported for measures of density based on these values of N
	Cause: these values of N
	Effect: the hypothesis that space density increases the odds of a coinage occurs in the construction is supported for measures of density

CASE: 31
Stag: 99 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This is arguably because a higher N helps to better discriminate between dense clusters where all items are close together from looser ones that consist of a few u ' \ u2018 ' core u ' \ u2019 ' items surrounded by more distant neighbors
	Cause: a higher N helps to better discriminate between dense clusters where all items are close together from looser ones that consist of a few u ' \ u2018 ' core u ' \ u2019 ' items surrounded by more distant neighbors
	Effect: This is arguably

CASE: 32
Stag: 100 101 
	Pattern: 0 [[['imply', 'implies', 'implied', 'mean', 'means', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: This result illustrates the role of type frequency in syntactic productivity a measure of density that is supported by a higher number of types makes better prediction than a measure supported by fewer types This means that productivity not only hinges on how the existing semantic space relates to the novel item , it also occurs more reliably when this relation is attested by more items
	Cause: This result illustrates the role of type frequency in syntactic productivity a measure of density that is supported by a higher number of types makes better prediction than a measure supported by fewer types
	Effect: that productivity not only hinges on how the existing semantic space relates to the novel item

CASE: 33
Stag: 102 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: These finding support the view that semantic density and type frequency , while they both positively influence syntactic productivity , do so in different ways density defines the necessary conditions for a new coinage to occur , while type frequency increases the confidence that this coinage is indeed possible
	Cause: These finding support the view that semantic density and type frequency , while they both positively influence syntactic productivity , do
	Effect: in different ways density defines the necessary conditions for a new coinage to occur , while type frequency increases the confidence that this coinage is indeed possible

CASE: 34
Stag: 106 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using multidimensional scaling and logistic regression , it was shown that the occurrence of new items throughout the history of the construction can be predicted by the density of the semantic space in the neighborhood of these items in prior usage
	Cause: Using multidimensional scaling and logistic regression
	Effect: it was shown that the occurrence of new items throughout the history of the construction can be predicted by the density of the semantic space in the neighborhood of these items in prior usage

