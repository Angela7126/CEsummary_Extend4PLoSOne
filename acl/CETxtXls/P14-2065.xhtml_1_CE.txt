************************************************************
P14-2065.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 4 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Verbs such as hit and like do not describe a change of state and so cannot appear in both forms
	Cause: [(0, 0), (0, 12)]
	Effect: [(0, 15), (0, 20)]

CASE: 1
Stag: 20 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: VerbNet (Kipper et al., 2008; based on Levin, 1993) lists over 6,000 verbs, categorized into 280 classes according to the syntactic frames they can appear in
	Cause: [(0, 10), (0, 10)]
	Effect: [(0, 12), (0, 30)]

CASE: 2
Stag: 20 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: VerbNet (Kipper et al., 2008; based on Levin, 1993) lists over 6,000 verbs, categorized into 280 classes according to the syntactic frames they can appear in
	Cause: [(0, 13), (0, 15)]
	Effect: [(0, 0), (0, 10)]

CASE: 3
Stag: 34 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: In principle, these judgments would come from naive annotators, since researchers u'\u2019' intuitions about subtle judgments may be unconsciously clouded by theoretical commitments [ 4 ]
	Cause: [(0, 12), (0, 31)]
	Effect: [(0, 0), (0, 9)]

CASE: 4
Stag: 35 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The Semantic Consistency Hypothesis would be supported if, within that database, predicates with the same syntactic properties were systematically related semantically
	Cause: [(0, 8), (0, 21)]
	Effect: [(0, 0), (0, 6)]

CASE: 5
Stag: 45 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Collecting data from naive subjects is even more laborious, particularly since the average Man on the Street is not necessarily equipped with metalinguistic concepts like caused change of state and propositional attitude
	Cause: [(0, 12), (0, 32)]
	Effect: [(0, 0), (0, 10)]

CASE: 6
Stag: 53 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: One significant challenge for any such project is first classifying verbs according to the syntactic frames they can appear in
	Cause: [(0, 13), (0, 19)]
	Effect: [(0, 0), (0, 10)]

CASE: 7
Stag: 53 54 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: One significant challenge for any such project is first classifying verbs according to the syntactic frames they can appear in Thus, at least initially, we are focusing on the 6,000+ verbs already cataloged in VerbNet
	Cause: [(0, 0), (0, 19)]
	Effect: [(1, 1), (1, 17)]

CASE: 8
Stag: 54 55 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Thus, at least initially, we are focusing on the 6,000+ verbs already cataloged in VerbNet As such, the VerbCorner Project is also verifying and validating the semantics currently encoded in VerbNet
	Cause: [(1, 1), (1, 16)]
	Effect: [(0, 0), (0, 17)]

CASE: 9
Stag: 56 57 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: VerbNet will be edited as necessary based on the empirical results Integration with VerbNet has additional benefits, since VerbNet itself is integrated with a variety of linguistic resources, such as PropBank and Penn TreeBank
	Cause: [(0, 5), (1, 23)]
	Effect: [(0, 0), (0, 3)]

CASE: 10
Stag: 57 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Integration with VerbNet has additional benefits, since VerbNet itself is integrated with a variety of linguistic resources, such as PropBank and Penn TreeBank
	Cause: [(0, 8), (0, 23)]
	Effect: [(0, 0), (0, 5)]

CASE: 11
Stag: 59 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: We selected semantic features of interest based on those most commonly cited in the linguistics literature, with a particular focus on those that u'\u2013' according to VerbNet u'\u2013' apply to many predicates
	Cause: [(0, 8), (0, 15)]
	Effect: [(0, 17), (0, 39)]

CASE: 12
Stag: 59 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: We selected semantic features of interest based on those most commonly cited in the linguistics literature, with a particular focus on those that u'\u2013' according to VerbNet u'\u2013' apply to many predicates
	Cause: [(0, 14), (0, 16)]
	Effect: [(0, 6), (0, 11)]

CASE: 13
Stag: 60 61 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Previous research has shown that humans find it easier to reason about real-world scenarios than make abstract judgments [ 3 ] Thus, for each feature (e.g.,, movement ), we converted the metalinguistic judgment ( u'\u201c' Does this verb entail movement on the part of some entity u'\u201d' ) into a real-world problem
	Cause: [(0, 0), (0, 20)]
	Effect: [(1, 1), (1, 43)]

CASE: 14
Stag: 68 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Previous work suggests that it is the semantic entailments that matter, particularly for explaining the syntactic behavior of verbs [ 10 ]
	Cause: [(0, 14), (0, 22)]
	Effect: [(0, 0), (0, 12)]

CASE: 15
Stag: 69 70 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The exact semantics associated with a verb may depend on its syntactic frame Thus Sally rolled the ball entails that somebody applied force to the ball (namely
	Cause: [(0, 0), (0, 12)]
	Effect: [(1, 1), (1, 13)]

CASE: 16
Stag: 71 72 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Sally), whereas The ball rolled does not Thus, we investigate the semantics of each verb in each syntactic frame available to it (as described by VerbNet
	Cause: [(0, 0), (0, 8)]
	Effect: [(1, 1), (1, 20)]

CASE: 17
Stag: 76 77 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Given the sheer scale of the project, data-collection is expected to take several years at least Thus, data-collection has been broken up into a series of phases
	Cause: [(0, 0), (0, 16)]
	Effect: [(1, 1), (1, 11)]

CASE: 18
Stag: 82 83 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Below, we summarize the main findings thus far In Phase 1 of the project, we focused on 11 verb classes (Table 3) comprising 641 verbs and seven different semantic entailments (Table 2
	Cause: [(0, 0), (0, 6)]
	Effect: [(0, 8), (1, 26)]

CASE: 19
Stag: 89 90 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Each task had been iteratively piloted and redesigned until inter-annotator reliability was acceptable, as described in a previous publication However, these pilot studies involved a small number of items which were coded by all annotators
	Cause: [(0, 15), (1, 16)]
	Effect: [(0, 0), (0, 12)]

CASE: 20
Stag: 92 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because we recruited large numbers of annotators, most of whom annotated only a few items, typical measures of inter-annotator agreement such as Cohen u'\u2019' s kappa are not easily calculated
	Cause: [(0, 1), (0, 6)]
	Effect: [(0, 8), (0, 35)]

CASE: 21
Stag: 96 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since there were typically 4 or more possible answers per item, inter-annotator agreement was well above chance
	Cause: [(0, 1), (0, 10)]
	Effect: [(0, 12), (0, 17)]

CASE: 22
Stag: 102 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In fact, annotators frequently flagged these items as ungrammatical, which is a valuable result in itself for improving VerbNet
	Cause: [(0, 19), (0, 20)]
	Effect: [(0, 0), (0, 17)]

CASE: 23
Stag: 103 104 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We next investigated whether our results support the Semantic Consistency Hypothesis As noted above, the question is not whether all verbs in the same syntactic class share the same semantic entailments
	Cause: [(1, 1), (1, 16)]
	Effect: [(0, 0), (0, 10)]

CASE: 24
Stag: 105 106 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Even a single verb may have different semantic entailments when placed in different syntactic frames Thus, calculating consistency of a class must take differing frames into account
	Cause: [(0, 0), (0, 14)]
	Effect: [(1, 1), (1, 12)]

CASE: 25
Stag: 107 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: There are many sophisticated rubrics for calculating consistency
	Cause: [(0, 6), (0, 7)]
	Effect: [(0, 0), (0, 4)]

CASE: 26
Stag: 115 116 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The consistency for this class/frame combination is 60% The consistency for the class as a whole is the average across frames
	Cause: [(1, 6), (1, 12)]
	Effect: [(0, 1), (1, 4)]

CASE: 27
Stag: 118 119 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Mean consistency averaged across classes is shown for each task in Table 2 As expected, consistency was lowest for Evaluation , which is not expected to necessarily correlate with syntax
	Cause: [(1, 1), (1, 17)]
	Effect: [(0, 0), (0, 12)]

