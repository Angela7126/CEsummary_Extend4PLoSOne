************************************************************
P14-1065.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 3 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Rather than proposing a single new metric , we show that discourse information is complementary to the state-of-the-art evaluation metrics , and thus should be taken into account in the development of future richer evaluation metrics
	Cause: Rather than proposing a single new metric , we show that discourse information is complementary to the state-of-the-art evaluation metrics
	Effect: should be taken into account in the development of future richer evaluation metrics

CASE: 1
Stag: 4 5 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: From its foundations , Statistical Machine Translation -LRB- SMT -RRB- had two defining characteristics first , translation was modeled as a generative process at the sentence-level Second , it was purely statistical over words or word sequences and made little to no use of linguistic information
	Cause: a generative process at the sentence-level Second , it was purely statistical over words or word sequences and made little to no use of linguistic
	Effect: From its foundations , Statistical Machine Translation -LRB- SMT -RRB- had two defining characteristics first , translation was modeled

CASE: 2
Stag: 6 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Although modern SMT systems have switched to a discriminative log-linear framework , which allows for additional sources as features , it is generally hard to incorporate dependencies beyond a small window of adjacent words , thus making it difficult to use linguistically-rich models
	Cause: Although modern SMT systems have switched to a discriminative log-linear framework , which allows for additional sources as features , it is generally hard to incorporate dependencies beyond a small window of adjacent words
	Effect: making it difficult to use linguistically-rich

CASE: 3
Stag: 6 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Although modern SMT systems have switched to a discriminative log-linear framework , which allows for additional sources as features , it is generally hard to incorporate dependencies beyond a small window of adjacent words
	Cause: features , it is generally hard to incorporate dependencies beyond a small window of adjacent words
	Effect: modern SMT systems have switched to a discriminative log-linear framework , which allows for additional sources

CASE: 4
Stag: 7 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Recently , there have been two promising research directions for improving SMT and its evaluation a -RRB- by using more structured linguistic information , such as syntax -LSB- -RSB- , hierarchical structures -LSB- -RSB- , and semantic roles -LSB- -RSB- , and -LRB- b -RRB- by going beyond the sentence-level , e.g. , , translating at the document level -LSB- -RSB-
	Cause: improving SMT and its evaluation a -RRB- by using more structured linguistic information , such as syntax -LSB- -RSB- , hierarchical structures -LSB- -RSB- , and semantic roles -LSB- -RSB- , and -LRB- b -RRB- by going beyond the sentence-level , e.g. , , translating at the document level -LSB- -RSB-
	Effect: Recently , there have been two promising research directions

CASE: 5
Stag: 8 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Going beyond the sentence-level is important since sentences rarely stand on their own in a well-written text
	Cause: sentences rarely stand on their own in a well-written text
	Effect: Going beyond the sentence-level is important

CASE: 6
Stag: 10 11 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The logical relationship between sentences carries important information that allows the text to express a meaning as a whole beyond the sum of its separate parts Note that sentences can be made of several clauses , which in turn can be interrelated through the same logical relations
	Cause: a whole beyond the sum of its separate parts Note that sentences can be made of several clauses , which in
	Effect: The logical relationship between sentences carries important information that allows the text to express a meaning

CASE: 7
Stag: 11 12 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Note that sentences can be made of several clauses , which in turn can be interrelated through the same logical relations Thus , in a coherent text , discourse units -LRB- sentences or clauses -RRB- are logically connected the meaning of a unit relates to that of the previous and the following units
	Cause: Note that sentences can be made of several clauses , which in turn can be interrelated through the same logical relations
	Effect: , in a coherent text , discourse units -LRB- sentences or clauses -RRB- are logically connected the meaning of a unit relates to that of the previous and the following units

CASE: 8
Stag: 23 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In this paper , rather than proposing yet another MT evaluation metric , we show that discourse information is complementary to many existing evaluation metrics , and thus should not be ignored
	Cause: In this paper , rather than proposing yet another MT evaluation metric , we show that discourse information is complementary to many existing evaluation metrics
	Effect: should not be ignored

CASE: 9
Stag: 25 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: These metrics tasks are based on sentence-level evaluation , which arguably can limit the benefits of using global discourse properties
	Cause: sentence-level evaluation
	Effect: which arguably can limit the benefits of using global discourse properties

CASE: 10
Stag: 26 27 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Fortunately , several sentences are long and complex enough to present rich discourse structures connecting their basic clauses Thus , although limited , this setting is able to demonstrate the potential of discourse-level information for MT evaluation
	Cause: Fortunately , several sentences are long and complex enough to present rich discourse structures connecting their basic clauses
	Effect: , although limited , this setting is able to demonstrate the potential of discourse-level information for MT evaluation

CASE: 11
Stag: 29 30 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Addressing discourse-level phenomena in machine translation is relatively new as a research direction Some recent work has looked at anaphora resolution -LSB- 5 -RSB- and discourse connectives -LSB- 1 -RSB- , to mention two examples
	Cause: a research direction Some recent work has looked at anaphora resolution -LSB- 5 -RSB- and discourse connectives -LSB- 1 -RSB- , to mention two
	Effect: Addressing discourse-level phenomena in machine translation is relatively new

CASE: 12
Stag: 33 34 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: A common argument , is that current automatic evaluation metrics such as BLEU are inadequate to capture discourse-related aspects of translation quality -LSB- 5 -RSB- Thus , there is consensus that discourse-informed MT evaluation metrics are needed in order to advance research in this direction
	Cause: A common argument , is that current automatic evaluation metrics such as BLEU are inadequate to capture discourse-related aspects of translation quality -LSB- 5 -RSB-
	Effect: , there is consensus that discourse-informed MT evaluation metrics are needed in order to advance research in this direction

CASE: 13
Stag: 36 37 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The field of automatic evaluation metrics for MT is very active , and new metrics are continuously being proposed , especially in the context of the evaluation campaigns that run as part of the Workshops on Statistical Machine Translation -LRB- WMT 2008-2012 -RRB- , and NIST Metrics for Machine Translation Challenge -LRB- MetricsMATR -RRB- , among others For example , at WMT12 , 12 metrics were compared -LSB- -RSB- , most of them new
	Cause: part of the Workshops on Statistical Machine Translation -LRB- WMT 2008-2012 -RRB- , and NIST Metrics for Machine Translation Challenge -LRB- MetricsMATR -RRB- , among others For example , at WMT12 , 12 metrics were compared -LSB- -RSB- , most of them
	Effect: new metrics are continuously being proposed , especially in the context of the evaluation campaigns that run

CASE: 14
Stag: 45 46 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 2010 -RRB- , which use the Discourse Representation Theory -LSB- -RSB- and tree-based discourse representation structures -LRB- DRS -RRB- produced by a semantic parser They calculate the similarity between the MT output and references based on DRS subtree matching , as defined in -LSB- 7 -RSB- , DRS lexical overlap , and DRS morpho-syntactic overlap
	Cause: defined in -LSB- 7 -RSB- , DRS lexical overlap , and DRS morpho-syntactic
	Effect: the Discourse Representation Theory -LSB- -RSB- and tree-based discourse representation structures -LRB- DRS -RRB- produced by a semantic parser They calculate the similarity between the MT output and references based on DRS subtree matching

CASE: 15
Stag: 47 48 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However , they could not improve correlation with human judgments , as evaluated on the MetricsMATR dataset Compared to the previous work , -LRB- i -RRB- we use a different discourse representation -LRB- RST -RRB- , -LRB- ii -RRB- we compare discourse parses using all-subtree kernels -LSB- -RSB- , -LRB- iii -RRB- we evaluate on much larger datasets , for several language pairs and for multiple metrics , and -LRB- iv -RRB- we do demonstrate better correlation with human judgments
	Cause: evaluated on the MetricsMATR dataset Compared to the previous work , -LRB- i -RRB- we use a different discourse representation -LRB- RST -RRB- , -LRB- ii
	Effect: However , they could not improve correlation with human judgments

CASE: 16
Stag: 53 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Our working hypothesis is that the similarity between the discourse structures of an automatic and of a reference translation provides additional information that can be valuable for evaluating MT systems
	Cause: evaluating MT systems
	Effect: Our working hypothesis is that the similarity between the discourse structures of an automatic and of a reference translation provides additional information that can be valuable

CASE: 17
Stag: 54 55 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In particular , we believe that good translations should tend to preserve discourse relations As an example , consider the three discourse trees -LRB- DTs -RRB- shown in Figure 4 a -RRB- for a reference -LRB- human -RRB- translation , and -LRB- b -RRB- and -LRB- c -RRB- for translations of two different systems on the WMT12 test dataset
	Cause: an example , consider the three discourse trees -LRB-
	Effect: In particular , we believe that good translations should tend to preserve discourse relations

CASE: 18
Stag: 58 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Discourse units linked by a relation are further distinguished based on their relative importance in the text nuclei are the core parts of the relation while satellites are supportive ones
	Cause: their relative importance in the text nuclei are the core parts of the relation while satellites are supportive ones
	Effect: Discourse units linked by a relation are further distinguished

CASE: 19
Stag: 59 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: Note that the nuclearity and relation labels in the reference translation are also realized in the system translation in -LRB- b -RRB- , but not in -LRB- c -RRB- , which makes -LRB- b -RRB- a better translation compared to -LRB- c -RRB- , according to our hypothesis
	Cause: our hypothesis
	Effect: Note that the nuclearity and relation labels in the reference translation are also realized in the system translation in -LRB- b -RRB- , but not in -LRB- c -RRB- , which makes -LRB- b -RRB- a better translation compared to -LRB- c -RRB-

CASE: 20
Stag: 82 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: As shown in Figure 7 , DR does not include any lexical item , and therefore measures the similarity between two translations in terms of their discourse structures only
	Cause: As shown in Figure 7 , DR does not include any lexical item
	Effect: measures the similarity between two translations in terms of their discourse structures only

CASE: 21
Stag: 87 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In order to allow the tree kernel to find subtree matches at the word level , we include an additional layer of dummy leaves as was done in -LSB- -RSB- ; not shown in Figure 7 , for simplicity
	Cause: was done in -LSB- -RSB- ;
	Effect: In order to allow the tree kernel to find subtree matches at the word level , we include an additional layer of dummy leaves

CASE: 22
Stag: 98 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: To do so , we contrast different MT evaluation metrics with and without discourse information
	Cause: To do
	Effect: we contrast different MT evaluation metrics with and

CASE: 23
Stag: 113 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The individual metrics combined in Asiya - all can be naturally categorized according to the type of linguistic information they use to compute the quality scores
	Cause: the type of linguistic information they use to compute the quality scores
	Effect: The individual metrics combined in Asiya - all can be naturally categorized

CASE: 24
Stag: 123 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Combination of three metric variants based on predicate argument structures -LRB- semantic role labeling u ' \ u2018 ' SR-Mr -LRB- * -RRB- u ' \ u2019 ' , u ' \ u2018 ' SR-Or -LRB- * -RRB- u ' \ u2019 ' , and u ' \ u2018 ' SR-Or u ' \ u2019 '
	Cause: predicate argument structures -LRB- semantic role labeling u ' \ u2018 ' SR-Mr -LRB- * -RRB- u ' \ u2019 '
	Effect: u ' \ u2018 ' SR-Or -LRB- * -RRB- u ' \ u2019 ' , and u ' \ u2018 ' SR-Or u ' \ u2019 '

CASE: 25
Stag: 125 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Combination of two metrics variants based on semantic parsing
	Cause: semantic parsing
	Effect: Combination of two metrics variants

CASE: 26
Stag: 126 127 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 6 6 In Asiya the metrics from this family are referred to as u ' \ u201c ' Discourse Representation u ' \ u201d ' metrics However , the structures they consider are actually very different from the discourse structures exploited in this paper
	Cause: u ' \ u201c ' Discourse Representation u ' \ u201d ' metrics However ,
	Effect: the metrics from this family are referred to

CASE: 27
Stag: 129 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For clarity , we will refer to them as semantic parsing metrics u ' \ u2018 ' DR-Or -LRB- * -RRB- u ' \ u2019 ' and u ' \ u2018 ' DR-Orp -LRB- * -RRB- u ' \ u2019 '
	Cause: semantic parsing metrics u ' \ u2018 ' DR-Or -LRB- * -RRB- u ' \ u2019 ' and u ' \ u2018 ' DR-Orp -LRB- * -RRB- u ' \ u2019 '
	Effect: For clarity , we will refer to them

CASE: 28
Stag: 133 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: Annotators rank the output of five systems according to perceived translation quality
	Cause: perceived translation quality
	Effect: Annotators rank the output of five systems

CASE: 29
Stag: 134 135 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: The organizers relied on a random selection of systems , and a large number of comparisons between pairs of them , to make comparisons across systems feasible -LSB- -RSB- As a result , for each source sentence , only relative rankings were available
	Cause: The organizers relied on a random selection of systems , and a large number of comparisons between pairs of them , to make comparisons across systems feasible -LSB- -RSB-
	Effect: for each source sentence , only relative rankings were available

CASE: 30
Stag: 135 136 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: As a result , for each source sentence , only relative rankings were available As in the WMT12 experimental setup , we use these rankings to calculate correlation with human judgments at the sentence-level , i.e. , Kendall u ' \ u2019 ' s Tau ; see -LSB- -RSB- for details
	Cause: in the WMT12 experimental setup , we use these rankings to calculate correlation with human judgments at the sentence-level , i.e. , Kendall u ' \ u2019 ' s Tau ; see -LSB- -RSB- for details
	Effect: As a result , for each source sentence , only relative rankings were available

CASE: 31
Stag: 138 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In order to use the WMT12 data for training a learning-to-rank model , we transformed the five-way relative rankings into ten pairwise comparisons
	Cause: training a learning-to-rank model
	Effect: In order to use the WMT12 data

CASE: 32
Stag: 139 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For instance , if a judge ranked the output of systems A , B , C , D , E as A B C D E , this would entail that A B , A C , A D and A E , etc
	Cause: A B C D E , this would entail that A B , A C , A D and A E , etc
	Effect: instance , if a judge ranked the output of systems A , B , C , D , E

CASE: 33
Stag: 140 141 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To determine the relative weights for the tuned combinations , we followed a similar approach to the one used by PRO to tune the relative weights of the components of a log-linear SMT model -LSB- -RSB- , also using Maximum Entropy as the base learning algorithm Unlike PRO , -LRB- i -RRB- we use human judgments , not automatic scores , and -LRB- ii -RRB- we train on all pairs , not on a subsample
	Cause: the base learning algorithm Unlike PRO , -LRB- i -RRB- we use human judgments , not automatic scores , and -LRB- ii -RRB- we train on all pairs , not on a
	Effect: To determine the relative weights for the tuned combinations , we followed a similar approach to the one used by PRO to tune the relative weights of the components of a log-linear SMT model -LSB- -RSB- , also using Maximum Entropy

CASE: 34
Stag: 147 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This made TerrorCat u ' \ u2019 ' s score negative , as we present it in Table 3
	Cause: we present it in Table 3
	Effect: This made TerrorCat u ' \ u2019 ' s score negative

CASE: 35
Stag: 166 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: As expected , DR - lex performs better than DR since it is lexicalized -LRB- at the unigram level -RRB- , and also gives partial credit to correct structures
	Cause: it is lexicalized -LRB- at the unigram level -RRB-
	Effect: and also gives partial credit to correct structures

CASE: 36
Stag: 167 168 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Individually , DR - lex outperforms most of the metrics from group II , and ranks as the second best metric in that group Furthermore , when combined with individual metrics in group II , DR - lex is able to improve consistently over each one of them
	Cause: the second best metric in that group Furthermore , when combined with individual metrics in group II , DR - lex is able to improve consistently over each one
	Effect: Individually , DR - lex outperforms most of the metrics from group II , and ranks

CASE: 37
Stag: 173 174 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: However , over all metrics and all language pairs , DR - lex is able to obtain an average improvement in correlation of +.035 , which is remarkably higher than that of DR Thus , we can conclude that at the system-level , adding discourse information to a metric , even using the simplest of the combination schemes , is a good idea for most of the metrics , and can help to significantly improve the correlation with human judgments
	Cause: However , over all metrics and all language pairs , DR - lex is able to obtain an average improvement in correlation of +.035 , which is remarkably higher than that of DR
	Effect: , we can conclude that at the system-level , adding discourse information to a metric , even using the simplest of the combination schemes , is a good idea for most of the metrics , and can help to significantly improve the correlation with human judgments

CASE: 38
Stag: 179 180 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Conversely , ties and incomplete discourse analysis were not a problem at the system-level , where evidence from all 3,003 test sentences is aggregated , and allows to rank systems more precisely Due to the low score of DR as an individual metric , it fails to yield improvements when uniformly combined with other metrics
	Cause: an individual metric , it fails to yield improvements when uniformly combined with other metrics
	Effect: ties and incomplete discourse analysis were not a problem at the system-level , where evidence from all 3,003 test sentences is aggregated , and allows to rank systems more precisely Due to the low score of DR

CASE: 39
Stag: 181 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Again , DR - lex is better than DR ; with a positive Tau of +.133 , yet as an individual metric , it ranks poorly compared to other metrics in group II
	Cause: an individual metric , it ranks poorly compared to other metrics in group II
	Effect: lex is better than DR ; with a positive Tau of +.133 , yet

CASE: 40
Stag: 189 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: For cross-validation in WMT12 , we used ten folds of approximately equal sizes , each containing about 300 sentences we constructed the folds by putting together entire documents , thus not allowing sentences from a document to be split over two different folds
	Cause: For cross-validation in WMT12 , we used ten folds of approximately equal sizes , each containing about 300 sentences we constructed the folds by putting together entire documents
	Effect: not allowing sentences from a document to be split over two different

CASE: 41
Stag: 189 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: For cross-validation in WMT12 , we used ten folds of approximately equal sizes , each containing about 300 sentences we constructed the folds by putting together entire documents
	Cause: putting together entire documents
	Effect: For cross-validation in WMT12 , we used ten folds of approximately equal sizes , each containing about 300 sentences we constructed the folds

CASE: 42
Stag: 194 195 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The results are shown in Table 4 As in previous sections we present the average results over all four language pairs
	Cause: in previous sections we present the average results over all four language pairs
	Effect: The results are shown in Table 4

CASE: 43
Stag: 197 198 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Interestingly , the tuned combinations that include the much weaker metric DR now improve over 12 out of 13 of the individual metrics in groups II and III , and only slightly degrades the score of the 13th one -LRB- spede07pP Note that the Asiya metrics are combinations of several metrics , and these combinations -LRB- which exclude DR and DR - lex -RRB- can be also tuned ; this yields sizable improvements over the untuned versions as column three in the table shows
	Cause: column three in the table shows
	Effect: spede07pP Note that the Asiya metrics are combinations of several metrics , and these combinations -LRB- which exclude DR and DR - lex -RRB- can be also tuned ; this yields sizable improvements over the untuned versions

CASE: 44
Stag: 206 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Since the metrics that participated in WMT11 and WMT12 are different -LRB- and even when they have the same name , there is no guarantee that they have not changed from 2011 to 2012 -RRB- , we only report results for the versions of NIST , Rouge , TER , and BLEU available in Asiya , as well as for the Asiya metrics , thus ensuring that the metrics in the experiments are consistent for 2011 and 2012
	Cause: Since the metrics that participated in WMT11 and WMT12 are different -LRB- and even when they have the same name , there is no guarantee that they have not changed from 2011 to 2012 -RRB- , we only report results for the versions of NIST , Rouge , TER , and BLEU available in Asiya , as well as for the Asiya metrics
	Effect: ensuring that the metrics in the experiments are consistent for 2011 and

CASE: 45
Stag: 206 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the metrics that participated in WMT11 and WMT12 are different -LRB- and even when they have the same name , there is no guarantee that they have not changed from 2011 to 2012 -RRB- , we only report results for the versions of NIST , Rouge , TER , and BLEU available in Asiya , as well as for the Asiya metrics
	Cause: the metrics that participated in WMT11 and WMT12 are different -LRB- and even when they have the same
	Effect: there is no guarantee that they have not changed from 2011 to 2012 -RRB- , we only report results for the versions of NIST , Rouge , TER , and BLEU available in Asiya , as well as for the Asiya metrics

CASE: 46
Stag: 214 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This shows that the weights learned on WMT12 generalize well , as they are also good for WMT11
	Cause: they are also good for WMT11
	Effect: This shows that the weights learned on WMT12 generalize well

CASE: 47
Stag: 216 217 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This is remarkable given that DR has a strong negative Tau as an individual metric at the sentence-level This suggests that both DR and DR - lex contain information that is complementary to that of the individual metrics that we experimented with
	Cause: an individual metric at the sentence-level This suggests that both DR and DR - lex contain information that is complementary to that of the individual metrics that we experimented
	Effect: This is remarkable given that DR has a strong negative Tau

CASE: 48
Stag: 217 218 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: This suggests that both DR and DR - lex contain information that is complementary to that of the individual metrics that we experimented with Overall , from the experimental results in this section , we can conclude that discourse structure is an important information source to be taken into account in the automatic evaluation of machine translation output
	Cause: suggests that both DR and DR - lex contain information that is complementary to that of the individual metrics that we experimented with Overall , from
	Effect: section , we can conclude that discourse structure is an important information source to be taken into account in the automatic evaluation of machine translation output

CASE: 49
Stag: 224 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: Yet , many of the ongoing efforts have been moderately successful according to traditional evaluation metrics
	Cause: traditional evaluation metrics
	Effect: Yet , many of the ongoing efforts have been moderately successful

CASE: 50
Stag: 228 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In the future , we plan to work on integrated representations of syntactic , semantic and discourse-based structures , which would allow us to train evaluation metrics based on more fine-grained features
	Cause: more fine-grained features
	Effect: In the future , we plan to work on integrated representations of syntactic , semantic and discourse-based structures , which would allow us to train evaluation metrics

CASE: 51
Stag: 230 231 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First , at the sentence-level , we can use discourse information to re-rank alternative MT hypotheses ; this could be applied either for MT parameter tuning , or as a post-processing step for the MT output Second , we propose to move in the direction of using discourse information beyond the sentence-level
	Cause: a post-processing step for the MT output Second , we propose to move in the direction of using discourse information beyond the
	Effect: can use discourse information to re-rank alternative MT hypotheses ; this could be applied either for MT parameter tuning , or

