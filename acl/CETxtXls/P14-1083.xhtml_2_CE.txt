************************************************************
P14-1083.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We show how to generate responses by grounding SMT in the task of executing a semantic parse of a translated query against a database
	Cause: grounding SMT in the task of executing a semantic parse of a translated query against a database
	Effect: We show how to generate responses

CASE: 1
Stag: 6 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Successful communication of meaning is measured by a successful interaction in this task , and feedback from this interaction is used for learning
	Cause: learning
	Effect: Successful communication of meaning is measured by a successful interaction in this task , and feedback from this interaction is used

CASE: 2
Stag: 8 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: For example , in the context of a game , a description of a game rule is translated successfully if correct game moves can be performed based only on the translation
	Cause: correct game moves can be performed based only on the translation
	Effect: For example , in the context of a game , a description of a game rule is translated successfully

CASE: 3
Stag: 9 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: In the context of a question-answering scenario , a question is translated successfully if the correct answer is returned based only on the translation of the query
	Cause: the correct answer is returned based only on the translation of the query
	Effect: In the context of a question-answering scenario , a question is translated successfully

CASE: 4
Stag: 11 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Here , learning proceeds by u ' \ u201c ' trying out u ' \ u201d ' translation hypotheses , receiving a response from interacting in the task , and converting this response into a supervision signal for updating model parameters
	Cause: updating model parameters
	Effect: Here , learning proceeds by u ' \ u201c ' trying out u ' \ u201d ' translation hypotheses , receiving a response from interacting in the task , and converting this response into a supervision signal

CASE: 5
Stag: 12 13 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In case of positive feedback , the predicted translation can be treated as reference translation for a structured learning update In case of negative feedback , a structural update can be performed against translations that have been approved previously by positive task feedback
	Cause: reference translation for a structured learning update In case of negative feedback , a structural update can be performed against translations that have been approved previously by positive task
	Effect: In case of positive feedback , the predicted translation can be treated

CASE: 6
Stag: 18 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Response-based learning can repeatedly try out system predictions by interacting in the extrinsic task
	Cause: interacting in the extrinsic task
	Effect: Response-based learning can repeatedly try out system predictions

CASE: 7
Stag: 25 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Building on prior work in grounded semantic parsing , we generate translations of queries , and receive feedback by executing semantic parses of translated queries against the database
	Cause: Building on prior work in grounded semantic parsing
	Effect: we generate translations of queries , and receive feedback by executing semantic parses of translated queries against the database

CASE: 8
Stag: 25 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: we generate translations of queries , and receive feedback by executing semantic parses of translated queries against the database
	Cause: executing semantic parses of translated queries against the database
	Effect: we generate translations of queries , and receive feedback

CASE: 9
Stag: 28 29 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We show in an error analysis that this improvement can be attributed to using structural and lexical variants of reference translations as positive examples in response-based learning Furthermore , translations produced by response-based learning are found to be grammatical
	Cause: positive examples in response-based learning Furthermore , translations produced by response-based learning are found to be
	Effect: We show in an error analysis that this improvement can be attributed to using structural and lexical variants of reference translations

CASE: 10
Stag: 29 30 
	Pattern: 5 [['due', 'to']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Furthermore , translations produced by response-based learning are found to be grammatical This is due to the possibility to boost similarity to human reference translations by the additional use of a cost function in our approach
	Cause: the possibility to boost similarity to human reference translations by the additional use of a cost function in our approach
	Effect: Furthermore , translations produced by response-based learning are found to be grammatical

CASE: 11
Stag: 36 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since there are many possible correct parses , matching against a single gold standard falls short of grounding in a non-linguistic environment
	Cause: there are many possible correct parses
	Effect: matching against a single gold standard falls short of grounding in a non-linguistic environment

CASE: 12
Stag: 41 42 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: A recent important research direction in SMT has focused on employing automated translation as an aid to human translators Computer assisted translation -LRB- CAT -RRB- subsumes several modes of interaction , ranging from binary feedback on the quality of the system prediction -LSB- Saluja et al. 2012 -RSB- , to human post-editing operations on a system prediction resulting in a reference translation -LSB- Cesa-Bianchi et al. 2008 -RSB- , to human acceptance or overriding of sentence completion predictions -LSB- Langlais et al. 2000 , Barrachina et al. 2008 , Koehn and Haddow2009 -RSB-
	Cause: an aid to human translators Computer assisted translation -LRB- CAT -RRB- subsumes several modes of interaction , ranging from binary feedback on the quality of the system prediction -LSB- Saluja et al. 2012 -RSB- , to human post-editing operations on a system prediction resulting in a reference translation -LSB- Cesa-Bianchi et al. 2008 -RSB- , to human acceptance or overriding of sentence completion predictions -LSB- Langlais et al. 2000 , Barrachina et al. 2008 , Koehn and Haddow2009
	Effect: A recent important research direction in SMT has focused on employing automated translation

CASE: 13
Stag: 44 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since retraining the SMT model after each interaction is too costly , online adaptation after each interaction has become the learning protocol of choice for CAT
	Cause: retraining the SMT model after each interaction is too costly
	Effect: online adaptation after each interaction has become the learning protocol of choice for CAT

CASE: 14
Stag: 50 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Our work differs from these approaches in that exactly this dependency is alleviated by learning from responses in an extrinsic task
	Cause: learning from responses in an extrinsic task
	Effect: Our work differs from these approaches in that exactly this dependency is alleviated

CASE: 15
Stag: 52 53 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However , despite offering direct and reliable prediction of translation quality , the cost and lack of reusability has confined task-based evaluations involving humans to testing scenarios , but prevented a use for interactive training of SMT systems as in our work Lastly , our work is related to cross-lingual natural language processing such as cross-lingual question answering or cross-lingual information retrieval as conducted at recent evaluation campaigns of the CLEF initiative
	Cause: in our work Lastly , our work is related to cross-lingual natural language processing such as cross-lingual question answering or cross-lingual information retrieval as conducted at recent evaluation campaigns of the CLEF
	Effect: However , despite offering direct and reliable prediction of translation quality , the cost and lack of reusability has confined task-based evaluations involving humans to testing scenarios , but prevented a use for interactive training of SMT systems

CASE: 16
Stag: 54 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: 1 1 http://www.clef-initiative.eu While these approaches focus on improvements of the respective natural language processing task , our goal is to improve SMT by gathering feedback from the task
	Cause: gathering feedback from the task
	Effect: 1 1 http://www.clef-initiative.eu While these approaches focus on improvements of the respective natural language processing task , our goal is to improve SMT

CASE: 17
Stag: 59 60 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The diagram in Figure 1 gives a sketch of response-based learning from semantic parsing in the geographical domain Given a manual German translation of the English query as source sentence , the SMT system produces an English target translation
	Cause: source sentence , the SMT system produces an English target translation
	Effect: The diagram in Figure 1 gives a sketch of response-based learning from semantic parsing in the geographical domain Given a manual German translation of the English query

CASE: 18
Stag: 62 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Feedback is generated by executing the parse against the database of geographical facts
	Cause: executing the parse against the database of geographical facts
	Effect: Feedback is generated

CASE: 19
Stag: 77 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Despite a large difference to the original English string , key terms such as elevations and heights , or USA and US , can be mapped into the same predicate in the semantic parse , thus allowing to receive positive feedback from parse execution against the geographical database
	Cause: Despite a large difference to the original English string , key terms such as elevations and heights , or USA and US , can be mapped into the same predicate in the semantic parse
	Effect: allowing to receive positive feedback from parse execution against the geographical database

CASE: 20
Stag: 78 79 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Recent approaches to machine learning for SMT formalize the task of discriminating good from bad translations as a structured prediction problem Assume a joint feature representation u ' \ u03a6 ' u ' \ u2062 ' -LRB- x , y -RRB- of input sentences x and output translations y u ' \ u2208 ' Y u ' \ u2062 ' -LRB- x -RRB- , and a linear scoring function s u ' \ u2062 ' -LRB- x , y ; w -RRB- for predicting a translation y ^ -LRB- where u ' \ u27e8 ' u ' \ u22c5 ' , u ' \ u22c5 ' u ' \ u27e9 ' denotes the standard vector dot product -RRB- s.t
	Cause: a structured prediction problem Assume a joint feature representation u ' \ u03a6 ' u ' \ u2062 ' -LRB- x , y -RRB- of input sentences x and output translations y u ' \ u2208 ' Y u ' \ u2062 ' -LRB- x -RRB- , and a linear scoring function s u ' \ u2062 ' -LRB- x , y ; w -RRB- for predicting a translation y ^ -LRB- where u ' \ u27e8 ' u ' \ u22c5 ' , u ' \ u22c5 ' u ' \ u27e9 ' denotes
	Effect: Recent approaches to machine learning for SMT formalize the task of discriminating good from bad translations

CASE: 21
Stag: 79 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Assume a joint feature representation u ' \ u03a6 ' u ' \ u2062 ' -LRB- x , y -RRB- of input sentences x and output translations y u ' \ u2208 ' Y u ' \ u2062 ' -LRB- x -RRB- , and a linear scoring function s u ' \ u2062 ' -LRB- x , y ; w -RRB- for predicting a translation y ^ -LRB- where u ' \ u27e8 ' u ' \ u22c5 ' , u ' \ u22c5 ' u ' \ u27e9 ' denotes the standard vector dot product -RRB- s.t
	Cause: predicting a translation y ^
	Effect: Assume a joint feature representation u ' \ u03a6 ' u ' \ u2062 ' -LRB- x , y -RRB- of input sentences x and output translations y u ' \ u2208 ' Y u ' \ u2062 ' -LRB- x -RRB- , and a linear scoring function s u ' \ u2062 ' -LRB- x , y ; w -RRB-

CASE: 22
Stag: 80 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: The structured perceptron algorithm -LSB- Collins2002 -RSB- learns an optimal weight vector w by updating w on input x -LRB- i -RRB- by the following rule , in case the predicted translation y ^ is different from and scored higher than the reference translation y -LRB- i -RRB-
	Cause: updating w on input x -LRB- i -RRB- by the following rule , in case the predicted translation y ^ is different from
	Effect: and scored higher than the reference translation y -LRB- i -RRB-

CASE: 23
Stag: 83 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Firstly , update rules that require to compute a feature representation for the reference translation are suboptimal in SMT , because often human-generated reference translations can not be generated by the SMT system
	Cause: often human-generated reference translations can not be generated by the SMT system
	Effect: Firstly , update rules that require to compute a feature representation for the reference translation are suboptimal in SMT

CASE: 24
Stag: 85 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Computation of distance to the reference translation usually involves cost functions based on sentence-level BLEU -LRB- Nakov et al. 2012 , inter alia -RRB- and incorporates the current model score , leading to various ramp loss objectives described in Gimpel and Smith2012
	Cause: sentence-level BLEU
	Effect: inter alia -RRB- and incorporates the current model score , leading to various ramp loss objectives described in Gimpel and Smith2012

CASE: 25
Stag: 88 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Here a meaning representation is u ' \ u201c ' tried out u ' \ u201d ' by iteratively generating system outputs , receiving feedback from world interaction , and updating the model parameters
	Cause: iteratively generating system outputs , receiving feedback from world interaction , and updating the model parameters
	Effect: a meaning representation is u ' \ u201c ' tried out u ' \ u201d '

CASE: 26
Stag: 92 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: We need to ensure that gold-standard translations lead to positive task-based feedback , that means they can be parsed and executed successfully against the database
	Cause: We need to ensure
	Effect: positive task-based feedback , that means they can be parsed and executed successfully against the database

CASE: 27
Stag: 93 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In addition , we can use translation-specific cost functions based on sentence-level BLEU in order to boost similarity of translations to human reference translations
	Cause: sentence-level BLEU in order to boost similarity of translations to human reference translations
	Effect: In addition , we can use translation-specific cost functions

CASE: 28
Stag: 94 95 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We denote feedback by a binary execution function e u ' \ u2062 ' -LRB- y -RRB- u ' \ u2208 ' -LCB- 1 , 0 -RCB- that tests whether executing the semantic parse for the prediction against the database receives the same answer as the parse for the gold standard reference Our cost function c u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- = -LRB- 1 - BLEU u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- -RRB- is based on a version of sentence-level BLEU Nakov et al. 2012
	Cause: the parse for the gold standard reference Our cost function c u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- = -LRB- 1 - BLEU u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- -RRB- is based on a version of sentence-level BLEU Nakov et al.
	Effect: We denote feedback by a binary execution function e u ' \ u2062 ' -LRB- y -RRB- u ' \ u2208 ' -LCB- 1 , 0 -RCB- that tests whether executing the semantic parse for the prediction against the database receives the same answer

CASE: 29
Stag: 95 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Our cost function c u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- = -LRB- 1 - BLEU u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- -RRB- is based on a version of sentence-level BLEU Nakov et al. 2012
	Cause: a version of sentence-level BLEU Nakov et al. 2012
	Effect: u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- = -LRB- 1 - BLEU u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- -RRB-

CASE: 30
Stag: 95 96 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Our cost function c u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- = -LRB- 1 - BLEU u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- -RRB- is based on a version of sentence-level BLEU Nakov et al. 2012 Define y + as a surrogate gold-standard translation that receives positive feedback , has a high model score , and a low cost of predicting y instead of y -LRB- i -RRB-
	Cause: a surrogate gold-standard translation that receives positive feedback , has a high model score , and a low cost of predicting y instead of
	Effect: u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- = -LRB- 1 - BLEU u ' \ u2062 ' -LRB- y -LRB- i -RRB- , y -RRB- -RRB- is based on a version of sentence-level BLEU Nakov et al. 2012 Define y +

CASE: 31
Stag: 97 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: The opposite of y + is the translation y - that leads to negative feedback , has a high model score , and a high cost
	Cause: The opposite of y + is the translation y -
	Effect: negative feedback

CASE: 32
Stag: 101 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: The intuition behind this update rule is to discriminate the translation y + that leads to positive feedback and best approximates -LRB- or is identical to -RRB- the reference within the means of the model from a translation y - which is favored by the model but does not execute and has high cost
	Cause: The intuition behind this update rule is to discriminate the translation y +
	Effect: positive feedback

CASE: 33
Stag: 102 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This is done by putting all the weight on the former
	Cause: putting all the weight on the former
	Effect: This is done

CASE: 34
Stag: 104 105 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Upon predicting translation y ^ , in case of positive feedback from the task , we treat the prediction as surrogate reference by setting y + u ' \ u2190 ' y ^ , and by adding it to the set of reference translations for future use Then we need to compute y - , and update by the difference in feature representations of y + and y - , at a learning rate u ' \ u0397 '
	Cause: surrogate reference by setting y + u ' \ u2190 ' y ^ , and by adding it to the set of reference translations for future use Then we need to compute y - , and update by the difference in feature representations of y + and y - , at a learning rate u ' \ u0397
	Effect: Upon predicting translation y ^ , in case of positive feedback from the task , we treat the prediction

CASE: 35
Stag: 106 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: If the feedback is negative , we want to move the weights away from the prediction , thus we treat it as y -
	Cause: If the feedback is negative , we want to move the weights away from the prediction
	Effect: we treat it as y -

CASE: 36
Stag: 106 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the feedback is negative , we want to move the weights away from the prediction
	Cause: the feedback is negative
	Effect: we want to move the weights away from the prediction

CASE: 37
Stag: 108 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If either y + or y - can not be computed , the example is skipped
	Cause: either y + or y - can not be computed
	Effect: the example is skipped

CASE: 38
Stag: 113 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: The cost function can be implemented by different versions of sentence-wise BLEU , or it can be omitted completely so that learning relies on task-based feedback alone , similar to algorithms recently suggested for semantic parsing -LSB- Goldwasser and Roth2013 , Kwiatowski et al. 2013 , Berant et al. 2013 -RSB-
	Cause: The cost function can be implemented by different versions of sentence-wise BLEU , or it can be omitted completely
	Effect: learning relies on task-based feedback alone , similar to algorithms recently suggested for semantic parsing -LSB- Goldwasser and Roth2013 , Kwiatowski et al. 2013 , Berant et al. 2013 -RSB-

CASE: 39
Stag: 114 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Lastly , regularization can be introduced by using update rules corresponding to primal form optimization variants of support vector machines -LSB- Collobert and Bengio2004 , Chapelle2007 , Shalev-Shwartz et al. 2007 -RSB-
	Cause: using update rules
	Effect: corresponding to primal form optimization variants of support vector machines -LSB- Collobert and Bengio2004 , Chapelle2007 , Shalev-Shwartz et al. 2007 -RSB-

CASE: 40
Stag: 120 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: This parser is itself based on SMT , trained on parallel data consisting of English queries and linearized logical forms , and on a language model trained on linearized logical forms
	Cause: SMT
	Effect: trained on parallel data consisting of English queries and linearized logical forms , and on a language model trained on linearized logical forms

CASE: 41
Stag: 133 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Variants of the response-based learning algorithm described above are implemented as a stand-alone tool that operates on cdec n - best lists of 10,000 translations of the Geoquery training data
	Cause: a stand-alone tool that operates on cdec n - best lists
	Effect: Variants of the response-based learning algorithm described above are implemented

CASE: 42
Stag: 136 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In addition to the model score s , it uses a cost function c based on sentence-level BLEU -LSB- Nakov et al. 2012 -RSB- and tests translation hypotheses for task-based feedback using a binary execution function e
	Cause: sentence-level BLEU -LSB- Nakov et al. 2012 -RSB- and tests translation hypotheses for task-based feedback using a binary execution function e
	Effect: In addition to the model score s , it uses a cost function c

CASE: 43
Stag: 137 138 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This algorithm can convert predicted translations into references by task-feedback , and additionally use the given original English queries as references Method 2 , named Exec , relies on task-execution by function e and searches for executable or non-executable translations with highest score s to distinguish positive from negative training examples
	Cause: references by task-feedback , and additionally use the given original English queries as references Method 2 ,
	Effect: This algorithm can convert predicted translations into references by task-feedback , and additionally use the given original English queries

CASE: 44
Stag: 139 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: It does not use a cost function and thus can not make use of the original English queries
	Cause: It does not use a cost function
	Effect: can not make use of the original English queries

CASE: 45
Stag: 141 142 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This algorithm can be seen as a stochastic -LRB- sub -RRB- gradient descent variant of Rampion -LSB- Gimpel and Smith2012 -RSB- It does not make use of the semantic parser , but defines positive and negative examples based on score s and cost c with respect to human reference translations
	Cause: a stochastic -LRB- sub -RRB- gradient descent variant of Rampion -LSB- Gimpel and Smith2012 -RSB- It does not make use of the semantic parser , but defines positive and negative examples based on score s and cost c with respect to human reference
	Effect: This algorithm can be seen

CASE: 46
Stag: 142 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: It does not make use of the semantic parser , but defines positive and negative examples based on score s and cost c with respect to human reference translations
	Cause: score s and cost c with respect to human reference translations
	Effect: It does not make use of the semantic parser , but defines positive and negative examples

CASE: 47
Stag: 144 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Furthermore , we report precision , recall , and F1-score for executing semantic parses built from translation system outputs against the Geoquery database
	Cause: executing semantic parses built from translation system outputs against the Geoquery database
	Effect: Furthermore , we report precision , recall , and F1-score

CASE: 48
Stag: 145 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Precision is defined as the percentage of correctly answered examples out of those for which a parse could be produced ; recall is defined as the percentage of total examples answered correctly ; F1-score is the harmonic mean of both
	Cause: the percentage of correctly answered examples out of those for which a parse could be produced ; recall is defined as the percentage of total examples answered correctly ;
	Effect: Precision is defined

CASE: 49
Stag: 145 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: the percentage of correctly answered examples out of those for which a parse could be produced ; recall is defined as the percentage of total examples answered correctly ;
	Cause: the percentage of total examples answered
	Effect: examples out of those for which a parse could be produced ; recall is defined

CASE: 50
Stag: 150 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: We present an experimental comparison of the four different systems according to BLEU and F1 , using an extended semantic parser -LRB- trained on 880 Geoquery examples -RRB- and the original parser -LRB- trained on 600 Geoquery training examples
	Cause: BLEU and F1
	Effect: using an extended semantic parser -LRB- trained on 880 Geoquery examples -RRB- and the original parser -LRB- trained on 600 Geoquery training examples

CASE: 51
Stag: 153 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: A system ranking according to F1-score shows about 6 points difference between the respective methods , ranking Rebol over Rampion , Exec and cdec
	Cause: F1-score
	Effect: ranking Rebol over Rampion , Exec and cdec

CASE: 52
Stag: 155 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Rebol u ' \ u2019 ' s combination of task feedback with a cost function achieves the best results since positively executable hypotheses and reference translations can both be exploited to guide the learning process
	Cause: positively executable hypotheses and reference translations can both be exploited to guide the learning process
	Effect: Rebol u ' \ u2019 ' s combination of task feedback with a cost function achieves the best results

CASE: 53
Stag: 156 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since all English reference queries lead to positively executable parses in the setup that uses the extended semantic parser , Rampion implicitly also has access to task feedback
	Cause: all English reference queries lead to positively executable parses in the setup that uses the extended semantic parser
	Effect: Rampion implicitly also has access to task feedback

CASE: 54
Stag: 160 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Rebol performs worse since BLEU performance is optimized only implicitly in cases where original English queries function as positive examples
	Cause: BLEU performance is optimized only implicitly in cases where original English queries function as positive examples
	Effect: Rebol performs worse

CASE: 55
Stag: 167 
	Pattern: 5 [['due', 'to']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: We conjecture that this is due to a higher number of empty parses on the test set which makes this comparison unstable
	Cause: a higher number of empty parses on the test set which makes this comparison unstable
	Effect: We conjecture that

CASE: 56
Stag: 172 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: The examples show structural and lexical variation that leads to differences on the string level at equivalent positive feedback from the extrinsic task
	Cause: The examples show structural and lexical variation
	Effect: differences on the string level at equivalent positive feedback from the extrinsic task

CASE: 57
Stag: 174 175 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Lexical and structural variants of reference translations can be used to boost model parameters towards translations with positive feedback , while the same translations might be considered as negative examples in standard structured learning Table 5 shows examples where translations from Rebol and Rampion differ from the gold standard reference , and predictions by Rebol lead to positive feedback , while predictions by Rampion lead to negative feedback
	Cause: negative examples in standard structured learning Table 5 shows examples where translations from Rebol and Rampion differ from the gold standard reference , and predictions by Rebol lead to positive feedback ,
	Effect: Lexical and structural variants of reference translations can be used to boost model parameters towards translations with positive feedback , while the same translations might be considered

CASE: 58
Stag: 175 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Table 5 shows examples where translations from Rebol and Rampion differ from the gold standard reference , and predictions by Rebol lead to positive feedback , while predictions by Rampion lead to negative feedback
	Cause: predictions by Rampion
	Effect: negative feedback

CASE: 59
Stag: 178 179 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This can be attributed to the use of sentence-level BLEU as cost function in Rampion and Rebol Translation errors of Rampion can be traced back to mistranslations of key terms -LRB- city versus capital , limits or boundaries versus border
	Cause: cost function in Rampion and Rebol Translation errors of Rampion can be traced back to mistranslations of key terms -LRB- city versus capital , limits or boundaries versus
	Effect: This can be attributed to the use of sentence-level BLEU

CASE: 60
Stag: 185 
	Pattern: 5 [['due', 'to']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Our error analysis shows that response-based learning generates grammatical translations which is due to the additional use of a cost function that boosts similarity of translations to human reference translations
	Cause: the additional use of a cost function that boosts similarity of translations to human reference translations
	Effect: Our error analysis shows that response-based learning generates grammatical translations

