************************************************************
P14-2129.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 1 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Models to derive such non-hierarchical annotations are finite-state, so inference is very fast
	Cause: [(0, 0), (0, 7)]
	Effect: [(0, 10), (0, 13)]

CASE: 1
Stag: 3 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: For example, in incremental (simultaneous) machine translation [ 13 ] , sub-sentential segments are translated independently and sequentially, hence the fully-connected syntactic structure is not generally available
	Cause: [(0, 1), (0, 20)]
	Effect: [(0, 23), (0, 30)]

CASE: 2
Stag: 3 4 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: For example, in incremental (simultaneous) machine translation [ 13 ] , sub-sentential segments are translated independently and sequentially, hence the fully-connected syntactic structure is not generally available Even so, locally-connected source language parse structures can inform both segmentation and translation of each segment in such a translation scenario
	Cause: [(0, 1), (1, 0)]
	Effect: [(1, 3), (1, 21)]

CASE: 3
Stag: 6 
	Pattern: 0 [['due', 'to', 'the', 'fact', 'that']]---- [['&R', '(,)'], ['&C']]
	sentTXT: We follow the XML community in naming structures of this type hedges (not to be confused with the rhetorical device of the same name), due to the fact that they are like smaller versions of trees which occur in sequences
	Cause: [(0, 32), (0, 42)]
	Effect: [(0, 0), (0, 25)]

CASE: 4
Stag: 9 10 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Similar constraints have been used in dependency parsing [ 6 , 5 ] , where the use of hard constraints on the distance between heads and dependents is known as vine parsing It is also reminiscent of so-called Semi-Markov models [ 12 ] , which allow finite-state models to reason about segments rather than just tags by imposing segment length limits
	Cause: [(0, 30), (1, 11)]
	Effect: [(0, 0), (0, 28)]

CASE: 5
Stag: 10 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: It is also reminiscent of so-called Semi-Markov models [ 12 ] , which allow finite-state models to reason about segments rather than just tags by imposing segment length limits
	Cause: [(0, 25), (0, 28)]
	Effect: [(0, 0), (0, 23)]

CASE: 6
Stag: 14 15 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In such a way, hedges are sequentially connected to the top-most non-terminal in the tree, as demonstrated in Figure 1 After applying such a transform to a treebank, we can induce grammars and modify parsing to search as needed to recover just these constituents
	Cause: [(0, 18), (1, 24)]
	Effect: [(0, 0), (0, 15)]

CASE: 7
Stag: 15 16 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: After applying such a transform to a treebank, we can induce grammars and modify parsing to search as needed to recover just these constituents In this paper, we propose several methods to parse hedge constituents and examine their accuracy/efficiency tradeoffs
	Cause: [(0, 19), (1, 16)]
	Effect: [(0, 0), (0, 17)]

CASE: 8
Stag: 29 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: For example, the span of the non-root S , SBAR , ADJP , and VP nodes in Figure 1 (a) have spans between 10 and 13, hence are removed in the tree in Figure 1 (b
	Cause: [(0, 0), (0, 28)]
	Effect: [(0, 31), (0, 40)]

CASE: 9
Stag: 30 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If we apply this transform to an entire treebank, we can use the transformed trees to induce a PCFG for parsing
	Cause: [(0, 1), (0, 8)]
	Effect: [(0, 10), (0, 21)]

CASE: 10
Stag: 31 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Figure 2 plots the percentage of constituents from the original WSJ Penn treebank (sections 2-21) retained in the transformed version, as we vary the maximum span length parameter L
	Cause: [(0, 24), (0, 29)]
	Effect: [(0, 1), (0, 21)]

CASE: 11
Stag: 33 34 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Most experiments in this paper will focus on L = 7 , which is short enough to provide a large speedup yet still cover a large fraction of constituents As stated earlier, our brute-force baseline approach is to parse the sentence using a full context-free grammar (CFG) and then hedge-transform the result
	Cause: [(1, 1), (1, 25)]
	Effect: [(0, 0), (0, 28)]

CASE: 12
Stag: 35 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This method should yield a ceiling on hedge-parsing accuracy, as it has access to rich contextual information (as compared to grammars trained on transformed trees
	Cause: [(0, 11), (0, 26)]
	Effect: [(0, 0), (0, 8)]

CASE: 13
Stag: 37 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since we limit the span of non-terminal labels, we can constrain the search performed by the parser, greatly reduce the CYK processing time
	Cause: [(0, 1), (0, 7)]
	Effect: [(0, 9), (0, 23)]

CASE: 14
Stag: 42 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: Further, if the binarization systematically groups the leftmost or the rightmost children under these new non-terminals (the most common strategy), then constituents with span greater than L will either begin at the first word (leftmost grouping) or end at the last word (rightmost), further constraining the number of cells in the chart requiring work
	Cause: [(0, 3), (0, 22)]
	Effect: [(0, 25), (0, 62)]

CASE: 15
Stag: 50 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Note also that these latter cells (spanning L words) may be less expensive, as the set of possible non-terminals is reduced to only those introduced by binarization
	Cause: [(0, 17), (0, 29)]
	Effect: [(0, 3), (0, 14)]

CASE: 16
Stag: 51 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: It is possible to parse with a standardly induced PCFG using this sort of hedge constrained parsing that only considers a subset of the chart cells, and speedups are achieved, however this is clearly non-optimal, since the model is ill-suited to combining hedges into flat structures at the root of the tree
	Cause: [(0, 39), (0, 54)]
	Effect: [(0, 0), (0, 36)]

CASE: 17
Stag: 52 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Space constraints preclude inclusion of trials with this method, but the net result is a severe degradation in accuracy (tens of points of F-measure) versus standard parsing
	Cause: [(0, 0), (0, 10)]
	Effect: [(0, 15), (0, 29)]

CASE: 18
Stag: 52 53 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Space constraints preclude inclusion of trials with this method, but the net result is a severe degradation in accuracy (tens of points of F-measure) versus standard parsing Thus, we train a grammar in a matched condition, which we call it a hedgebank grammar
	Cause: [(0, 0), (0, 29)]
	Effect: [(1, 1), (1, 17)]

CASE: 19
Stag: 57 58 
	Pattern: 0 [[['enable', 'enables', 'enabled']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@', '&TODO@R@']]
	sentTXT: A unique property of hedge constituents compared to constituents in the original parse trees is that they are sequentially connected to the top-most node This property enables us to chunk the sentence into segments that correspond to complete hedges, and parse the segments independently (and simultaneously) instead of parsing the entire sentence
	Cause: [(0, 0), (0, 23)]
	Effect: [(1, 3), (1, 30)]

CASE: 20
Stag: 63 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: We treat this as a binary classification task which decides if a word can begin a new hedge
	Cause: [(0, 11), (0, 17)]
	Effect: [(0, 0), (0, 9)]

CASE: 21
Stag: 64 65 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use hedge segmentation as a finite-state pre-processing step for hedge context-free parsing Our task is to learn which words can begin ( B ) a hedge constituent
	Cause: [(0, 5), (1, 13)]
	Effect: [(0, 0), (0, 3)]

CASE: 22
Stag: 66 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Given a set of labeled pairs ( S , H ) where S is a sentence of n words w 1 u'\u2062' u'\u2026' u'\u2062' w n and H is its hedge parse tree, word w b belongs to B if there is a hedge constituent spanning w b u'\u2062' u'\u2026' u'\u2062' w e for some e u'\u2265' b and w b belongs to B Â¯ otherwise
	Cause: [(0, 53), (0, 60)]
	Effect: [(0, 0), (0, 51)]

CASE: 23
Stag: 70 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We restrict the types to the most important types u'\u2013' following the 11 chunk types annotated in the CoNLL-2000 chunking task [ 11 ] u'\u2013' by replacing all other types with a new type OUT
	Cause: [(0, 34), (0, 42)]
	Effect: [(0, 0), (0, 32)]

CASE: 24
Stag: 70 71 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We restrict the types to the most important types u'\u2013' following the 11 chunk types annotated in the CoNLL-2000 chunking task [ 11 ] u'\u2013' by replacing all other types with a new type OUT Thus, u'\u201c' Analysts u'\u201d' is labeled B G ; u'\u201c' much u'\u201d' , B u'\ud835' u'\udc41' u'\ud835' u'\udc43' ; u'\u201c' will u'\u201d' , B u'\ud835' u'\udc49' u'\ud835' u'\udc43' and so on
	Cause: [(0, 0), (0, 42)]
	Effect: [(1, 1), (1, 87)]

CASE: 25
Stag: 85 86 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Segmentation accuracy is reported as an F1-score of unlabeled segment bracketing We ran timing tests on an Intel 2.66GHz processor with 3MB of cache and 2GB of memory
	Cause: [(0, 5), (1, 16)]
	Effect: [(0, 0), (0, 3)]

CASE: 26
Stag: 87 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Note that segmentation time is negligible compared to the parsing time, hence is omitted in reported time
	Cause: [(0, 0), (0, 10)]
	Effect: [(0, 13), (0, 17)]

CASE: 27
Stag: 88 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Efficiency results are reported as number of words parsed per second (w/s
	Cause: [(0, 5), (0, 11)]
	Effect: [(0, 0), (0, 3)]

CASE: 28
Stag: 95 96 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The final two rows show performance with automatic segmentation, using a model that includes either unlabeled or labeled segmentation tags, as described in the last section Segmentation accuracy is better for the model with labels, although overall that accuracy is rather low
	Cause: [(0, 23), (1, 9)]
	Effect: [(0, 0), (0, 20)]

CASE: 29
Stag: 99 100 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The results show the same patterns as on the development set Finally, Figure 3 shows the speed of inference, labeled precision and labeled recall of annotating hedge constituents on the test set as a function of the maximum span parameter L , versus the baseline parser
	Cause: [(0, 7), (1, 35)]
	Effect: [(0, 0), (0, 5)]

CASE: 30
Stag: 100 101 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Finally, Figure 3 shows the speed of inference, labeled precision and labeled recall of annotating hedge constituents on the test set as a function of the maximum span parameter L , versus the baseline parser Keep in mind that the number of reference constituents increases as L increases, hence both precision and recall can decrease as the parameter grows
	Cause: [(0, 24), (1, 24)]
	Effect: [(0, 0), (0, 22)]

CASE: 31
Stag: 101 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Keep in mind that the number of reference constituents increases as L increases, hence both precision and recall can decrease as the parameter grows
	Cause: [(0, 11), (0, 24)]
	Effect: [(0, 4), (0, 9)]

CASE: 32
Stag: 101 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Keep in mind that the number of reference constituents increases as L increases, hence both precision and recall can decrease as the parameter grows
	Cause: [(0, 11), (0, 13)]
	Effect: [(0, 0), (0, 9)]

