************************************************************
P14-1062.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 3 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since individual sentences are rarely observed or not observed at all, one must represent a sentence in terms of features that depend on the words and short n -grams in the sentence that are frequently observed
	Cause: [(0, 1), (0, 10)]
	Effect: [(0, 12), (0, 17)]

CASE: 1
Stag: 10 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: A central class of models are those based on neural networks
	Cause: [(0, 9), (0, 10)]
	Effect: [(0, 0), (0, 6)]

CASE: 2
Stag: 13 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: They can be trained to obtain generic vectors for words and phrases by predicting, for instance, the contexts in which the words and phrases occur
	Cause: [(0, 13), (0, 13)]
	Effect: [(0, 0), (0, 11)]

CASE: 3
Stag: 14 15 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Through supervised training, neural sentence models can fine-tune these vectors to information that is specific to a certain task Besides comprising powerful classifiers as part of their architecture, neural sentence models can be used to condition a neural language model to generate sentences word by word []
	Cause: [(1, 5), (1, 29)]
	Effect: [(0, 1), (1, 3)]

CASE: 4
Stag: 23 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Secondly, the pooling parameter k can be dynamically chosen by making k a function of other aspects of the network or the input
	Cause: [(0, 11), (0, 23)]
	Effect: [(0, 0), (0, 9)]

CASE: 5
Stag: 27 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Like in the convolutional networks for object recognition [] , we enrich the representation in the first layer by computing multiple feature maps with different filters applied to the input sentence
	Cause: [(0, 20), (0, 31)]
	Effect: [(0, 0), (0, 18)]

CASE: 6
Stag: 28 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Subsequent layers also have multiple feature maps computed by convolving filters with all the maps from the layer below
	Cause: [(0, 9), (0, 18)]
	Effect: [(0, 0), (0, 7)]

CASE: 7
Stag: 40 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The network matches the accuracy of other state-of-the-art methods that are based on large sets of engineered features and hand-coded knowledge resources
	Cause: [(0, 13), (0, 21)]
	Effect: [(0, 0), (0, 10)]

CASE: 8
Stag: 42 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The network is trained on 1.6 million tweets labelled automatically according to the emoticon that occurs in them
	Cause: [(0, 12), (0, 17)]
	Effect: [(0, 0), (0, 9)]

CASE: 9
Stag: 53 54 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: By adding a max pooling layer to the network, the TDNN can be adopted as a sentence model [] Various neural sentence models have been described
	Cause: [(0, 16), (1, 5)]
	Effect: [(0, 0), (0, 14)]

CASE: 10
Stag: 63 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The RNN is primarily used as a language model, but may also be viewed as a sentence model with a linear structure
	Cause: [(0, 6), (0, 22)]
	Effect: [(0, 0), (0, 4)]

CASE: 11
Stag: 65 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Finally, a further class of neural sentence models is based on the convolution operation and the TDNN architecture []
	Cause: [(0, 12), (0, 20)]
	Effect: [(0, 2), (0, 8)]

CASE: 12
Stag: 69 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Concretely, we think of u'\ud835' u'\udc2c' as the input sentence and u'\ud835' u'\udc2c' i u'\u2208' u'\u211d' is a single feature value associated with the i -th word in the sentence
	Cause: [(0, 16), (0, 55)]
	Effect: [(0, 0), (0, 14)]

CASE: 13
Stag: 74 75 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Out-of-range input values u'\ud835' u'\udc2c' i where i 1 or i s are taken to be zero The result of the narrow convolution is a subsequence of the result of the wide convolution
	Cause: [(0, 0), (0, 24)]
	Effect: [(1, 7), (1, 15)]

CASE: 14
Stag: 84 85 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: A TDNN convolves a sequence of inputs u'\ud835' u'\udc2c' with a set of weights u'\ud835' u'\udc26' As in the TDNN for phoneme recognition [] , the sequence u'\ud835' u'\udc2c' is viewed as having a time dimension and the convolution is applied over the time dimension
	Cause: [(1, 1), (1, 37)]
	Effect: [(0, 0), (0, 31)]

CASE: 15
Stag: 86 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: Each u'\ud835' u'\udc2c' j is often not just a single value, but a vector of d values so that u'\ud835' u'\udc2c' u'\u2208' u'\u211d' d × s
	Cause: [(0, 0), (0, 25)]
	Effect: [(0, 28), (0, 49)]

CASE: 16
Stag: 89 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Multiple convolutional layers may be stacked by taking the resulting sequence u'\ud835' u'\udc1c' as input to the next layer
	Cause: [(0, 7), (0, 26)]
	Effect: [(0, 0), (0, 5)]

CASE: 17
Stag: 90 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: The Max-TDNN sentence model is based on the architecture of a TDNN []
	Cause: [(0, 7), (0, 13)]
	Effect: [(0, 0), (0, 3)]

CASE: 18
Stag: 94 95 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The fixed-sized vector u'\ud835' u'\udc1c' m u'\u2062' a u'\u2062' x is then used as input to a fully connected layer for classification The Max-TDNN model has many desirable properties
	Cause: [(0, 30), (1, 5)]
	Effect: [(0, 0), (0, 28)]

CASE: 19
Stag: 100 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Increasing m or stacking multiple convolutional layers of the narrow type makes the range of the feature detectors larger; at the same time it also exacerbates the neglect of the margins of the sentence and increases the minimum size s of the input sentence required by the convolution
	Cause: [(0, 0), (0, 10)]
	Effect: [(0, 11), (0, 19)]

CASE: 20
Stag: 100 101 
	Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
	sentTXT: Increasing m or stacking multiple convolutional layers of the narrow type makes the range of the feature detectors larger; at the same time it also exacerbates the neglect of the margins of the sentence and increases the minimum size s of the input sentence required by the convolution For this reason higher-order and long-range feature detectors cannot be easily incorporated into the model
	Cause: [(0, 0), (0, 48)]
	Effect: [(1, 3), (1, 15)]

CASE: 21
Stag: 107 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: In the network the width of a feature map at an intermediate layer varies depending on the length of the input sentence; the resulting architecture is the Dynamic Convolutional Neural Network
	Cause: [(0, 0), (0, 21)]
	Effect: [(0, 27), (0, 31)]

CASE: 22
Stag: 113 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: A convolutional layer in the network is obtained by convolving a matrix of weights u'\ud835' u'\udc26' u'\u2208' u'\u211d' d × m with the matrix of activations at the layer below
	Cause: [(0, 9), (0, 44)]
	Effect: [(0, 0), (0, 7)]

CASE: 23
Stag: 114 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: For example, the second layer is obtained by applying a convolution to the sentence matrix u'\ud835' u'\udc2c' itself
	Cause: [(0, 9), (0, 15)]
	Effect: [(0, 16), (0, 26)]

CASE: 24
Stag: 125 126 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This guarantees that the input to the fully connected layers is independent of the length of the input sentence But, as we see next, at intermediate convolutional layers the pooling parameter k is not fixed, but is dynamically selected in order to allow for a smooth extraction of higher-order and longer-range features
	Cause: [(1, 3), (1, 20)]
	Effect: [(0, 3), (1, 0)]

CASE: 25
Stag: 133 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: For an example in sentiment prediction, according to the equation a first order feature such as a positive word occurs at most k 1 times in a sentence of length s , whereas a second order feature such as a negated phrase or clause occurs at most k 2 times
	Cause: [(0, 9), (0, 19)]
	Effect: [(0, 33), (0, 50)]

CASE: 26
Stag: 136 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If we temporarily ignore the pooling layer, we may state how one computes each d -dimensional column a in the matrix u'\ud835' u'\udc1a' resulting after the convolutional and non-linear layers
	Cause: [(0, 1), (0, 6)]
	Effect: [(0, 8), (0, 39)]

CASE: 27
Stag: 141 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Second order features are similarly obtained by applying Eq
	Cause: [(0, 7), (0, 8)]
	Effect: [(0, 0), (0, 5)]

CASE: 28
Stag: 148 149 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We denote a feature map of the i -th order by u'\ud835' u'\udc05' i As in convolutional networks for object recognition, to increase the number of learnt feature detectors of a certain order, multiple feature maps u'\ud835' u'\udc05' 1 i , u'\u2026' , u'\ud835' u'\udc05' n i may be computed in parallel at the same layer
	Cause: [(1, 1), (1, 52)]
	Effect: [(0, 0), (0, 22)]

CASE: 29
Stag: 150 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Each feature map u'\ud835' u'\udc05' j i is computed by convolving a distinct set of filters arranged in a matrix u'\ud835' u'\udc26' j , k i with each feature map u'\ud835' u'\udc05' k i - 1 of the lower order i - 1 and summing the results
	Cause: [(0, 18), (0, 70)]
	Effect: [(0, 0), (0, 16)]

CASE: 30
Stag: 151 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: where * indicates the wide convolution
	Cause: [(0, 1), (0, 1)]
	Effect: [(0, 3), (0, 5)]

CASE: 31
Stag: 156 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Full dependence between different rows could be achieved by making u'\ud835' u'\udc0c' in Eq
	Cause: [(0, 9), (0, 21)]
	Effect: [(0, 0), (0, 7)]

CASE: 32
Stag: 160 161 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: For a map of d rows, folding returns a map of d / 2 rows, thus halving the size of the representation With a folding layer, a feature detector of the i -th order depends now on two rows of feature values in the lower maps of order i - 1
	Cause: [(0, 0), (0, 15)]
	Effect: [(0, 18), (1, 29)]

CASE: 33
Stag: 163 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We describe some of the properties of the sentence model based on the DCNN
	Cause: [(0, 12), (0, 13)]
	Effect: [(0, 0), (0, 9)]

CASE: 34
Stag: 170 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The filters u'\ud835' u'\udc26' of the wide convolution in the first layer can learn to recognise specific n -grams that have size less or equal to the filter width m ; as we see in the experiments, m in the first layer is often set to a relatively large value such as 10
	Cause: [(0, 41), (0, 62)]
	Effect: [(0, 0), (0, 39)]

CASE: 35
Stag: 173 174 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: A sentence model based on a recurrent neural network is sensitive to word order, but it has a bias towards the latest words that it takes as input [] This gives the RNN excellent performance at language modelling, but it is suboptimal for remembering at once the n -grams further back in the input sentence
	Cause: [(0, 28), (1, 18)]
	Effect: [(0, 15), (0, 26)]

CASE: 36
Stag: 174 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: This gives the RNN excellent performance at language modelling, but it is suboptimal for remembering at once the n -grams further back in the input sentence
	Cause: [(0, 15), (0, 19)]
	Effect: [(0, 0), (0, 13)]

CASE: 37
Stag: 180 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: A node from a layer is connected to a node from the next higher layer if the lower node is involved in the convolution that computes the value of the higher node
	Cause: [(0, 16), (0, 31)]
	Effect: [(0, 0), (0, 14)]

CASE: 38
Stag: 191 192 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Higher-order features have highly variable ranges that can be either short and focused or global and long as the input sentence Likewise, the edges of a subgraph in the induced graph reflect these varying ranges
	Cause: [(0, 18), (1, 13)]
	Effect: [(0, 0), (0, 16)]

CASE: 39
Stag: 201 202 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The feature extraction function as stated in Eq 6 has a more general form than that in a RecNN, where the value of m is generally 2
	Cause: [(0, 5), (1, 12)]
	Effect: [(0, 0), (0, 3)]

CASE: 40
Stag: 206 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We begin by specifying aspects of the implementation and the training of the network
	Cause: [(0, 3), (0, 13)]
	Effect: [(0, 0), (0, 1)]

CASE: 41
Stag: 212 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using the well-known convolution theorem, we can compute fast one-dimensional linear convolutions at all rows of an input matrix by using Fast Fourier Transforms
	Cause: [(0, 0), (0, 4)]
	Effect: [(0, 6), (0, 24)]

CASE: 42
Stag: 212 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Using the well-known convolution theorem, we can compute fast one-dimensional linear convolutions at all rows of an input matrix by using Fast Fourier Transforms
	Cause: [(0, 15), (0, 18)]
	Effect: [(0, 0), (0, 13)]

CASE: 43
Stag: 218 219 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Likewise, in the fine-grained case, we use the standard 8544/1101/2210 splits Labelled phrases that occur as subparts of the training sentences are treated as independent training instances
	Cause: [(1, 5), (1, 15)]
	Effect: [(0, 0), (1, 3)]

CASE: 44
Stag: 228 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: The binary result is based on a DCNN that has a wide convolutional layer followed by a folding layer, a dynamic k -max pooling layer and a non-linearity; it has a second wide convolutional layer followed by a folding layer, a k -max pooling layer and a non-linearity
	Cause: [(0, 6), (0, 18)]
	Effect: [(0, 20), (0, 44)]

CASE: 45
Stag: 232 233 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: The network is topped by a softmax classification layer The DCNN for the fine-grained result has the same architecture, but the filters have size 10 and 7, the top pooling parameter k is 5 and the number of maps is, respectively, 6 and 12
	Cause: [(0, 1), (1, 2)]
	Effect: [(1, 26), (1, 38)]

CASE: 46
Stag: 238 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: The Max-TDNN performs worse than the NBoW likely due to the excessive pooling of the max pooling operation; the latter discards most of the sentiment features of the words in the input sentence
	Cause: [(0, 10), (0, 17)]
	Effect: [(0, 18), (0, 33)]

CASE: 47
Stag: 240 241 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the next experiment we compare the performance of the DCNN with those of methods that use heavily engineered resources As an aid to question answering, a question may be classified as belonging to one of many question types
	Cause: [(1, 1), (1, 19)]
	Effect: [(0, 0), (0, 19)]

CASE: 48
Stag: 264 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The difference in performance between the DCNN and the NBoW further suggests that the ability of the DCNN to both capture features based on long n -grams and to hierarchically combine these features is highly beneficial
	Cause: [(0, 24), (0, 36)]
	Effect: [(0, 0), (0, 21)]

CASE: 49
Stag: 269 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the filters have width 7, for each of the 288 feature detectors we rank all 7 -grams occurring in the validation and test sets according to their activation of the detector
	Cause: [(0, 1), (0, 5)]
	Effect: [(0, 7), (0, 33)]

CASE: 50
Stag: 269 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: Since the filters have width 7, for each of the 288 feature detectors we rank all 7 -grams occurring in the validation and test sets according to their activation of the detector
	Cause: [(0, 22), (0, 26)]
	Effect: [(0, 0), (0, 19)]

CASE: 51
Stag: 272 273 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We find detectors for multiple other notable constructs including u'\u2018' all u'\u2019' , u'\u2018' or u'\u2019' , u'\u2018' with u'\u2026' that u'\u2019' , u'\u2018' as u'\u2026' as u'\u2019' The feature detectors learn to recognise not just single n -grams, but patterns within n -grams that have syntactic, semantic or structural significance
	Cause: [(0, 57), (1, 22)]
	Effect: [(0, 0), (0, 55)]

