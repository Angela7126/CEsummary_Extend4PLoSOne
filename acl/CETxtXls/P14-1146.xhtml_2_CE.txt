************************************************************
P14-1146.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 2 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This is problematic for sentiment analysis as they usually map words with similar syntactic context but opposite sentiment polarity , such as good and bad , to neighboring word vectors
	Cause: they usually map words with similar syntactic context but opposite sentiment polarity , such as good and bad , to neighboring word vectors
	Effect: This is problematic for sentiment analysis

CASE: 1
Stag: 6 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Experiments on applying SSWE to a benchmark Twitter sentiment classification dataset in SemEval 2013 show that -LRB- 1 -RRB- the SSWE feature performs comparably with hand-crafted features in the top-performed system ; -LRB- 2 -RRB- the performance is further improved by concatenating SSWE with existing feature set
	Cause: concatenating SSWE with existing feature set
	Effect: Experiments on applying SSWE to a benchmark Twitter sentiment classification dataset in SemEval 2013 show that -LRB- 1 -RRB- the SSWE feature performs comparably with hand-crafted features in the top-performed system ; -LRB- 2 -RRB- the performance is further improved

CASE: 2
Stag: 8 9 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The objective is to classify the sentiment polarity of a tweet as positive , negative or neutral The majority of existing approaches follow Pang et al
	Cause: positive , negative or neutral The majority of existing approaches follow Pang et
	Effect: The objective is to classify the sentiment polarity of a tweet

CASE: 3
Stag: 15 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: It is therefore desirable to discover explanatory factors from the data and make the learning algorithms less dependent on extensive feature engineering -LSB- 4 -RSB-
	Cause: It is
	Effect: desirable to discover explanatory factors from the data and make the learning algorithms less dependent on extensive feature engineering -LSB- 4 -RSB-

CASE: 4
Stag: 16 17 
	Pattern: 2 [['accordingly']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: For the task of sentiment classification , an effective feature learning method is to compose the representation of a sentence -LRB- or document -RRB- from the representations of the words or phrases it contains -LSB- 40 , 47 -RSB- Accordingly , it is a crucial step to learn the word representation -LRB- or word embedding -RRB- , which is a dense , low-dimensional and real-valued vector for a word
	Cause: For the task of sentiment classification , an effective feature learning method is to compose the representation of a sentence -LRB- or document -RRB- from the representations of the words or phrases it contains -LSB- 40 , 47 -RSB-
	Effect: it is a crucial step to learn the word representation -LRB- or word embedding -RRB- , which is a dense , low-dimensional and real-valued vector for a word

CASE: 5
Stag: 19 20 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: The most serious problem is that traditional methods typically model the syntactic context of words but ignore the sentiment information of text As a result , words with opposite polarity , such as good and bad , are mapped into close vectors
	Cause: The most serious problem is that traditional methods typically model the syntactic context of words but ignore the sentiment information of text
	Effect: words with opposite polarity , such as good and bad , are mapped into close vectors

CASE: 6
Stag: 23 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: We encode the sentiment information into the continuous representation of words , so that it is able to separate good and bad to opposite ends of the spectrum
	Cause: We encode the sentiment information into the continuous representation of words ,
	Effect: it is able to separate good and bad to opposite ends of the spectrum

CASE: 7
Stag: 25 26 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We learn the sentiment-specific word embedding from tweets , leveraging massive tweets with emoticons as distant-supervised corpora without any manual annotations These automatically collected tweets contain noises so they can not be directly used as gold training data to build sentiment classifiers , but they are effective enough to provide weakly supervised signals for training the sentiment-specific word embedding
	Cause: distant-supervised corpora without any manual annotations These automatically collected tweets contain noises so they can not be directly used as gold training data to build sentiment classifiers , but they are effective enough to provide weakly supervised signals for training the sentiment-specific word
	Effect: We learn the sentiment-specific word embedding from tweets , leveraging massive tweets with emoticons

CASE: 8
Stag: 26 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: These automatically collected tweets contain noises so they can not be directly used as gold training data to build sentiment classifiers , but they are effective enough to provide weakly supervised signals for training the sentiment-specific word embedding
	Cause: These automatically collected tweets contain noises
	Effect: they can not be directly used as gold training data to build sentiment classifiers , but they are effective enough to provide weakly supervised signals for training the sentiment-specific word embedding

CASE: 9
Stag: 26 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: they can not be directly used as gold training data to build sentiment classifiers , but they are effective enough to provide weakly supervised signals for training the sentiment-specific word embedding
	Cause: gold training data to build sentiment classifiers , but they
	Effect: they can not be directly used

CASE: 10
Stag: 27 28 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We apply SSWE as features in a supervised learning framework for Twitter sentiment classification , and evaluate it on the benchmark dataset in SemEval 2013 In the task of predicting positive/negative polarity of tweets , our method yields 84.89 % in macro-F1 by only using SSWE as feature , which is comparable to the top-performed system based on hand-crafted features -LRB- 84.70 %
	Cause: features in a supervised learning framework for Twitter sentiment classification , and evaluate it on the benchmark dataset in SemEval 2013 In the task of predicting positive/negative polarity of tweets , our
	Effect: We apply SSWE

CASE: 11
Stag: 28 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the task of predicting positive/negative polarity of tweets , our method yields 84.89 % in macro-F1 by only using SSWE as feature , which is comparable to the top-performed system based on hand-crafted features -LRB- 84.70 %
	Cause: feature , which is comparable to the top-performed system based on hand-crafted features -LRB- 84.70 %
	Effect: In the task of predicting positive/negative polarity of tweets , our method yields 84.89 % in macro-F1 by only using SSWE

CASE: 12
Stag: 30 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The quality of SSWE is also directly evaluated by measuring the word similarity in the embedding space for sentiment lexicons
	Cause: measuring the word similarity in the embedding space for sentiment lexicons
	Effect: The quality of SSWE is also directly evaluated

CASE: 13
Stag: 43 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Many studies on Twitter sentiment classification -LSB- 32 , 10 , 1 , 22 , 48 -RSB- leverage massive noisy-labeled tweets selected by positive and negative emoticons as training set and build sentiment classifiers directly , which is called distant supervision -LSB- 17 -RSB-
	Cause: training set and build sentiment classifiers directly , which is called distant supervision -LSB- 17 -RSB-
	Effect: classification -LSB- 32 , 10 , 1 , 22 , 48 -RSB- leverage massive noisy-labeled tweets selected by positive and negative emoticons

CASE: 14
Stag: 54 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: It has the same length as the size of the vocabulary , and only one dimension is 1 , with all others being 0
	Cause: the size of the vocabulary , and only one dimension is 1 , with all others being
	Effect: It has the same length

CASE: 15
Stag: 56 57 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However , the one-hot word representation can not sufficiently capture the complex linguistic characteristics of words With the revival of interest in deep learning -LSB- 2 -RSB- , incorporating the continuous representation of a word as features has been proving effective in a variety of NLP tasks , such as parsing -LSB- 35 -RSB- , language modeling -LSB- 3 , 29 -RSB- and NER -LSB- 43 -RSB-
	Cause: features has been proving effective in a variety of NLP tasks , such as parsing -LSB- 35 -RSB- , language modeling -LSB- 3 , 29 -RSB- and NER -LSB- 43 -RSB-
	Effect: However , the one-hot word representation can not sufficiently capture the complex linguistic characteristics of words With the revival of interest in deep learning -LSB- 2 -RSB- , incorporating the continuous representation of a word

CASE: 16
Stag: 63 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Socher et al propose Recursive Neural Network -LRB- RNN -RRB- -LSB- 38 -RSB- , matrix-vector RNN -LSB- 37 -RSB- and Recursive Neural Tensor Network -LRB- RNTN -RRB- -LSB- 40 -RSB- to learn the compositionality of phrases of any length based on the representation of each pair of children recursively
	Cause: the representation of each pair of children
	Effect: Socher et al propose Recursive Neural Network -LRB- RNN -RRB- -LSB- 38 -RSB- , matrix-vector RNN -LSB- 37 -RSB- and Recursive Neural Tensor Network -LRB- RNTN -RRB- -LSB- 40 -RSB- to learn the compositionality of phrases of any length

CASE: 17
Stag: 79 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2011 -RRB- introduce C W model to learn word embedding based on the syntactic contexts of words
	Cause: the syntactic contexts of words
	Effect: 2011 -RRB- introduce C W model to learn word embedding

CASE: 18
Stag: 85 86 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The original and corrupted ngrams are treated as inputs of the feed-forward neural network , respectively The output f c u ' \ u2062 ' w is the language model score of the input , which is calculated as given in Equation 2 , where L is the lookup table of word embedding , w 1 , w 2 , b 1 , b 2 are the parameters of linear layers
	Cause: inputs of the feed-forward neural network , respectively The output f c u ' \ u2062 ' w is the language model score of the input , which is calculated as given in Equation 2 , where L is the lookup table of word embedding , w 1
	Effect: The original and corrupted ngrams are treated

CASE: 19
Stag: 86 87 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The output f c u ' \ u2062 ' w is the language model score of the input , which is calculated as given in Equation 2 , where L is the lookup table of word embedding , w 1 , w 2 , b 1 , b 2 are the parameters of linear layers Following the traditional C W model -LSB- 9 -RSB- , we incorporate the sentiment information into the neural network to learn sentiment-specific word embedding
	Cause: given in Equation 2 , where L is the lookup table of word embedding , w 1 , w 2 , b 1 , b 2 are the parameters of linear layers Following the traditional C W model -LSB- 9 -RSB- , we incorporate the sentiment information into the neural network to learn sentiment-specific word embedding
	Effect: u ' \ u2062 ' w is the language model score of the input , which is calculated

CASE: 20
Stag: 88 89 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We develop three neural networks with different strategies to integrate the sentiment information of tweets As an unsupervised approach , C W model does not explicitly capture the sentiment information of texts
	Cause: an unsupervised approach , C W model does not explicitly capture the sentiment information of texts
	Effect: We develop three neural networks with different strategies to integrate the sentiment information of tweets

CASE: 21
Stag: 90 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: An intuitive solution to integrate the sentiment information is predicting the sentiment distribution of text based on input ngram
	Cause: input ngram
	Effect: An intuitive solution to integrate the sentiment information is predicting the sentiment distribution of text

CASE: 22
Stag: 91 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We do not utilize the entire sentence as input because the length of different sentences might be variant
	Cause: the length of different sentences might be variant
	Effect: We do not utilize the entire sentence as input

CASE: 23
Stag: 91 92 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: We do not utilize the entire sentence as input because the length of different sentences might be variant We therefore slide the window of ngram across a sentence , and then predict the sentiment polarity based on each ngram with a shared neural network
	Cause: do not utilize the entire sentence as input because the length of different sentences might be variant We
	Effect: slide the window of ngram across a sentence , and then predict the sentiment polarity based on each ngram with a shared neural network

CASE: 24
Stag: 93 94 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In the neural network , the distributed representation of higher layer are interpreted as features describing the input Thus , we utilize the continuous vector of top layer to predict the sentiment distribution of text
	Cause: In the neural network , the distributed representation of higher layer are interpreted as features describing the input
	Effect: , we utilize the continuous vector of top layer to predict the sentiment distribution of text

CASE: 25
Stag: 95 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Assuming there are K labels , we modify the dimension of top layer in C W model as K and add a s u ' \ u2062 ' o u ' \ u2062 ' f u ' \ u2062 ' t u ' \ u2062 ' m u ' \ u2062 ' a u ' \ u2062 ' x layer upon the top layer
	Cause: Assuming there are K labels , we modify the dimension of top layer in C W model as K and add a s u ' \ u2062 ' o
	Effect: u ' \ u2062 ' f u ' \ u2062 ' t u '

CASE: 26
Stag: 97 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: S u ' \ u2062 ' o u ' \ u2062 ' f u ' \ u2062 ' t u ' \ u2062 ' m u ' \ u2062 ' a u ' \ u2062 ' x layer is suitable for this scenario because its outputs are interpreted as conditional probabilities
	Cause: its outputs are interpreted as conditional probabilities
	Effect: S u ' \ u2062 ' o u ' \ u2062 ' f u ' \ u2062 ' t u ' \ u2062 ' m u ' \ u2062 ' a u ' \ u2062 ' x layer is suitable for this scenario

CASE: 27
Stag: 103 104 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: SSWE h is trained by predicting the positive ngram as -LSB- 1,0 -RSB- and the negative ngram as -LSB- 0,1 -RSB- However , the constraint of SSWE h is too strict
	Cause: -LSB- 1,0 -RSB- and the negative ngram as -LSB- 0,1 -RSB- However , the constraint of SSWE h is too
	Effect: SSWE h is trained by predicting the positive ngram

CASE: 28
Stag: 105 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The distribution of -LSB- 0.7,0.3 -RSB- can also be interpreted as a positive label because the positive score is larger than the negative score
	Cause: the positive score is larger than the negative score
	Effect: The distribution of -LSB- 0.7,0.3 -RSB- can also be interpreted as a positive label

CASE: 29
Stag: 106 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Similarly , the distribution of -LSB- 0.2,0.8 -RSB- indicates negative polarity
	Cause: the distribution of -LSB- 0.2,0.8 -RSB-
	Effect: negative polarity

CASE: 30
Stag: 107 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on the above observation , the hard constraints in SSWE h should be relaxed
	Cause: the above observation
	Effect: the hard constraints in SSWE h should be relaxed

CASE: 31
Stag: 108 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the sentiment polarity of a tweet is positive , the predicted positive score is expected to be larger than the predicted negative score , and the exact reverse if the tweet has negative polarity
	Cause: the sentiment polarity of a tweet is positive
	Effect: the predicted positive score is expected to be larger than the predicted negative score , and the exact reverse if the tweet has negative polarity

CASE: 32
Stag: 108 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: the predicted positive score is expected to be larger than the predicted negative score , and the exact reverse if the tweet has negative polarity
	Cause: the tweet has negative polarity
	Effect: the predicted positive score is expected to be larger than the predicted negative score , and the exact reverse

CASE: 33
Stag: 110 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Compared with SSWE h , the s u ' \ u2062 ' o u ' \ u2062 ' f u ' \ u2062 ' t u ' \ u2062 ' m u ' \ u2062 ' a u ' \ u2062 ' x layer is removed because SSWE r does not require probabilistic interpretation
	Cause: SSWE r does not require probabilistic interpretation
	Effect: Compared with SSWE h , the s u ' \ u2062 ' o u ' \ u2062 ' f u ' \ u2062 ' t u ' \ u2062 ' m u ' \ u2062 ' a u ' \ u2062 ' x layer is removed

CASE: 34
Stag: 117 118 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: SSWE u is illustrated in Figure 1 -LRB- c Given an original -LRB- or corrupted -RRB- ngram and the sentiment polarity of a sentence as the input , SSWE u predicts a two-dimensional vector for each input ngram
	Cause: the input , SSWE u predicts a two-dimensional vector for each input ngram
	Effect: SSWE u is illustrated in Figure 1 -LRB- c Given an original -LRB- or corrupted -RRB- ngram and the sentiment polarity of a sentence

CASE: 35
Stag: 122 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where l u ' \ u2062 ' o u ' \ u2062 ' s u ' \ u2062 ' s c u ' \ u2062 ' w u ' \ u2062 ' -LRB- t , t r -RRB- is the syntactic loss as given in Equation 1 , l u ' \ u2062 ' o u ' \ u2062 ' s u ' \ u2062 ' s u u ' \ u2062 ' s u ' \ u2062 ' -LRB- t , t r -RRB- is the sentiment loss as described in Equation 9
	Cause: given in Equation 1 , l u ' \ u2062 ' o u ' \ u2062 ' s u ' \ u2062 ' s u u ' \ u2062 ' s u ' \ u2062 '
	Effect: l u ' \ u2062 ' o u ' \ u2062 ' s u ' \ u2062 ' s c u ' \ u2062 ' w u ' \ u2062 ' -LRB- t , t r -RRB- is the syntactic loss

CASE: 36
Stag: 132 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: We train SSWE h , SSWE r and SSWE u by taking the derivative of the loss through back-propagation with respect to the whole set of parameters -LSB- 9 -RSB- , and use AdaGrad -LSB- 12 -RSB- to update the parameters
	Cause: taking the derivative of the loss through back-propagation with respect to the whole set of parameters
	Effect: -LSB- 9 -RSB- , and use AdaGrad -LSB- 12 -RSB- to update the parameters

CASE: 37
Stag: 133 134 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We empirically set the window size as 3 , the embedding length as 50 , the length of hidden layer as 20 and the learning rate of AdaGrad as 0.1 for all baseline and our models We learn embedding for unigrams , bigrams and trigrams separately with same neural network and same parameter setting
	Cause: 3 , the embedding length as 50 , the length of hidden layer as 20 and the learning rate of AdaGrad as 0.1 for all baseline and our models We learn embedding for unigrams , bigrams and trigrams separately with same neural network and same parameter
	Effect: We empirically set the window size

CASE: 38
Stag: 136 137 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We apply sentiment-specific word embedding for Twitter sentiment classification under a supervised learning framework as in previous work -LSB- 33 -RSB- Instead of hand-crafting features , we incorporate the continuous representation of words and phrases as the feature of a tweet
	Cause: in previous work -LSB- 33 -RSB- Instead of hand-crafting features , we incorporate the continuous representation of words and phrases as the feature of a
	Effect: We apply sentiment-specific word embedding for Twitter sentiment classification under a supervised learning framework

CASE: 39
Stag: 137 138 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Instead of hand-crafting features , we incorporate the continuous representation of words and phrases as the feature of a tweet The sentiment classifier is built from tweets with manually annotated sentiment polarity
	Cause: the feature of a tweet The sentiment classifier is built from tweets with manually annotated sentiment
	Effect: Instead of hand-crafting features , we incorporate the continuous representation of words and phrases

CASE: 40
Stag: 139 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We explore m u ' \ u2062 ' i u ' \ u2062 ' n , a u ' \ u2062 ' v u ' \ u2062 ' e u ' \ u2062 ' r u ' \ u2062 ' a u ' \ u2062 ' g u ' \ u2062 ' e and m u ' \ u2062 ' a u ' \ u2062 ' x convolutional layers -LSB- 9 , 36 -RSB- , which have been used as simple and effective methods for compositionality learning in vector-based semantics -LSB- 28 -RSB- , to obtain the tweet representation
	Cause: simple and effective methods for compositionality learning in vector-based semantics -LSB- 28 -RSB- , to obtain the tweet
	Effect: We explore m u ' \ u2062 ' i u ' \ u2062 ' n , a u ' \ u2062 ' v u ' \ u2062 ' e u ' \ u2062 ' r u ' \ u2062 ' a u ' \ u2062 ' g u ' \ u2062 ' e and m u ' \ u2062 ' a u ' \ u2062 ' x convolutional layers -LSB- 9 , 36 -RSB- , which have been used

CASE: 41
Stag: 139 140 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: We explore m u ' \ u2062 ' i u ' \ u2062 ' n , a u ' \ u2062 ' v u ' \ u2062 ' e u ' \ u2062 ' r u ' \ u2062 ' a u ' \ u2062 ' g u ' \ u2062 ' e and m u ' \ u2062 ' a u ' \ u2062 ' x convolutional layers -LSB- 9 , 36 -RSB- , which have been used as simple and effective methods for compositionality learning in vector-based semantics -LSB- 28 -RSB- , to obtain the tweet representation The result is the concatenation of vectors derived from different convolutional layers
	Cause: We explore m u ' \ u2062 ' i u ' \ u2062 ' n , a u ' \ u2062 ' v u ' \ u2062 ' e u ' \ u2062 ' r u ' \ u2062 ' a u ' \ u2062 ' g u ' \ u2062 ' e and m u ' \ u2062 ' a u ' \ u2062 ' x convolutional layers -LSB- 9 , 36 -RSB- , which have been used as simple and effective methods for compositionality learning in vector-based semantics -LSB- 28 -RSB- , to obtain the tweet representation
	Effect: the concatenation of vectors derived from different convolutional layers

CASE: 42
Stag: 146 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We conduct experiments to evaluate SSWE by incorporating it into a supervised learning framework for Twitter sentiment classification
	Cause: incorporating it into a supervised learning framework for Twitter sentiment classification
	Effect: We conduct experiments to evaluate SSWE

CASE: 43
Stag: 147 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We also directly evaluate the effectiveness of the SSWE by measuring the word similarity in the embedding space for sentiment lexicons
	Cause: measuring the word
	Effect: We also directly evaluate the effectiveness of the SSWE

CASE: 44
Stag: 150 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: However , we were unable to download all the training and development sets because some tweets were deleted or not available due to modified authorization status
	Cause: some tweets were deleted or not available due to modified authorization
	Effect: However , we were unable to download all the training and development sets

CASE: 45
Stag: 164 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Recursive Autoencoder -LSB- 39 -RSB- has been proven effective in many sentiment analysis tasks by learning compositionality automatically
	Cause: learning compositionality automatically
	Effect: Recursive Autoencoder -LSB- 39 -RSB- has been proven effective in many sentiment analysis tasks

CASE: 46
Stag: 168 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: We re-implement this system because the codes are not publicly available 3 3 For 3-class sentiment classification in SemEval 2013 , our re-implementation of NRC achieved 68.3 % , 0.7 % lower than NRC -LRB- 69 % -RRB- due to less training data
	Cause: the codes are not publicly available 3 3 For 3-class sentiment classification in SemEval 2013
	Effect: our re-implementation of NRC achieved 68.3 % , 0.7 % lower than NRC -LRB- 69 % -RRB- due to less training data

CASE: 47
Stag: 168 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: our re-implementation of NRC achieved 68.3 % , 0.7 % lower than NRC -LRB- 69 % -RRB- due to less training data
	Cause: less training data
	Effect: our re-implementation of NRC achieved 68.3 % , 0.7 % lower than NRC -LRB- 69 % -RRB-

CASE: 48
Stag: 171 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We do not compare with RNTN -LSB- 40 -RSB- because we can not efficiently train the RNTN model
	Cause: we can not efficiently train the RNTN model
	Effect: We do not compare with RNTN -LSB- 40 -RSB-

CASE: 49
Stag: 172 173 
	Pattern: 1 [['reason'], [['that', 'because']]]---- [['&R', '(,/./;/--)', '&ONE', '(&ADJ)'], ['(for &THIS (&NP))', '&BE'], ['&C']]
	sentTXT: The reason lies in that the tweets in our dataset do not have accurately parsed results or fine grained sentiment labels for phrases Another reason is that the RNTN model trained on movie reviews can not be directly applied on tweets due to the differences between domains -LSB- 8 -RSB-
	Cause: the RNTN model trained on movie reviews can not be directly applied on tweets due to the differences between domains -LSB- 8 -RSB-
	Effect: The reason lies in that the tweets in our dataset do not have accurately parsed results or fine grained sentiment labels for phrases

CASE: 50
Stag: 175 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Distant supervision is relatively weak because the noisy-labeled tweets are treated as the gold standard , which affects the performance of classifier
	Cause: the noisy-labeled tweets are treated as the gold standard
	Effect: which affects the performance of classifier

CASE: 51
Stag: 176 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The results of bag-of-ngram -LRB- uni/bi/tri-gram -RRB- features are not satisfied because the one-hot word representation can not capture the latent connections between words
	Cause: the one-hot word representation can not capture the latent connections between words
	Effect: The results of bag-of-ngram -LRB- uni/bi/tri-gram -RRB- features are not satisfied

CASE: 52
Stag: 180 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We achieve 84.98 % by using only SSWE u as features without borrowing any sentiment lexicons or hand-crafted rules
	Cause: using only SSWE u as features without borrowing any sentiment lexicons or hand-crafted rules
	Effect: We achieve 84.98 %

CASE: 53
Stag: 183 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We also compare SSWE u with the ngram feature by integrating SSWE into NRC-ngram
	Cause: integrating SSWE into NRC-ngram
	Effect: We also compare SSWE u with the ngram feature

CASE: 54
Stag: 184 185 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The concatenated features SSWE u + NRC-ngram -LRB- 86.48 % -RRB- outperform the original feature set of NRC -LRB- 84.73 % As a reference , we apply SSWE u on subjective classification of tweets , and obtain 72.17 % in macro-F1 by using only SSWE u as feature
	Cause: a reference , we apply SSWE u on subjective classification of tweets , and
	Effect: The concatenated features SSWE u + NRC-ngram -LRB- 86.48 % -RRB- outperform the original feature set of NRC -LRB- 84.73 %

CASE: 55
Stag: 187 188 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We compare sentiment-specific word embedding -LRB- SSWE h , SSWE r , SSWE u -RRB- with baseline embedding learning algorithms by only using word embedding as features for Twitter sentiment classification We use the embedding of unigrams , bigrams and trigrams in the experiment
	Cause: features for Twitter sentiment classification We use the embedding of unigrams , bigrams and trigrams in the
	Effect: We compare sentiment-specific word embedding -LRB- SSWE h , SSWE r , SSWE u -RRB- with baseline embedding learning algorithms by only using word embedding

CASE: 56
Stag: 190 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We utilize the Skip-gram model because it performs better than CBOW in our experiments
	Cause: it performs better than CBOW in our experiments
	Effect: We utilize the Skip-gram model

CASE: 57
Stag: 192 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We compare with C W and word2vec as they have been proved effective in many NLP tasks
	Cause: they have been proved effective in many NLP tasks
	Effect: We compare with C W and word2vec

CASE: 58
Stag: 194 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Table 3 shows the performance on the positive/negative classification of tweets 5 5 MVSA and ReEmb are not suitable for learning bigram and trigram embedding because their sentiment predictor functions only utilize the unigram embedding
	Cause: their sentiment predictor functions only utilize the unigram embedding
	Effect: Table 3 shows the performance on the positive/negative classification of tweets 5 5 MVSA and ReEmb are not suitable for learning bigram and trigram embedding

CASE: 59
Stag: 199 200 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: From the first column of Table 3 , we can see that the performance of C W and word2vec are obviously lower than sentiment-specific word embeddings by only using unigram embedding as features The reason is that C W and word2vec do not explicitly exploit the sentiment information of the text , resulting in that the words with opposite polarity such as good and bad are mapped to close word vectors
	Cause: features The reason is that C W and word2vec do not explicitly exploit the sentiment information of the text ,
	Effect: From the first column of Table 3 , we can see that the performance of C W and word2vec are obviously lower than sentiment-specific word embeddings by only using unigram embedding

CASE: 60
Stag: 199 200 
	Pattern: 1 [['reason'], [['that', 'because']]]---- [['&R', '(,/./;/--)', '&ONE', '(&ADJ)'], ['(for &THIS (&NP))', '&BE'], ['&C']]
	sentTXT: From the first column of Table 3 , we can see that the performance of C W and word2vec are obviously lower than sentiment-specific word embeddings by only using unigram embedding as features The reason is that C W and word2vec do not explicitly exploit the sentiment information of the text , resulting in that the words with opposite polarity such as good and bad are mapped to close word vectors
	Cause: C W and word2vec do not explicitly exploit the sentiment information of the text , resulting in that the words with opposite polarity such as good and bad are mapped to close word vectors
	Effect: From the first column of Table 3 , we can see that the performance of C W and word2vec are obviously lower than sentiment-specific word embeddings by only using unigram embedding as features

CASE: 61
Stag: 201 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: When such word embeddings are fed as features to a Twitter sentiment classifier , the discriminative ability of sentiment words are weakened thus the classification performance is affected
	Cause: When such word embeddings are fed as features to a Twitter sentiment classifier , the discriminative ability of sentiment words are weakened
	Effect: the classification performance is affected

CASE: 62
Stag: 201 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: When such word embeddings are fed as features to a Twitter sentiment classifier , the discriminative ability of sentiment words are weakened
	Cause: features to a Twitter sentiment classifier , the discriminative ability of sentiment words are weakened
	Effect: such word embeddings are fed

CASE: 63
Stag: 208 209 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The underlying reason is that a phrase , which can not be accurately represented by unigram embedding , is directly encoded into the ngram embedding as an idiomatic unit A typical case in sentiment analysis is that the composed phrase and multiword expression may have a different sentiment polarity than the individual words it contains , such as not -LSB- bad -RSB- and -LSB- great -RSB- deal of -LRB- the word in the bracket has different sentiment polarity with the ngram
	Cause: an idiomatic unit A typical case in sentiment analysis is that the composed phrase and multiword expression may have a different sentiment polarity than the individual words it contains , such as not -LSB- bad -RSB- and
	Effect: The underlying reason is that a phrase , which can not be accurately represented by unigram embedding , is directly encoded into the ngram embedding

CASE: 64
Stag: 212 213 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We tune the hyper-parameter u ' \ u0391 ' of SSWE u on the development set by using unigram embedding as features As given in Equation 8 , u ' \ u0391 ' is the weighting score of syntactic loss of SSWE u and trades-off the syntactic and sentiment losses
	Cause: features As given in Equation 8 , u ' \ u0391 ' is the weighting score of syntactic loss of SSWE u and trades-off the
	Effect: We tune the hyper-parameter u ' \ u0391 ' of SSWE u on the development set by using unigram embedding

CASE: 65
Stag: 212 213 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We tune the hyper-parameter u ' \ u0391 ' of SSWE u on the development set by using unigram embedding as features As given in Equation 8 , u ' \ u0391 ' is the weighting score of syntactic loss of SSWE u and trades-off the syntactic and sentiment losses
	Cause: given in Equation 8 , u ' \ u0391 ' is the weighting score of syntactic loss of SSWE u and trades-off the syntactic and sentiment losses
	Effect: We tune the hyper-parameter u ' \ u0391 ' of SSWE u on the development set by using unigram embedding as features

CASE: 66
Stag: 221 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: We set the u ' \ u0391 ' of SSWE u as 0.5 , according to the experiments shown in Figure 2
	Cause: the experiments shown in Figure 2
	Effect: We set the u ' \ u0391 ' of SSWE u as 0.5

CASE: 67
Stag: 224 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The underlying reason is that when more tweets are incorporated , the word embedding is better estimated as the vocabulary size is larger and the context and sentiment information are richer
	Cause: the vocabulary size is larger and
	Effect: The underlying reason is that when more tweets are incorporated , the word embedding is better estimated

CASE: 68
Stag: 226 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: When we have more than 10 million tweets , the performance remains stable as the contexts of words have been mostly covered
	Cause: the contexts of words have been mostly covered
	Effect: When we have more than 10 million tweets , the performance remains stable

CASE: 69
Stag: 235 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We only use unigram embedding in this section because these sentiment lexicons do not contain phrases
	Cause: these sentiment lexicons do not contain phrases
	Effect: We only use unigram embedding in this section

CASE: 70
Stag: 238 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The accuracy of random result is 50 % as positive and negative words are randomly occurred in the nearest neighbors of each word
	Cause: positive and negative words are randomly occurred in the nearest neighbors of each word
	Effect: The accuracy of random result is 50 %

CASE: 71
Stag: 243 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: SSWE outperforms MVSA and ReEmb by exploiting more context information of words and sentiment information of sentences , respectively
	Cause: exploiting more context information of words and sentiment information of sentences , respectively
	Effect: SSWE outperforms MVSA and ReEmb

CASE: 72
Stag: 244 245 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In this paper , we propose learning continuous word representations as features for Twitter sentiment classification under a supervised learning framework We show that the word embedding learned by traditional neural networks are not effective enough for Twitter sentiment classification
	Cause: features for Twitter sentiment classification under a supervised learning framework We show that the word embedding learned by traditional neural networks are not effective enough for Twitter sentiment
	Effect: In this paper , we propose learning continuous word representations

CASE: 73
Stag: 246 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: These methods typically only model the context information of words so that they can not distinguish words with similar context but opposite sentiment polarity -LRB- e.g. , good and bad
	Cause: These methods typically only model the context information of words
	Effect: they can not distinguish words with similar context but opposite sentiment polarity -LRB- e.g. , good and bad

CASE: 74
Stag: 247 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We learn sentiment-specific word embedding -LRB- SSWE -RRB- by integrating the sentiment information into the loss functions of three neural networks
	Cause: integrating the sentiment information into the loss functions of three neural networks
	Effect: We learn sentiment-specific word embedding -LRB- SSWE -RRB-

CASE: 75
Stag: 249 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: The effectiveness of SSWE has been implicitly evaluated by using it as features in sentiment classification on the benchmark dataset in SemEval 2013 , and explicitly verified by measuring word similarity in the embedding space for sentiment lexicons
	Cause: using it as features in sentiment classification on the benchmark dataset in SemEval 2013
	Effect: , and explicitly verified by measuring word similarity in the embedding space for sentiment lexicons

