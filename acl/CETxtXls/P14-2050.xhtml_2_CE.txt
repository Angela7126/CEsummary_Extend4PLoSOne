************************************************************
P14-2050.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 4 5 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Word representation is central to natural language processing The default approach of representing words as discrete and distinct symbols is insufficient for many tasks , and suffers from poor generalization
	Cause: discrete and distinct symbols is insufficient for many tasks , and suffers from poor generalization
	Effect: representation is central to natural language processing The default approach of representing words

CASE: 1
Stag: 6 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: For example , the symbolic representation of the words u ' \ u201c ' pizza u ' \ u201d ' and u ' \ u201c ' hamburger u ' \ u201d ' are completely unrelated even if we know that the word u ' \ u201c ' pizza u ' \ u201d ' is a good argument for the verb u ' \ u201c ' eat u ' \ u201d ' , we can not infer that u ' \ u201c ' hamburger u ' \ u201d ' is also a good argument
	Cause: we know that the word u ' \ u201c ' pizza u ' \ u201d ' is a good argument for the verb u ' \ u201c ' eat u ' \ u201d '
	Effect: we can not infer that u ' \ u201c ' hamburger u ' \ u201d ' is also a good argument

CASE: 2
Stag: 6 7 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: For example , the symbolic representation of the words u ' \ u201c ' pizza u ' \ u201d ' and u ' \ u201c ' hamburger u ' \ u201d ' are completely unrelated even if we know that the word u ' \ u201c ' pizza u ' \ u201d ' is a good argument for the verb u ' \ u201c ' eat u ' \ u201d ' , we can not infer that u ' \ u201c ' hamburger u ' \ u201d ' is also a good argument We thus seek a representation that captures semantic and syntactic similarities between words
	Cause: example , the symbolic representation of the words u ' \ u201c ' pizza u ' \ u201d ' and u ' \ u201c ' hamburger u ' \ u201d ' are completely unrelated even if we know that the word u ' \ u201c ' pizza u ' \ u201d ' is a good argument for the verb u ' \ u201c ' eat u ' \ u201d ' , we can not infer that u ' \ u201c ' hamburger u ' \ u201d ' is also a good argument We
	Effect: seek a representation that captures semantic and syntactic similarities between words

CASE: 3
Stag: 8 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: A very common paradigm for acquiring such representations is based on the distributional hypothesis of Harris -LSB- 16 -RSB- , stating that words in similar contexts have similar meanings
	Cause: the distributional hypothesis of Harris -LSB- 16 -RSB-
	Effect: stating that words in similar contexts have similar meanings

CASE: 4
Stag: 9 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on the distributional hypothesis , many methods of deriving word representations were explored in the NLP community
	Cause: the distributional hypothesis
	Effect: many methods of deriving word representations were explored in the NLP community

CASE: 5
Stag: 10 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: On one end of the spectrum , words are grouped into clusters based on their contexts -LSB- 5 , 32 -RSB-
	Cause: their contexts -LSB- 5 , 32 -RSB-
	Effect: On one end of the spectrum , words are grouped into clusters

CASE: 6
Stag: 11 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: On the other end , words are represented as a very high dimensional but sparse vectors in which each entry is a measure of the association between the word and a particular context -LRB- see -LSB- 30 , 3 -RSB- for a comprehensive survey
	Cause: a very high dimensional but sparse vectors in which each entry is a measure of the association between the word and a particular context -LRB- see -LSB- 30 , 3
	Effect: On the other end , words are represented

CASE: 7
Stag: 13 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Most recently , it has been proposed to represent words as dense vectors that are derived by various training methods inspired from neural-network language modeling -LSB- 4 , 10 , 23 , 20 , 21 -RSB-
	Cause: dense vectors that are derived by various training methods inspired from neural-network language modeling -LSB- 4 , 10 , 23 , 20 , 21
	Effect: Most recently , it has been proposed to represent words

CASE: 8
Stag: 13 14 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Most recently , it has been proposed to represent words as dense vectors that are derived by various training methods inspired from neural-network language modeling -LSB- 4 , 10 , 23 , 20 , 21 -RSB- These representations , referred to as u ' \ u201c ' neural embeddings u ' \ u201d ' or u ' \ u201c ' word embeddings u ' \ u201d ' , have been shown to perform well across a variety of tasks -LSB- 29 , 9 , 26 , 2 -RSB-
	Cause: u ' \ u201c ' neural embeddings u ' \ u201d ' or u ' \ u201c ' word embeddings u ' \ u201d ' , have been shown to perform well across a variety of tasks -LSB- 29 ,
	Effect: Most recently , it has been proposed to represent words as dense vectors that are derived by various training methods inspired from neural-network language modeling -LSB- 4 , 10 , 23 , 20 , 21 -RSB- These representations , referred to

CASE: 9
Stag: 15 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Word embeddings are easy to work with because they enable efficient computation of word similarities through low-dimensional matrix operations
	Cause: they enable efficient computation of word similarities through low-dimensional matrix operations
	Effect: Word embeddings are easy to work with

CASE: 10
Stag: 27 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: In Section 5 we show that the SkipGram model does allow for some introspection by querying it for contexts that are u ' \ u201c ' activated by u ' \ u201d ' a target word
	Cause: querying it for contexts that are u ' \ u201c ' activated by u ' \ u201d ' a target word
	Effect: In Section 5 we show that the SkipGram model does allow for some introspection

CASE: 11
Stag: 32 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the skip-gram model , each word w u ' \ u2208 ' W is associated with a vector v w u ' \ u2208 ' R d and similarly each context c u ' \ u2208 ' C is represented as a vector v c u ' \ u2208 ' R d , where W is the words vocabulary , C is the contexts vocabulary , and d is the embedding dimensionality
	Cause: a vector v c u ' \ u2208 ' R d , where W is the words vocabulary , C is the contexts
	Effect: In the skip-gram model , each word w u ' \ u2208 ' W is associated with a vector v w u ' \ u2208 ' R d and similarly each context c u ' \ u2208 ' C is represented

CASE: 12
Stag: 33 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The entries in the vectors are latent , and treated as parameters to be learned
	Cause: parameters to be learned
	Effect: The entries in the vectors are latent , and treated

CASE: 13
Stag: 34 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Loosely speaking , we seek parameter values -LRB- that is , vector representations for both words and contexts -RRB- such that the dot product v w u ' \ u22c5 ' v c associated with u ' \ u201c ' good u ' \ u201d ' word-context pairs is maximized
	Cause: Loosely speaking
	Effect: we seek parameter values -LRB- that is , vector representations for both words and contexts -RRB- such that the dot product v w u ' \ u22c5 ' v c associated with u ' \ u201c ' good u ' \ u201d ' word-context pairs is maximized

CASE: 14
Stag: 45 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: This can be easily achieved by setting v c = v w and v c u ' \ u22c5 ' v w = K for all c , w , where K is large enough number
	Cause: setting v c = v w and v
	Effect: c u ' \ u22c5 ' v w = K for all c , w , where K is large enough

CASE: 15
Stag: 46 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: In order to prevent the trivial solution , the objective is extended with -LRB- w , c -RRB- pairs for which p -LRB- D = 1 w , c -RRB- must be low , i.e. , pairs which are not in the data , by generating the set D u ' \ u2032 ' of random -LRB- w , c -RRB- pairs -LRB- assuming they are all incorrect -RRB- , yielding the negative-sampling training objective
	Cause: generating the set D u ' \ u2032 ' of random -LRB- w , c -RRB- pairs
	Effect: -LRB- assuming they are all incorrect -RRB- , yielding the negative-sampling training objective

CASE: 16
Stag: 53 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: We follow the method proposed by Mikolov et al for each -LRB- w , c -RRB- u ' \ u2208 ' D we construct n samples -LRB- w , c 1 -RRB- , u ' \ u2026 ' , -LRB- w , c n -RRB- , where n is a hyperparameter and each c j is drawn according to its unigram distribution raised to the 3 / 4 power
	Cause: its unigram distribution
	Effect: We follow the method proposed by Mikolov et al for each -LRB- w , c -RRB- u ' \ u2208 ' D we construct n samples -LRB- w , c 1 -RRB- , u ' \ u2026 ' , -LRB- w , c n -RRB- , where n is a hyperparameter and each c j is drawn

CASE: 17
Stag: 54 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Optimizing this objective makes observed word-context pairs have similar embeddings , while scattering unobserved pairs
	Cause: Optimizing this objective makes
	Effect: observed word-context pairs have similar embeddings ,

CASE: 18
Stag: 57 58 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The context vocabulary C is thus identical to the word vocabulary W However , this restriction is not required by the model ; contexts need not correspond to words , and the number of context-types can be substantially larger than the number of word-types
	Cause: The context vocabulary C is
	Effect: identical to the word vocabulary W However , this restriction is not required by the model ; contexts need not correspond to words , and the number of context-types can be substantially larger than the number of

CASE: 19
Stag: 60 61 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In this paper we experiment with dependency-based syntactic contexts Syntactic contexts capture different information than bag-of-word contexts , as we demonstrate using the sentence u ' \ u201c ' Australian scientist discovers star with telescope u ' \ u201d '
	Cause: we demonstrate using the sentence u ' \ u201c ' Australian scientist discovers star with telescope u
	Effect: we experiment with dependency-based syntactic contexts Syntactic contexts capture different information than bag-of-word contexts

CASE: 20
Stag: 67 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: The software defaults to prune rare words based on their frequency , and has an option for sub-sampling the frequent words
	Cause: sub-sampling the frequent words
	Effect: The software defaults to prune rare words based on their frequency , and has an option

CASE: 21
Stag: 67 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: The software defaults to prune rare words based on their frequency , and has an option
	Cause: their frequency
	Effect: and has an option

CASE: 22
Stag: 71 72 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Moreover , the contexts are unmarked , resulting in discovers being a context of both stars and scientist , which may result in stars and scientists ending up as neighbours in the embedded space A window size of 5 is commonly used to capture broad topical content , whereas smaller windows contain more focused information about the target word
	Cause: neighbours in the embedded space A window size of 5 is commonly used to capture broad topical content , whereas smaller windows contain more focused information about the target
	Effect: Moreover , the contexts are unmarked , resulting in discovers being a context of both stars and scientist , which may result in stars and scientists ending up

CASE: 23
Stag: 73 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: An alternative to the bag-of-words approach is to derive contexts based on the syntactic relations the word participates in
	Cause: the syntactic relations the word participates in
	Effect: An alternative to the bag-of-words approach is to derive contexts

CASE: 24
Stag: 79 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: They capture relations to words that are far apart and thus u ' \ u201c ' out-of-reach u ' \ u201d ' with small window bag-of-words -LRB- e.g. , the instrument of discover is telescope/prep _ with -RRB- , and also filter out u ' \ u201c ' coincidental u ' \ u201d ' contexts which are within the window but not directly related to the target word -LRB- e.g. , Australian is not used as the context for discovers
	Cause: They capture relations to words that are far apart
	Effect: u ' \ u201c ' out-of-reach u ' \ u201d ' with small window bag-of-words -LRB- e.g. , the instrument of discover is telescope/prep _ with -RRB- , and also filter out u ' \ u201c ' coincidental u ' \ u201d ' contexts which are within the window but not directly related to the target word -LRB- e.g. , Australian is not used as the context for discovers

CASE: 25
Stag: 80 81 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In addition , the contexts are typed , indicating , for example , that stars are objects of discovery and scientist s are subjects We thus expect the syntactic contexts to yield more focused embeddings , capturing more functional and less topical similarity
	Cause: addition , the contexts are typed , indicating , for example , that stars are objects of discovery and scientist s are subjects We
	Effect: expect the syntactic contexts to yield more focused embeddings , capturing more functional and less topical similarity

CASE: 26
Stag: 99 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: This observation holds for Turing 3 3 Deps generated a list of scientists whose name ends with u ' \ u201c ' ing u ' \ u201d '
	Cause: Turing 3 3 Deps generated a list of scientists whose name ends with u ' \ u201c ' ing u ' \ u201d '
	Effect: This observation holds

CASE: 27
Stag: 103 104 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Turney -LSB- 31 -RSB- described this distinction as domain similarity versus functional similarity The Florida example presents an ontological difference ; bag-of-words contexts generate meronyms -LRB- counties or cities within Florida -RRB- , while dependency-based contexts provide cohyponyms -LRB- other US states
	Cause: domain similarity versus functional similarity The Florida example presents an ontological difference ; bag-of-words contexts generate meronyms -LRB- counties or cities within Florida -RRB- , while dependency-based contexts provide cohyponyms -LRB- other US
	Effect: Turney -LSB- 31 -RSB- described this distinction

CASE: 28
Stag: 106 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The next two examples demonstrate that similarities induced from Deps share a syntactic function -LRB- adjectives and gerunds -RRB- , while similarities based on BoW are more diverse
	Cause: BoW are more diverse
	Effect: The next two examples demonstrate that similarities induced from Deps share a syntactic function -LRB- adjectives and gerunds -RRB- , while similarities

CASE: 29
Stag: 109 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since word2vec removes the subsampled words from the corpus before creating the window contexts , this option effectively increases the window size , resulting in greater topicality
	Cause: word2vec removes the subsampled words from the corpus before creating the
	Effect: this option effectively increases the

CASE: 30
Stag: 115 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The pairs are ranked according to cosine similarities between the embedded words
	Cause: cosine similarities between the embedded words
	Effect: The pairs are ranked

CASE: 31
Stag: 121 122 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: When reversing the task such that the goal is to rank the related terms above the similar ones , the results are reversed , as expected -LRB- not shown 5 5 Additional experiments -LRB- not presented in this paper -RRB- reinforce our conclusion
	Cause: expected -LRB- not shown 5 5 Additional experiments -LRB- not presented in this paper -RRB- reinforce
	Effect: reversing the task such that the goal is to rank the related terms above the similar ones , the results are reversed

CASE: 32
Stag: 123 124 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In particular , we found that Deps perform dramatically worse than BoW contexts on analogy tasks as in -LSB- 22 , 17 -RSB- Neural word embeddings are often considered opaque and uninterpretable , unlike sparse vector space representations in which each dimension corresponds to a particular known context , or LDA models where dimensions correspond to latent topics
	Cause: in -LSB- 22 , 17 -RSB- Neural word embeddings are often considered opaque and uninterpretable , unlike sparse vector space representations in which each dimension corresponds to a particular known context , or LDA models where dimensions correspond to latent topics
	Effect: In particular , we found that Deps perform dramatically worse than BoW contexts on analogy tasks

CASE: 33
Stag: 128 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If we keep the context embeddings , we can query the model for the contexts that are most activated by -LRB- have the highest dot product with -RRB- a given target word
	Cause: we keep the context embeddings
	Effect: we can query the model for the contexts that are most activated by -LRB- have the highest dot product with -RRB- a given target word

CASE: 34
Stag: 128 129 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: If we keep the context embeddings , we can query the model for the contexts that are most activated by -LRB- have the highest dot product with -RRB- a given target word By doing so , we can see what the model learned to be a good discriminative context for the word
	Cause: we keep the context embeddings , we can query the model for the contexts that are most activated by -LRB- have the highest dot product with -RRB- a given target word By doing
	Effect: we can see what the model learned to be a good discriminative context for the word

CASE: 35
Stag: 132 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Additionally , the collapsed preposition relation is very useful -LRB- e.g. , for capturing the school aspect of hogwarts
	Cause: capturing the school aspect of hogwarts
	Effect: Additionally , the collapsed preposition relation is very useful -LRB- e.g. ,

CASE: 36
Stag: 134 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: In the future , we hope that insights from such model introspection will allow us to develop better contexts , by focusing on conjunctions and prepositions for example , or by trying to figure out why the subject and object relations are absent and finding ways of increasing their contributions
	Cause: focusing on conjunctions and prepositions for example
	Effect: , or by trying to figure out why the subject and object relations are absent and finding ways of increasing their

