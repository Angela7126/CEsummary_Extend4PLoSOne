************************************************************
P14-1052.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 1 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We study the problem of generating an English sentence given an underlying probabilistic grammar , a world and a communicative goal We model the generation problem as a Markov decision process with a suitably defined reward function that reflects the communicative goal
	Cause: a Markov decision process with a suitably defined reward function that reflects the communicative
	Effect: We study the problem of generating an English sentence given an underlying probabilistic grammar , a world and a communicative goal We model the generation problem

CASE: 1
Stag: 10 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The problem is restricted because in our work , we do not consider the issue of how to fragment a complex goal into multiple sentences -LRB- discourse planning
	Cause: in our work , we do not consider the issue of how to fragment a complex goal into multiple sentences -LRB- discourse planning
	Effect: The problem is restricted

CASE: 2
Stag: 15 16 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Other approaches view NLG as a planning problem -LSB- 10 -RSB- Here , the communicative goal is treated as a predicate to be satisfied , and the grammar and vocabulary are suitably encoded as logical operators
	Cause: a planning problem -LSB- 10 -RSB- Here , the communicative goal is treated as a predicate to be
	Effect: Other approaches view NLG

CASE: 3
Stag: 16 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Here , the communicative goal is treated as a predicate to be satisfied , and the grammar and vocabulary are suitably encoded as logical operators
	Cause: a predicate to be satisfied , and the grammar and vocabulary are suitably encoded as logical operators
	Effect: Here , the communicative goal is treated

CASE: 4
Stag: 19 20 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: A key limitation is the logical nature of automated planning systems , which do not handle probabilistic grammars , or force ad-hoc approaches for doing so -LSB- 1 -RSB- A second limitation comes from restrictions on the goal it may be difficult to ensure that some specific piece of information should not be communicated , or to specify preferences over communicative goals , or specify general conditions , like that the sentence should be readable by a sixth grader
	Cause: A key limitation is the logical nature of automated planning systems , which do not handle probabilistic grammars , or force ad-hoc approaches for doing
	Effect: -LSB- 1 -RSB- A second limitation comes from restrictions on the goal it may be difficult to ensure that some specific piece of information should not be communicated , or to specify preferences over communicative goals , or specify general conditions , like that the sentence should be readable by a sixth

CASE: 5
Stag: 21 
	Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
	sentTXT: A third limitation comes from the search process without strong heuristics , most planners get bogged down when given communicative goals that require chaining together long sequences of operators -LSB- 11 -RSB-
	Cause: chaining together long sequences of operators
	Effect: A third limitation comes from the search process without strong heuristics , most planners get bogged down when given communicative goals

CASE: 6
Stag: 24 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This setting allows us to address the limitations outlined above it is naturally probabilistic , and handles probabilistic grammars ; we are able to specify complex communicative goals and general criteria through a suitably-defined reward function ; and , as we show in our experiments , recent developments in fast planning in large MDPs result in a generation system that can rapidly deal with very specific communicative goals
	Cause: we show in our experiments , recent developments in fast planning in large MDPs result in a generation system that can rapidly deal with very specific communicative goals
	Effect: This setting allows us to address the limitations outlined above it is naturally probabilistic , and handles probabilistic grammars ; we are able to specify complex communicative goals and general criteria through a suitably-defined reward function ; and

CASE: 7
Stag: 26 27 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Finally , the decision-theoretic setting allows for a precise tradeoff between exploration of the grammar and vocabulary to find a better solution and exploitation of the current most promising -LRB- partial -RRB- solution , instead of a heuristic search through the solution space as performed by standard planning approaches Below , we first describe related work , followed by a detailed description of our approach
	Cause: performed by standard planning approaches Below , we first describe related work ,
	Effect: Finally , the decision-theoretic setting allows for a precise tradeoff between exploration of the grammar and vocabulary to find a better solution and exploitation of the current most promising -LRB- partial -RRB- solution , instead of a heuristic search through the solution space

CASE: 8
Stag: 31 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: One direction can be thought of as u ' \ u201c ' overgeneration and ranking u ' \ u201d ' Here some -LRB- possibly probabilistic -RRB- structure is used to generate multiple candidate sentences , which are then ranked according to how well they satisfy the generation criteria
	Cause: u ' \ u201c ' overgeneration and ranking u ' \ u201d ' Here some -LRB- possibly probabilistic -RRB- structure is used to generate multiple candidate sentences , which are then ranked according to how well they satisfy the generation
	Effect: One direction can be thought of

CASE: 9
Stag: 32 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: This includes work based on chart generation and parsing -LSB- 17 , 6 -RSB-
	Cause: chart generation and parsing -LSB- 17 , 6 -RSB-
	Effect: This includes work

CASE: 10
Stag: 33 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: These generators assign semantic meaning to each individual token , then use a set of rules to decide if two words can be combined
	Cause: two words can be combined
	Effect: These generators assign semantic meaning to each individual token , then use a set of rules to decide

CASE: 11
Stag: 38 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using dynamic programming , the highest ranked sentence from this structure is then output
	Cause: Using dynamic programming
	Effect: the highest ranked sentence from this structure is then output

CASE: 12
Stag: 40 41 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: A second line of attack formalizes NLG as an AI planning problem SPUD -LSB- 18 -RSB- , a system for NLG through microplanning , considers NLG as a problem which requires realizing a deliberative process of goal-directed activity
	Cause: an AI planning problem SPUD -LSB- 18 -RSB- , a system for NLG through microplanning , considers NLG as a problem which requires realizing a deliberative process of goal-directed
	Effect: A second line of attack formalizes NLG

CASE: 13
Stag: 47 48 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This chain is sometimes referred to as the u ' \ u201c ' NLG Pipeline u ' \ u201d ' -LSB- 16 -RSB- Another approach , called integrated generation , considers both sentence generation portions of the pipeline together -LSB- 10 -RSB-
	Cause: the u ' \ u201c ' NLG Pipeline u ' \ u201d ' -LSB- 16 -RSB- Another approach , called integrated generation , considers both sentence generation portions of the pipeline together -LSB- 10
	Effect: This chain is sometimes referred to

CASE: 14
Stag: 51 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: These generators generate parses for the sentence at the same time as the sentence , which keeps them from generating realizations that are grammatically incorrect , and keeps them from generating grammatical structures that can not be realized properly
	Cause: the sentence , which keeps them from generating realizations that
	Effect: These generators generate parses for the sentence at the same time

CASE: 15
Stag: 59 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The first step finds an adjoining location by searching through our sentence to find any subtree with a root whose label matches the root node of the auxiliary tree
	Cause: searching through our sentence to find any subtree with a root whose label matches the root node of the auxiliary tree
	Effect: The first step finds an adjoining location

CASE: 16
Stag: 60 61 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the second step , the target subtree is removed from the sentence tree , and placed in the auxiliary tree as a direct replacement for the foot node Finally , the modified auxiliary tree is placed back in the sentence tree in the original target location
	Cause: a direct replacement for the foot node Finally , the modified auxiliary tree is placed back in the sentence tree in the original target
	Effect: In the second step , the target subtree is removed from the sentence tree , and placed in the auxiliary tree

CASE: 17
Stag: 64 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Recent approaches such as PCRISP -LSB- 1 -RSB- attempt to remedy this , but do so in a somewhat ad-hoc way , by transforming the probabilities into costs , because they rely on deterministic planning to actually realize the output
	Cause: Recent approaches such as PCRISP -LSB- 1 -RSB- attempt to remedy this , but do
	Effect: in a somewhat ad-hoc way , by transforming the probabilities into costs , because they rely on deterministic planning to actually realize the

CASE: 18
Stag: 65 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: In this work , we directly address this by using a more expressive underlying formalism , a Markov decision process -LRB- MDP
	Cause: using a more expressive underlying formalism
	Effect: , a Markov decision process -LRB- MDP

CASE: 19
Stag: 82 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Entities are defined as any element anchored by precisely one node in the tree which can appear in a statement representing the semantic content of the tree
	Cause: any element anchored by precisely one node in the tree which can appear in a statement representing the semantic content of the
	Effect: Entities are defined

CASE: 20
Stag: 84 85 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We refer to this list as a lexicon Each word in the lexicon is annotated with its first-order logic semantics with any number of entities present in its subtree as the arguments
	Cause: a lexicon Each word in the lexicon is annotated with its first-order logic semantics with any number of entities present in its subtree as the
	Effect: We refer to this list

CASE: 21
Stag: 85 86 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Each word in the lexicon is annotated with its first-order logic semantics with any number of entities present in its subtree as the arguments A world specification is simply a list of all statements which are true in the world surrounding our generation
	Cause: the arguments A world specification is simply a list of all statements which are true in the world surrounding our
	Effect: Each word in the lexicon is annotated with its first-order logic semantics with any number of entities present in its subtree

CASE: 22
Stag: 89 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Before execution begins , our grammar is pruned to remove entries which can not possibly be used in generation for the given problem , by transitively discovering all predicates that hold about the entities mentioned in the goal in the world , and eliminating all trees not about any of these
	Cause: transitively discovering all predicates that hold about the entities mentioned in the goal in the world , and eliminating all trees not about any of these
	Effect: Before execution begins , our grammar is pruned to remove entries which can not possibly be used in generation for the given problem ,

CASE: 23
Stag: 90 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This often allows STRUCT to be resilient to large grammar sizes , as our experiments will show
	Cause: our experiments will show
	Effect: This often allows STRUCT to be resilient to large grammar sizes

CASE: 24
Stag: 90 91 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This often allows STRUCT to be resilient to large grammar sizes , as our experiments will show We formulate NLG as a planning problem on a Markov decision process -LRB- MDP -RRB- -LSB- 15 -RSB-
	Cause: a planning problem on a Markov decision process -LRB- MDP -RRB- -LSB- 15 -RSB-
	Effect: This often allows STRUCT to be resilient to large grammar sizes , as our experiments will show We formulate NLG

CASE: 25
Stag: 98 99 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: In the MDP we use for NLG , we must define each element of the tuple in such a way that a plan in the MDP becomes a sentence in a natural language Our set of states , therefore , will be partial sentences which are in the language defined by our PLTAG input
	Cause: the MDP we use for NLG , we must define each element of the tuple in such a way that a plan in the MDP becomes a sentence in a natural language Our set of states
	Effect: will be partial sentences which are in the language defined by our PLTAG input

CASE: 26
Stag: 100 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: There are an infinite number of these states , since TAG adjoins can be repeated indefinitely
	Cause: TAG adjoins can be repeated indefinitely
	Effect: There are an infinite number of these states

CASE: 27
Stag: 101 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Nonetheless , given a specific world and communicative goal , only a fraction of this MDP needs to be explored , and , as we show below , a good solution can often be found quickly using a variation of the UCT algorithm -LSB- 9 -RSB-
	Cause: we show below , a good solution can often be found quickly using a variation of the UCT algorithm -LSB- 9 -RSB-
	Effect: Nonetheless , given a specific world and communicative goal , only a fraction of this MDP needs to be explored , and

CASE: 28
Stag: 103 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since we are using PLTAGs in this work , this means every action adds a word to the partial sentence
	Cause: we are using PLTAGs in this work
	Effect: this means every action adds a word to the partial sentence

CASE: 29
Stag: 105 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on these state and action definitions , the transition function takes a mapping between a partial sentence / action pair and the partial sentences which can result from one particular PLTAG adjoin / substitution , and returns the probability of that rule in the grammar
	Cause: these state and action definitions
	Effect: the transition function takes a mapping between a partial sentence / action pair and the partial sentences which can result from one particular PLTAG adjoin / substitution , and returns the probability of that rule in the grammar

CASE: 30
Stag: 106 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: In order to control the search space , we restrict the structure of the MDP so that while substitutions are available , only those operations are considered when determining the distribution over the next state , without any adjoins
	Cause: In order to control the search space , we restrict the structure of the MDP
	Effect: while substitutions are available , only those operations are considered when determining the distribution over the next state ,

CASE: 31
Stag: 108 109 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This allows STRUCT to operate as an anytime algorithm , described further below The immediate value of a state , intuitively , describes closeness of an arbitrary partial sentence to our communicative goal
	Cause: an anytime algorithm , described further below The immediate value of a state , intuitively , describes closeness of an arbitrary partial sentence to our communicative
	Effect: This allows STRUCT to operate

CASE: 32
Stag: 110 111 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Each partial sentence is annotated with its semantic information , built up using the semantic annotations associated with the PLTAG trees Thus we use as a reward a measure of the match between the semantic annotation of the partial tree and the communicative goal
	Cause: Each partial sentence is annotated with its semantic information , built up using the semantic annotations associated with the PLTAG trees
	Effect: we use as a reward a measure of the match between the semantic annotation of the partial tree and the communicative goal

CASE: 33
Stag: 113 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: For an exact reward signal , when checking this overlap , we need to substitute each combination of entities in the goal into predicates in the sentence so we can return a high value if there are any mappings which are both possible -LRB- contain no statements which are not present in the grounded world -RRB- and mostly fulfill the goal -LRB- contain most of the goal predicates
	Cause: For an exact reward signal , when checking this overlap , we need to substitute each combination of entities in the goal into predicates in the sentence
	Effect: we can return a high value if there are any mappings which are both possible -LRB- contain no statements which are not present in the grounded world -RRB- and mostly fulfill the goal -LRB- contain most of the goal predicates

CASE: 34
Stag: 113 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: we can return a high value if there are any mappings which are both possible -LRB- contain no statements which are not present in the grounded world -RRB- and mostly fulfill the goal -LRB- contain most of the goal predicates
	Cause: there are any mappings which are both possible -LRB- contain no statements which are not present in the grounded world -RRB- and mostly fulfill the goal -LRB- contain most of the goal predicates
	Effect: we can return a high value

CASE: 35
Stag: 114 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: However , this is combinatorial ; also , most entities within sentences do not interact -LRB- e.g. , if we say u ' \ u201c ' the white rabbit jumped on the orange carrot , u ' \ u201d ' the whiteness of the rabbit has nothing to do with the carrot -RRB- , and finally , an approximate reward signal generally works well enough unless we need to emit nested subclauses
	Cause: we say u ' \ u201c ' the white rabbit jumped on the orange carrot
	Effect: u ' \ u201d ' the whiteness of the rabbit has nothing to do with the carrot -RRB- , and finally , an approximate reward

CASE: 36
Stag: 114 115 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: However , this is combinatorial ; also , most entities within sentences do not interact -LRB- e.g. , if we say u ' \ u201c ' the white rabbit jumped on the orange carrot , u ' \ u201d ' the whiteness of the rabbit has nothing to do with the carrot -RRB- , and finally , an approximate reward signal generally works well enough unless we need to emit nested subclauses Thus as an approximation , we use a reward signal where we simply count how many individual predicates overlap with the goal with some entity substitution
	Cause: However , this is combinatorial ; also , most entities within sentences do not interact -LRB- e.g. , if we say u ' \ u201c ' the white rabbit jumped on the orange carrot , u ' \ u201d ' the whiteness of the rabbit has nothing to do with the carrot -RRB- , and finally , an approximate reward signal generally works well enough unless we need to emit nested subclauses
	Effect: as an approximation , we use a reward signal where we simply count how many individual predicates overlap with the goal with some entity substitution

CASE: 37
Stag: 118 
	Pattern: 8 [['because']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&ADV)'], ['&C']]
	sentTXT: We generally use a discount factor of 1 ; this is because we are willing to generate lengthy sentences in order to ensure we match our goal
	Cause: we are willing to generate lengthy sentences in order to ensure we match our goal
	Effect: We generally use a discount factor of 1

CASE: 38
Stag: 119 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: A discount factor of 1 can be problematic in general since it can cause rewards to diverge , but since there are a finite number of terms in our reward function -LRB- determined by the communicative goal and the fact that because of lexicalization we do not loop -RRB- , this is not a problem for us
	Cause: there are a finite number of
	Effect: this is not a problem for us

CASE: 39
Stag: 127 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using the UCT approach with a suitably defined MDP -LRB- explained above -RRB- allows us to naturally handle probabilistic grammars as well as formulate NLG as a planning problem , unifying the distinct lines of attack described in Section 2
	Cause: Using the UCT approach with a suitably
	Effect: defined MDP -LRB- explained above -RRB- allows us to naturally handle probabilistic grammars as well as formulate NLG as a planning problem , unifying

CASE: 40
Stag: 128 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Further , the theoretical guarantees of UCT translate into fast generation in many cases , as we demonstrate in our experiments
	Cause: we demonstrate in our experiments
	Effect: Further , the theoretical guarantees of UCT translate into fast generation in many cases

CASE: 41
Stag: 134 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: In order to build a lookahead tree , we use a u ' \ u201c ' rollout policy u ' \ u201d ' This policy has two components if it encounters a state already in the tree , it follows a u ' \ u201c ' tree policy , u ' \ u201d ' discussed further below
	Cause: it encounters a state already in the tree
	Effect: it follows a u ' \ u201c ' tree policy , u ' \ u201d ' discussed further below

CASE: 42
Stag: 135 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If it encounters a new state , the policy reverts to a u ' \ u201c ' default u ' \ u201d ' policy that randomly samples an action
	Cause: it encounters a new state
	Effect: the policy reverts to a u ' \ u201c ' default u ' \ u201d ' policy that randomly samples an action

CASE: 43
Stag: 137 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because this is a Monte Carlo estimate , typically , we run several simultaneous trials , and we keep track of the rewards received by each choice and use this to select the best action at the root
	Cause: this is a Monte Carlo estimate
	Effect: typically , we run several simultaneous trials , and we keep track of the rewards received by each choice and use this to select the best action at the root

CASE: 44
Stag: 139 140 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Here Q u ' \ u2062 ' -LRB- s , a -RRB- is the estimated value of a as observed in the tree search , computed as a sum over future rewards observed after -LRB- s , a N u ' \ u2062 ' -LRB- s -RRB- and N u ' \ u2062 ' -LRB- s , a -RRB- are visit counts for the state and state-action pair
	Cause: observed in the tree search , computed as a sum over future rewards observed after -LRB- s , a N u ' \ u2062 ' -LRB- s -RRB- and N u '
	Effect: Here Q u ' \ u2062 ' -LRB- s , a -RRB- is the estimated value of a

CASE: 45
Stag: 140 141 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: N u ' \ u2062 ' -LRB- s -RRB- and N u ' \ u2062 ' -LRB- s , a -RRB- are visit counts for the state and state-action pair Thus the second term is an exploration term that biases the algorithm towards visiting actions that have not been explored enough c is a constant that trades off exploration and exploitation
	Cause: N u ' \ u2062 ' -LRB- s -RRB- and N u ' \ u2062 ' -LRB- s , a -RRB- are visit counts for the state and state-action pair
	Effect: the second term is an exploration term that biases the algorithm towards visiting actions that have not been explored enough c is a constant that trades off exploration and

CASE: 46
Stag: 144 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: First , because we receive frequent , reasonably accurate feedback , we favor breadth over depth in the tree search
	Cause: we receive frequent
	Effect: reasonably accurate feedback , we favor breadth over depth in the tree search

CASE: 47
Stag: 146 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Second , UCT was originally used in an adversarial environment , and so is biased to select actions leading to the best average reward rather than the action leading to the best overall reward
	Cause: Second , UCT was originally used in an adversarial environment
	Effect: is biased to select actions leading to the best average reward rather than the action leading to the best overall reward

CASE: 48
Stag: 147 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: This is not true for us , however , so we choose the latter action instead
	Cause: This is not true for us , however
	Effect: we choose the latter action instead

CASE: 49
Stag: 149 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: After every action is selected and applied , we check to see if we are in a state in which the algorithm could terminate -LRB- i.e. , the sentence has no nonterminals yet to be expanded
	Cause: we are in a state in which the algorithm could terminate -LRB- i.e.
	Effect: the sentence has no nonterminals yet to be expanded

CASE: 50
Stag: 149 150 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: After every action is selected and applied , we check to see if we are in a state in which the algorithm could terminate -LRB- i.e. , the sentence has no nonterminals yet to be expanded If so , we determine if this is the best possibly-terminal state we have seen so far
	Cause: every action is selected and applied , we check to see if we are in a state in which the algorithm could terminate -LRB- i.e. , the sentence has no nonterminals yet to be expanded If
	Effect: we determine if this is the best possibly-terminal state we have seen so far

CASE: 51
Stag: 150 151 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: If so , we determine if this is the best possibly-terminal state we have seen so far If so , we store it , and continue the generation process
	Cause: , we determine if this is the best possibly-terminal state we have seen so far If
	Effect: we store it , and continue the generation process

CASE: 52
Stag: 152 153 
	Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
	sentTXT: Whenever we reach a terminal state , we begin again from the start state of the MDP Because of the structure restriction above -LRB- substitution before adjoin -RRB- , STRUCT generates a valid sentence quickly
	Cause: Whenever we reach a terminal state , we begin again from the start state of the MDP
	Effect: , STRUCT generates a valid sentence quickly

CASE: 53
Stag: 154 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This enables STRUCT to perform as an anytime algorithm , which if interrupted will return the highest-value complete and valid sentence it has found
	Cause: an anytime algorithm , which if interrupted will return the highest-value complete and valid
	Effect: This enables STRUCT to perform

CASE: 54
Stag: 155 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: This also allows partial completion of communicative goals if not all goals can be achieved simultaneously in the time given
	Cause: not all goals can be achieved simultaneously in the time given
	Effect: This also allows partial completion of communicative goals

CASE: 55
Stag: 156 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: In this section , we compare STRUCT to a state-of-the-art NLG system , CRISP , 1 1 We were unfortunately unable to get the PCRISP system to compile , and so we could not evaluate it and evaluate three hypotheses i -RRB- STRUCT is comparable in speed and generation quality to CRISP as it generates increasingly large referring expressions , -LRB- ii -RRB- STRUCT is comparable in speed and generation quality to CRISP as the size of the grammar which they use increases , and -LRB- iii -RRB- STRUCT is capable of communicating complex propositions , including multiple concurrent goals , negated goals , and nested subclauses
	Cause: we compare STRUCT to a state-of-the-art NLG system , CRISP , 1 1 We were unfortunately unable to get the PCRISP system to compile
	Effect: we could not evaluate it and evaluate three hypotheses i -RRB- STRUCT is comparable in speed and generation quality to CRISP as it generates increasingly large referring expressions , -LRB- ii -RRB- STRUCT is comparable in speed and generation quality to CRISP as the size of the grammar which they use increases , and -LRB- iii -RRB- STRUCT is capable of communicating complex propositions , including multiple concurrent goals , negated goals , and nested

CASE: 56
Stag: 156 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: we could not evaluate it and evaluate three hypotheses i -RRB- STRUCT is comparable in speed and generation quality to CRISP as it generates increasingly large referring expressions , -LRB- ii -RRB- STRUCT is comparable in speed and generation quality to CRISP as the size of the grammar which they use increases , and -LRB- iii -RRB- STRUCT is capable of communicating complex propositions , including multiple concurrent goals , negated goals , and nested
	Cause: it generates increasingly large referring expressions , -LRB- ii -RRB- STRUCT is comparable in speed and generation quality to CRISP as the size of the grammar which they use increases , and -LRB- iii -RRB- STRUCT is capable of communicating complex propositions , including multiple concurrent goals , negated goals , and nested
	Effect: we could not evaluate it and evaluate three hypotheses i -RRB- STRUCT is comparable in speed and generation quality to CRISP

CASE: 57
Stag: 161 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: The times reported are from the start of the generation process , eliminating variations due to interpreter startup , input parsing , etc
	Cause: interpreter startup , input parsing , etc
	Effect: The times reported are from the start of the generation process , eliminating variations

CASE: 58
Stag: 162 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We begin by describing experiments comparing STRUCT to CRISP
	Cause: describing experiments comparing STRUCT to CRISP
	Effect: We begin

CASE: 59
Stag: 166 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: In this experiment , m u ' \ u2062 ' a u ' \ u2062 ' x u ' \ u2062 ' D u ' \ u2062 ' e u ' \ u2062 ' p u ' \ u2062 ' t u ' \ u2062 ' h was set equal to 1 , since each action taken improved the sentence in a way measurable by our reward function n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s was set equal to k u ' \ u2062 ' -LRB- k + 1 -RRB- , since this is the number of adjoining sites available in the final step of generation , times the number of potential words to adjoin
	Cause: each action taken improved the sentence in a way measurable by our reward function n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s was set equal to k u ' \ u2062 ' -LRB- k + 1 -RRB- , since this is the number of adjoining sites available in the final step of
	Effect: In this experiment , m u ' \ u2062 ' a u ' \ u2062 ' x u ' \ u2062 ' D u ' \ u2062 ' e u ' \ u2062 ' p u ' \ u2062 ' t u ' \ u2062 ' h was set equal to 1

CASE: 60
Stag: 166 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: each action taken improved the sentence in a way measurable by our reward function n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s was set equal to k u ' \ u2062 ' -LRB- k + 1 -RRB- , since this is the number of adjoining sites available in the final step of
	Cause: this is the number of adjoining sites available in the final step of
	Effect: each action taken improved the sentence in a way measurable by our reward function n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s was set equal to k u ' \ u2062 ' -LRB- k + 1 -RRB-

CASE: 61
Stag: 173 174 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Later experiments had successful referring expression generation of lengths as high as 25 The u ' \ u201c ' STRUCT_initial u ' \ u201d ' curve shows the time taken by STRUCT to come up with the first complete sentence , which partially solves the goal and which -LRB- at least -RRB- could be output if generation was interrupted and no better alternative was found
	Cause: high as 25 The u ' \ u201c ' STRUCT_initial u ' \ u201d ' curve shows the time taken by STRUCT to come up with the first complete sentence , which partially solves the
	Effect: Later experiments had successful referring expression generation of lengths

CASE: 62
Stag: 174 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The u ' \ u201c ' STRUCT_initial u ' \ u201d ' curve shows the time taken by STRUCT to come up with the first complete sentence , which partially solves the goal and which -LRB- at least -RRB- could be output if generation was interrupted and no better alternative was found
	Cause: generation was interrupted and
	Effect: The u ' \ u201c ' STRUCT_initial u ' \ u201d ' curve shows the time taken by STRUCT to come up with the first complete sentence , which partially solves the goal and which -LRB- at least -RRB- could be output

CASE: 63
Stag: 174 175 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The u ' \ u201c ' STRUCT_initial u ' \ u201d ' curve shows the time taken by STRUCT to come up with the first complete sentence , which partially solves the goal and which -LRB- at least -RRB- could be output if generation was interrupted and no better alternative was found As can be seen , this always happens very quickly
	Cause: can be seen , this always happens very quickly
	Effect: The u ' \ u201c ' STRUCT_initial u ' \ u201d ' curve shows the time taken by STRUCT to come up with the first complete sentence , which partially solves the goal and which -LRB- at least -RRB- could be output if generation was interrupted and no better alternative was found

CASE: 64
Stag: 178 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This experiment is set up in the same way as the one above , with the exception of l u ' \ u201c ' distracting u ' \ u201d ' words , words which are not useful in the sentence to be generated l is defined as j - k
	Cause: the one above , with the exception of l u ' \ u201c ' distracting u ' \ u201d ' words , words which are not useful in the sentence to be generated l is defined as
	Effect: This experiment is set up in the same way

CASE: 65
Stag: 185 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If we do not prune the grammar -LRB- as described in Section 3.1 -RRB- , STRUCT u ' \ u2019 ' s performance is similar to CRISP using the FF planner -LSB- 5 -RSB- , also profiled in -LSB- 11 -RSB- , which increased from 27 ms to 4.4 seconds over the interval from j = 1 to j = 10
	Cause: described in Section 3.1 -RRB- , STRUCT u '
	Effect: we do not prune the grammar -LRB-

CASE: 66
Stag: 187 188 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This is due almost entirely to the required increase in the value of n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s as the grammar size increases At the low end , we can use n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s = 20 , but at l = 50 , we must use n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s = 160 in order to ensure perfect generation as soon as possible
	Cause: the grammar size increases At the low end , we can use n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s = 20 , but at l = 50 , we must use n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s = 160 in order to ensure perfect generation as soon as
	Effect: \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s

CASE: 67
Stag: 188 189 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: At the low end , we can use n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s = 20 , but at l = 50 , we must use n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s = 160 in order to ensure perfect generation as soon as possible Note that , as STRUCT is an anytime algorithm , valid sentences are available very early in the generation process , despite the size of the set of adjoining trees
	Cause: STRUCT is an anytime algorithm , valid sentences are available very early in the generation process , despite the size of the set of adjoining trees
	Effect: At the low end , we can use n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s = 20 , but at l = 50 , we must use n u ' \ u2062 ' u u ' \ u2062 ' m u ' \ u2062 ' T u ' \ u2062 ' r u ' \ u2062 ' i u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' s = 160 in order to ensure perfect generation as soon as possible Note that

CASE: 68
Stag: 193 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: STRUCT u ' \ u2019 ' s performance improves significantly if we allow for pruning
	Cause: we allow for pruning
	Effect: STRUCT u ' \ u2019 ' s performance improves significantly

CASE: 69
Stag: 197 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: Our experiments do not show any significant impact on runtime due to the pruning procedure itself , even on large grammars
	Cause: the pruning procedure itself
	Effect: Our experiments do not show any significant impact on runtime

CASE: 70
Stag: 202 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: In that section , the referred-to dog was unique , and it was therefore possible to produce a referring expression which identified it unambiguously
	Cause: In that section , the referred-to dog was unique , and it was
	Effect: possible to produce a referring expression which identified it unambiguously

CASE: 71
Stag: 203 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: In this experiment , we remove this condition by creating a situation in which the generator will be forced to ambiguously refer to several dogs
	Cause: creating a situation in which the generator will be forced to ambiguously refer to several dogs
	Effect: In this experiment , we remove this condition

CASE: 72
Stag: 205 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since these adjectives do not further disambiguate their subject , our generator should not use them in its output
	Cause: these adjectives do not further disambiguate their subject
	Effect: our generator should not use them in its output

CASE: 73
Stag: 206 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: We then encode these adjectives into communicative goals , so that they will be included in the output of the generator despite not assisting in the accomplishment of disambiguation
	Cause: We then encode these adjectives into communicative goals ,
	Effect: they will be included in the output of the generator despite not assisting in the accomplishment of disambiguation

CASE: 74
Stag: 208 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We would have as our goal both u ' \ u201c ' sleeps -LRB- c -RRB- u ' \ u201d ' and u ' \ u201c ' black -LRB- c -RRB- u ' \ u201d '
	Cause: our goal both u ' \ u201c ' sleeps -LRB- c -RRB- u ' \ u201d ' and u ' \ u201c ' black -LRB- c -RRB- u ' \ u201d '
	Effect: We would have

CASE: 75
Stag: 210 211 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We find that , in all cases , these otherwise useless adjectives are included in the output of our generator , indicating that STRUCT is successfully balancing multiple communicative goals As we show in figure 6 -LRB- the u ' \ u201c ' Positive Goals u ' \ u201d ' curve -RRB- , the presence of additional satisfiable semantic goals does not substantially affect the time required for generation
	Cause: we show in figure 6 -LRB- the u ' \ u201c ' Positive Goals u ' \ u201d ' curve -RRB- , the presence of additional satisfiable semantic goals does not substantially affect the time required for generation
	Effect: We find that , in all cases , these otherwise useless adjectives are included in the output of our generator , indicating that STRUCT is successfully balancing multiple communicative goals

CASE: 76
Stag: 218 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We again modify the problem used earlier by adding to our lexicon several new adjectives , each applicable only to the target of our referring expression
	Cause: adding to our lexicon several new adjectives , each applicable only to the target of our referring expression
	Effect: the problem used earlier

CASE: 77
Stag: 219 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since our target can now be referred to unambiguously using only one adjective , our generator should just select one of these new adjectives -LRB- we experimentally confirmed this
	Cause: our target can now be referred to unambiguously using only one adjective
	Effect: our generator should just select one of these new adjectives -LRB- we experimentally confirmed this

CASE: 78
Stag: 220 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: We then encode these adjectives into negated communicative goals , so that they will not be included in the output of the generator , despite allowing a much shorter referring expression
	Cause: We then encode these adjectives into negated communicative goals ,
	Effect: they will not be included in the output of the generator , despite allowing a much shorter referring expression

CASE: 79
Stag: 225 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since this experiment alters the grammar size , we see the time to final generation growing linearly with grammar size
	Cause: this experiment alters the grammar size
	Effect: we see the

CASE: 80
Stag: 227 228 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: This is a case where pruning does not help us in reducing the grammar size ; we can not optimistically prune out words that we do not plan to use Doing so might reduce the ability of STRUCT to produce a sentence which partially fulfills its goals
	Cause: is a case where pruning does not help us in reducing the grammar size ; we can not optimistically prune out words that we do not plan to use Doing
	Effect: might reduce the ability of STRUCT to produce a sentence which partially fulfills its goals

CASE: 81
Stag: 233 234 
	Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
	sentTXT: Notably , we must adjoin the word u ' \ u201c ' which u ' \ u201d ' to u ' \ u201c ' the dog u ' \ u201d ' during the portion of generation where the sentence reads u ' \ u201c ' the dog chased the cat u ' \ u201d ' This decision requires us to do planning deeper than one level in the MDP , which increases the number of simulations STRUCT requires in order to get the correct result
	Cause: us
	Effect: Notably , we must adjoin the word u ' \ u201c ' which u ' \ u201d ' to u ' \ u201c ' the dog u ' \ u201d ' during the portion of generation where the sentence reads u ' \ u201c ' the dog chased the cat u ' \ u201d '

CASE: 82
Stag: 241 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Notice that , because the exact reward function is being used , the time to generate is longer in this experiment
	Cause: the exact reward function is being used
	Effect: the time to generate is longer in this experiment

CASE: 83
Stag: 242 
	Pattern: 9 [['consequently']]---- [['&C', '(,/;/./--)'], ['(,)', '&R']]
	sentTXT: To the best of our knowledge , CRISP is not able to generate sentences of this form due to an insufficiency in the way it handles TAGs , and consequently we present our results without this baseline
	Cause: CRISP is not able to generate sentences of this form due to an insufficiency in the way it handles TAGs , and
	Effect: we present our results without this baseline

CASE: 84
Stag: 242 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: CRISP is not able to generate sentences of this form due to an insufficiency in the way it handles TAGs , and
	Cause: an insufficiency in the way
	Effect: it handles TAGs , and

CASE: 85
Stag: 247 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Given sufficient depth for the search -LRB- d = 3 was sufficient for our experiments , as our reward signal is fine-grained -RRB- , STRUCT will produce two sentences joined by the conjunction u ' \ u201c ' and u ' \ u201d '
	Cause: our reward signal is fine-grained -RRB- , STRUCT will produce two sentences joined by the conjunction u ' \ u201c ' and u ' \ u201d '
	Effect: sufficient depth for the search -LRB- d = 3 was sufficient for our experiments

CASE: 86
Stag: 248 249 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Again , we follow prior work in our experiment design -LSB- 11 -RSB- As we can see in Figures 10 , 10 , and 10 , STRUCT successfully generates results for conjunctions of up to five sentences
	Cause: we can see in Figures 10 , 10 , and 10 , STRUCT successfully generates results for conjunctions of up to five sentences
	Effect: Again , we follow prior work in our experiment design -LSB- 11 -RSB-

CASE: 87
Stag: 254 255 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: They attempted to generate sentences with three entities and failed to find a result within their 4 GB memory limit As we can see , CRISP generates a result slightly faster than STRUCT when we are working with a single entity , but works much much slower for two entities and can not generate results for a third entity
	Cause: we can see , CRISP generates a result slightly faster than STRUCT when we are working with a single entity , but works much much slower for two entities and can not generate results for a third entity
	Effect: They attempted to generate sentences with three entities and failed to find a result within their 4 GB memory limit

CASE: 88
Stag: 255 256 
	Pattern: 8 [['because']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&ADV)'], ['&C']]
	sentTXT: As we can see , CRISP generates a result slightly faster than STRUCT when we are working with a single entity , but works much much slower for two entities and can not generate results for a third entity According to Koller u ' \ u2019 ' s findings , this is because the search space grows by a factor of the universe size with the addition of another entity -LSB- 11 -RSB-
	Cause: the search space grows by a factor of the universe size with the addition of another entity -LSB- 11 -RSB-
	Effect: we can see , CRISP generates a result slightly faster than STRUCT when we are working with a single entity , but works much much slower for two entities and can not generate results for a third entity According to Koller u ' \ u2019 ' s findings

CASE: 89
Stag: 258 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: STRUCT formalizes the generation problem as an MDP and applies a version of the UCT algorithm , a fast online MDP planner , to solve it
	Cause: an MDP and applies a version of the UCT algorithm ,
	Effect: STRUCT formalizes the generation problem

CASE: 90
Stag: 258 259 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: STRUCT formalizes the generation problem as an MDP and applies a version of the UCT algorithm , a fast online MDP planner , to solve it Thus , STRUCT naturally handles probabilistic grammars
	Cause: STRUCT formalizes the generation problem as an MDP and applies a version of the UCT algorithm , a fast online MDP planner , to solve it
	Effect: , STRUCT naturally handles probabilistic grammars

CASE: 91
Stag: 265 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: A second direction is that , due to the nature of the approach , STRUCT is highly amenable to parallelization
	Cause: the nature of the approach
	Effect: STRUCT is highly amenable to parallelization

