************************************************************
P14-1100.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 2 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The main algorithm is based on lifting the concept of additive tree metrics for structure learning of latent trees in the phylogenetic and machine learning communities to the case where the tree structure varies across examples
	Cause: lifting the concept of additive tree metrics for structure learning of latent trees in the phylogenetic and machine learning communities to the case where the tree structure varies across examples
	Effect: The main algorithm is

CASE: 1
Stag: 6 7 
	Pattern: 0 [[['imply', 'implies', 'implied', 'mean', 'means', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: Cognitively , it is more plausible to assume that children obtain only terminal strings of parse trees and not the actual parse trees This means the unsupervised setting is a better model for studying language acquisition
	Cause: Cognitively , it is more plausible to assume that children obtain only terminal strings of parse trees and not the actual parse trees
	Effect: the unsupervised setting

CASE: 2
Stag: 9 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Most existing solutions treat the problem of unsupervised parsing by assuming a generative process over parse trees e.g. , probabilistic context free grammars -LSB- Jelinek et al. 1992 -RSB- , and the constituent context model -LSB- Klein and Manning2002 -RSB-
	Cause: assuming a generative process over parse trees e.g. , probabilistic context free grammars -LSB- Jelinek et al. 1992 -RSB- , and the constituent context model -LSB- Klein and Manning2002 -RSB-
	Effect: Most existing solutions treat the problem of unsupervised parsing

CASE: 3
Stag: 10 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Learning then reduces to finding a set of parameters that are estimated by identifying a local maximum of an objective function such as the likelihood -LSB- Klein and Manning2002 -RSB- or a variant of it -LSB- Smith and Eisner2005 , Cohen and Smith2009 , Headden et al. 2009 , Spitkovsky et al. 2010b , Gillenwater et al. 2010 , Golland et al. 2012 -RSB-
	Cause: identifying a local maximum of an objective function such as the likelihood -LSB- Klein and Manning2002 -RSB- or a variant of it -LSB- Smith and Eisner2005 , Cohen and Smith2009 , Headden et al. 2009 , Spitkovsky et al. 2010b , Gillenwater et al. 2010 , Golland et al. 2012 -RSB-
	Effect: Learning then reduces to finding a set of parameters that are estimated

CASE: 4
Stag: 11 12 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Unfortunately , finding the global maximum for these objective functions is usually intractable -LSB- Cohen and Smith2012 -RSB- which often leads to severe local optima problems -LRB- but see Gormley and Eisner , 2013 Thus , strong experimental results are often achieved by initialization techniques -LSB- Klein and Manning2002 , Gimpel and Smith2012 -RSB- , incremental dataset use -LSB- Spitkovsky et al. 2010a -RSB- and other specialized techniques to avoid local optima such as count transforms -LSB- Spitkovsky et al. 2013 -RSB-
	Cause: Unfortunately , finding the global maximum for these objective functions is usually intractable -LSB- Cohen and Smith2012 -RSB- which often leads to severe local optima problems -LRB- but see Gormley and Eisner , 2013
	Effect: , strong experimental results are often achieved by initialization techniques -LSB- Klein and Manning2002 , Gimpel and Smith2012 -RSB- , incremental dataset use -LSB- Spitkovsky et al. 2010a -RSB- and other specialized techniques to avoid local optima such as count transforms -LSB- Spitkovsky et al. 2013 -RSB-

CASE: 5
Stag: 21 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: However , due to the presence of latent variables , structure learning of latent trees is substantially more complicated than in observed models
	Cause: the presence of latent variables
	Effect: structure learning of latent trees is substantially more complicated than in observed models

CASE: 6
Stag: 23 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: Intuitively , however , latent tree models encode low rank dependencies among the observed variables permitting the development of u ' \ u201c ' spectral u ' \ u201d ' methods that can lead to provably correct solutions
	Cause: Intuitively , however , latent tree models encode low rank dependencies among the observed variables permitting the development of u ' \ u201c ' spectral u ' \ u201d ' methods
	Effect: provably correct solutions

CASE: 7
Stag: 24 25 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In particular we leverage the concept of additive tree metrics -LSB- Buneman1971 , Buneman1974 -RSB- in phylogenetics and machine learning that can create a special distance metric among the observed variables as a function of the underlying spectral dependencies -LSB- Choi et al. 2011 , Song et al. 2011 , Anandkumar et al. 2011 , Ishteva et al. 2012 -RSB- Additive tree metrics can be leveraged by u ' \ u201c ' meta-algorithms u ' \ u201d ' such as neighbor-joining -LSB- Saitou and Nei1987 -RSB- and recursive grouping -LSB- Choi et al. 2011 -RSB- to provide consistent learning algorithms for latent trees
	Cause: a function of the underlying spectral dependencies -LSB- Choi et al. 2011 , Song et al. 2011 , Anandkumar et al. 2011 , Ishteva et al. 2012 -RSB- Additive tree metrics can be leveraged by u ' \ u201c ' meta-algorithms u ' \ u201d ' such as neighbor-joining -LSB- Saitou and Nei1987 -RSB- and recursive grouping -LSB- Choi et al. 2011 -RSB- to provide consistent learning algorithms for latent
	Effect: we leverage the concept of additive tree metrics -LSB- Buneman1971 , Buneman1974 -RSB- in phylogenetics and machine learning that can create a special distance metric among the observed variables

CASE: 8
Stag: 26 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Moreover , we show that it is desirable to learn the u ' \ u201c ' minimal u ' \ u201d ' latent tree based on the tree metric -LRB- u ' \ u201c ' minimum evolution u ' \ u201d ' in phylogenetics
	Cause: the tree metric -LRB- u ' \ u201c ' minimum evolution u ' \ u201d
	Effect: Moreover , we show that it is desirable to learn the u ' \ u201c ' minimal u ' \ u201d ' latent tree

CASE: 9
Stag: 28 29 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: Unlike in phylogenetics and graphical models , where a single latent tree is constructed for all the data , in our case , each part of speech sequence is associated with its own parse tree This leads to a severe data sparsity problem even for moderately long sentences
	Cause: Unlike in phylogenetics and graphical models , where a single latent tree is constructed for all the data , in our case , each part of speech sequence is associated with its own parse tree
	Effect: a severe data sparsity problem even for moderately long sentences

CASE: 10
Stag: 53 54 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: However , the choice of verb -LRB- w 1 -RRB- is mostly independent of the determiner We could thus conclude that w 2 and w 3 should be closer in the parse tree than w 1 and w 2 , giving us the correct structure
	Cause: , the choice of verb -LRB- w 1 -RRB- is mostly independent of the determiner We could
	Effect: conclude that w 2 and w 3 should be closer in the parse tree than w 1 and w 2 , giving us the correct structure

CASE: 11
Stag: 57 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Following this intuition , we propose to model the distribution over the latent bracketing states and words for each tag sequence u ' \ ud835 ' u ' \ udc99 ' as a latent tree graphical model , which encodes conditional independences among the words given the latent states
	Cause: a latent tree graphical model , which encodes conditional independences among the words given the latent
	Effect: Following this intuition , we propose to model the distribution over the latent bracketing states and words for each tag sequence u ' \ ud835 ' u ' \ udc99 '

CASE: 12
Stag: 67 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The model assumes a factorization according to a latent-variable tree
	Cause: a latent-variable tree
	Effect: The model assumes a factorization

CASE: 13
Stag: 68 69 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The latent variables can incorporate various linguistic properties , such as head information , valence of dependency being generated , and so on This information is expected to be learned automatically from data
	Cause: The latent variables can incorporate various linguistic properties , such as head information , valence of dependency being generated
	Effect: information , valence of dependency being generated , and so on This information is expected to be learned automatically from

CASE: 14
Stag: 71 72 
	Pattern: 0 [[['imply', 'implies', 'implied', 'mean', 'means', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
	sentTXT: The orientation of the tree is determined by a direction mapping h dir u ' \ u2062 ' -LRB- u -RRB- , which is fixed during learning and decoding This means our decoder first identifies -LRB- given a POS sequence -RRB- an undirected tree , and then orients it by applying h dir on the resulting tree -LRB- see below
	Cause: The orientation of the tree is determined by a direction mapping h dir u ' \ u2062 ' -LRB- u -RRB- , which is fixed during learning and decoding
	Effect: our decoder

CASE: 15
Stag: 77 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Decide on u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' , the undirected latent tree that u ' \ ud835 ' u ' \ udc99 ' maps to
	Cause: Decide on u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB-
	Effect: u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' ,

CASE: 16
Stag: 80 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: Generate a tuple u ' \ ud835 ' u ' \ udc97 ' = -LRB- w 1 , u ' \ u2026 ' , w u ' \ u2113 ' , z 1 , u ' \ u2026 ' , z H -RRB- where w i u ' \ u2208 ' u ' \ u211d ' p , z j u ' \ u2208 ' u ' \ u211d ' m according to Eq
	Cause: Eq
	Effect: Generate a tuple u ' \ ud835 ' u ' \ udc97 ' = -LRB- w 1 , u ' \ u2026 ' , w u ' \ u2113 ' , z 1 , u ' \ u2026 ' , z H -RRB- where w i u ' \ u2208 ' u ' \ u211d ' p , z j u ' \ u2208 ' u ' \ u211d ' m

CASE: 17
Stag: 83 
	Pattern: 0 [['enables']]---- [['&V-ing@C@'], ['&NP@R@', '&TODO@R@']]
	sentTXT: Generating a bracketing via an undirected tree enables us to build on existing methods for structure learning of latent-tree graphical models -LSB- Choi et al. 2011 , Anandkumar et al. 2011 -RSB-
	Cause: Generating a bracketing via an undirected tree
	Effect: us to build on existing methods for structure learning of latent-tree graphical models

CASE: 18
Stag: 85 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This undirected tree is converted into a directed tree by applying h dir
	Cause: applying h dir
	Effect: This undirected tree is converted into a directed tree

CASE: 19
Stag: 88 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: It marks the edge e i , j that splits the tree according to the top bracket as the u ' \ u201c ' root edge u ' \ u201d ' -LRB- marked in red in Figure 1 -LRB- center
	Cause: the u ' \ u201c ' root edge u ' \ u201d ' -LRB- marked in red in Figure 1 -LRB- center
	Effect: It marks the edge e i , j that splits the tree according to the top bracket

CASE: 20
Stag: 88 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: It marks the edge e i , j that splits the tree according to the top bracket
	Cause: the top bracket
	Effect: It marks the edge e i , j that splits the tree

CASE: 21
Stag: 89 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: It then creates t from u by directing the tree outward from e i , j as shown in Figure 1 -LRB- center
	Cause: directing the tree outward from e i , j as shown in Figure 1 -LRB- center
	Effect: It then creates t from u

CASE: 22
Stag: 89 90 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: It then creates t from u by directing the tree outward from e i , j as shown in Figure 1 -LRB- center The resulting t is a binary bracketing parse tree
	Cause: It then creates t from u by directing the tree outward from e i , j as shown in Figure 1 -LRB- center
	Effect: a binary bracketing parse tree

CASE: 23
Stag: 94 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: As indicated in the above section , we restrict the set of undirected trees to be those such that after applying h dir the resulting t is projective i.e. , there are no crossing brackets
	Cause: As indicated in the above section , we restrict the set of undirected trees to be those such that after applying h dir
	Effect: projective i.e. , there are no crossing brackets

CASE: 24
Stag: 99 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We can then proceed by learning how to map a POS sequence u ' \ ud835 ' u ' \ udc99 ' to a tree t u ' \ u2208 ' u ' \ ud835 ' u ' \ udcaf ' -LRB- through u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' -RRB- by focusing only on examples in u ' \ ud835 ' u ' \ udc9f ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB-
	Cause: learning how to map a POS sequence u ' \ ud835 ' u ' \ udc99 ' to a tree t u ' \ u2208 ' u ' \ ud835 ' u ' \ udcaf ' -LRB- through u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' -RRB- by focusing only on examples in u ' \ ud835 ' u ' \ udc9f ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB-
	Effect: We can then proceed

CASE: 25
Stag: 102 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If all the variables were observed , then the Chow-Liu algorithm -LSB- Chow and Liu1968 -RSB- could be used to find the most likely tree structure u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 '
	Cause: all the variables were observed
	Effect: then the Chow-Liu algorithm -LSB- Chow and Liu1968 -RSB- could be used to find the most likely tree structure u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 '

CASE: 26
Stag: 114 115 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: For example , as we see in 3.2 we will define the distance d u ' \ u2062 ' -LRB- i , j -RRB- to be a function of the covariance matrix u ' \ ud835 ' u ' \ udd3c ' -LSB- v i v j u ' \ u22a4 ' u -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- , u ' \ u0398 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- -RSB- Thus if v i and v j are both observed variables , the distance can be directly computed from the data
	Cause: For example , as we see in 3.2 we will define the distance d u ' \ u2062 ' -LRB- i , j -RRB- to be a function of the covariance matrix u ' \ ud835 ' u ' \ udd3c ' -LSB- v i v j u ' \ u22a4 ' u -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- , u ' \ u0398 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- -RSB-
	Effect: if v i and v j are both observed variables , the distance can be directly computed from the data

CASE: 27
Stag: 118 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: -LSB- M -RSB- -LSB- M -RSB- u ' \ u2192 ' u ' \ u211d ' is an additive tree metric -LSB- Erd s et al. 1999 -RSB- for the undirected tree u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc31 ' -RRB- if it is a distance metric , 2 2 This means that it satisfies d u ' \ u2062 ' -LRB- i , j -RRB- = 0 if and only if i = j , the triangle inequality and is also symmetric and furthermore , u ' \ u2200 ' i , j u ' \ u2208 ' -LSB- M -RSB- the following relation holds
	Cause: it is a distance metric , 2 2 This means that it satisfies d u ' \ u2062 ' -LRB- i , j -RRB- = 0 if and only if i = j , the triangle inequality and is also symmetric and furthermore , u ' \ u2200 ' i , j u ' \ u2208 ' -LSB- M -RSB- the following relation holds
	Effect: M -RSB- -LSB- M -RSB- u ' \ u2192 ' u ' \ u211d ' is an additive tree metric -LSB- Erd s et al. 1999 -RSB- for the undirected tree u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc31 ' -RRB-

CASE: 28
Stag: 119 120 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where path u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc31 ' -RRB- u ' \ u2062 ' -LRB- i , j -RRB- is the set of all the edges in the -LRB- undirected -RRB- path from i to j in the tree u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc31 ' -RRB- As we describe below , given the tree structure , the additive tree metric property allows us to compute u ' \ u201c ' backwards u ' \ u201d ' the distances among the latent variables as a function of the distances among the observed variables
	Cause: we describe below , given the tree structure , the additive tree metric property allows us to compute u ' \ u201c ' backwards u ' \ u201d ' the distances among the latent variables as a function of the distances among the observed variables
	Effect: path u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc31 ' -RRB- u ' \ u2062 ' -LRB- i , j -RRB- is the set of all the edges in the -LRB- undirected -RRB- path from i to j in the tree u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc31 ' -RRB-

CASE: 29
Stag: 123 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: In addition , since u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- is assumed to be known from context , we denote d u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- u ' \ u2062 ' -LRB- i , j -RRB- just by d u ' \ u2062 ' -LRB- i , j -RRB-
	Cause: u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- is assumed to be known from context
	Effect: we denote d u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- u ' \ u2062 ' -LRB- i , j -RRB- just by d u ' \ u2062 ' -LRB- i , j -RRB-

CASE: 30
Stag: 124 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: Given the fact that the distance between a pair of nodes is a function of the random variables they represent -LRB- according to the true model -RRB- , only u ' \ ud835 ' u ' \ udc6b ' W u ' \ u2062 ' W can be empirically estimated from data
	Cause: the true model
	Effect: only u ' \ ud835 ' u ' \ udc6b ' W u ' \ u2062 ' W can be empirically estimated from data

CASE: 31
Stag: 124 125 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Given the fact that the distance between a pair of nodes is a function of the random variables they represent -LRB- according to the true model -RRB- , only u ' \ ud835 ' u ' \ udc6b ' W u ' \ u2062 ' W can be empirically estimated from data However , if the underlying tree structure is known , then Definition 1 can be leveraged to compute u ' \ ud835 ' u ' \ udc6b ' Z u ' \ u2062 ' Z and u ' \ ud835 ' u ' \ udc6b ' Z u ' \ u2062 ' W as we show below
	Cause: we show below
	Effect: the fact that the distance between a pair of nodes is a function of the random variables they represent -LRB- according to the true model -RRB- , only u ' \ ud835 ' u ' \ udc6b ' W u ' \ u2062 ' W can be empirically estimated from data However , if the underlying tree structure is known , then Definition 1 can be leveraged to compute u ' \ ud835 ' u ' \ udc6b ' Z u ' \ u2062 ' Z and u ' \ ud835 ' u ' \ udc6b ' Z u ' \ u2062 ' W

CASE: 32
Stag: 127 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: It then follows that the other elements of the distance matrix can be computed based on Definition 1
	Cause: Definition 1
	Effect: It then follows that the other elements of the distance matrix can be computed

CASE: 33
Stag: 134 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Then using path additivity -LRB- Definition 1 -RRB- , it can be shown that for any a u ' \ u2217 ' u ' \ u2208 ' A u ' \ u2217 ' , b u ' \ u2217 ' u ' \ u2208 ' B u ' \ u2217 ' it holds that
	Cause: Then using path additivity -LRB- Definition 1 -RRB-
	Effect: it can be shown that for any a u ' \ u2217 ' u ' \ u2208 ' A u ' \ u2217 ' , b u ' \ u2217 ' u ' \ u2208 ' B u ' \ u2217 ' it holds that

CASE: 34
Stag: 141 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Empirically , one can obtain a more robust empirical estimate d ^ u ' \ u2062 ' -LRB- i , j -RRB- by averaging over all valid choices of a u ' \ u2217 ' , b u ' \ u2217 ' in Eq
	Cause: averaging over all valid choices of a u ' \ u2217 ' , b u ' \ u2217 ' in Eq
	Effect: Empirically , one can obtain a more robust empirical estimate d ^ u ' \ u2062 ' -LRB- i , j -RRB-

CASE: 35
Stag: 151 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If w i and z i were discrete , represented as binary vectors , the above assumption would correspond to requiring all conditional probability tables in the latent tree to have rank m
	Cause: binary vectors , the above assumption would correspond to requiring all conditional probability tables in the latent tree to have rank m
	Effect: i and z i were discrete , represented

CASE: 36
Stag: 154 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Furthermore , Assumption 1 makes it explicit that regardless of the size of p , the relationships among the variables in the latent tree are restricted to be of rank m , and are thus low rank since p m
	Cause: Furthermore , Assumption 1 makes it explicit that regardless of the size of p , the relationships among the variables in the latent tree are restricted to be of rank m , and are
	Effect: low rank since p m

CASE: 37
Stag: 158 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If Assumption 1 holds then , d spectral is an additive tree metric -LRB- Definition 1
	Cause: Assumption 1 holds then
	Effect: d spectral is an additive tree metric -LRB- Definition

CASE: 38
Stag: 160 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: From here , we use d to denote d spectral , since that is the metric we use for our learning algorithm
	Cause: that is the metric we use for our learning algorithm
	Effect: From here , we use d to denote d spectral

CASE: 39
Stag: 161 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: It has been shown -LSB- Rzhetsky and Nei1993 -RSB- that for any additive tree metric , u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- can be recovered by solving arg u ' \ u2062 ' min u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' u ' \ u2061 ' c u ' \ u2062 ' -LRB- u -RRB- for c u ' \ u2062 ' -LRB- u -RRB-
	Cause: solving arg u ' \ u2062 ' min u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' u ' \ u2061 ' c u ' \ u2062 ' -LRB- u -RRB- for c u ' \ u2062 ' -LRB- u -RRB-
	Effect: It has been shown -LSB- Rzhetsky and Nei1993 -RSB- that for any additive tree metric , u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- can be recovered

CASE: 40
Stag: 165 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Note that the metric d we use in defining c u ' \ u2062 ' -LRB- u -RRB- is based on the expectations from the true distribution
	Cause: the expectations from the true distribution
	Effect: Note that the metric d we use in defining c u ' \ u2062 ' -LRB- u -RRB- is

CASE: 41
Stag: 166 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: In practice , the true distribution is unknown , and therefore we use an approximation for the distance metric d ^
	Cause: In practice , the true distribution is unknown
	Effect: we use an approximation for the distance metric d ^

CASE: 42
Stag: 166 167 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In practice , the true distribution is unknown , and therefore we use an approximation for the distance metric d ^ As we discussed in 3.1 all elements of the distance matrix are functions of observable quantities if the underlying tree u is known
	Cause: we discussed in 3.1 all elements of the distance matrix are functions of observable quantities if the underlying tree u is known
	Effect: we use an approximation for the distance metric d ^

CASE: 43
Stag: 171 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However , if we restrict u to be in u ' \ ud835 ' u ' \ udcb0 ' , as we do in the above , then maximizing c ^ u ' \ u2062 ' -LRB- u -RRB- over u ' \ ud835 ' u ' \ udcb0 ' can be solved using the bilexical parsing algorithm from Eisner and Satta1999
	Cause: we do in the above , then maximizing c ^ u ' \ u2062 ' -LRB- u -RRB- over u ' \ ud835 ' u ' \ udcb0 ' can be solved using the bilexical parsing algorithm from Eisner and Satta1999
	Effect: we restrict u to be in u ' \ ud835 ' u ' \ udcb0 '

CASE: 44
Stag: 171 172 
	Pattern: 8 [['because']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&ADV)'], ['&C']]
	sentTXT: However , if we restrict u to be in u ' \ ud835 ' u ' \ udcb0 ' , as we do in the above , then maximizing c ^ u ' \ u2062 ' -LRB- u -RRB- over u ' \ ud835 ' u ' \ udcb0 ' can be solved using the bilexical parsing algorithm from Eisner and Satta1999 This is because the computation of the other sub-blocks of the distance matrix only depend on the partitions of the nodes shown in Figure 3 into A , B , G , and H , and not on the entire tree structure
	Cause: the computation of the other sub-blocks of the distance matrix only depend on the partitions of the nodes shown in Figure 3 into A , B , G , and H , and not on the entire tree structure
	Effect: However , if we restrict u to be in u ' \ ud835 ' u ' \ udcb0 ' , as we do in the above , then maximizing c ^ u ' \ u2062 ' -LRB- u -RRB- over u ' \ ud835 ' u ' \ udcb0 ' can be solved using the bilexical parsing algorithm from Eisner and Satta1999

CASE: 45
Stag: 172 173 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: This is because the computation of the other sub-blocks of the distance matrix only depend on the partitions of the nodes shown in Figure 3 into A , B , G , and H , and not on the entire tree structure Therefore , the procedure to find a bracketing for a given POS tag u ' \ ud835 ' u ' \ udc99 ' is to first estimate the distance matrix sub-block u ' \ ud835 ' u ' \ udc6b ' ^ W u ' \ u2062 ' W from raw text data -LRB- see 3.4 -RRB- , and then solve the optimization problem arg u ' \ u2062 ' min u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' u ' \ u2061 ' c ^ u ' \ u2062 ' -LRB- u -RRB- using a variant of the Eisner-Satta algorithm where c ^ u ' \ u2062 ' -LRB- u -RRB- is identical to c u ' \ u2062 ' -LRB- u -RRB- in Eq
	Cause: This is because the computation of the other sub-blocks of the distance matrix only depend on the partitions of the nodes shown in Figure 3 into A , B , G , and H , and not on the entire tree structure
	Effect: the procedure to find a bracketing for a given POS tag u ' \ ud835 ' u ' \ udc99 ' is to first estimate the distance matrix sub-block u ' \ ud835 ' u ' \ udc6b ' ^ W u ' \ u2062 ' W from raw text data -LRB- see 3.4 -RRB- , and then solve the optimization problem arg u ' \ u2062 ' min u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' u ' \ u2061 ' c ^ u ' \ u2062 ' -LRB- u -RRB- using a variant of the Eisner-Satta algorithm where c ^ u ' \ u2062 ' -LRB- u -RRB- is identical to c u ' \ u2062 ' -LRB- u -RRB- in Eq

CASE: 46
Stag: 189 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First an undirected u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' is generated -LRB- only as a function of the POS tags -RRB- , and then u is mapped to a bracketing using a direction mapping h dir
	Cause: a function of the POS tags -RRB- , and then u is mapped to a bracketing using a direction mapping h
	Effect: an undirected u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' is generated -LRB- only

CASE: 47
Stag: 190 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: We then showed that we can define a distance metric between nodes in the undirected tree , such that minimizing it leads to a recovery of u
	Cause: it
	Effect: a recovery of u

CASE: 48
Stag: 192 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the true distance metric is known , with respect to the true distribution that generates the words in a sentence , then u can be fully recovered by optimizing the cost function c u ' \ u2062 ' -LRB- u
	Cause: the true distance metric is known
	Effect: with respect to the true distribution that generates the words in a sentence , then u can be fully recovered by optimizing the cost function c u ' \ u2062

CASE: 49
Stag: 192 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: with respect to the true distribution that generates the words in a sentence , then u can be fully recovered by optimizing the cost function c u ' \ u2062
	Cause: optimizing the cost
	Effect: function c u ' \ u2062

CASE: 50
Stag: 194 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: We now address the data sparsity problem , in particular that u ' \ ud835 ' u ' \ udc9f ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- can be very small , and therefore estimating d for each POS sequence separately can be problematic
	Cause: We now address the data sparsity problem , in particular that u ' \ ud835 ' u ' \ udc9f ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- can be very small
	Effect: estimating d for each POS sequence separately can be problematic

CASE: 51
Stag: 202 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The local syntactic context acts as an u ' \ u201c ' anchor , u ' \ u201d ' which enhances or replaces a word index in a sentence with local syntactic context
	Cause: an u ' \ u201c ' anchor , u ' \ u201d ' which enhances or replaces a word index in a sentence with local syntactic
	Effect: The local syntactic context acts

CASE: 52
Stag: 208 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Instead of computing this block by computing the empirical covariance matrix for positions -LRB- j , k -RRB- in the data u ' \ ud835 ' u ' \ udc9f ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- , the algorithm uses all of the pairs -LRB- j u ' \ u2032 ' , k u ' \ u2032 ' -RRB- from all of N training examples
	Cause: computing the empirical covariance matrix for positions -LRB- j , k -RRB- in the data u ' \ ud835 ' u ' \ udc9f ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB-
	Effect: , the algorithm uses all of the pairs -LRB- j u ' \ u2032 ' , k u ' \ u2032 ' -RRB- from all of N training examples

CASE: 53
Stag: 211 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Once the empirical estimates for the covariance matrices are obtained , a variant of the Eisner-Satta algorithm is used , as mentioned in 3.3
	Cause: the empirical estimates for the covariance matrices are obtained
	Effect: a variant of the Eisner-Satta algorithm is used , as mentioned in 3.3

CASE: 54
Stag: 212 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Our main theoretical guarantee is that Algorithm 1 will recover the correct tree u u ' \ u2208 ' u ' \ ud835 ' u ' \ udcb0 ' with high probability , if the given top bracket is correct and if we obtain enough examples -LRB- u ' \ ud835 ' u ' \ udc98 ' -LRB- i -RRB- , u ' \ ud835 ' u ' \ udc99 ' -LRB- i -RRB- -RRB- from the model in 2
	Cause: we obtain enough examples -LRB- u ' \ ud835 ' u ' \ udc98 '
	Effect: u ' \ ud835 ' u ' \ udc99 ' -LRB-

CASE: 55
Stag: 215 216 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Denote u ' \ u03a3 ' u ' \ ud835 ' u ' \ udc99 ' u ' \ u2062 ' -LRB- j , k -RRB- -LRB- r -RRB- as the r t u ' \ u2062 ' h singular value of u ' \ ud835 ' u ' \ udeba ' u ' \ ud835 ' u ' \ udc99 ' u ' \ u2062 ' -LRB- j , k Let u ' \ u03a3 ' u ' \ u2217 ' u ' \ u2062 ' -LRB- x -RRB- : = min j , k u ' \ u2208 ' u ' \ u2113 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- u ' \ u2061 ' min u ' \ u2061 ' -LRB- u ' \ u03a3 ' u ' \ ud835 ' u ' \ udc99 ' u ' \ u2062 ' -LRB- j , k -RRB- -LRB- m -RRB- -RRB-
	Cause: the r t u ' \ u2062 ' h singular value of u ' \ ud835 ' u ' \ udeba ' u ' \ ud835 ' u ' \ udc99 ' u ' \ u2062 ' -LRB- j , k Let u ' \ u03a3 ' u ' \ u2217 ' u ' \ u2062 ' -LRB- x -RRB- : = min j , k u ' \ u2208 ' u ' \ u2113 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- u ' \ u2061 ' min u ' \ u2061 ' -LRB- u ' \ u03a3 ' u ' \ ud835 ' u ' \ udc99 ' u ' \ u2062 ' -LRB- j , k -RRB- -LRB- m -RRB- -RRB-
	Effect: ' \ u03a3 ' u ' \ ud835 ' u ' \ udc99 ' u ' \ u2062 ' -LRB- j , k -RRB- -LRB- r -RRB-

CASE: 56
Stag: 216 217 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Let u ' \ u03a3 ' u ' \ u2217 ' u ' \ u2062 ' -LRB- x -RRB- : = min j , k u ' \ u2208 ' u ' \ u2113 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- u ' \ u2061 ' min u ' \ u2061 ' -LRB- u ' \ u03a3 ' u ' \ ud835 ' u ' \ udc99 ' u ' \ u2062 ' -LRB- j , k -RRB- -LRB- m -RRB- -RRB- Define u ^ as the estimated tree for tag sequence u ' \ ud835 ' u ' \ udc31 ' and u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc31 ' -RRB- as the correct tree
	Cause: the estimated tree for tag sequence u ' \ ud835 ' u ' \ udc31 ' and u u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc31 ' -RRB- as the correct tree
	Effect: ' \ u03a3 ' u ' \ u2217 ' u ' \ u2062 ' -LRB- x -RRB- : = min j , k u ' \ u2208 ' u ' \ u2113 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- u ' \ u2061 ' min u ' \ u2061 ' -LRB- u ' \ u03a3 ' u ' \ ud835 ' u ' \ udc99 ' u ' \ u2062 ' -LRB- j , k -RRB- -LRB- m -RRB- -RRB- Define u ^

CASE: 57
Stag: 221 222 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: where u ' \ u039d ' u ' \ ud835 ' u ' \ udc99 ' u ' \ u2062 ' -LRB- u ' \ u0393 ' -RRB- , defined in the supplementary , is a function of the underlying distribution over the tag sequences u ' \ ud835 ' u ' \ udc99 ' and the kernel bandwidth u ' \ u0393 ' Thus , the sample complexity of our approach depends on the dimensionality of the latent and observed states -LRB- m and p -RRB- , the underlying singular values of the cross-covariance matrices -LRB- u ' \ u03a3 ' u ' \ u2217 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- -RRB- and the difference in the cost of the true tree compared to the cost of the incorrect trees -LRB- u ' \ u25b3 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB-
	Cause: where u ' \ u039d ' u ' \ ud835 ' u ' \ udc99 ' u ' \ u2062 ' -LRB- u ' \ u0393 ' -RRB- , defined in the supplementary , is a function of the underlying distribution over the tag sequences u ' \ ud835 ' u ' \ udc99 ' and the kernel bandwidth u ' \ u0393 '
	Effect: , the sample complexity of our approach depends on the dimensionality of the latent and observed states -LRB- m and p -RRB- , the underlying singular values of the cross-covariance matrices -LRB- u ' \ u03a3 ' u ' \ u2217 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- -RRB- and the difference in the cost of the true tree compared to the cost of the incorrect trees -LRB- u ' \ u25b3 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB-

CASE: 58
Stag: 236 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If no verb exists , return -LRB- -LSB- 0 , 1 -RSB- , -LSB- 1 , u ' \ u2113 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- -RSB- -RRB-
	Cause: no verb exists
	Effect: return -LRB- -LSB- 0 , 1 -RSB- , -LSB- 1 , u ' \ u2113 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u '

CASE: 59
Stag: 236 237 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If no verb exists , return -LRB- -LSB- 0 , 1 -RSB- , -LSB- 1 , u ' \ u2113 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- -RSB- -RRB- As mentioned earlier , each w i can be an arbitrary feature vector
	Cause: mentioned earlier , each w i can be an arbitrary feature vector
	Effect: no verb exists , return -LRB- -LSB- 0 , 1 -RSB- , -LSB- 1 , u ' \ u2113 ' u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc99 ' -RRB- -RSB- -RRB-

CASE: 60
Stag: 242 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The OSCCA embeddings behaved better , so we only report its results
	Cause: The OSCCA embeddings behaved better
	Effect: we only report its results

CASE: 61
Stag: 252 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: For CCM , we found that if the full dataset -LRB- all sentence lengths -RRB- is used in training , then performance degrades when evaluating on sentences of length u ' \ u2264 ' 10
	Cause: the full dataset -LRB- all sentence lengths -RRB- is used in training
	Effect: then performance degrades when

CASE: 62
Stag: 252 253 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: For CCM , we found that if the full dataset -LRB- all sentence lengths -RRB- is used in training , then performance degrades when evaluating on sentences of length u ' \ u2264 ' 10 We therefore restrict the data used with CCM to sentences of length u ' \ u2264 ' u ' \ u2113 ' , where u ' \ u2113 ' is the maximal sentence length being evaluated
	Cause: CCM , we found that if the full dataset -LRB- all sentence lengths -RRB- is used in training , then performance degrades when evaluating on sentences of length u ' \ u2264 ' 10 We
	Effect: restrict the data used with CCM to sentences of length u ' \ u2264 ' u ' \ u2113 ' , where u ' \ u2113 ' is the maximal sentence length being evaluated

CASE: 63
Stag: 254 255 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: This does not happen with our algorithm , which manages to leverage lexical information whenever more data is available We therefore use the full data for our method for all lengths
	Cause: does not happen with our algorithm , which manages to leverage lexical information whenever more data is available We
	Effect: use the full data for our method for all lengths

CASE: 64
Stag: 258 259 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: For CCM , we also experimented with the original parts of speech , universal tags -LRB- CCM-U -RRB- , the cross-product of the original parts of speech with the Brown clusters -LRB- CCM-OB -RRB- , and the cross-product of the universal tags with the Brown clusters -LRB- CCM-UB The results in Table 1 indicate that the vanilla setting is the best for CCM
	Cause: For CCM , we also experimented with the original parts of speech , universal tags -LRB- CCM-U -RRB- , the cross-product of the original parts of speech with the Brown clusters -LRB- CCM-OB -RRB- , and the cross-product of the universal tags with the Brown clusters -LRB- CCM-UB
	Effect: the best for CCM

CASE: 65
Stag: 259 260 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The results in Table 1 indicate that the vanilla setting is the best for CCM Thus , for all results , we use universal tags for our method and the original POS tags for CCM
	Cause: The results in Table 1 indicate that the vanilla setting is the best for CCM
	Effect: , for all results , we use universal tags for our method and the original POS tags for CCM

CASE: 66
Stag: 267 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: We also tried letting CCM choose different hyperparameters for different sentence lengths based on dev-set likelihood , but this gave worse results than holding them fixed
	Cause: dev-set likelihood
	Effect: but this gave worse results than holding them fixed

CASE: 67
Stag: 271 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: NN , CC , and BC indicate the performance of our method for neural embeddings , CCA embeddings , and Brown clustering respectively , using the heuristic for h dir described in 4.1
	Cause: NN , CC , and BC
	Effect: the performance of our method for neural embeddings , CCA embeddings , and Brown clustering respectively , using the heuristic for h dir described in 4.1

CASE: 68
Stag: 273 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: For our method , test set results can be obtained by using Algorithm 3.3 -LRB- except the distances are computed using the training data
	Cause: using Algorithm 3.3 -LRB- except the distances are computed using the training data
	Effect: For our method , test set results can be obtained

CASE: 69
Stag: 280 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We didn u ' \ u2019 ' t have neural embeddings for German and Chinese -LRB- which worked best for English -RRB- and thus only used Brown cluster embeddings
	Cause: We didn u ' \ u2019 ' t have neural embeddings for German and Chinese -LRB- which worked best for English -RRB-
	Effect: only used Brown cluster embeddings

CASE: 70
Stag: 282 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: However , for German and Chinese note that the u ' \ u201c ' BC-O u ' \ u201d ' performs substantially better , suggesting that if we had a better top bracket heuristic our performance would increase
	Cause: we had a better top bracket heuristic our performance would increase
	Effect: German and Chinese note that the u ' \ u201c ' BC-O u ' \ u201d ' performs substantially better , suggesting that

CASE: 71
Stag: 285 286 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Figure 4 shows a histogram of the performance level for sentences of length u ' \ u2264 ' 10 for different random initializers As one can see , for some restarts , CCM obtains accuracies lower than 30 u ' \ u2062 ' % due to local optima
	Cause: one can see , for some restarts , CCM obtains accuracies lower than 30 u ' \ u2062 ' % due to local optima
	Effect: Figure 4 shows a histogram of the performance level for sentences of length u ' \ u2264 ' 10 for different random initializers

CASE: 72
Stag: 287 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Our method does not suffer from local optima and thus does not require careful initialization
	Cause: Our method does not suffer from local optima
	Effect: does not require careful initialization

CASE: 73
Stag: 288 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Our approach is not directly comparable to Seginer u ' \ u2019 ' s because he uses punctuation , while we use POS tags
	Cause: he uses punctuation
	Effect: while we use POS tags

