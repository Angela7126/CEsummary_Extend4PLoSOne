************************************************************
P14-1058.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Although the distributional hypothesis has been applied successfully in many natural language processing tasks , systems using distributional information have been limited to a single domain because the distribution of a word can vary between domains as the word u ' \ u2019 ' s predominant meaning changes
	Cause: the distribution of a word can vary between domains as the word u ' \ u2019 ' s predominant meaning changes
	Effect: Although the distributional hypothesis has been applied successfully in many natural language processing tasks , systems using distributional information have been limited to a single domain

CASE: 1
Stag: 0 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: the distribution of a word can vary between domains as the word u ' \ u2019 ' s predominant meaning changes
	Cause: the word u ' \ u2019 ' s predominant meaning changes
	Effect: the distribution of a word can vary between domains

CASE: 2
Stag: 1 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: However , if it were possible to predict how the distribution of a word changes from one domain to another , the predictions could be used to adapt a system trained in one domain to work in another
	Cause: it were possible to predict how the distribution of a word changes from one domain to another
	Effect: the predictions could be used to adapt a system trained in one domain to work in another

CASE: 3
Stag: 9 10 
	Pattern: 9 [['consequently']]---- [['&C', '(,/;/./--)'], ['(,)', '&R']]
	sentTXT: For example , in the domain of portable computer reviews the word lightweight is often associated with positive sentiment bearing words such as sleek or compact , whereas in the movie review domain the same word is often associated with negative sentiment-bearing words such as superficial or formulaic Consequently , the distributional representations of the word lightweight will differ considerably between the two domains
	Cause: For example , in the domain of portable computer reviews the word lightweight is often associated with positive sentiment bearing words such as sleek or compact , whereas in the movie review domain the same word is often associated with negative sentiment-bearing words such as superficial or formulaic
	Effect: the distributional representations of the word lightweight will differ considerably between the two domains

CASE: 4
Stag: 11 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this paper , given the distribution w u ' \ u2192 ' \ cS of a word w in the source domain \ cS , we propose an unsupervised method for predicting its distribution w u ' \ u2192 ' \ cT in a different target domain \ cT
	Cause: predicting its distribution w u ' \ u2192 ' \ cT in a different target domain \ cT
	Effect: In this paper , given the distribution w u ' \ u2192 ' \ cS of a word w in the source domain \ cS , we propose an unsupervised method

CASE: 5
Stag: 14 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Domain adaptation -LRB- DA -RRB- of sentiment classification becomes extremely challenging when the distributions of words in the source and the target domains are very different , because the features learnt from the source domain labeled reviews might not appear in the target domain reviews that must be classified
	Cause: the features learnt from the source domain labeled reviews might not appear in the target domain reviews that must be classified
	Effect: Domain adaptation -LRB- DA -RRB- of sentiment classification becomes extremely challenging when the distributions of words in the source and the target domains are very different

CASE: 6
Stag: 15 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By predicting the distribution of a word across different domains , we can find source domain features that are similar to the features in target domain reviews , thereby reducing the mismatch of features between the two domains
	Cause: predicting the distribution of a word across different domains
	Effect: , we can find source domain features that are similar to the features in target domain reviews , thereby reducing the mismatch of features between the two domains

CASE: 7
Stag: 21 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using two popular multi-domain datasets , we evaluate the proposed method in two prediction tasks a -RRB- predicting the POS of a word in a target domain , and -LRB- b -RRB- predicting the sentiment of a review in a target domain
	Cause: Using two popular multi-domain datasets
	Effect: we evaluate the proposed method in two prediction tasks a -RRB- predicting the POS of a word in a target domain , and -LRB- b -RRB- predicting the sentiment of a review in a target domain

CASE: 8
Stag: 23 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because our proposed distribution prediction method is unsupervised and task independent , it is potentially useful for a wide range of DA tasks such entity extraction -LSB- -RSB- or dependency parsing -LSB- -RSB-
	Cause: our proposed distribution prediction method is unsupervised and task independent
	Effect: it is potentially useful for a wide range of DA tasks such entity extraction -LSB- -RSB- or dependency parsing -LSB- -RSB-

CASE: 9
Stag: 25 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Given the distribution w u ' \ u2192 ' \ cS of a word w in a source domain \ cS , we propose a method for learning its distribution w u ' \ u2192 ' \ cT in a target domain \ cT
	Cause: learning its distribution w u ' \ u2192 ' \ cT in a target domain \ cT
	Effect: Given the distribution w u ' \ u2192 ' \ cS of a word w in a source domain \ cS , we propose a method

CASE: 10
Stag: 26 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using the learnt distribution prediction model , we propose a method to learn a cross-domain POS tagger
	Cause: Using the learnt distribution prediction model
	Effect: we propose a method to learn a cross-domain POS tagger

CASE: 11
Stag: 27 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using the learnt distribution prediction model , we propose a method to learn a cross-domain sentiment classifier
	Cause: Using the learnt distribution prediction model
	Effect: we propose a method to learn a cross-domain sentiment classifier

CASE: 12
Stag: 29 30 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Learning semantic representations for words using documents from a single domain has received much attention lately -LSB- -RSB- As we have already discussed , the semantics of a word varies across different domains , and such variations are not captured by models that only learn a single semantic representation for a word using documents from a single domain
	Cause: we have already discussed , the semantics of a word varies across different domains , and such variations
	Effect: semantic representations for words using documents from a single domain has received much attention lately -LSB- -RSB-

CASE: 13
Stag: 32 33 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For example , the word signal is predominately used as a noun in MEDLINE , whereas it appears predominantly as an adjective in the Wall Street Journal -LRB- WSJ -RRB- -LSB- -RSB- Consequently , a tagger trained on WSJ would incorrectly tag signal in MEDLINE append the source domain labeled data with predicted pivots -LRB- i.e. , words that appear in both the source and target domains -RRB- to adapt a POS tagger to a target domain propose a cross-domain POS tagging method by training two separate models a generalised model and a domain-specific model
	Cause: a noun in MEDLINE , whereas it appears predominantly as an adjective in the Wall Street Journal -LRB- WSJ -RRB- -LSB- -RSB- Consequently , a tagger trained on WSJ would incorrectly tag signal in MEDLINE append the source domain labeled data with predicted pivots -LRB- i.e. , words that appear in both the source and target domains -RRB- to adapt a POS tagger to a target domain propose a cross-domain POS tagging method by training two separate models a generalised model and a domain-specific
	Effect: For example , the word signal is predominately used

CASE: 14
Stag: 32 33 
	Pattern: 9 [['consequently']]---- [['&C', '(,/;/./--)'], ['(,)', '&R']]
	sentTXT: For example , the word signal is predominately used as a noun in MEDLINE , whereas it appears predominantly as an adjective in the Wall Street Journal -LRB- WSJ -RRB- -LSB- -RSB- Consequently , a tagger trained on WSJ would incorrectly tag signal in MEDLINE append the source domain labeled data with predicted pivots -LRB- i.e. , words that appear in both the source and target domains -RRB- to adapt a POS tagger to a target domain propose a cross-domain POS tagging method by training two separate models a generalised model and a domain-specific model
	Cause: For example , the word signal is predominately used as a noun in MEDLINE , whereas it appears predominantly as an adjective in the Wall Street Journal -LRB- WSJ -RRB- -LSB- -RSB-
	Effect: a tagger trained on WSJ would incorrectly tag signal in MEDLINE append the source domain labeled data with predicted pivots -LRB- i.e. , words that appear in both the source and target domains -RRB- to adapt a POS tagger to a target domain propose a cross-domain POS tagging method by training two separate models a generalised model and a domain-specific model

CASE: 15
Stag: 35 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Adding latent states to the smoothing model further improves the POS tagging accuracy -LSB- -RSB- propose a training set filtering method where they eliminate shorter words from the training data based on the intuition that longer words are more likely to be examples of productive linguistic processes than shorter words
	Cause: the intuition that longer words are more likely to be examples of productive linguistic processes than shorter words
	Effect: Adding latent states to the smoothing model further improves the POS tagging accuracy -LSB- -RSB- propose a training set filtering method where they eliminate shorter words from the training data

CASE: 16
Stag: 48 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: However , if a small amount of labeled data is available for the target domain , it can be used to further improve the performance of DA tasks -LSB- -RSB-
	Cause: a small amount of labeled data is available for the target domain
	Effect: it can be used to further improve the performance of DA tasks -LSB- -RSB-

CASE: 17
Stag: 52 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using a standard stop word list , we filter out frequent non-content unigrams and select the remainder as unigram features to represent a sentence
	Cause: Using a standard stop word list
	Effect: we filter out frequent non-content unigrams and select the remainder as unigram features to represent a sentence

CASE: 18
Stag: 52 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: we filter out frequent non-content unigrams and select the remainder as unigram features to represent a sentence
	Cause: unigram features to represent a sentence
	Effect: we filter out frequent non-content unigrams and select the remainder

CASE: 19
Stag: 56 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using data from a single domain , we construct a feature co-occurrence matrix \ mat u ' \ u2062 ' A in which columns correspond to unigram features and rows correspond to either unigram or bigram features
	Cause: Using data from a single domain , we construct a feature co-occurrence matrix
	Effect: \ mat u ' \ u2062 ' A in which columns correspond to unigram features and

CASE: 20
Stag: 59 60 
	Pattern: 9 [['consequently']]---- [['&C', '(,/;/./--)'], ['(,)', '&R']]
	sentTXT: Moreover , co-occurrences of bigrams are rare compared to co-occurrences of unigrams , and co-occurrences involving a unigram and a bigram Consequently , in matrix \ mat u ' \ u2062 ' A , we consider co-occurrences only between unigrams vs unigrams , and bigrams vs unigrams
	Cause: Moreover , co-occurrences of bigrams are rare compared to co-occurrences of unigrams , and co-occurrences involving a unigram and a bigram
	Effect: in matrix \ mat u ' \ u2062 ' A , we consider co-occurrences only between unigrams vs unigrams , and bigrams vs unigrams

CASE: 21
Stag: 65 66 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Matrix \ mat u ' \ u2062 ' F has the same number of rows , n r , and columns , n c , as the raw co-occurrence matrix \ mat u ' \ u2062 ' A Note that in addition to the above-mentioned representation , there are many other ways to represent the distribution of a word in a particular domain -LSB- -RSB-
	Cause: the raw co-occurrence matrix \ mat u ' \ u2062 ' A Note that in addition to the above-mentioned representation , there are many other ways to represent the distribution of a word in a particular domain -LSB-
	Effect: Matrix \ mat u ' \ u2062 ' F has the same number of rows , n r , and columns , n c

CASE: 22
Stag: 68 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the method we propose in Section 3.2 to predict the distribution of a word across domains does not depend on the particular feature representation method , any of these alternative methods could be used
	Cause: the method we propose in Section 3.2 to predict the distribution of a word across domains does not depend on the particular feature representation method
	Effect: any of these alternative methods could be used

CASE: 23
Stag: 72 73 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Each row in \ mat u ' \ u2062 ' F ^ is considered as representing a word in a lower k -LRB- u ' \ u226a ' n c -RRB- dimensional feature space corresponding to a particular domain Distribution prediction in this lower dimensional feature space is preferrable to prediction over the original feature space because there are reductions in overfitting , feature sparseness , and the learning time
	Cause: representing a word in a lower k -LRB- u ' \ u226a ' n c -RRB- dimensional feature space corresponding to a particular domain Distribution prediction in this lower dimensional feature space is preferrable to prediction over the original feature space because there are reductions in overfitting , feature sparseness
	Effect: Each row in \ mat u ' \ u2062 ' F ^ is considered

CASE: 24
Stag: 73 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Distribution prediction in this lower dimensional feature space is preferrable to prediction over the original feature space because there are reductions in overfitting , feature sparseness , and the learning time
	Cause: there are reductions in overfitting , feature sparseness , and the learning time
	Effect: Distribution prediction in this lower dimensional feature space is preferrable to prediction over the original feature space

CASE: 25
Stag: 77 78 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the literature , such features are often referred to as pivots , and they have been shown to be useful for DA , allowing the weights learnt to be transferred from one domain to another Various criteria have been proposed for selecting a small set of pivots for DA , such as the mutual information of a word with the two domains -LSB- -RSB-
	Cause: pivots , and they have been shown to be useful for DA , allowing the weights learnt to be transferred from one domain to another Various criteria have been proposed for selecting a small set of pivots for DA , such as the mutual information of a word with the two domains -LSB-
	Effect: In the literature , such features are often referred to

CASE: 26
Stag: 78 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Various criteria have been proposed for selecting a small set of pivots for DA , such as the mutual information of a word with the two domains -LSB- -RSB-
	Cause: selecting a small set of pivots for DA , such as the mutual information of a word with the two domains -LSB- -RSB-
	Effect: Various criteria have been proposed

CASE: 27
Stag: 81 82 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Note that the dimensionality of w u ' \ u2192 ' \ cS -LRB- i -RRB- and w u ' \ u2192 ' \ cT -LRB- i -RRB- need not be equal , and we may select different numbers of singular vectors to approximate \ mat u ' \ u2062 ' F ^ \ cS and \ mat u ' \ u2062 ' F ^ \ cT We model distribution prediction as a multivariate regression problem where , given a set -LCB- -LRB- w u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cT -LRB- i -RRB- -RRB- -RCB- i = 1 n consisting of pairs of feature vectors selected from each domain for the pivots in \ cW , we learn a mapping from the inputs -LRB- w u ' \ u2192 ' \ cS -LRB- i -RRB- -RRB- to the outputs -LRB- w u ' \ u2192 ' \ cT -LRB- i -RRB-
	Cause: a multivariate regression problem where , given a set -LCB- -LRB- w u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cT -LRB- i -RRB- -RRB- -RCB- i = 1 n consisting of pairs of feature vectors selected from each domain for the pivots in \ cW , we learn a mapping from the inputs -LRB- w u ' \ u2192 ' \ cS -LRB- i -RRB-
	Effect: the dimensionality of w u ' \ u2192 ' \ cS -LRB- i -RRB- and w u ' \ u2192 ' \ cT -LRB- i -RRB- need not be equal , and we may select different numbers of singular vectors to approximate \ mat u ' \ u2062 ' F ^ \ cS and \ mat u ' \ u2062 ' F ^ \ cT We model distribution prediction

CASE: 28
Stag: 86 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Let \ mat u ' \ u2062 ' X and \ mat u ' \ u2062 ' Y denote matrices formed by arranging respectively the vectors w u ' \ u2192 ' \ cS -LRB- i -RRB- s and w u ' \ u2192 ' \ cT -LRB- i -RRB- in rows
	Cause: arranging respectively the vectors w u ' \ u2192 ' \ cS -LRB- i -RRB- s
	Effect: and w u ' \ u2192 ' \ cT -LRB- i -RRB- in rows

CASE: 29
Stag: 89 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: The matrices , u ' \ ud835 ' u ' \ udeb2 ' , u ' \ ud835 ' u ' \ udeaa ' , \ mat u ' \ u2062 ' P , and \ mat u ' \ u2062 ' Q are constructed respectively by arranging u ' \ u039b ' u ' \ u2192 ' l , u ' \ u0393 ' u ' \ u2192 ' l , p u ' \ u2192 ' l , and q u ' \ u2192 ' l vectors as columns
	Cause: arranging u ' \ u039b ' u ' \ u2192 ' l
	Effect: , u ' \ u0393 ' u ' \ u2192 ' l , p u ' \ u2192 ' l , and q u ' \ u2192 ' l vectors as columns

CASE: 30
Stag: 97 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: It is based on the two block NIPALS routine -LSB- -RSB- and iteratively discovers L pairs of vectors -LRB- u ' \ u039b ' u ' \ u2192 ' l , u ' \ u0393 ' u ' \ u2192 ' l -RRB- such that the covariances , Cov u ' \ u2062 ' -LRB- u ' \ u039b ' u ' \ u2192 ' l , u ' \ u0393 ' u ' \ u2192 ' l -RRB- , are maximised under the constraint \ norm u ' \ u2062 ' p u ' \ u2192 ' l = \ norm u ' \ u2062 ' q u ' \ u2192 ' l = 1
	Cause: the two block NIPALS routine -LSB- -RSB- and iteratively discovers L pairs of vectors -LRB- u ' \ u039b ' u ' \ u2192 ' l
	Effect: u ' \ u0393 ' u ' \ u2192 ' l -RRB- such that the covariances , Cov u ' \ u2062 ' -LRB- u ' \ u039b ' u ' \ u2192 ' l , u ' \ u0393 ' u ' \ u2192 ' l -RRB- , are maximised under the constraint \ norm u ' \ u2062 ' p u ' \ u2192 ' l = \ norm u ' \ u2062 ' q u ' \ u2192 ' l = 1

CASE: 31
Stag: 101 102 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This is an important point , and means that the distribution prediction method is independent of the task to which it may subsequently be applied As we go on to show in Section 6 , this enables us to use the same distribution prediction method for both POS tagging and sentiment classification
	Cause: we go on to show in Section 6 , this enables us to use the same distribution prediction method for both POS tagging and sentiment classification
	Effect: This is an important point , and means that the distribution prediction method is independent of the task to which it may subsequently be applied

CASE: 32
Stag: 108 109 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Next , for each word w in a source domain labeled -LRB- i.e. , manually POS tagged -RRB- sentence , we select its neighbours u -LRB- i -RRB- in the source domain as additional features Specifically , we measure the similarity , sim u ' \ u2062 ' -LRB- u u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cS -RRB- , between the source domain distributions of u -LRB- i -RRB- and w , and select the top r similar neighbours u -LRB- i -RRB- for each word w as additional features for w
	Cause: additional features Specifically , we measure the similarity , sim u ' \ u2062 ' -LRB- u u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cS -RRB- , between the source domain distributions of u -LRB- i -RRB- and w , and select the top r similar neighbours u -LRB- i -RRB- for each word w as additional features for w
	Effect: Next , for each word w in a source domain labeled -LRB- i.e. , manually POS tagged -RRB- sentence , we select its neighbours u -LRB- i -RRB- in the source domain

CASE: 33
Stag: 110 111 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We refer to such features as distributional features in this work The value of a neighbour u -LRB- i -RRB- selected as a distributional feature is set to its similarity score sim u ' \ u2062 ' -LRB- u u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cS
	Cause: distributional features in this work The value of a neighbour u -LRB- i -RRB- selected as a distributional feature is set to its similarity score sim u ' \ u2062 ' -LRB- u u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \
	Effect: We refer to such features

CASE: 34
Stag: 111 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The value of a neighbour u -LRB- i -RRB- selected as a distributional feature is set to its similarity score sim u ' \ u2062 ' -LRB- u u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cS
	Cause: a distributional feature is set to its similarity score sim u ' \ u2062 ' -LRB- u u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cS
	Effect: The value of a neighbour u -LRB- i -RRB- selected

CASE: 35
Stag: 114 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: At test time , for each word w that appears in a target domain test sentence , we measure the similarity , sim u ' \ u2062 ' -LRB- \ mat u ' \ u2062 ' M u ' \ u2062 ' u u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cT -RRB- , and select the most similar r words u -LRB- i -RRB- in the source domain labeled sentences as the distributional features for w , with their values set to sim u ' \ u2062 ' -LRB- \ mat u ' \ u2062 ' M u ' \ u2062 ' u u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cT
	Cause: the distributional features for w , with their values set to sim u ' \ u2062 ' -LRB- \ mat u ' \ u2062 ' M u ' \ u2062 ' u u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cT
	Effect: each word w that appears in a target domain test sentence , we measure the similarity , sim u ' \ u2062 ' -LRB- \ mat u ' \ u2062 ' M u ' \ u2062 ' u u ' \ u2192 ' \ cS -LRB- i -RRB- , w u ' \ u2192 ' \ cT -RRB- , and select the most similar r words u -LRB- i -RRB- in the source domain labeled sentences

CASE: 36
Stag: 123 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First , we lemmatise each word in a source domain labeled review x u ' \ u2192 ' \ cS -LRB- i -RRB- , and extract both unigrams and bigrams as features to represent x u ' \ u2192 ' \ cS -LRB- i -RRB- by a binary-valued feature vector
	Cause: features to represent x u ' \ u2192 ' \ cS -LRB- i -RRB- by a binary-valued feature vector
	Effect: First , we lemmatise each word in a source domain labeled review x u ' \ u2192 ' \ cS -LRB- i -RRB- , and extract both unigrams and bigrams

CASE: 37
Stag: 127 128 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Next , we train a PLSR model , \ mat u ' \ u2062 ' M , as described in Section 3.2 using unlabeled reviews in the source and target domains At test time , we represent a test target review H using a binary-valued feature vector h u ' \ u2192 ' of unigrams and bigrams of lemmas of the words in H , as we did for source domain labeled train reviews
	Cause: described in Section 3.2 using unlabeled reviews in the source and target domains At test time , we represent a test target review H using a binary-valued feature vector h u ' \ u2192 ' of unigrams and bigrams of lemmas of the words in H , as we did for source domain labeled train reviews
	Effect: Next , we train a PLSR model , \ mat u ' \ u2062 ' M

CASE: 38
Stag: 128 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: At test time , we represent a test target review H using a binary-valued feature vector h u ' \ u2192 ' of unigrams and bigrams of lemmas of the words in H , as we did for source domain labeled train reviews
	Cause: we did for source domain labeled train reviews
	Effect: At test time , we represent a test target review H using a binary-valued feature vector h u ' \ u2192 ' of unigrams and bigrams of lemmas of the words in H

CASE: 39
Stag: 136 137 
	Pattern: 0 [[['enable', 'enables', 'enabled']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@', '&TODO@R@']]
	sentTXT: In particular , we do not find distributional features independently for each word in the test review This enables us to find distributional features that are consistent with all the features in a test review
	Cause: In particular , we do not find distributional features independently for each word in the test review
	Effect: us to find distributional features that are consistent with all the features in a test review

CASE: 40
Stag: 140 141 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For representation , we considered distributional features u -LRB- i -RRB- in descending order of their scores given by Equation 4 , and then taking the inverse-rank as the values for the distributional features -LSB- -RSB- However , none of these alternatives resulted in performance gains
	Cause: the values for the distributional features -LSB- -RSB- However , none of these alternatives resulted in performance gains
	Effect: For representation , we considered distributional features u -LRB- i -RRB- in descending order of their scores given by Equation 4 , and then taking the inverse-rank

CASE: 41
Stag: 145 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: We observed that setting r larger than 10 did not result in significant improvements in tagging accuracy , but only increased the train time due to the larger feature space
	Cause: the larger feature space
	Effect: We observed that setting r larger than 10 did not result in significant improvements in tagging accuracy , but only increased the train time

CASE: 42
Stag: 145 146 
	Pattern: 9 [['consequently']]---- [['&C', '(,/;/./--)'], ['(,)', '&R']]
	sentTXT: We observed that setting r larger than 10 did not result in significant improvements in tagging accuracy , but only increased the train time due to the larger feature space Consequently , we set r = 10 in POS tagging
	Cause: We observed that setting r larger than 10 did not result in significant improvements in tagging accuracy , but only increased the train time due to the larger feature space
	Effect: we set r = 10 in POS tagging

CASE: 43
Stag: 150 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To evaluate DA for POS tagging , following , we use sections 2 - 21 from Wall Street Journal -LRB- WSJ -RRB- as the source domain labeled data
	Cause: the source domain labeled data
	Effect: To evaluate DA for POS tagging , following , we use sections 2 - 21 from Wall Street Journal -LRB- WSJ -RRB-

CASE: 44
Stag: 151 152 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: An additional 100 , 000 WSJ sentences from the 1988 release of the WSJ corpus are used as the source domain unlabeled data Following , we use the POS labeled sentences in the SACNL dataset -LSB- -RSB- for the five target domains
	Cause: the source domain unlabeled data Following , we use the POS labeled sentences in the SACNL dataset -LSB- -RSB- for the five target
	Effect: An additional 100 , 000 WSJ sentences from the 1988 release of the WSJ corpus are used

CASE: 45
Stag: 152 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Following , we use the POS labeled sentences in the SACNL dataset -LSB- -RSB- for the five target domains
	Cause: Following
	Effect: we use the POS labeled sentences in the SACNL dataset -LSB- -RSB- for the five target domains

CASE: 46
Stag: 158 159 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use the standard split of 800 positive and 800 negative labeled reviews from each domain as training data , and the remainder for testing For each domain \ cD in the SANCL -LRB- POS tagging -RRB- and Amazon review -LRB- sentiment classification -RRB- datasets , we create a PPMI weighted co-occurrence matrix \ mat u ' \ u2062 ' F \ cD
	Cause: training data , and the remainder for testing For each domain \ cD in the SANCL -LRB- POS tagging -RRB- and Amazon review -LRB- sentiment classification -RRB- datasets , we create a PPMI weighted co-occurrence matrix \ mat u ' \ u2062 ' F \
	Effect: We use the standard split of 800 positive and 800 negative labeled reviews from each domain

CASE: 47
Stag: 163 164 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In cross-domain POS tagging , WSJ is always the source domain , whereas the five domains in SANCL dataset are considered as the target domains For this setting we have 9822 pivots on average
	Cause: the target domains For this setting we have 9822 pivots on
	Effect: In cross-domain POS tagging , WSJ is always the source domain , whereas the five domains in SANCL dataset are considered

CASE: 48
Stag: 169 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: By limiting the evaluation to unseen words instead of all words , we can evaluate the gain in POS tagging accuracy solely due to DA
	Cause: DA
	Effect: By limiting the evaluation to unseen words instead of all words , we can evaluate the gain in POS tagging accuracy solely

CASE: 49
Stag: 169 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By limiting the evaluation to unseen words instead of all words , we can evaluate the gain in POS tagging accuracy solely
	Cause: limiting the evaluation to unseen words instead of all words
	Effect: , we can evaluate the gain in POS tagging accuracy solely

CASE: 50
Stag: 175 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: If w does not appear in the target domain , then w u ' \ u2192 ' \ cT is set to the zero vector
	Cause: w does not appear in the target domain
	Effect: w u ' \ u2192 ' \ cT is set to the zero vector

CASE: 51
Stag: 177 178 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The DA method proposed in Section 4.1 is shown as the Proposed method Filter denotes the training set filtering method proposed by for the DA of POS taggers
	Cause: the Proposed method Filter denotes the training set filtering method proposed by for the DA of POS
	Effect: The DA method proposed in Section 4.1 is shown

CASE: 52
Stag: 180 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Recall that the \ cT p u ' \ u2062 ' r u ' \ u2062 ' e u ' \ u2062 ' d baseline can not find source domain words that do not appear in the target domain as distributional features for the words in the target domain test reviews
	Cause: distributional features for the words in the target domain test reviews
	Effect: ' \ u2062 ' r u ' \ u2062 ' e u ' \ u2062 ' d baseline can not find source domain words that do not appear in the target domain

CASE: 53
Stag: 180 181 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Recall that the \ cT p u ' \ u2062 ' r u ' \ u2062 ' e u ' \ u2062 ' d baseline can not find source domain words that do not appear in the target domain as distributional features for the words in the target domain test reviews Therefore , when the overlap between the vocabularies used in the source and the target domains is small , \ cT p u ' \ u2062 ' r u ' \ u2062 ' e u ' \ u2062 ' d can not reduce the mismatch between the feature spaces
	Cause: Recall that the \ cT p u ' \ u2062 ' r u ' \ u2062 ' e u ' \ u2062 ' d baseline can not find source domain words that do not appear in the target domain as distributional features for the words in the target domain test reviews
	Effect: when the overlap between the vocabularies used in the source and the target domains is small , \ cT p u ' \ u2062 ' r u ' \ u2062 ' e u ' \ u2062 ' d can not reduce the mismatch between the feature spaces

CASE: 54
Stag: 184 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The improvements of Proposed over the previously proposed Filter are statistically significant in all domains except the Emails domain -LRB- denoted by u ' \ u2020 ' in Table 2 according to the Binomial exact test at 95 u ' \ u2062 ' % confidence
	Cause: the Binomial exact test at 95 u ' \ u2062 ' % confidence
	Effect: The improvements of Proposed over the previously proposed Filter are statistically significant in all domains except the Emails domain -LRB- denoted by u ' \ u2020 ' in Table 2

CASE: 55
Stag: 187 188 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The baselines NA , \ cS u ' \ ud835 ' u ' \ udc29 ' u ' \ ud835 ' u ' \ udc2b ' u ' \ ud835 ' u ' \ udc1e ' u ' \ ud835 ' u ' \ udc1d ' , and \ cT u ' \ ud835 ' u ' \ udc29 ' u ' \ ud835 ' u ' \ udc2b ' u ' \ ud835 ' u ' \ udc1e ' u ' \ ud835 ' u ' \ udc1d ' are defined similarly as in Section 6.1 SST is the Sentiment Sensitive Thesaurus proposed by
	Cause: in Section 6.1 SST is the Sentiment Sensitive Thesaurus proposed
	Effect: The baselines NA , \ cS u ' \ ud835 ' u ' \ udc29 ' u ' \ ud835 ' u ' \ udc2b ' u ' \ ud835 ' u ' \ udc1e ' u ' \ ud835 ' u ' \ udc1d ' , and \ cT u ' \ ud835 ' u ' \ udc29 ' u ' \ ud835 ' u ' \ udc2b ' u ' \ ud835 ' u ' \ udc1e ' u ' \ ud835 ' u ' \ udc1d ' are defined similarly

CASE: 56
Stag: 193 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: All methods are evaluated under the same settings , including train/test split , feature spaces , pivots , and classification algorithms so that any differences in performance can be directly attributable to their domain adaptability
	Cause: All methods are evaluated under the same settings , including train/test split , feature spaces , pivots , and classification algorithms
	Effect: any differences in performance can be directly attributable to their domain adaptability

CASE: 57
Stag: 195 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: This upper baseline represents the classification accuracy we could hope to obtain if we were to have labeled data for the target domain
	Cause: we were to have labeled data for the target domain
	Effect: This upper baseline represents the classification accuracy we could hope to obtain

CASE: 58
Stag: 203 204 
	Pattern: 0 [[['enable', 'enables', 'enabled']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@', '&TODO@R@']]
	sentTXT: In contrast , our Proposed method predicts the distribution of a word in the target domain , given its distribution in the source domain , thereby explicitly translating the source domain reviews to the target This property enables us to apply the proposed distribution prediction method to tasks other than sentiment analysis such as POS tagging where we must identify distributional features for individual words
	Cause: In contrast , our Proposed method predicts the distribution of a word in the target domain , given its distribution in the source domain , thereby explicitly translating the source domain reviews to the target
	Effect: us to apply the proposed distribution prediction method to tasks other than sentiment analysis such as POS tagging where we must identify distributional features for individual words

CASE: 59
Stag: 208 209 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To evaluate the effect of the PLSR dimensions , we fixed k = 1000 and measured the cross-domain sentiment classification accuracy over a range of L values As shown in Figure 2 , accuracy remains stable across a wide range of PLSR dimensions
	Cause: shown in Figure 2 , accuracy remains stable across a wide range of PLSR dimensions
	Effect: To evaluate the effect of the PLSR dimensions , we fixed k = 1000 and measured the cross-domain sentiment classification accuracy over a range of L values

CASE: 60
Stag: 210 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because the time complexity of Algorithm 3.2 increases linearly with L , it is desirable that we select smaller L values in practice
	Cause: the time complexity of Algorithm 3.2 increases linearly with L
	Effect: it is desirable that we select smaller L values in practice

CASE: 61
Stag: 213 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because the dimensionality of the source and target domain feature spaces is equal to k , the complexity of the least square regression problem increases with k
	Cause: the dimensionality of the source and target domain feature spaces is equal to k
	Effect: the complexity of the least square regression problem increases with k

CASE: 62
Stag: 213 214 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Because the dimensionality of the source and target domain feature spaces is equal to k , the complexity of the least square regression problem increases with k Therefore , larger k values result in overfitting to the train data and classification accuracy is reduced on the target test data
	Cause: Because the dimensionality of the source and target domain feature spaces is equal to k , the complexity of the least square regression problem increases with k
	Effect: larger k values result in overfitting to the train data and classification accuracy is reduced on the target test data

CASE: 63
Stag: 214 215 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Therefore , larger k values result in overfitting to the train data and classification accuracy is reduced on the target test data As an example of the distribution prediction method , in Table 3 we show the top 3 similar distributional features u in the books -LRB- source -RRB- domain , predicted for the electronics -LRB- target -RRB- domain word w = u ' \ ud835 ' u ' \ udc59 ' u ' \ ud835 ' u ' \ udc56 ' u ' \ ud835 ' u ' \ udc54 ' u ' \ u210e ' u ' \ ud835 ' u ' \ udc61 ' u ' \ ud835 ' u ' \ udc64 ' u ' \ ud835 ' u ' \ udc52 ' u ' \ ud835 ' u ' \ udc56 ' u ' \ ud835 ' u ' \ udc54 ' u ' \ u210e ' u ' \ ud835 ' u ' \ udc61 ' , by different similarity measures
	Cause: an example of the distribution prediction method , in Table 3 we show the top 3 similar distributional features u in the books -LRB- source -RRB- domain , predicted for the electronics -LRB- target -RRB- domain word w = u ' \ ud835 ' u ' \ udc59 ' u ' \ ud835 ' u ' \ udc56 ' u ' \ ud835 ' u ' \ udc54 ' u ' \ u210e ' u ' \ ud835 ' u ' \ udc61 ' u ' \ ud835 ' u ' \ udc64 ' u ' \ ud835 ' u ' \ udc52 ' u ' \ ud835 ' u ' \ udc56 ' u ' \ ud835 ' u ' \ udc54 ' u ' \ u210e ' u ' \ ud835 ' u ' \ udc61 ' , by different similarity measures
	Effect: k values result in overfitting to the train data and classification accuracy is reduced on the target test data

CASE: 64
Stag: 221 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Interestingly , we see that by using the distributions predicted by the proposed method -LRB- i.e. , sim u ' \ u2062 ' -LRB- \ mat u ' \ u2062 ' M u ' \ u2062 ' u \ cS , w \ cT -RRB- -RRB- we overcome this problem and find relevant distributional features from the source domain
	Cause: using the distributions predicted by the proposed method -LRB- i.e. , sim u ' \ u2062 ' -LRB- \ mat u ' \ u2062 ' M u ' \ u2062 ' u \ cS , w \ cT -RRB- -RRB- we overcome this problem and find relevant distributional features from the source domain
	Effect: Interestingly , we see that

CASE: 65
Stag: 222 223 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Although for illustrative purposes we used the word lightweight , which occurs in both the source and the target domains , our proposed method does not require the source domain distribution w \ cS for a word w in a target domain document Therefore , it can find distributional features even for words occurring only in the target domain , thereby reducing the feature mismatch between the two domains
	Cause: Although for illustrative purposes we used the word lightweight , which occurs in both the source and the target domains , our proposed method does not require the source domain distribution w \ cS for a word w in a target domain document
	Effect: it can find distributional features even for words occurring only in the target domain , thereby reducing the feature mismatch between the two domains

