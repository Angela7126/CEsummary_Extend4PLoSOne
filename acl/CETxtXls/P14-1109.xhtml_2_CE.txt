************************************************************
P14-1109.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 4 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By performing probability integral transform , our approach moves beyond the standard count-based bag-of-words models in NLP , and improves previous work on text regression by incorporating the correlation among local features in the form of semiparametric Gaussian copula
	Cause: performing probability integral transform
	Effect: , our approach moves beyond the standard count-based bag-of-words models in NLP , and improves previous work on text regression by incorporating the correlation among local features in the form of semiparametric Gaussian copula

CASE: 1
Stag: 4 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: , our approach moves beyond the standard count-based bag-of-words models in NLP , and improves previous work on text regression by incorporating the correlation among local features in the form of semiparametric Gaussian copula
	Cause: incorporating the correlation among local features in the form of semiparametric Gaussian copula
	Effect: our approach moves beyond the standard count-based bag-of-words models in NLP , and improves previous work on text regression

CASE: 2
Stag: 13 14 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Given a piece of earnings call transcript , we investigate a semiparametric approach for automatic prediction of future financial risk 1 1 In this work , the risk is defined as the measured volatility of stock prices from the week following the earnings call teleconference See details in Section 5
	Cause: the measured volatility of stock prices from the week following the earnings call teleconference See details in Section 5
	Effect: a piece of earnings call transcript , we investigate a semiparametric approach for automatic prediction of future financial risk 1 1 In this work , the risk is defined

CASE: 3
Stag: 15 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To do this , we formulate the problem as a text regression task , and use a Gaussian copula with probability integral transform to model the uniform marginals and their dependencies
	Cause: a text regression task , and use a Gaussian copula with probability integral transform to model
	Effect: To do this , we formulate the problem

CASE: 4
Stag: 24 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By varying the number of dimensions of the covariates and the size of the training data , we show that the improvements over the baselines are robust across different parameter settings on three datasets
	Cause: varying the number of dimensions of the covariates and the size of the training data
	Effect: , we show that the improvements over the baselines are robust across different parameter settings on three datasets

CASE: 5
Stag: 35 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using the same dataset , Tsai and Wang -LSB- 41 -RSB- reformulate the regression problem as a text ranking problem
	Cause: Using the same dataset
	Effect: Tsai and Wang -LSB- 41 -RSB- reformulate the regression problem as a text ranking problem

CASE: 6
Stag: 38 39 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: -LSB- 45 -RSB- have proposed the use of frame-level semantic features to understand financial news , but they treat the stock movement prediction problem as a binary classification task Broadly speaking , our work is also aligned to recent studies that make use of social media data to predict the stock market -LSB- 3 , 47 -RSB-
	Cause: a binary classification task Broadly speaking , our work is also aligned to recent studies that make use of social media data to predict the stock market -LSB- 3 , 47
	Effect: financial news , but they treat the stock movement prediction problem

CASE: 7
Stag: 39 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Broadly speaking , our work is also aligned to recent studies that make use of social media data to predict the stock market -LSB- 3 , 47 -RSB-
	Cause: Broadly speaking
	Effect: our work is also aligned to recent studies that make use of social media data to predict the stock market -LSB- 3 , 47 -RSB-

CASE: 8
Stag: 44 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: For example , when bag-of-word-unigrams are present in the feature space , it is easier if one does not explicitly model the stochastic dependencies among the words , even though doing so might hurt the predictive power , while the variance from the correlations among the random variables is not explained
	Cause: For example , when bag-of-word-unigrams are present in the feature space , it is easier if one does not explicitly model the stochastic dependencies among the words , even though doing
	Effect: might hurt the predictive power , while the variance from the correlations among the random variables is not explained

CASE: 9
Stag: 44 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: For example , when bag-of-word-unigrams are present in the feature space , it is easier if one does not explicitly model the stochastic dependencies among the words , even though doing
	Cause: one does not explicitly model the stochastic dependencies among the words , even though doing
	Effect: For example , when bag-of-word-unigrams are present in the feature space , it is easier

CASE: 10
Stag: 47 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: On the other hand , once such assumptions are removed , another problem arises u ' \ u2014 ' they might be prone to errors , and suffer from the overfitting issue
	Cause: such assumptions are removed
	Effect: another problem arises u ' \ u2014 ' they might be prone to errors , and suffer from the overfitting issue

CASE: 11
Stag: 47 48 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: On the other hand , once such assumptions are removed , another problem arises u ' \ u2014 ' they might be prone to errors , and suffer from the overfitting issue Therefore , coping with the tradeoff between expressiveness and overfitting , seems to be rather important in statistical approaches that capture stochastic dependency
	Cause: On the other hand , once such assumptions are removed , another problem arises u ' \ u2014 ' they might be prone to errors , and suffer from the overfitting issue
	Effect: coping with the tradeoff between expressiveness and overfitting , seems to be rather important in statistical approaches that capture stochastic dependency

CASE: 12
Stag: 50 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: On one hand , copula models -LSB- 31 -RSB- seek to explicitly model the dependency of random variables by separating the marginals and their correlations
	Cause: separating the marginals and their correlations
	Effect: On one hand , copula models -LSB- 31 -RSB- seek to explicitly model the dependency of random variables

CASE: 13
Stag: 53 54 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: From an information-theoretic point of view -LSB- 38 -RSB- , various problems in text analytics can be formulated as estimating the probability mass/density functions of tokens in text In NLP , many of the probabilistic text models work in the discrete space -LSB- 9 , 2 -RSB- , but our model is different since the text features are sparse , we first perform kernel density estimates to smooth out the zeroing items , and then calculate the empirical cumulative distribution function -LRB- CDF -RRB- of the random variables
	Cause: estimating the probability mass/density functions of tokens in text In NLP , many of the probabilistic text models work in the discrete space -LSB- 9 , 2 -RSB- , but our model is different since the text features are sparse , we first perform kernel density estimates to smooth out the zeroing items , and then calculate the empirical cumulative distribution function -LRB- CDF -RRB- of the random variables
	Effect: From an information-theoretic point of view -LSB- 38 -RSB- , various problems in text analytics can be formulated

CASE: 14
Stag: 54 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: In NLP , many of the probabilistic text models work in the discrete space -LSB- 9 , 2 -RSB- , but our model is different since the text features are sparse , we first perform kernel density estimates to smooth out the zeroing items , and then calculate the empirical cumulative distribution function -LRB- CDF -RRB- of the random variables
	Cause: the text features are sparse
	Effect: we first perform kernel density estimates to smooth out the zeroing items , and then calculate the empirical cumulative distribution function -LRB- CDF -RRB- of the random variables

CASE: 15
Stag: 55 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By doing this , we are essentially performing probability integral transform u ' \ u2014 ' an important statistical technique that moves beyond the count-based bag-of-words feature space to marginal cumulative density functions space
	Cause: doing this
	Effect: , we are essentially performing probability integral transform u ' \ u2014 ' an important statistical technique that moves beyond the count-based bag-of-words feature space to marginal cumulative density functions space

CASE: 16
Stag: 56 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Last but not least , by using a parametric copula , in our case , the Gaussian copula , we reduce the computational cost from fully nonparametric methods , and explicitly model the correlations among the covariate and the dependent variable
	Cause: using a parametric copula
	Effect: , in our case , the Gaussian copula , we reduce the computational cost from fully nonparametric methods , and explicitly model the correlations among the covariate and the dependent

CASE: 17
Stag: 60 61 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the statistics literature , copula is widely known as a family of distribution function The idea behind copula theory is that the cumulative distribution function -LRB- CDF -RRB- of a random vector can be represented in the form of uniform marginal cumulative distribution functions , and a copula that connects these marginal CDFs , which describes the correlations among the input random variables
	Cause: a family of distribution function The idea behind copula theory is that the cumulative distribution function -LRB- CDF -RRB- of a random vector can be represented in the form of uniform marginal cumulative distribution functions , and a copula that connects these marginal CDFs , which describes the correlations among the input random
	Effect: In the statistics literature , copula is widely known

CASE: 18
Stag: 62 63 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However , in order to have a valid multivariate distribution function regardless of n - dimensional covariates , not every function can be used as a copula function The central idea behind copula , therefore , can be summarize by the Sklar u ' \ u2019 ' s theorem and the corollary
	Cause: a copula function The central idea behind copula , therefore , can be summarize by the Sklar u ' \ u2019 ' s theorem and the
	Effect: However , in order to have a valid multivariate distribution function regardless of n - dimensional covariates , not every function can be used

CASE: 19
Stag: 62 63 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: However , in order to have a valid multivariate distribution function regardless of n - dimensional covariates , not every function can be used as a copula function The central idea behind copula , therefore , can be summarize by the Sklar u ' \ u2019 ' s theorem and the corollary
	Cause: , in order to have a valid multivariate distribution function regardless of n - dimensional covariates , not every function can be used as a copula function The central idea behind copula
	Effect: can be summarize by the Sklar u ' \ u2019 ' s theorem and the corollary

CASE: 20
Stag: 66 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Then , if the marginal functions are continuous , there exists a unique copula C , such that
	Cause: the marginal functions are continuous
	Effect: there exists a unique copula C ,

CASE: 21
Stag: 67 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Furthermore , if the distributions are continuous , the multivariate dependency structure and the marginals might be separated , and the copula can be considered independent of the marginals -LSB- 21 , 32 -RSB-
	Cause: the distributions are continuous
	Effect: the multivariate dependency structure and the marginals might be separated , and

CASE: 22
Stag: 67 68 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Furthermore , if the distributions are continuous , the multivariate dependency structure and the marginals might be separated , and the copula can be considered independent of the marginals -LSB- 21 , 32 -RSB- Therefore , the copula does not have requirements on the marginal distributions , and any arbitrary marginals can be combined and their dependency structure can be modeled using the copula
	Cause: Furthermore , if the distributions are continuous , the multivariate dependency structure and the marginals might be separated , and the copula can be considered independent of the marginals -LSB- 21 , 32 -RSB-
	Effect: the copula does not have requirements on the marginal distributions , and any arbitrary marginals can be combined and their dependency structure can be modeled using the copula

CASE: 23
Stag: 74 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The problem is that text features are sparse , so we need to perform nonparametric kernel density estimation to smooth out the distribution of each variable
	Cause: The problem is that text features are sparse
	Effect: we need to perform nonparametric kernel density estimation to smooth out the distribution of each variable

CASE: 24
Stag: 77 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Here , K u ' \ u2062 ' -LRB- u ' \ u22c5 ' -RRB- is the kernel function , where in our case , we use the Box kernel 2 2 It is also known as the original Parzen windows -LSB- 33 -RSB-
	Cause: the original Parzen windows -LSB- 33 -RSB-
	Effect: Here , K u ' \ u2062 ' -LRB- u ' \ u22c5 ' -RRB- is the kernel function , where in our case , we use the Box kernel 2 2 It is also known

CASE: 25
Stag: 79 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Comparing to the Gaussian kernel and other kernels , the Box kernel is simple , and computationally inexpensive
	Cause: Comparing to the Gaussian kernel and other kernels
	Effect: the Box kernel is simple , and computationally inexpensive

CASE: 26
Stag: 80 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: The parameter h is the bandwidth for smoothing 3 3 In our implementation , we use the default h of the Box kernel in the ksdensity function in Matlab
	Cause: smoothing 3 3 In our implementation , we use the default h of the Box kernel in the ksdensity function in Matlab
	Effect: The parameter h is the bandwidth

CASE: 27
Stag: 83 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: where u ' \ ud835 ' u ' \ udc08 ' u ' \ u2062 ' -LCB- u ' \ u22c5 ' -RCB- is the indicator function , and u ' \ u039d ' indicates the current value that we are evaluating
	Cause: u ' \ ud835 ' u ' \ udc08 ' u ' \ u2062 ' -LCB- u ' \ u22c5 ' -RCB- is the indicator function , and u ' \ u039d '
	Effect: the current value that we are evaluating

CASE: 28
Stag: 84 85 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Note that the above step is also known as probability integral transform -LSB- 11 -RSB- , which allows us to convert any given continuous distribution to random variables having a uniform distribution This is of crucial importance to modeling text data instead of using the classic bag-of-words representation that uses raw counts , we are now working with uniform marginal CDFs , which helps coping with the overfitting issue due to noise and data sparsity
	Cause: probability integral transform -LSB- 11 -RSB- , which allows us to convert any given continuous distribution to random variables having a uniform distribution This is of crucial importance to modeling text data instead of using the classic bag-of-words representation that uses raw counts , we are now working with uniform marginal CDFs , which
	Effect: the above step is also known

CASE: 29
Stag: 85 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: This is of crucial importance to modeling text data instead of using the classic bag-of-words representation that uses raw counts , we are now working with uniform marginal CDFs , which helps coping with the overfitting issue due to noise and data sparsity
	Cause: noise and data sparsity
	Effect: This is of crucial importance to modeling text data instead of using the classic bag-of-words representation that uses raw counts , we are now working with uniform marginal CDFs , which helps coping with the overfitting issue

CASE: 30
Stag: 86 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Now that we have obtained the marginals , and then the joint distribution can be constructed by applying the copula function that models the stochastic dependencies among marginal CDFs
	Cause: applying the copula
	Effect: function that models the stochastic dependencies among marginal CDFs

CASE: 31
Stag: 96 97 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Christensen -LSB- 8 -RSB- shows that sorting and balanced binary trees can be used to calculate the correlation coefficients with complexity of O u ' \ u2062 ' -LRB- n u ' \ u2062 ' log u ' \ u2061 ' n Therefore , the computational complexity of MLE for the proposed model is O u ' \ u2062 ' -LRB- n u ' \ u2062 ' log u ' \ u2061 ' n -RRB-
	Cause: Christensen -LSB- 8 -RSB- shows that sorting and balanced binary trees can be used to calculate the correlation coefficients with complexity of O u ' \ u2062 ' -LRB- n u ' \ u2062 ' log u ' \ u2061 ' n
	Effect: the computational complexity of MLE for the proposed model is O u ' \ u2062 ' -LRB- n u ' \ u2062 ' log u ' \ u2061 ' n -RRB-

CASE: 32
Stag: 99 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: F x 1 -LRB- x 1 -RRB- , u ' \ u2026 ' , F x n -LRB- x n -RRB- -RRB- , one needs to solve the mean response u ' \ ud835 ' u ' \ udc04 ' ^ -LRB- F y -LRB- y
	Cause: F x 1 -LRB- x 1 -RRB- , u ' \ u2026 ' , F x n -LRB- x n -RRB- -RRB- , one needs to solve the mean response
	Effect: u ' \ ud835 ' u ' \ udc04 ' ^ -LRB- F y -LRB-

CASE: 33
Stag: 107 
	Pattern: 1 [['why'], ['that']]---- [[], ['&R', '&BE'], ['&C']]
	sentTXT: Again , the reason why we perform approximated inference is that exact inference in the high-dimensional Gaussian copula density is non-trivial , and might not have analytical solutions , but approximate inference using maximum density sampling from the Gaussian copula significantly relaxes the complexity of inference
	Cause: exact inference in the high-dimensional Gaussian copula density is non-trivial , and might not have analytical solutions , but approximate inference using maximum density sampling from the Gaussian copula significantly relaxes the complexity of inference
	Effect: we perform approximated inference

CASE: 34
Stag: 132 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using the stock prices , we can use the equations above to calculate the measured stock volatility after the earnings call , which is the standard measure of risks in finance , and the dependent variable y of our predictive task
	Cause: Using the stock prices
	Effect: we can use the equations above to calculate the measured stock volatility after the earnings call , which is the standard measure of risks in finance , and the dependent variable y of our predictive task

CASE: 35
Stag: 140 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We use the Statistical Toolbox u ' \ u2019 ' s linear regression implementation in Matlab , and LibSVM -LSB- 6 -RSB- for training and testing the SVM models
	Cause: training and testing the SVM models
	Effect: We use the Statistical Toolbox u ' \ u2019 ' s linear regression implementation in Matlab , and LibSVM -LSB- 6 -RSB-

CASE: 36
Stag: 142 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Note that since the kernel density estimation in the proposed copula model is nonparametric , and we only need to learn the u ' \ u03a3 ' in the Gaussian copula , there is no hyperparameters that need to be tuned
	Cause: the kernel density estimation in the proposed copula model is nonparametric
	Effect: and we only need to learn the u ' \ u03a3 ' in the Gaussian copula , there is no hyperparameters that need to be tuned

CASE: 37
Stag: 143 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Spearman u ' \ u2019 ' s correlation -LSB- 20 -RSB- and Kendall u ' \ u2019 ' s tau -LSB- 23 -RSB- have been widely used in many regression problems in NLP -LSB- 1 , 46 , 42 , 41 -RSB- , and here we use them to measure the quality of predicted values u ' \ ud835 ' u ' \ udc32 ' ^ by comparing to the vector of ground truth u ' \ ud835 ' u ' \ udc32 '
	Cause: comparing to the vector of ground truth u ' \ ud835 ' u ' \ udc32 '
	Effect: many regression problems in NLP -LSB- 1 , 46 , 42 , 41 -RSB- , and here we use them to measure the quality of predicted values u ' \ ud835 ' u ' \ udc32 ' ^

CASE: 38
Stag: 153 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Comparing to second-best approaches , all improvements obtained by the copula model are statistically significant
	Cause: Comparing to second-best approaches
	Effect: all improvements obtained by the copula model are statistically significant

CASE: 39
Stag: 157 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This is not surprising at all , because as max-margin models , soft-margin SVM only needs a handful of examples that come with nonvanishing coefficients -LRB- support vectors -RRB- to find a reasonable margin
	Cause: as max-margin models , soft-margin SVM only needs a handful of examples that come with nonvanishing coefficients -LRB- support vectors -RRB- to find a reasonable margin
	Effect: This is not surprising at all

CASE: 40
Stag: 162 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Finally , we investigate the robustness of the proposed semiparametric Gaussian copula regression model by varying the amount of features in the covariate space
	Cause: varying the amount of features in the covariate space
	Effect: Finally , we investigate the robustness of the proposed semiparametric Gaussian copula regression model

CASE: 41
Stag: 167 168 
	Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
	sentTXT: Both linear and non-linear SVM models do not have any advantages over the proposed approach On the post-2009 dataset that concerns economic growth and recovery , the boundaries among all methods are very clear
	Cause: economic growth and recovery , the boundaries among all methods
	Effect: linear and non-linear SVM models do not have any advantages over the proposed approach On the post-2009 dataset

CASE: 42
Stag: 182 183 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: What are the advantages of copula-based models , and what makes it perform so well One advantage we see from the copula model is that it does not require any assumptions on the marginal distributions
	Cause: What are the advantages of copula-based models , and what makes it perform
	Effect: well One advantage we see from the copula model is that it does not require any assumptions on the marginal

CASE: 43
Stag: 185 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This is rather restricted , because the possible shapes from a K - 1 simplex of Dirichlet is always limited in some sense
	Cause: the possible shapes from a K - 1 simplex of Dirichlet is always limited in some sense
	Effect: This is rather restricted

CASE: 44
Stag: 187 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This is extremely practical , because in many natural language processing tasks , we often have to deal with features that are extracted from many different domains and signals
	Cause: in many natural language processing tasks , we often have to deal with features that are extracted from many different domains and signals
	Effect: This is extremely practical

CASE: 45
Stag: 188 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By applying the Probability Integral Transform to raw features in the copula model , we essentially avoid comparing apples and oranges in the feature space , which is a common problem in bag-of-features models in NLP
	Cause: applying the Probability Integral Transform to raw features in the copula model
	Effect: , we essentially avoid comparing apples and oranges in the feature space , which is a common problem in bag-of-features models in NLP

CASE: 46
Stag: 191 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: In contrast , by considering the semiparametric case , we not only obtain some expressiveness from the nonparametric models , but also reduce the complexity of the task we are only interested in the finite-dimensional components u ' \ u03a3 ' in the Gaussian copula with O u ' \ u2062 ' -LRB- n u ' \ u2062 ' log u ' \ u2061 ' n -RRB- complexity , which is not as computationally difficult as the completely nonparametric cases
	Cause: considering the semiparametric case
	Effect: , we not only obtain some expressiveness from the nonparametric models , but also reduce the complexity of the task we are only interested in the finite-dimensional components u ' \ u03a3 ' in the Gaussian copula with O u ' \ u2062 ' -LRB- n u ' \ u2062 ' log u ' \ u2061 ' n -RRB- complexity , which is not as computationally difficult as the completely nonparametric cases

CASE: 47
Stag: 192 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Also , by modeling the marginals and their correlations seperately , our approach is cleaner , easy-to-understand , and allows us to have more flexibility to model the uncertainty of data
	Cause: modeling the marginals and their correlations seperately
	Effect: , our approach is cleaner , easy-to-understand , and allows us to have more flexibility to model the uncertainty of data

CASE: 48
Stag: 193 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Our pilot experiment also aligns with our hypothesis when not performing the kernel density estimation part for smoothing out the marginal distributions , the performances dropped significantly when sparser features are included
	Cause: smoothing out the marginal distributions
	Effect: Our pilot experiment also aligns with our hypothesis when not performing the kernel density estimation part

CASE: 49
Stag: 196 197 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: However , this might not be practical at all in image processing , the u ' \ u201c ' cloud u ' \ u201d ' pixel of a pixel showing the blue sky of a picture are more likelihood to co-occur in the same picture ; in natural language processing , the word u ' \ u201c ' mythical u ' \ u201d ' is more likely to co-occur with the word u ' \ u201c ' unicorn u ' \ u201d ' , rather than the word u ' \ u201c ' popcorn u ' \ u201d ' Therefore , by modeling the correlations among marginal CDFs , the copula model has gained the insights on the dependency structures of the random variables , and thus , the performance of the regression task is boosted
	Cause: However , this might not be practical at all in image processing , the u ' \ u201c ' cloud u ' \ u201d ' pixel of a pixel showing the blue sky of a picture are more likelihood to co-occur in the same picture ; in natural language processing , the word u ' \ u201c ' mythical u ' \ u201d ' is more likely to co-occur with the word u ' \ u201c ' unicorn u ' \ u201d ' , rather than the word u ' \ u201c ' popcorn u ' \ u201d '
	Effect: by modeling the correlations among marginal CDFs , the copula model has gained the insights on the dependency structures of the random variables , and thus , the performance of the regression task is boosted

CASE: 50
Stag: 207 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Focusing on the three financial crisis related datasets , the proposed model significantly outperform the standard linear regression method in statistics and strong discriminative support vector regression baselines
	Cause: Focusing on the three financial crisis related datasets
	Effect: the proposed model significantly outperform the standard linear regression method in statistics and strong discriminative support vector regression baselines

CASE: 51
Stag: 208 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By varying the size of the training data and the dimensionality of the covariates , we have demonstrated that our proposed model is relatively robust across different parameter settings
	Cause: varying the size of the training data and the dimensionality of the covariates
	Effect: , we have demonstrated that our proposed model is relatively robust across different parameter settings

