************************************************************
P14-1008.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees []
	Cause: [(0, 17), (0, 20)]
	Effect: [(0, 0), (0, 15)]

CASE: 1
Stag: 4 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because, answers returned by a query depend on the specific database, but implication is independent of any databases
	Cause: [(0, 1), (0, 11)]
	Effect: [(0, 13), (0, 19)]

CASE: 2
Stag: 5 6 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: For example, answers to the question u'\u201c' What books are read by students u'\u201d' , should always be a subset of answers to u'\u201c' What books are ever read by anyone u'\u201d' , no matter how we store the data of students and how many records of books are there in our database Thus, our first step is to fix a notation which abstracts the calculation process of DCS trees, so as to clarify its meaning without the aid of any existing database
	Cause: [(0, 0), (0, 69)]
	Effect: [(1, 1), (1, 31)]

CASE: 3
Stag: 11 12 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Moreover, to compensate the lack of background knowledge in practical inference, we combine our framework with the idea of tree transformation [] , to propose a way of generating knowledge in logical representation from entailment rules [] , which are by now typically considered as syntactic rewriting rules We test our system on FraCaS [] and PASCAL RTE datasets []
	Cause: [(0, 49), (1, 12)]
	Effect: [(0, 2), (0, 47)]

CASE: 4
Stag: 18 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The DCS tree in Figure 1 is interpreted as a command for querying these tables, obtaining u'\u201c' reading u'\u201d' entries whose u'\u201c' SUBJ u'\u201d' field is student and whose u'\u201c' OBJ u'\u201d' field is book
	Cause: [(0, 9), (0, 53)]
	Effect: [(0, 0), (0, 7)]

CASE: 5
Stag: 18 19 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: The DCS tree in Figure 1 is interpreted as a command for querying these tables, obtaining u'\u201c' reading u'\u201d' entries whose u'\u201c' SUBJ u'\u201d' field is student and whose u'\u201c' OBJ u'\u201d' field is book The result is a set { John reads Ulysses , u'\u2026' } , which is called a denotation
	Cause: [(0, 0), (0, 59)]
	Effect: [(1, 3), (1, 21)]

CASE: 6
Stag: 21 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Figure 2 shows an example with a quantifier u'\u201c' every u'\u201d' , which is marked as u'\u201c' u'\u2282' u'\u201d' on the edge ( u'\ud835' u'\udc25' u'\ud835' u'\udc28' u'\ud835' u'\udc2f' u'\ud835' u'\udc1e' ) u'\u2062' OBJ-ARG u'\u2062' ( u'\ud835' u'\udc1d' u'\ud835' u'\udc28' u'\ud835' u'\udc20' ) and interpreted as a division operator q u'\u2282' u'\ud835' u'\ude7e' u'\ud835' u'\ude71' u'\ud835' u'\ude79' (§ 2.2
	Cause: [(0, 0), (0, 133)]
	Effect: [(0, 134), (0, 169)]

CASE: 7
Stag: 21 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Figure 2 shows an example with a quantifier u'\u201c' every u'\u201d' , which is marked as u'\u201c' u'\u2282' u'\u201d' on the edge ( u'\ud835' u'\udc25' u'\ud835' u'\udc28' u'\ud835' u'\udc2f' u'\ud835' u'\udc1e' ) u'\u2062' OBJ-ARG u'\u2062' ( u'\ud835' u'\udc1d' u'\ud835' u'\udc28' u'\ud835' u'\udc20' ) and interpreted as a division operator q u'\u2282' u'\ud835' u'\ude7e' u'\ud835' u'\ude71' u'\ud835' u'\ude79' (§ 2.2
	Cause: [(0, 24), (0, 133)]
	Effect: [(0, 1), (0, 22)]

CASE: 8
Stag: 24 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This is not trivial, however, because DCS works under the assumption that databases are explicitly available
	Cause: [(0, 8), (0, 17)]
	Effect: [(0, 0), (0, 5)]

CASE: 9
Stag: 25 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Obviously this is unrealistic for logical inference on unrestricted texts, because we cannot prepare a database for everything in the world
	Cause: [(0, 12), (0, 22)]
	Effect: [(0, 0), (0, 9)]

CASE: 10
Stag: 27 28 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Our solution is to redefine DCS trees without the aid of any databases, by considering each node of a DCS tree as a content word in a sentence (but may no longer be a table in a specific database), while each edge represents semantic relations between two words The labels on both ends of an edge, such as SUBJ (subject) and OBJ (object), are considered as semantic roles of the corresponding words 1 1 The semantic role ARG is specifically defined for denoting nominal predicate
	Cause: [(0, 23), (1, 41)]
	Effect: [(0, 0), (0, 21)]

CASE: 11
Stag: 28 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: The labels on both ends of an edge, such as SUBJ (subject) and OBJ (object), are considered as semantic roles of the corresponding words 1 1 The semantic role ARG is specifically defined for denoting nominal predicate
	Cause: [(0, 40), (0, 42)]
	Effect: [(0, 0), (0, 38)]

CASE: 12
Stag: 29 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: To formulate the database querying process defined by a DCS tree, we provide formal semantics to DCS trees by employing relational algebra [] for representing the query
	Cause: [(0, 26), (0, 28)]
	Effect: [(0, 0), (0, 24)]

CASE: 13
Stag: 29 30 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To formulate the database querying process defined by a DCS tree, we provide formal semantics to DCS trees by employing relational algebra [] for representing the query As described below, we represent meanings of sentences with abstract denotations , and logical relations among sentences are computed as relations among their abstract denotations
	Cause: [(1, 1), (1, 17)]
	Effect: [(0, 0), (0, 28)]

CASE: 14
Stag: 36 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: 3 3 Using division operator, subsumption can be represented by non-emptiness, since for sets A , B of the same dimension, q u'\u2282' u'\u2062' ( A , B ) u'\u2260' u'\u2205' u'\u21d4' A u'\u2282' B
	Cause: [(0, 14), (0, 61)]
	Effect: [(0, 5), (0, 11)]

CASE: 15
Stag: 38 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Abstract denotations and statements are convenient for representing semantics of various types of expressions and linguistic knowledge
	Cause: [(0, 7), (0, 16)]
	Effect: [(0, 0), (0, 5)]

CASE: 16
Stag: 41 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on abstract denotations, we briefly describe our process to apply DCS to textual inference
	Cause: [(0, 2), (0, 3)]
	Effect: [(0, 5), (0, 15)]

CASE: 17
Stag: 49 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: A DCS tree u'\ud835' u'\udcaf' = ( u'\ud835' u'\udca9' , u'\u2130' ) is defined as a rooted tree, where each node u'\u03a3' u'\u2208' u'\ud835' u'\udca9' is labeled with a content word w u'\u2062' ( u'\u03a3' ) and each edge ( u'\u03a3' , u'\u03a3' u'\u2032' ) u'\u2208' u'\u2130' u'\u2282' u'\ud835' u'\udca9' × u'\ud835' u'\udca9' is labeled with a pair of semantic roles ( r , r u'\u2032' ) 7 7 The definition differs slightly from the original , mainly for the sake of simplicity and clarity
	Cause: [(0, 35), (0, 168)]
	Effect: [(0, 0), (0, 33)]

CASE: 18
Stag: 61 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: If ( u'\u03a3' , u'\u03a4' i ) is assigned by a quantification marker u'\u201c' u'\u2282' u'\u201d' 8 8 Multiple quantifiers can be processed similarly then the abstract denotation is 9 9 The result of [[ u'\ud835' u'\udcaf' ]] depends on the order of the children u'\u03a4' 1 , u'\u2026' , u'\u03a4' n
	Cause: [(0, 1), (0, 43)]
	Effect: [(0, 45), (0, 93)]

CASE: 19
Stag: 63 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where u'\ud835' u'\udcaf' u'\u2032' is the same tree as u'\ud835' u'\udcaf' except that the edge ( u'\u03a3' , u'\u03a4' i ) is removed
	Cause: [(0, 21), (0, 49)]
	Effect: [(0, 2), (0, 19)]

CASE: 20
Stag: 68 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since meanings of sentences are represented by statements on abstract denotations, logical inference among sentences is reduced to deriving new relations among abstract denotations
	Cause: [(0, 1), (0, 10)]
	Effect: [(0, 12), (0, 24)]

CASE: 21
Stag: 69 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: This is done by applying axioms to known statements, and approximately 30 axioms are implemented (Table 3
	Cause: [(0, 4), (0, 8)]
	Effect: [(0, 9), (0, 18)]

CASE: 22
Stag: 75 76 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We built an inference engine to perform logical inference on abstract denotations as above In this logical system, we treat abstract denotations as terms and statements as atomic sentences , which are far more easier to handle than first order predicate logic (FOL) formulas
	Cause: [(0, 13), (1, 31)]
	Effect: [(0, 0), (0, 11)]

CASE: 23
Stag: 76 77 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In this logical system, we treat abstract denotations as terms and statements as atomic sentences , which are far more easier to handle than first order predicate logic (FOL) formulas Furthermore, all implemented axioms are horn clauses, hence we can employ forward-chaining, which is very efficient
	Cause: [(0, 10), (1, 14)]
	Effect: [(0, 0), (0, 8)]

CASE: 24
Stag: 77 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Furthermore, all implemented axioms are horn clauses, hence we can employ forward-chaining, which is very efficient
	Cause: [(0, 0), (0, 7)]
	Effect: [(0, 10), (0, 18)]

CASE: 25
Stag: 80 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using disjointness we implemented two types of negations i) atomic negation, for each content word w we allow negation w ¯ of that word, characterized by the property w u'\u2225' w ¯ ; and (ii) root negation, for a DCS tree u'\ud835' u'\udcaf' and its denotation [[ u'\ud835' u'\udcaf' ]] , the negation of u'\ud835' u'\udcaf' is represented by u'\ud835' u'\udcaf' u'\u2225' u'\ud835' u'\udcaf' , meaning that u'\ud835' u'\udcaf' = u'\u2205' in its effect
	Cause: [(0, 0), (0, 102)]
	Effect: [(0, 103), (0, 118)]

CASE: 26
Stag: 84 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Selection operators are implemented as markers assigned to abstract denotations, with specially designed axioms
	Cause: [(0, 5), (0, 13)]
	Effect: [(0, 0), (0, 3)]

CASE: 27
Stag: 88 89 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use Stanford CoreNLP to resolve coreferences [] , whereas coreference is implemented as a special type of selection If a node u'\u03a3' in a DCS tree u'\ud835' u'\udcaf' belongs to a mention cluster m , we take the abstract denotation [[ u'\ud835' u'\udcaf' u'\u03a3' ]] and make a selection s m u'\u2062' ([[ u'\ud835' u'\udcaf' u'\u03a3' ]]) , which is regarded as the abstract denotation of that mention
	Cause: [(0, 15), (1, 94)]
	Effect: [(0, 0), (0, 13)]

CASE: 28
Stag: 89 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If a node u'\u03a3' in a DCS tree u'\ud835' u'\udcaf' belongs to a mention cluster m , we take the abstract denotation [[ u'\ud835' u'\udcaf' u'\u03a3' ]] and make a selection s m u'\u2062' ([[ u'\ud835' u'\udcaf' u'\u03a3' ]]) , which is regarded as the abstract denotation of that mention
	Cause: [(0, 1), (0, 27)]
	Effect: [(0, 29), (0, 95)]

CASE: 29
Stag: 96 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: However, this method does not work for real-world datasets such as PASCAL RTE [] , because of the knowledge bottleneck it is often the case that the lack of sufficient linguistic knowledge causes failure of inference, thus the system outputs u'\u201c' no entailment u'\u201d' for almost all pairs []
	Cause: [(0, 0), (0, 37)]
	Effect: [(0, 40), (0, 60)]

CASE: 30
Stag: 96 
	Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
	sentTXT: However, this method does not work for real-world datasets such as PASCAL RTE [] , because of the knowledge bottleneck it is often the case that the lack of sufficient linguistic knowledge causes failure of inference, thus the system outputs u'\u201c' no entailment u'\u201d' for almost all pairs []
	Cause: [(0, 0), (0, 15)]
	Effect: [(0, 22), (0, 37)]

CASE: 31
Stag: 97 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: The transparent syntax-to-semantics interface of DCS enables us to back off to NLP techniques during inference for catching up the lack of knowledge
	Cause: [(0, 17), (0, 22)]
	Effect: [(0, 0), (0, 15)]

CASE: 32
Stag: 105 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: On-the-fly knowledge is generated by aligning paths in DCS trees
	Cause: [(0, 5), (0, 9)]
	Effect: [(0, 0), (0, 3)]

CASE: 33
Stag: 106 107 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: A path is considered as joining two germs in a DCS tree, where a germ is defined as a specific semantic role of a node For example, Figure 5 shows DCS trees of the following sentences (a simplified pair from RTE2-dev
	Cause: [(0, 5), (1, 17)]
	Effect: [(0, 0), (0, 3)]

CASE: 34
Stag: 113 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Two paths are aligned if the joined germs are aligned, and we impose constraints on aligned germs to inhibit meaningless alignments, as described below
	Cause: [(0, 5), (0, 22)]
	Effect: [(0, 0), (0, 3)]

CASE: 35
Stag: 116 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The abstract denotation of a germ is defined in a top-down manner for the root node u'\u03a1' of a DCS tree u'\ud835' u'\udcaf' , we define its denotation [[ u'\u03a1' ]] u'\ud835' u'\udcaf' as the denotation of the entire tree [[ u'\ud835' u'\udcaf' ]] ; for a non-root node u'\u03a4' and its parent node u'\u03a3' , let the edge ( u'\u03a3' , u'\u03a4' ) be labeled by semantic roles ( r , r u'\u2032' ) , then define
	Cause: [(0, 60), (0, 132)]
	Effect: [(0, 0), (0, 58)]

CASE: 36
Stag: 117 118 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Now for a germ r u'\u2062' ( u'\u03a3' ) , the denotation is defined as the projection of the denotation of node u'\u03a3' onto the specific semantic role r [[ r u'\u2062' ( u'\u03a3' ) ]] u'\ud835' u'\udcaf' = u'\u03a0' r u'\u2062' ( [[ u'\u03a3' ]] u'\ud835' u'\udcaf' )
	Cause: [(0, 23), (1, 58)]
	Effect: [(0, 0), (0, 21)]

CASE: 37
Stag: 120 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Similarly, denotation of germ u'\ud835' u'\ude7e' u'\ud835' u'\ude71' u'\ud835' u'\ude79' u'\u2062' ( u'\ud835' u'\udc1b' u'\ud835' u'\udc25' u'\ud835' u'\udc1a' u'\ud835' u'\udc26' u'\ud835' u'\udc1e' ) in T of Figure 5 indicates the object of u'\u201c' blame u'\u201d' as in the sentence u'\u201c' Tropical storm Debby is blamed for death u'\u201d' , which is a tropical storm , is Debby , etc
	Cause: [(0, 17), (0, 96)]
	Effect: [(0, 98), (0, 143)]

CASE: 38
Stag: 121 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values [] of that variable
	Cause: [(0, 2), (0, 7)]
	Effect: [(0, 9), (0, 40)]

CASE: 39
Stag: 122 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: The logical clue to align germs is if there exists an abstract denotation, other than W , that is a superset of both abstract denotations of two germs, then the two germs can be aligned
	Cause: [(0, 8), (0, 12)]
	Effect: [(0, 14), (0, 35)]

CASE: 40
Stag: 129 130 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Accepted aligned paths are converted into statements, which are used as new knowledge The conversion is done by first performing a DCS tree transformation according to the aligned paths, and then declare a subsumption relation between the denotations of aligned germs
	Cause: [(0, 12), (1, 27)]
	Effect: [(0, 0), (0, 10)]

CASE: 41
Stag: 130 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: The conversion is done by first performing a DCS tree transformation according to the aligned paths, and then declare a subsumption relation between the denotations of aligned germs
	Cause: [(0, 13), (0, 15)]
	Effect: [(0, 17), (0, 28)]

CASE: 42
Stag: 134 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved in Figure 6 , though the tree transformation can be seen as generated from the entailment rule u'\u201c' X is blamed for death u'\u2192' X causes loss of life u'\u201d' , the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby
	Cause: [(0, 3), (0, 13)]
	Effect: [(0, 15), (0, 54)]

CASE: 43
Stag: 134 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved in Figure 6 , though the tree transformation can be seen as generated from the entailment rule u'\u201c' X is blamed for death u'\u2192' X causes loss of life u'\u201d' , the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby
	Cause: [(0, 16), (0, 35)]
	Effect: [(0, 0), (0, 14)]

CASE: 44
Stag: 134 135 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved in Figure 6 , though the tree transformation can be seen as generated from the entailment rule u'\u201c' X is blamed for death u'\u2192' X causes loss of life u'\u201d' , the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby Hence, the process can also be used to generate knowledge from context sensitive rules [] , which are known to have higher quality []
	Cause: [(0, 0), (0, 87)]
	Effect: [(1, 2), (1, 26)]

CASE: 45
Stag: 144 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: For example, named entities are singletons, so we add axioms such as u'\u2200' x ; ( x u'\u2282' u'\ud835' u'\udc13' u'\ud835' u'\udc28' u'\ud835' u'\udc26' x u'\u2260' u'\u2205' ) u'\u2192' u'\ud835' u'\udc13' u'\ud835' u'\udc28' u'\ud835' u'\udc26' u'\u2282' x
	Cause: [(0, 0), (0, 6)]
	Effect: [(0, 9), (0, 110)]

CASE: 46
Stag: 146 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For example, the similarity score of the path alignment u'\u201c' OBJ ( blame ) IOBJ - ARG ( death ) u'\u2248' SUBJ ( cause ) OBJ - ARG ( loss ) MOD - ARG ( life ) u'\u201d' is calculated as the cosine similarity of vectors blame + death and cause + loss + life
	Cause: [(0, 54), (0, 66)]
	Effect: [(0, 1), (0, 52)]

CASE: 47
Stag: 149 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The threshold for accepted path alignments is set to 0.4 , based on pre-experiments on RTE development sets
	Cause: [(0, 13), (0, 17)]
	Effect: [(0, 0), (0, 9)]

CASE: 48
Stag: 153 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Most of the problems do not require lexical knowledge, so we use our primary textual inference system without on-the-fly knowledge nor WordNet, to test the performance of the DCS framework as formal semantics
	Cause: [(0, 0), (0, 8)]
	Effect: [(0, 11), (0, 34)]

CASE: 49
Stag: 154 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: To obtain the three-valued output (i.e., yes , no , and unknown ), we output u'\u201c' yes u'\u201d' if H is proven, or try to prove the negation of H if H is not proven
	Cause: [(0, 30), (0, 46)]
	Effect: [(0, 0), (0, 28)]

CASE: 50
Stag: 154 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: To obtain the three-valued output (i.e., yes , no , and unknown ), we output u'\u201c' yes u'\u201d' if H is proven, or try to prove the negation of H if H is not proven
	Cause: [(0, 13), (0, 16)]
	Effect: [(0, 0), (0, 11)]

CASE: 51
Stag: 155 156 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To negate H , we use the root negation as described in § 2.5 If the negation of H is proven, we output u'\u201c' no u'\u201d' , otherwise we output u'\u201c' unknown u'\u201d'
	Cause: [(0, 10), (1, 14)]
	Effect: [(0, 0), (0, 8)]

CASE: 52
Stag: 156 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the negation of H is proven, we output u'\u201c' no u'\u201d' , otherwise we output u'\u201c' unknown u'\u201d'
	Cause: [(0, 1), (0, 6)]
	Effect: [(0, 8), (0, 33)]

CASE: 53
Stag: 158 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences
	Cause: [(0, 1), (0, 7)]
	Effect: [(0, 9), (0, 37)]

CASE: 54
Stag: 160 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Compared to and , our system does not need a pre-trained alignment model, and it improves by making multi-sentence inferences
	Cause: [(0, 18), (0, 20)]
	Effect: [(0, 9), (0, 16)]

CASE: 55
Stag: 164 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: On PASCAL RTE datasets, strict logical inference is known to have very low recall [] , so on-the-fly knowledge is crucial in this setting
	Cause: [(0, 0), (0, 16)]
	Effect: [(0, 19), (0, 25)]

CASE: 56
Stag: 167 168 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: When only primary knowledge is used in inference (the first row), recalls are actually very low; After we activate the on-the-fly knowledge, recalls jump to over 50%, with a moderate fall of precision As a result, accuracies significantly increase
	Cause: [(0, 0), (0, 39)]
	Effect: [(1, 4), (1, 6)]

CASE: 57
Stag: 176 177 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Stern11 [] and Stern12 [] extend this framework to utilize entailment rules as tree transformations These are more tailored systems using machine learning with many handcrafted features
	Cause: [(0, 15), (1, 10)]
	Effect: [(0, 0), (0, 13)]

CASE: 58
Stag: 179 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Summing up test data from RTE2 to RTE5, Figure 7 shows the proportion of all proven pairs and their precision
	Cause: [(0, 0), (0, 7)]
	Effect: [(0, 9), (0, 20)]

CASE: 59
Stag: 191 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Finally, to see if we u'\u201c' get lucky u'\u201d' on RTE5 data in the choice of word vectors and thresholds, we change the thresholds from 0.1 to 0.7 and draw the precision-recall curve, using two types of word vectors, Mikolov13 and Turian10
	Cause: [(0, 5), (0, 17)]
	Effect: [(0, 30), (0, 53)]

CASE: 60
Stag: 191 192 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Finally, to see if we u'\u201c' get lucky u'\u201d' on RTE5 data in the choice of word vectors and thresholds, we change the thresholds from 0.1 to 0.7 and draw the precision-recall curve, using two types of word vectors, Mikolov13 and Turian10 As shown in Figure 8 , though the precision drops for Turian10 , both curves show the pattern that our system keeps gaining recall while maintaining precision to a certain level
	Cause: [(1, 1), (1, 30)]
	Effect: [(0, 6), (0, 53)]

