************************************************************
P14-1079.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 3 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Our algorithmic framework is based on the assumption that the rank of item-by-feature and item-by-label joint matrix is low
	Cause: the assumption that the rank of item-by-feature and item-by-label joint matrix is low
	Effect: Our algorithmic framework

CASE: 1
Stag: 8 9 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Traditional supervised methods -LSB- 28 , 1 -RSB- on small hand-labeled corpora , such as MUC 1 1 http://www.itl.nist.gov/iaui/894.02/related projects/muc / and ACE 2 2 http://www.itl.nist.gov/iad/mig/tests/ace/ , can achieve high precision and recall However , as producing hand-labeled corpora is laborius and expensive , the supervised approach can not satisfy the increasing demand of building large-scale knowledge repositories with the explosion of Web texts
	Cause: producing hand-labeled corpora is laborius and expensive , the supervised approach can not satisfy the increasing demand of building large-scale knowledge repositories with the explosion of Web texts
	Effect: methods -LSB- 28 , 1 -RSB- on small hand-labeled corpora , such as MUC 1 1 http://www.itl.nist.gov/iaui/894.02/related projects/muc / and ACE 2 2 http://www.itl.nist.gov/iad/mig/tests/ace/ , can achieve high precision and recall However

CASE: 2
Stag: 11 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The intuition of the paradigm is that one can take advantage of several knowledge bases , such as WordNet 3 3 http://wordnet.princeton.edu , Freebase 4 4 http://www.freebase.com and YAGO 5 5 http://www.mpi-inf.mpg.de/yago-naga/yago , to automatically label free texts , like Wikipedia 6 6 http://www.wikipedia.org and New York Times corpora 7 7 http://catalog.ldc.upenn.edu/LDC2008T19 , based on some heuristic alignment assumptions
	Cause: some heuristic alignment assumptions
	Effect: The intuition of the paradigm is that one can take advantage of several knowledge bases , such as WordNet 3 3 http://wordnet.princeton.edu , Freebase 4 4 http://www.freebase.com and YAGO 5 5 http://www.mpi-inf.mpg.de/yago-naga/yago , to automatically label free texts , like Wikipedia 6 6 http://www.wikipedia.org and New York Times corpora 7 7 http://catalog.ldc.upenn.edu/LDC2008T19

CASE: 3
Stag: 12 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: An example accounting for the basic but practical assumption is illustrated in Figure 1 , in which we know that the two entities -LRB- Barack Obama , U.S are not only involved in the relation instances 8 8 According to convention , we regard a structured triple r u ' \ u2062 ' -LRB- e i , e j -RRB- as a relation instance which is composed of a pair of entities e i , e j and a relation name r with respect to them coming from knowledge bases -LRB- President-of -LRB- Barack Obama , U.S. -RRB- and Born-in -LRB- Barack Obama , U.S. -RRB- -RRB- , but also co-occur in several relation mentions 9 9 The sentences that contain the given entity pair are called relation mentions appearing in free texts -LRB- Barack Obama is the 44th and current President of the U.S and Barack Obama was born in Honolulu , Hawaii , U.S etc
	Cause: a relation instance which is composed of a pair of entities e i , e j and a relation name r with respect to them coming from knowledge bases -LRB- President-of -LRB- Barack Obama , U.S. -RRB- and Born-in -LRB- Barack Obama , U.S. -RRB- -RRB- , but also co-occur in several relation mentions 9 9 The sentences that contain the given entity pair are called relation mentions appearing in free texts -LRB- Barack Obama is the 44th and current President of the U.S and Barack Obama was born in Honolulu , Hawaii ,
	Effect: An example accounting for the basic but practical assumption is illustrated in Figure 1 , in which we know that the two entities -LRB- Barack Obama , U.S are not only involved in the relation instances 8 8 According to convention , we regard a structured triple r u ' \ u2062 ' -LRB- e i , e j -RRB-

CASE: 4
Stag: 12 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: An example accounting for the basic but practical assumption is illustrated in Figure 1 , in which we know that the two entities -LRB- Barack Obama , U.S are not only involved in the relation instances 8 8 According to convention , we regard a structured triple r u ' \ u2062 ' -LRB- e i , e j -RRB-
	Cause: convention
	Effect: we regard a structured triple r u ' \ u2062 ' -LRB- e i , e j -RRB-

CASE: 5
Stag: 21 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: For example , the second relation mention in Figure 1 does not explicitly describe any relation instance , so features extracted from this sentence can be noisy
	Cause: For example , the second relation mention in Figure 1 does not explicitly describe any relation instance
	Effect: features extracted from this sentence can be noisy

CASE: 6
Stag: 24 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Similar to noisy features , the generated labels can be incomplete
	Cause: Similar to noisy features
	Effect: the generated labels can be incomplete

CASE: 7
Stag: 26 27 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: However , the incomplete knowledge base does not contain the corresponding relation instance -LRB- Senate-of -LRB- Barack Obama , U.S. -RRB- Therefore , the distant supervision paradigm may generate incomplete labeling corpora
	Cause: However , the incomplete knowledge base does not contain the corresponding relation instance -LRB- Senate-of -LRB- Barack Obama , U.S. -RRB-
	Effect: the distant supervision paradigm may generate incomplete labeling corpora

CASE: 8
Stag: 30 31 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: To the best of our knowledge , we are the first to apply this technique on relation extraction with distant supervision More specifically , as shown in Figure 2 , we model the task with a sparse matrix whose rows present items -LRB- entity pairs -RRB- and columns contain noisy textual features and incomplete relation labels
	Cause: shown in Figure 2 , we model the task with a sparse matrix whose rows present items -LRB- entity pairs -RRB- and columns contain noisy textual features and incomplete relation labels
	Effect: the best of our knowledge , we are the first to apply this technique on relation extraction with distant supervision More specifically

CASE: 9
Stag: 32 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In such a way , relation classification is transformed into a problem of completing the unknown labels for testing items in the sparse matrix that concatenates training and testing textual features with training labels , based on the assumption that the item-by-feature and item-by-label joint matrix is of low rank
	Cause: the assumption that the item-by-feature and item-by-label joint matrix is of low rank
	Effect: In such a way , relation classification is transformed into a problem of completing the unknown labels for testing items in the sparse matrix that concatenates training and testing textual features with training labels

CASE: 10
Stag: 42 43 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: -LSB- 23 -RSB- used WordNet as the knowledge base to discover more hpyernym/hyponym relations between entities from news articles However , either bioinformatic database or WordNet is maintained by a few experts , thus hardly kept up-to-date
	Cause: the knowledge base to discover more hpyernym/hyponym relations between entities from news articles However , either bioinformatic database or WordNet is maintained by a few experts , thus hardly kept up-to-date
	Effect: 23 -RSB- used WordNet

CASE: 11
Stag: 43 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: However , either bioinformatic database or WordNet is maintained by a few experts , thus hardly kept up-to-date
	Cause: However , either bioinformatic database or WordNet is maintained by a few experts
	Effect: hardly kept up-to-date

CASE: 12
Stag: 43 44 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However , either bioinformatic database or WordNet is maintained by a few experts , thus hardly kept up-to-date As we are stepping into the big data era , the explosion of unstructured Web texts simulates us to build more powerful models that can automatically extract relation instances from large-scale online natural language corpora without hand-labeled annotation
	Cause: we are stepping into the big data era , the explosion of unstructured Web texts simulates us to build more powerful models that can automatically extract relation instances from large-scale online natural language corpora without hand-labeled annotation
	Effect: However , either bioinformatic database or WordNet is maintained by a few experts , thus hardly kept up-to-date

CASE: 13
Stag: 47 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: The basic alignment assumption of this work is that if a pair of entities participate in a relation , all sentences that mention these entities are labeled by that relation name
	Cause: a pair of entities participate in a relation
	Effect: all sentences that mention these entities are labeled by that relation name

CASE: 14
Stag: 57 58 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Our work is more relevant to Riedel et al u ' \ u2019 ' s -LSB- 21 -RSB- which considered the task as a matrix factorization problem Their approach is composed of several models , such as PCA -LSB- 7 -RSB- and collaborative filtering -LSB- 15 -RSB-
	Cause: a matrix factorization problem Their approach is composed of several models ,
	Effect: Our work is more relevant to Riedel et al u ' \ u2019 ' s -LSB- 21 -RSB- which considered the task

CASE: 15
Stag: 63 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Our models for relation extraction are based on the theoretic framework proposed by Goldberg et al
	Cause: the theoretic framework proposed by Goldberg et al
	Effect: Our models for relation extraction

CASE: 16
Stag: 65 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The new framework for classification enhances the robustness to data noise by penalizing different cost functions for features and labels
	Cause: penalizing different cost functions for features and labels
	Effect: The new framework for classification enhances the robustness to data noise

CASE: 17
Stag: 66 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Suppose that we have built a training corpus for relation classification with n items -LRB- entity pairs -RRB- , d - dimensional textual features , and t labels -LRB- relations -RRB- , based on the basic alignment assumption proposed by Mintz et al
	Cause: the basic alignment assumption proposed by Mintz et al
	Effect: Suppose that we have built a training corpus for relation classification with n items -LRB- entity pairs -RRB- , d - dimensional textual features , and t labels -LRB- relations -RRB-

CASE: 18
Stag: 73 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: This linear classification problem can be transformed into completing the unobservable entries in Y t u ' \ u2062 ' e u ' \ u2062 ' s u ' \ u2062 ' t by means of the observable entries in X t u ' \ u2062 ' r u ' \ u2062 ' a u ' \ u2062 ' i u ' \ u2062 ' n , Y t u ' \ u2062 ' r u ' \ u2062 ' a u ' \ u2062 ' i u ' \ u2062 ' n and X t u ' \ u2062 ' e u ' \ u2062 ' s u ' \ u2062 ' t , based on the assumption that the rank of matrix u ' \ ud835 ' u ' \ udc19 ' u ' \ u2208 ' u ' \ u211d ' -LRB- n + m -RRB- -LRB- d + t -RRB- is low
	Cause: the assumption that the rank of matrix u ' \ ud835 ' u ' \ udc19 ' u ' \ u2208 ' u ' \ u211d ' -LRB- n + m -RRB- -LRB- d + t -RRB- is low
	Effect: This linear classification problem can be transformed into completing the unobservable entries in Y t u ' \ u2062 ' e u ' \ u2062 ' s u ' \ u2062 ' t by means of the observable entries in X t u ' \ u2062 ' r u ' \ u2062 ' a u ' \ u2062 ' i u ' \ u2062 ' n , Y t u ' \ u2062 ' r u ' \ u2062 ' a u ' \ u2062 ' i u ' \ u2062 ' n and X t u ' \ u2062 ' e u ' \ u2062 ' s u ' \ u2062 ' t

CASE: 19
Stag: 76 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Formula -LRB- 2 -RRB- is usually impractical for real problems as the entries in the matrix u ' \ ud835 ' u ' \ udc19 ' are corrupted by noise
	Cause: the entries in the matrix u ' \ ud835 ' u ' \ udc19 ' are corrupted by noise
	Effect: Formula -LRB- 2 -RRB- is usually impractical for real problems

CASE: 20
Stag: 78 79 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where u ' \ ud835 ' u ' \ udc19 ' * as the underlying low-rank matrix and E is the error matrix
	Cause: the underlying low-rank matrix and E is the error
	Effect: u ' \ ud835 ' u ' \ udc19 ' *

CASE: 21
Stag: 84 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: According to Formula -LRB- 1 -RRB- , u ' \ ud835 ' u ' \ udc19 ' * u ' \ u2208 ' u ' \ u211d ' -LRB- n + m -RRB- -LRB- d + t -RRB- can be represented as -LSB- X * , u ' \ ud835 ' u ' \ udc16 ' u ' \ u2062 ' X * -RSB- instead of -LSB- X * , Y * -RSB- , by explicitly modeling the bias vector u ' \ ud835 ' u ' \ udc1b '
	Cause: -LSB- X * , u ' \ ud835 ' u ' \ udc16 ' u ' \ u2062 ' X * -RSB- instead of -LSB- X * , Y * -RSB- , by explicitly modeling the bias vector u ' \ ud835 ' u ' \ udc1b '
	Effect: According to Formula -LRB- 1 -RRB- , u ' \ ud835 ' u ' \ udc19 ' * u ' \ u2208 ' u ' \ u211d ' -LRB- n + m -RRB- -LRB- d + t -RRB- can be represented

CASE: 22
Stag: 84 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to Formula -LRB- 1 -RRB- , u ' \ ud835 ' u ' \ udc19 ' * u ' \ u2208 ' u ' \ u211d ' -LRB- n + m -RRB- -LRB- d + t -RRB- can be represented
	Cause: Formula -LRB- 1 -RRB-
	Effect: u ' \ ud835 ' u ' \ udc19 ' * u ' \ u2208 ' u ' \ u211d ' -LRB- n + m -RRB- -LRB- d + t -RRB- can be represented

CASE: 23
Stag: 84 85 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: According to Formula -LRB- 1 -RRB- , u ' \ ud835 ' u ' \ udc19 ' * u ' \ u2208 ' u ' \ u211d ' -LRB- n + m -RRB- -LRB- d + t -RRB- can be represented as -LSB- X * , u ' \ ud835 ' u ' \ udc16 ' u ' \ u2062 ' X * -RSB- instead of -LSB- X * , Y * -RSB- , by explicitly modeling the bias vector u ' \ ud835 ' u ' \ udc1b ' Therefore , this convex optimization model is called DRMC-b
	Cause: According to Formula -LRB- 1 -RRB- , u ' \ ud835 ' u ' \ udc19 ' * u ' \ u2208 ' u ' \ u211d ' -LRB- n + m -RRB- -LRB- d + t -RRB- can be represented as -LSB- X * , u ' \ ud835 ' u ' \ udc16 ' u ' \ u2062 ' X * -RSB- instead of -LSB- X * , Y * -RSB- , by explicitly modeling the bias vector u ' \ ud835 ' u ' \ udc1b '
	Effect: this convex optimization model is called DRMC-b

CASE: 24
Stag: 89 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If we implicitly model the bias vector u ' \ ud835 ' u ' \ udc1b ' , u ' \ ud835 ' u ' \ udc19 ' * u ' \ u2208 ' u ' \ u211d ' -LRB- n + m -RRB- -LRB- 1 + d + t -RRB- can be denoted by -LSB- u ' \ ud835 ' u ' \ udfcf ' , X * , u ' \ ud835 ' u ' \ udc16 ' u ' \ u2032 ' u ' \ u2062 ' X * -RSB- instead of -LSB- X * , Y * -RSB- , in which u ' \ ud835 ' u ' \ udc16 ' u ' \ u2032 ' takes the role of -LSB- u ' \ ud835 ' u ' \ udc1b ' T ; u ' \ ud835 ' u ' \ udc16 ' -RSB- in DRMC-b
	Cause: we implicitly model the bias vector u ' \ ud835 ' u ' \ udc1b
	Effect: u ' \ ud835 ' u ' \ udc19 ' * u ' \ u2208 ' u ' \ u211d ' -LRB- n + m -RRB- -LRB- 1 + d + t -RRB- can be denoted by -LSB- u ' \ ud835 ' u ' \ udfcf ' , X * , u ' \ ud835 ' u ' \ udc16 ' u ' \ u2032 ' u ' \ u2062 ' X * -RSB- instead of -LSB- X * , Y * -RSB- , in which u ' \ ud835 ' u ' \ udc16 ' u ' \ u2032 ' takes the role of -LSB- u ' \ ud835 ' u ' \ udc1b ' T ; u ' \ ud835 ' u ' \ udc16 '

CASE: 25
Stag: 99 100 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: The matrix rank minimization problem is NP-hard Therefore , Cand s and Recht -LSB- 5 -RSB- suggested to use a convex relaxation , the nuclear norm minimization instead
	Cause: The matrix rank minimization problem is NP-hard
	Effect: Cand s and Recht -LSB- 5 -RSB- suggested to use a convex relaxation , the nuclear norm minimization instead

CASE: 26
Stag: 103 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Moreover , Goldfrab and Ma -LSB- 11 -RSB- proved the convergence of the FPC algorithm for solving the nuclear norm minimization problem
	Cause: solving the nuclear norm minimization problem
	Effect: Moreover , Goldfrab and Ma -LSB- 11 -RSB- proved the convergence of the FPC algorithm

CASE: 27
Stag: 103 104 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Moreover , Goldfrab and Ma -LSB- 11 -RSB- proved the convergence of the FPC algorithm for solving the nuclear norm minimization problem We thus adopt and modify the algorithm aiming to find the optima for our noise-tolerant models , i.e. , , Formulae -LRB- 3 -RRB- and -LRB- 4
	Cause: , Goldfrab and Ma -LSB- 11 -RSB- proved the convergence of the FPC algorithm for solving the nuclear norm minimization problem We
	Effect: adopt and modify the algorithm aiming to find the optima for our noise-tolerant models , i.e. , , Formulae -LRB- 3 -RRB- and -LRB- 4

CASE: 28
Stag: 105 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Algorithm 1 describes the modified FPC algorithm for solving DRMC-b , which contains two steps for each iteration
	Cause: solving DRMC-b , which contains two steps for each iteration
	Effect: Algorithm 1 describes the modified FPC algorithm

CASE: 29
Stag: 114 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: During the iteration , any negative value in u ' \ ud835 ' u ' \ udeba ' - u ' \ u03a4 ' u ' \ ud835 ' u ' \ udc33 ' u ' \ u2062 ' u ' \ u039c ' is assigned by zero , so that the rank of reconstructed matrix u ' \ ud835 ' u ' \ udc19 ' will be reduced , where u ' \ ud835 ' u ' \ udc19 ' = u ' \ ud835 ' u ' \ udc14 ' u ' \ u2062 ' m u ' \ u2062 ' a u ' \ u2062 ' x u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udeba ' - u ' \ u03a4 ' u ' \ ud835 ' u ' \ udc33 ' u ' \ u2062 ' u ' \ u039c ' , 0 -RRB- u ' \ u2062 ' u ' \ ud835 ' u ' \ udc15 ' u ' \ ud835 ' u ' \ udc13 '
	Cause: During the iteration , any negative value in u ' \ ud835 ' u ' \ udeba ' - u ' \ u03a4 ' u ' \ ud835 ' u ' \ udc33 ' u ' \ u2062 ' u ' \ u039c ' is assigned by zero ,
	Effect: the rank of reconstructed matrix u ' \ ud835 ' u ' \ udc19 ' will be reduced , where u ' \ ud835 ' u ' \ udc19 ' = u ' \ ud835 ' u ' \ udc14 ' u ' \ u2062 ' m u ' \ u2062 ' a u ' \ u2062 ' x u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udeba ' - u ' \ u03a4 ' u ' \ ud835 ' u ' \ udc33 ' u ' \ u2062 ' u ' \ u039c ' , 0 -RRB- u ' \ u2062 ' u ' \ ud835 ' u ' \ udc15 ' u ' \ ud835 ' u ' \ udc13

CASE: 30
Stag: 115 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: FPC algorithm for solving DRMC-b -LCB- algorithmic -RCB- \ REQUIRE Initial matrix u ' \ ud835 ' u ' \ udc19 ' u ' \ ud835 ' u ' \ udfce ' , bias u ' \ ud835 ' u ' \ udc1b ' u ' \ ud835 ' u ' \ udfce ' ; Parameters u ' \ u039c ' , u ' \ u039b ' ; Step sizes u ' \ u03a4 ' z , u ' \ u03a4 ' b
	Cause: solving DRMC-b -LCB- algorithmic -RCB- \ REQUIRE Initial matrix u ' \ ud835 ' u ' \ udc19 ' u ' \ ud835 ' u ' \ udfce ' , bias u ' \ ud835 ' u ' \ udc1b ' u ' \ ud835 ' u ' \ udfce ' ; Parameters u ' \ u039c ' , u ' \ u039b ' ; Step sizes u ' \ u03a4 ' z , u ' \ u03a4 '
	Effect: FPC algorithm

CASE: 31
Stag: 117 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: \ FOR u ' \ u039c ' = u ' \ u039c ' 1 u ' \ u039c ' 2 u ' \ u2026 ' u ' \ u039c ' F \ WHILE relative error u ' \ u0395 ' \ STATE Gradient step u ' \ ud835 ' u ' \ udc00 ' = u ' \ ud835 ' u ' \ udc19 ' - u ' \ u03a4 ' z u ' \ u2062 ' g u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc19 ' -RRB- , u ' \ ud835 ' u ' \ udc1b ' = u ' \ ud835 ' u ' \ udc1b ' - u ' \ u03a4 ' b u ' \ u2062 ' g u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc1b '
	Cause: \ FOR u ' \ u039c ' =
	Effect: u ' \ u039c ' 1 u ' \ u039c ' 2 u ' \ u2026 ' u ' \ u039c ' F \ WHILE relative error u ' \ u0395 ' \ STATE Gradient step u ' \ ud835 ' u ' \ udc00 ' = u ' \ ud835 ' u ' \ udc19 ' - u ' \ u03a4 ' z u ' \ u2062 ' g u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc19 ' -RRB- , u ' \ ud835 ' u ' \ udc1b ' = u ' \ ud835 ' u ' \ udc1b ' - u ' \ u03a4 ' b u ' \ u2062 ' g u ' \ u2062 ' -LRB- u

CASE: 32
Stag: 121 122 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: To accelerate the convergence , we use a continuation method to improve the speed u ' \ u039c ' is initialized by a large value u ' \ u039c ' 1 , thus resulting in the fast reduction of the rank at first Then the convergence slows down as u ' \ u039c ' decreases while obeying u ' \ u039c ' k + 1 = m u ' \ u2062 ' a u ' \ u2062 ' x u ' \ u2062 ' -LRB- u ' \ u039c ' k u ' \ u2062 ' u ' \ u0397 ' u ' \ u039c ' , u ' \ u039c ' F u ' \ u039c ' F is the final value of u ' \ u039c ' , and u ' \ u0397 ' u ' \ u039c ' is the decay parameter
	Cause: To accelerate the convergence , we use a continuation method to improve the speed u ' \ u039c ' is initialized by a large value u ' \ u039c ' 1
	Effect: resulting in the fast reduction of the rank at first Then the convergence slows down as u ' \ u039c ' decreases while obeying u ' \ u039c ' k + 1 = m u ' \ u2062 ' a u ' \ u2062 ' x u ' \ u2062 ' -LRB- u ' \ u039c ' k u ' \ u2062 ' u ' \ u0397 ' u ' \ u039c ' , u ' \ u039c ' F u ' \ u039c ' F is the final value of u ' \ u039c ' , and u ' \ u0397 ' u ' \ u039c ' is the decay parameter

CASE: 33
Stag: 122 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Then the convergence slows down as u ' \ u039c ' decreases while obeying u ' \ u039c ' k + 1 = m u ' \ u2062 ' a u ' \ u2062 ' x u ' \ u2062 ' -LRB- u ' \ u039c ' k u ' \ u2062 ' u ' \ u0397 ' u ' \ u039c ' , u ' \ u039c ' F u ' \ u039c ' F is the final value of u ' \ u039c ' , and u ' \ u0397 ' u ' \ u039c ' is the decay parameter
	Cause: u ' \ u039c ' decreases while obeying u ' \ u039c ' k + 1 = m u ' \ u2062 ' a u ' \ u2062 ' x u ' \ u2062 ' -LRB- u ' \ u039c ' k u ' \ u2062 ' u ' \ u0397 ' u ' \ u039c ' , u ' \ u039c ' F u ' \ u039c ' F is the final value of u ' \ u039c ' , and u ' \ u0397 ' u ' \ u039c ' is the decay parameter
	Effect: the convergence slows down

CASE: 34
Stag: 129 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: FPC algorithm for solving DRMC-1 -LCB- algorithmic -RCB- \ REQUIRE Initial matrix u ' \ ud835 ' u ' \ udc19 ' u ' \ ud835 ' u ' \ udfce ' ; Parameters u ' \ u039c ' , u ' \ u039b ' ; Step sizes u ' \ u03a4 ' z
	Cause: solving DRMC-1 -LCB- algorithmic -RCB- \ REQUIRE Initial matrix u ' \ ud835 ' u ' \ udc19 ' u ' \ ud835 ' u ' \ udfce ' ; Parameters u ' \ u039c ' , u ' \ u039b ' ; Step sizes u ' \ u03a4 '
	Effect: FPC algorithm

CASE: 35
Stag: 131 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: \ FOR u ' \ u039c ' = u ' \ u039c ' 1 u ' \ u039c ' 2 u ' \ u2026 ' u ' \ u039c ' F \ WHILE relative error u ' \ u0395 ' \ STATE Gradient step u ' \ ud835 ' u ' \ udc00 ' = u ' \ ud835 ' u ' \ udc19 ' - u ' \ u03a4 ' z u ' \ u2062 ' g u ' \ u2062 ' -LRB- u ' \ ud835 ' u ' \ udc19 '
	Cause: \ FOR u ' \ u039c ' =
	Effect: u ' \ u039c ' 1 u ' \ u039c ' 2 u ' \ u2026 ' u ' \ u039c ' F \ WHILE relative error u ' \ u0395 ' \ STATE Gradient step u ' \ ud835 ' u ' \ udc00 ' = u ' \ ud835 ' u ' \ udc19 ' - u ' \ u03a4 ' z u ' \ u2062 ' g u ' \ u2062 ' -LRB- u

CASE: 36
Stag: 136 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: \ ENSURE Completed Matrix Z
	Cause: \
	Effect: Completed Matrix Z

CASE: 37
Stag: 138 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The two widely used datasets that we adopt are both automatically generated by aligning Freebase to New York Times corpora
	Cause: aligning Freebase to New York Times corpora
	Effect: The two widely used datasets that we adopt are both automatically generated

CASE: 38
Stag: 158 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: -LSB- 16 -RSB- revealed that as long as the non-negative step sizes satisfy u ' \ u03a4 ' z m u ' \ u2062 ' i u ' \ u2062 ' n u ' \ u2062 ' -LRB- 4 u ' \ u2062 ' u ' \ u03a9 ' Y u ' \ u039b ' u ' \ u03a9 ' X and u ' \ u03a4 ' b 4 u ' \ u2062 ' u ' \ u03a9 ' Y u ' \ u039b ' u ' \ u2062 ' -LRB- n + m -RRB- , the FPC algorithm will guarantee to converge to a global optimum
	Cause: long as the non-negative step sizes satisfy u ' \ u03a4 ' z m u ' \ u2062 ' i u ' \ u2062 ' n u ' \ u2062 ' -LRB- 4 u ' \ u2062 ' u ' \ u03a9 ' Y u ' \ u039b ' u ' \ u03a9 ' X and u ' \ u03a4 ' b 4 u ' \ u2062 ' u ' \ u03a9 ' Y u ' \ u039b ' u ' \ u2062 ' -LRB- n + m -RRB- , the FPC algorithm will guarantee to converge to a global optimum
	Effect: -LSB- 16 -RSB- revealed that

CASE: 39
Stag: 158 159 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: -LSB- 16 -RSB- revealed that as long as the non-negative step sizes satisfy u ' \ u03a4 ' z m u ' \ u2062 ' i u ' \ u2062 ' n u ' \ u2062 ' -LRB- 4 u ' \ u2062 ' u ' \ u03a9 ' Y u ' \ u039b ' u ' \ u03a9 ' X and u ' \ u03a4 ' b 4 u ' \ u2062 ' u ' \ u03a9 ' Y u ' \ u039b ' u ' \ u2062 ' -LRB- n + m -RRB- , the FPC algorithm will guarantee to converge to a global optimum Therefore , we set u ' \ u03a4 ' z = u ' \ u03a4 ' b = 0.5 to satisfy the above constraints on both two datasets
	Cause: revealed that as long as the non-negative step sizes satisfy u ' \ u03a4 ' z m u ' \ u2062 ' i u ' \ u2062 ' n u ' \ u2062 ' -LRB- 4 u ' \ u2062 ' u ' \ u03a9 ' Y u ' \ u039b ' u ' \ u03a9 ' X and u ' \ u03a4 ' b 4 u ' \ u2062 ' u ' \ u03a9 ' Y u ' \ u039b ' u ' \ u2062 ' -LRB- n + m -RRB- , the FPC algorithm will guarantee to converge to a global optimum
	Effect: we set u ' \ u03a4 ' z = u ' \ u03a4 ' b = 0.5 to satisfy the above constraints on both two datasets

CASE: 40
Stag: 161 162 
	Pattern: 1 [['reason'], [['that', 'because']]]---- [['&R', '(,/./;/--)', '&ONE', '(&ADJ)'], ['(for &THIS (&NP))', '&BE'], ['&C']]
	sentTXT: In practice , we record the rank of matrix Z at each round of iteration until it converges at a rather small threshold u ' \ u0395 ' = 10 - 4 The reason is that we suppose the optimal low-rank representation of the matrix Z conveys the truly effective information about underlying semantic correlation between the features and the corresponding labels
	Cause: we suppose the optimal low-rank representation of the matrix Z conveys the truly effective information about underlying semantic correlation between the features and the corresponding labels
	Effect: , we record the rank of matrix Z at each round of iteration until it converges at a rather small threshold u ' \ u0395 ' = 10 - 4

CASE: 41
Stag: 168 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: On both two datasets , we observe an identical phenomenon that the performance gradually increases as the rank of the matrix declines before reaching the optimum
	Cause: the rank of the matrix declines before reaching the optimum
	Effect: On both two datasets , we observe an identical phenomenon that the performance gradually increases

CASE: 42
Stag: 169 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: However , it sharply decreases if we continue reducing the optimal rank
	Cause: we continue reducing the optimal rank
	Effect: However , it sharply decreases

CASE: 43
Stag: 169 170 
	Pattern: 2 [[['explanation', 'motivation'], 'is', 'that']]---- [['&R', '(,/./;/--)', '&ONE', '(&adj)'], ['&C']]
	sentTXT: However , it sharply decreases if we continue reducing the optimal rank An intuitive explanation is that the high-rank matrix contains much noise and the model tends to be overfitting , whereas the matrix of excessively low rank is more likely to lose principal information and the model tends to be underfitting
	Cause: the high-rank matrix contains much noise and the model tends to be overfitting , whereas the matrix of excessively low rank is more likely to lose principal information and the model tends to be underfitting
	Effect: However , it sharply decreases if we continue reducing the optimal rank

CASE: 44
Stag: 179 180 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: They set u ' \ u0398 ' = 5 in the original code by default Therefore , we follow their settings and adopt the same way to filter the features
	Cause: They set u ' \ u0398 ' = 5 in the original code by default
	Effect: we follow their settings and adopt the same way to filter the features

CASE: 45
Stag: 184 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: We bypass the description due to the limitation of space
	Cause: the limitation of space
	Effect: We bypass the description

CASE: 46
Stag: 187 188 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: In practical applications , we also concern about the precision on Top-N predicted relation instances Therefore , We compare the precision of Top-100s , Top-200s and Top-500s for DRMC-1 , DRMC-b and the state-of-the-art method NFE-13 -LSB- 21 -RSB-
	Cause: In practical applications , we also concern about the precision on Top-N predicted relation instances
	Effect: We compare the precision of Top-100s , Top-200s and Top-500s for DRMC-1 , DRMC-b and the state-of-the-art method NFE-13 -LSB- 21 -RSB-

CASE: 47
Stag: 192 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: Due to the noisy features and incomplete labels , the underlying low-rank data matrix with truly effective information tends to be corrupted and the rank of observed data matrix can be extremely high
	Cause: the noisy features and incomplete labels
	Effect: the underlying low-rank data matrix with truly effective information tends to be corrupted and the rank of observed data matrix can be extremely high

CASE: 48
Stag: 194 195 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However , those high ranks result in poor performance As the ranks decline before approaching the optimum , the performance gradually improves , implying that our approaches filter the noise in data and keep the principal information for classification via recovering the underlying low-rank data matrix
	Cause: the ranks decline before approaching the optimum , the performance gradually improves , implying that our approaches filter the noise in data and keep the principal information for classification via recovering the underlying low-rank data matrix
	Effect: However , those high ranks result in poor performance

CASE: 49
Stag: 201 
	Pattern: 2 [['for', 'the'], ['reason']]---- [['&R', '(,)', '(&ADV)'], ['(&ADJ)'], ['(that)', '&C']]
	sentTXT: In other words , for each approach , the amount of truly effective information about underlying semantic correlation keeps constant for the same dataset , which , to some extent , explains the reason why our approaches are robust to sparse features
	Cause: why our approaches are robust to sparse features
	Effect: In other words , for each approach , the amount of truly effective information about underlying semantic correlation keeps constant

CASE: 50
Stag: 203 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Our models are based on matrix completion with low-rank criterion
	Cause: matrix completion with low-rank criterion
	Effect: Our models

CASE: 51
Stag: 204 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: Experiments demonstrated that the low-rank representation of the feature-label matrix can exploit the underlying semantic correlated information for relation classification and is effective to overcome the difficulties incurred by sparse and noisy features and incomplete labels , so that we achieved significant improvements on performance
	Cause: Experiments demonstrated that the low-rank representation of the feature-label matrix can exploit the underlying semantic correlated information for relation classification and is effective to overcome the difficulties incurred by sparse and noisy features and incomplete labels ,
	Effect: we achieved significant improvements on performance

CASE: 52
Stag: 206 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First , they can not process new coming testing items efficiently , as we have to reconstruct the data matrix containing not only the testing items but also all the training items for relation classification , and compute in iterative fashion again
	Cause: we have to reconstruct the data matrix containing not only the testing items but also all the training items for relation classification , and compute in iterative fashion again
	Effect: First , they can not process new coming testing items efficiently

CASE: 53
Stag: 208 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: For the future work , we plan to improve our models so that they will be capable of incremental learning on large-scale datasets -LSB- 6 -RSB-
	Cause: For the future work , we plan to improve our models
	Effect: they will be capable of incremental learning on large-scale datasets -LSB- 6 -RSB-

