************************************************************
P14-1118.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: This paper defines a systematic approach to Opinion Mining -LRB- OM -RRB- on YouTube comments by -LRB- i -RRB- modeling classifiers for predicting the opinion polarity and the type of comment and -LRB- ii -RRB- proposing robust shallow syntactic structures for improving model adaptability
	Cause: predicting the opinion polarity and the type of comment
	Effect: This paper defines a systematic approach to Opinion Mining -LRB- OM -RRB- on YouTube comments by -LRB- i -RRB- modeling classifiers

CASE: 1
Stag: 5 6 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: YouTube is a unique environment , just like Twitter , but probably even richer multi-modal , with a social graph , and discussions between people sharing an interest Hence , doing sentiment research in such an environment is highly relevant for the community
	Cause: YouTube is a unique environment , just like Twitter , but probably even richer multi-modal , with a social graph , and discussions between people sharing an interest
	Effect: doing sentiment research in such an environment is highly relevant for the community

CASE: 2
Stag: 7 8 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: While the linguistic conventions used on Twitter and YouTube indeed show similarities -LSB- 2 -RSB- , focusing on YouTube allows to exploit context information , possibly also multi-modal information , not available in isolated tweets , thus rendering it a valuable resource for the future research Nevertheless , there is almost no work showing effective OM on YouTube comments
	Cause: While the linguistic conventions used on Twitter and YouTube indeed show similarities -LSB- 2 -RSB- , focusing on YouTube allows to exploit context information , possibly also multi-modal information , not available in isolated tweets
	Effect: rendering it a valuable resource for the future research Nevertheless , there is almost no work showing effective OM on YouTube

CASE: 3
Stag: 14 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The comment contains a product name xoom and some negative expressions , thus , a bag-of-words model would derive a negative polarity for this product
	Cause: comment contains a product name xoom and some negative expressions
	Effect: , a bag-of-words model would derive a negative polarity for this product

CASE: 4
Stag: 15 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In contrast , the opinion towards the product is neutral as the negative sentiment is expressed towards the video
	Cause: the negative sentiment is expressed towards the video
	Effect: In contrast , the opinion towards the product is neutral

CASE: 5
Stag: 24 
	Pattern: 0 [[['enable', 'enables', 'enabled']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@', '&TODO@R@']]
	sentTXT: 1 1 The corpus and the annotation guidelines are publicly available at http://projects.disi.unitn.it/iKernels/projects/sentube/ It is the first manually annotated corpus that enables researchers to use supervised methods on YouTube for comment classification and opinion analysis
	Cause: 1 1 The corpus and the annotation guidelines are publicly available at http://projects.disi.unitn.it/iKernels/projects/sentube/ It is the first manually annotated corpus
	Effect: researchers to use supervised methods on YouTube for comment classification and opinion analysis

CASE: 6
Stag: 28 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: The third contribution of the paper is a novel structural representation , based on shallow syntactic trees enriched with conceptual information , i.e. , , tags generalizing the specific topic of the video , e.g. , , iPad , Kindle , Toyota Camry
	Cause: shallow syntactic trees enriched with conceptual information
	Effect: i.e. , , tags generalizing the specific topic of the video , e.g. , , iPad , Kindle , Toyota Camry

CASE: 7
Stag: 30 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In particular , we define an efficient tree kernel derived from the Partial Tree Kernel , -LSB- 10 -RSB- , suitable for encoding structural representation of comments into Support Vector Machines -LRB- SVMs
	Cause: encoding structural representation of comments into Support Vector Machines -LRB- SVMs
	Effect: In particular , we define an efficient tree kernel derived from the Partial Tree Kernel , -LSB- 10 -RSB- , suitable

CASE: 8
Stag: 32 33 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Structural models generally improve on both tasks u ' \ u2013 ' polarity and type classification u ' \ u2013 ' yielding up to 30 % of relative improvement , when little data is available Hence , the impractical task of annotating data for each YouTube category can be mitigated by the use of models that adapt better across domains
	Cause: Structural models generally improve on both tasks u ' \ u2013 ' polarity and type classification u ' \ u2013 ' yielding up to 30 % of relative improvement , when little data is available
	Effect: the impractical task of annotating data for each YouTube category can be mitigated by the use of models that adapt better across domains

CASE: 9
Stag: 36 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: The aforementioned corpora are , however , only partially suitable for developing models on social media , since the informal text poses additional challenges for Information Extraction and Natural Language Processing
	Cause: the informal text poses additional challenges for Information Extraction and Natural Language Processing
	Effect: The aforementioned corpora are , however , only partially suitable for developing models on social media

CASE: 10
Stag: 37 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Similar to Twitter , most YouTube comments are very short , the language is informal with numerous accidental and deliberate errors and grammatical inconsistencies , which makes previous corpora less suitable to train models for OM on YouTube
	Cause: Similar to Twitter
	Effect: most YouTube comments are very short , the language is informal with numerous accidental and deliberate errors and grammatical inconsistencies , which makes previous corpora less suitable to train models for OM on YouTube

CASE: 11
Stag: 38 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: A recent study focuses on sentiment analysis for Twitter -LSB- 14 -RSB- , however , their corpus was compiled automatically by searching for emoticons expressing positive and negative sentiment only
	Cause: searching for emoticons expressing positive and negative sentiment only
	Effect: A recent study focuses on sentiment analysis for Twitter -LSB- 14 -RSB- , however , their corpus was compiled automatically

CASE: 12
Stag: 40 41 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: 2010 -RRB- focus on exploiting user ratings -LRB- counts of u ' \ u2018 ' thumbs up/down u ' \ u2019 ' as flagged by other users -RRB- of YouTube video comments to train classifiers to predict the community acceptance of new comments Hence , their goal is different predicting comment ratings , rather than predicting the sentiment expressed in a YouTube comment or its information content
	Cause: 2010 -RRB- focus on exploiting user ratings -LRB- counts of u ' \ u2018 ' thumbs up/down u ' \ u2019 ' as flagged by other users -RRB- of YouTube video comments to train classifiers to predict the community acceptance of new comments
	Effect: their goal is different predicting comment ratings , rather than predicting the sentiment expressed in a YouTube comment or its information content

CASE: 13
Stag: 42 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Exploiting the information from user ratings is a feature that we have not exploited thus far , but we believe that it is a valuable feature to use in future work
	Cause: Exploiting the information from user ratings is a feature that we have not exploited
	Effect: far , but we believe that it is a valuable feature to use in future

CASE: 14
Stag: 46 47 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: They help to build a system that is more robust across domains Therefore , rather than trying to build a specialized system for every new target domain , as it has been done in most prior work on domain adaptation -LSB- 3 , 4 -RSB- , the domain adaptation problem boils down to finding a more robust system -LSB- 25 , 17 -RSB-
	Cause: They help to build a system that is more robust across domains
	Effect: rather than trying to build a specialized system for every new target domain , as it has been done in most prior work on domain adaptation -LSB- 3 , 4 -RSB- , the domain adaptation problem boils down to finding a more robust system -LSB- 25 , 17 -RSB-

CASE: 15
Stag: 53 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Such classifiers are traditionally based on bag-of-words and more advanced features
	Cause: bag-of-words and more advanced features
	Effect: Such classifiers are traditionally

CASE: 16
Stag: 54 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In the next sections , we define a baseline feature vector model and a novel structural model based on kernel methods
	Cause: kernel methods
	Effect: In the next sections , we define a baseline feature vector model and a novel structural model

CASE: 17
Stag: 60 61 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For each of the lexicons , we use the number of words found in the comment that have positive and negative sentiment as a feature - negation the count of negation words , e.g. , , -LCB- don u ' \ u2019 ' t , never , not , etc
	Cause: a feature - negation the count of negation words , e.g. , , -LCB- don
	Effect: For each of the lexicons , we use the number of words found in the comment that have positive and negative sentiment

CASE: 18
Stag: 65 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Most of the videos come with a title and a short description , which can be used to encode the topicality of each comment by looking at their overlap
	Cause: looking at their overlap
	Effect: the videos come with a title and a short description , which can be used to encode the topicality of each comment

CASE: 19
Stag: 66 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We go beyond traditional feature vectors by employing structural models -LRB- STRUCT -RRB- , which encode each comment into a shallow syntactic tree
	Cause: employing structural models -LRB- STRUCT -RRB- , which encode each comment into a shallow syntactic tree
	Effect: We go beyond traditional feature vectors

CASE: 20
Stag: 72 73 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Moreover , such taggers have been recently updated with models -LSB- 18 , 5 -RSB- trained specifically to process noisy texts showing significant reductions in the error rate on user-generated texts , e.g. , , Twitter Hence , we use the CMU Twitter pos-tagger -LSB- 5 , 13 -RSB- to obtain the part-of-speech tags
	Cause: Moreover , such taggers have been recently updated with models -LSB- 18 , 5 -RSB- trained specifically to process noisy texts showing significant reductions in the error rate on user-generated texts , e.g. , , Twitter
	Effect: we use the CMU Twitter pos-tagger -LSB- 5 , 13 -RSB- to obtain the part-of-speech tags

CASE: 21
Stag: 83 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: In contrast , the STRUCT model relies on the fact that the negative word , destroy , refers to the PRODUCT -LRB- xoom -RRB- since they form a verbal phase -LRB- VP
	Cause: they form a verbal
	Effect: In contrast , the STRUCT model relies on the fact that the negative word , destroy , refers to the PRODUCT -LRB- xoom -RRB-

CASE: 22
Stag: 86 87 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Moreover , tree kernels generate all possible subtrees , thus producing generalized -LRB- back-off -RRB- features , e.g. , , -LSB- S -LSB- negative-VP -LSB- negative-V -LSB- destroy -RSB- -RSB- -LSB- PRODUCT-NP -RSB- -RSB- -RSB- -RSB- or -LSB- S -LSB- negative-VP -LSB- PRODUCT-NP -RSB- -RSB- -RSB- -RSB- We perform OM on YouTube using supervised methods , e.g. , , SVM
	Cause: Moreover , tree kernels generate all possible subtrees
	Effect: producing generalized -LRB- back-off -RRB- features , e.g. , , -LSB- S -LSB- negative-VP -LSB- negative-V -LSB- destroy -RSB- -RSB- -LSB- PRODUCT-NP -RSB- -RSB- -RSB- -RSB- or -LSB- S -LSB- negative-VP -LSB- PRODUCT-NP -RSB- -RSB- -RSB- -RSB- We perform OM on YouTube using supervised methods , e.g. , , SVM

CASE: 23
Stag: 90 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: A binary classifier is trained for each of the classes and the predicted class is obtained by taking a class from the classifier with a maximum prediction score
	Cause: taking a class from the classifier with a maximum prediction score
	Effect: A binary classifier is trained for each of the classes and the predicted class is obtained

CASE: 24
Stag: 97 98 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The STRUCT model treats each comment as a tuple u ' \ ud835 ' u ' \ udc99 ' = u ' \ u27e8 ' u ' \ ud835 ' u ' \ udc7b ' , u ' \ ud835 ' u ' \ udc97 ' u ' \ u27e9 ' composed of a shallow syntactic tree u ' \ ud835 ' u ' \ udc7b ' and a feature vector u ' \ ud835 ' u ' \ udc97 ' Hence , for each pair of comments u ' \ ud835 ' u ' \ udc99 ' 1 and u ' \ ud835 ' u ' \ udc99 ' 2 , we define the following comment similarity kernel
	Cause: a tuple u ' \ ud835 ' u ' \ udc99 ' = u ' \ u27e8 ' u ' \ ud835 ' u ' \ udc7b ' , u ' \ ud835 ' u ' \ udc97 ' u ' \ u27e9 ' composed of a shallow syntactic tree u ' \ ud835 ' u ' \ udc7b ' and a feature vector u ' \ ud835 ' u ' \ udc97 ' Hence , for each pair of comments u ' \ ud835 ' u ' \ udc99 ' 1 and u ' \ ud835 ' u ' \ udc99 ' 2 , we define the following comment similarity
	Effect: The STRUCT model treats each comment

CASE: 25
Stag: 97 98 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: The STRUCT model treats each comment as a tuple u ' \ ud835 ' u ' \ udc99 ' = u ' \ u27e8 ' u ' \ ud835 ' u ' \ udc7b ' , u ' \ ud835 ' u ' \ udc97 ' u ' \ u27e9 ' composed of a shallow syntactic tree u ' \ ud835 ' u ' \ udc7b ' and a feature vector u ' \ ud835 ' u ' \ udc97 ' Hence , for each pair of comments u ' \ ud835 ' u ' \ udc99 ' 1 and u ' \ ud835 ' u ' \ udc99 ' 2 , we define the following comment similarity kernel
	Cause: The STRUCT model treats each comment as a tuple u ' \ ud835 ' u ' \ udc99 ' = u ' \ u27e8 ' u ' \ ud835 ' u ' \ udc7b ' , u ' \ ud835 ' u ' \ udc97 ' u ' \ u27e9 ' composed of a shallow syntactic tree u ' \ ud835 ' u ' \ udc7b ' and a feature vector u ' \ ud835 ' u ' \ udc97 '
	Effect: for each pair of comments u ' \ ud835 ' u ' \ udc99 ' 1 and u ' \ ud835 ' u ' \ udc99 ' 2 , we define the following comment similarity kernel

CASE: 26
Stag: 105 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: where N T 1 and N T 2 are the sets of the T 1 u ' \ u2019 ' s and T 2 u ' \ u2019 ' s nodes , respectively and u ' \ u0394 ' u ' \ u2062 ' -LRB- n 1 , n 2 -RRB- is equal to the number of common fragments rooted in the n 1 and n 2 nodes , according to several possible definition of the atomic fragments
	Cause: several possible definition of the atomic fragments
	Effect: where N T 1 and N T 2 are the sets of the T 1 u ' \ u2019 ' s and T 2 u ' \ u2019 ' s nodes , respectively and u ' \ u0394 ' u ' \ u2062 ' -LRB- n 1 , n 2 -RRB- is equal to the number of common fragments rooted in the n 1 and n 2 nodes

CASE: 27
Stag: 106 107 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: To improve the speed computation of T u ' \ u2062 ' K , we consider pairs of nodes -LRB- n 1 , n 2 -RRB- belonging to the same tree level Thus , given H , the height of the STRUCT trees , where each level h contains nodes of the same type , i.e. , , chunk , POS , and lexical nodes , we define SHTK as the following 5 5 To have a similarity score between 0 and 1 , a normalization in the kernel space , i.e. , S u ' \ u2062 ' H u ' \ u2062 ' T u ' \ u2062 ' K u ' \ u2062 ' -LRB- T 1 , T 2 -RRB- S u ' \ u2062 ' H u ' \ u2062 ' T u ' \ u2062 ' K u ' \ u2062 ' -LRB- T 1 , T 1 -RRB- S u ' \ u2062 ' H u ' \ u2062 ' T u ' \ u2062 ' K u ' \ u2062 ' -LRB- T 2 , T 2 -RRB- is applied
	Cause: To improve the speed computation of T u ' \ u2062 ' K , we consider pairs of nodes -LRB- n 1 , n 2 -RRB- belonging to the same tree level
	Effect: , given H , the height of the STRUCT trees , where each level h contains nodes of the same type , i.e. , , chunk , POS , and lexical nodes , we define SHTK as the following 5 5 To have a similarity score between 0 and 1 , a normalization in the kernel space , i.e. , S u ' \ u2062 ' H u ' \ u2062 ' T u ' \ u2062 ' K u ' \ u2062 ' -LRB- T 1 , T 2 -RRB- S u ' \ u2062 ' H u ' \ u2062 ' T u ' \ u2062 ' K u ' \ u2062 ' -LRB- T 1 , T 1 -RRB- S u ' \ u2062 ' H u ' \ u2062 ' T u ' \ u2062 ' K u ' \ u2062 ' -LRB- T 2 , T 2 -RRB- is applied

CASE: 28
Stag: 121 122 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: When applied to STRUCT trees , SHTK exactly computes the same feature space as PTK , but in faster time -LRB- on average Indeed , SHTK required to be only applied to node pairs from the same level -LRB- see Eq
	Cause: PTK , but in faster time -LRB- on average Indeed , SHTK required
	Effect: applied to STRUCT trees , SHTK exactly computes the same feature space

CASE: 29
Stag: 124 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: This reduces the time for selecting the matching-node pairs carried out in PTK -LSB- 10 , 11 -RSB-
	Cause: selecting the matching-node pairs carried out in PTK -LSB- 10 , 11 -RSB-
	Effect: This reduces the time

CASE: 30
Stag: 125 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The fragment space is obviously the same , as the node labels of different levels in STRUCT are different and will not be matched by PTK either
	Cause: the node labels of different levels in STRUCT are different and will not be matched by PTK either
	Effect: The fragment space is obviously the same

CASE: 31
Stag: 141 142 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If the comment contains several statements of different polarities , it is annotated as both positive and negative u ' \ u201c ' Love the video but waiting for iPad 4 u ' \ u201d ' In total we have annotated 208 videos with around 35k comments -LRB- 128 videos TABLETS and 80 for AUTO
	Cause: both positive and negative u ' \ u201c ' Love the video but waiting for iPad 4 u ' \ u201d ' In total we have annotated 208 videos with around 35k comments -LRB-
	Effect: If the comment contains several statements of different polarities , it is annotated

CASE: 32
Stag: 150 151 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We treat each comment as expressing positive , negative or neutral sentiment Hence , the task is a three-way classification
	Cause: expressing positive , negative or neutral sentiment Hence , the task is a three-way classification
	Effect: We treat each comment

CASE: 33
Stag: 150 151 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: We treat each comment as expressing positive , negative or neutral sentiment Hence , the task is a three-way classification
	Cause: We treat each comment as expressing positive , negative or neutral sentiment
	Effect: the task is a three-way classification

CASE: 34
Stag: 153 154 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: One of the challenging aspects of sentiment analysis of YouTube data is that the comments may express the sentiment not only towards the product shown in the video , but also the video itself , i.e. , , users may post positive comments to the video while being generally negative about the product and vice versa Hence , it is of crucial importance to distinguish between these two types of comments
	Cause: One of the challenging aspects of sentiment analysis of YouTube data is that the comments may express the sentiment not only towards the product shown in the video , but also the video itself , i.e. , , users may post positive comments to the video while being generally negative about the product and vice versa
	Effect: it is of crucial importance to distinguish between these two types of comments

CASE: 35
Stag: 156 157 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Given that the main goal of sentiment analysis is to select sentiment-bearing comments and identify their polarity , distinguishing between off-topic and spam categories is not critical Thus , we merge the spam and off-topic into a single uninformative category
	Cause: Given that the main goal of sentiment analysis is to select sentiment-bearing comments and identify their polarity , distinguishing between off-topic and spam categories is not critical
	Effect: , we merge the spam and off-topic into a single uninformative category

CASE: 36
Stag: 162 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Considering a real-life application , it is important not only to detect the polarity of the comment , but to also identify if it is expressed towards the product or the video
	Cause: it is expressed towards the product or the video
	Effect: Considering a real-life application , it is important not only to detect the polarity of the comment , but to also identify

CASE: 37
Stag: 163 164 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 7 7 We exclude comments annotated as both video and product This enables the use of a simple flat multi-classifiers with seven categories for the full task , instead of a hierarchical multi-label classifiers -LRB- i.e. , , type classification first and then opinion polarity
	Cause: both video and product This enables the use of a simple flat multi-classifiers with seven categories for the full task ,
	Effect: 7 7 We exclude comments annotated

CASE: 38
Stag: 168 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the number of comments per video varies , the resulting sizes of each set are different -LRB- we use the larger split for TRAIN
	Cause: the number of comments per video varies
	Effect: the resulting sizes of each set are different -LRB- we use the larger split for TRAIN

CASE: 39
Stag: 174 
	Pattern: 1 [['it', 'is'], ['due', 'to'], ['that']]---- [[], ['(&ADV)'], ['&NP@C@'], ['&R']]
	sentTXT: It is likely due to the nature of the TABLETS videos , that are more geek-oriented , where users are more prone to share their opinions and enter involved discussions about a product
	Cause: the nature of the TABLETS videos
	Effect: are more geek-oriented , where users are more prone to share their opinions and enter involved discussions about a product

CASE: 40
Stag: 177 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: We start off by presenting the results for the traditional in-domain setting , where both TRAIN and TEST come from the same domain , e.g. , , AUTO or TABLETS
	Cause: presenting the results for the traditional in-domain setting
	Effect: , where both TRAIN and TEST come from the same domain , e.g. , , AUTO or TABLETS

CASE: 41
Stag: 178 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: Next , we show the learning curves to analyze the behavior of FVEC and STRUCT models according to the training size
	Cause: the training size
	Effect: Next , we show the learning curves to analyze the behavior of FVEC and STRUCT models

CASE: 42
Stag: 189 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In contrast , comments from TABLETS category tend to be more elaborated and well-argumented , thus , benefiting from the expressiveness of the structural representations
	Cause: In contrast , comments from TABLETS category tend to be more elaborated and well-argumented
	Effect: , benefiting from the expressiveness of the structural representations

CASE: 43
Stag: 194 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The learning curves depict the behavior of FVEC and STRUCT models as we increase the size of the training set
	Cause: we increase the size of the training set
	Effect: The learning curves depict the behavior of FVEC and STRUCT models

CASE: 44
Stag: 195 196 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Intuitively , the STRUCT model relies on more general syntactic patterns and may overcome the sparseness problems incurred by the FVEC model when little training data is available Nevertheless , as we see in Figure 2 , the learning curves for sentiment and type classification tasks across both product categories do not confirm this intuition
	Cause: we see in Figure 2 ,
	Effect: the STRUCT model relies on more general syntactic patterns and may overcome the sparseness problems incurred by the FVEC model when little training data is available Nevertheless

CASE: 45
Stag: 197 198 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The STRUCT model consistently outperforms the FVEC across all training sizes , but the gap in the performance does not increase when we move to smaller training sets As we will see next , this picture changes when we perform the cross-domain study
	Cause: we will see next , this picture changes when we perform the cross-domain study
	Effect: the gap in the performance does not increase when we move to smaller training sets

CASE: 46
Stag: 199 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: To understand the performance of our classifiers on other YouTube domains , we perform a set of cross-domain experiments by training on the data from one product category and testing on the other
	Cause: training on the data from one product category and testing on the other
	Effect: To understand the performance of our classifiers on other YouTube domains , we perform a set of cross-domain experiments

CASE: 47
Stag: 200 201 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Table 3 reports the accuracy for three tasks when we use all comments -LRB- TRAIN + TEST -RRB- from AUTO to predict on the TEST from TABLETS and in the opposite direction -LRB- TABLETS u ' \ u2192 ' AUTO When using AUTO as a source domain , STRUCT model provides additional 1-3 % of absolute improvement , except for the sentiment task
	Cause: a source domain , STRUCT model provides additional 1-3 % of absolute improvement , except for the sentiment task
	Effect: comments -LRB- TRAIN + TEST -RRB- from AUTO to predict on the TEST from TABLETS and in the opposite direction -LRB- TABLETS u ' \ u2192 ' AUTO When using AUTO

CASE: 48
Stag: 202 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Similar to the in-domain experiments , we studied the effect of the source domain size on the target test performance
	Cause: Similar to the in-domain experiments
	Effect: we studied the effect of the source domain size on the target test performance

CASE: 49
Stag: 206 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: AUTO is used as the source domain to train models , which are tested on TABLETS
	Cause: the source domain to train models , which
	Effect: AUTO is used

CASE: 50
Stag: 210 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This difference becomes smaller as we add data from the same domain
	Cause: we add data from the same domain
	Effect: This difference becomes smaller

CASE: 51
Stag: 211 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: This is an important advantage of our structural approach , since we can not realistically expect to obtain manual annotations for 10k + comments for each -LRB- of many thousands -RRB- product domains present on YouTube
	Cause: we can not realistically expect to obtain manual annotations for 10k + comments for each -LRB- of many thousands -RRB- product domains present on YouTube
	Effect: This is an important advantage of our structural approach

CASE: 52
Stag: 212 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Our STRUCT model is more accurate since it is able to induce structural patterns of sentiment
	Cause: it is able to induce structural patterns of sentiment
	Effect: Our STRUCT model is more accurate

CASE: 53
Stag: 214 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: The FVEC bag-of-words model misclassifies it to be positive , since it contains two positive expressions -LRB- better , better functionality -RRB- that outweigh a single negative expression -LRB- bulky
	Cause: it contains two positive expressions -LRB- better
	Effect: better functionality -RRB- that outweigh a single negative expression -LRB-

CASE: 54
Stag: 215 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The structural model , in contrast , is able to identify the product of interest -LRB- xoom -RRB- and associate it with the negative expression through a structural feature and thus correctly classify the comment as negative
	Cause: The structural model , in contrast , is able to identify the product of interest -LRB- xoom -RRB- and associate it with the negative expression through a structural feature
	Effect: correctly classify the comment as negative

CASE: 55
Stag: 217 218 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: The largest group of errors are implicit sentiments Thus , some comments do not contain any explicit positive or negative opinions , but provide detailed and well-argumented criticism , for example , this phone is heavy
	Cause: The largest group of errors are implicit sentiments
	Effect: , some comments do not contain any explicit positive or negative opinions , but provide detailed and well-argumented criticism , for example , this phone is heavy

CASE: 56
Stag: 221 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We carried out a systematic study on OM from YouTube comments by training a set of supervised multi-class classifiers distinguishing between video and product related opinions
	Cause: training a set of supervised multi-class classifiers distinguishing between video and product related opinions
	Effect: We carried out a systematic study on OM from YouTube comments

