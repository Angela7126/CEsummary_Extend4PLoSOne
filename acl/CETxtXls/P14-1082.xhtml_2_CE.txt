************************************************************
P14-1082.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 6 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: A classification-based approach is presented that is indeed found to improve significantly over these baselines by making use of a contextual window spanning a small number of neighbouring words
	Cause: making use of a contextual window spanning a small number of neighbouring words
	Effect: A classification-based approach is presented that is indeed found to improve significantly over these baselines

CASE: 1
Stag: 15 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The proposed application allows code switching and produces context-sensitive suggestions as writing progresses
	Cause: writing progresses
	Effect: The proposed application allows code switching and produces context-sensitive suggestions

CASE: 2
Stag: 20 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Input -LRB- L1 = French , L2 = English u ' \ u201c ' I rentre la maison because I am tired u ' \ u201d ' Desired output u ' \ u201c ' I return home because I am tired u ' \ u201d '
	Cause: I am tired u ' \ u201d ' Desired output u ' \ u201c ' I return home because I am tired u ' \ u201d '
	Effect: I rentre la maison

CASE: 3
Stag: 20 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: I am tired u ' \ u201d ' Desired output u ' \ u201c ' I return home because I am tired u ' \ u201d '
	Cause: I am tired u ' \ u201d '
	Effect: I am tired u ' \ u201d ' Desired output u ' \ u201c ' I return home

CASE: 4
Stag: 22 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: The main research question in this research is how to disambiguate an L1 word or phrase to its L2 translation based on an L2 context , and whether such cross-lingual contextual approaches provide added value compared to baseline models that are not context informed or compared to standard language models
	Cause: an L2 context
	Effect: and whether such cross-lingual contextual approaches provide added value compared to baseline models that are not context informed or compared to standard language models

CASE: 5
Stag: 23 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Preparing the data to build training and test data for our intended translation assistance system is not trivial , as the type of interactive translation assistant we aim to develop does not exist yet
	Cause: the type of interactive translation assistant we aim to develop does not exist yet
	Effect: the data to build training and test data for our intended translation assistance system is not trivial

CASE: 6
Stag: 32 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: It invokes GIZA + + -LSB- -RSB- to establish statistical word alignments based on the IBM Models and subsequently extracts phrases using the grow-diag-final algorithm -LSB- -RSB-
	Cause: the IBM Models and subsequently extracts phrases using the grow-diag-final algorithm -LSB- -RSB-
	Effect: It invokes GIZA + + -LSB- -RSB- to establish statistical word alignments

CASE: 7
Stag: 41 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Output a pair -LRB- s u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' t u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' c u ' \ u2062 ' e t u ' \ u2032 ' , s u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' t u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' c u ' \ u2062 ' e t -RRB- where s u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' t u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' c u ' \ u2062 ' e t u ' \ u2032 ' is a copy of t but with fragment f t substituted by f s , i.e. , the introduction of an L1 word or phrase in an L2 sentence
	Cause: f s
	Effect: ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' t u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' c u ' \ u2062 ' e t u ' \ u2032 ' , s u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' t u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' c u ' \ u2062 ' e t -RRB- where s u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' t u ' \ u2062 ' e u ' \ u2062 ' n u ' \ u2062 ' c u ' \ u2062 ' e t u ' \ u2032 ' is a copy of t but with fragment f t substituted

CASE: 8
Stag: 42 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: Step 4 is effectively a filter two thresholds can be configured to discard weak alignments , i.e. , those with low probabilities , from the phrase-translation table so that only strong couplings make it into the generated set
	Cause: Step 4 is effectively a filter two thresholds can be configured to discard weak alignments , i.e. , those with low probabilities , from the phrase-translation table
	Effect: only strong couplings make it into the generated set

CASE: 9
Stag: 43 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: The parameter u ' \ u039b ' 1 adds a constraint based on the product of the two conditional probabilities -LRB- P -LRB- f t f s -RRB- u ' \ u22c5 ' P -LRB- f s f t -RRB- -RRB- , and sets a threshold that has to be surpassed
	Cause: the product of the two conditional probabilities -LRB- P -LRB- f t f s -RRB- u ' \ u22c5 ' P -LRB- f s f t -RRB- -RRB-
	Effect: and sets a threshold that has to be surpassed

CASE: 10
Stag: 44 45 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: A second parameter u ' \ u039b ' 2 further limits the considered phrase pairs -LRB- f s , f t -RRB- to have the product of their conditional probabilities not not deviate more than a fraction u ' \ u039b ' 2 from the joint probability for the strongest possible pairing for f s , the source fragment f s u ' \ u2062 ' t u ' \ u2062 ' r u ' \ u2062 ' o u ' \ u2062 ' n u ' \ u2062 ' g u ' \ u2062 ' e u ' \ u2062 ' s u ' \ u2062 ' t u ' \ u2062 ' _ u ' \ u2062 ' t in Figure 1 corresponds to the best scoring translation for a given source fragment f s This metric thus effectively prunes weaker alternative translations in the phrase-translation table from being considered if there is a much stronger candidate
	Cause: second parameter u ' \ u039b ' 2 further limits the considered phrase pairs -LRB- f s , f t -RRB- to have the product of their conditional probabilities not not deviate more than a fraction u ' \ u039b ' 2 from the joint probability for the strongest possible pairing for f s , the source fragment f s u ' \ u2062 ' t u ' \ u2062 ' r u ' \ u2062 ' o u ' \ u2062 ' n u ' \ u2062 ' g u ' \ u2062 ' e u ' \ u2062 ' s u ' \ u2062 ' t u ' \ u2062 ' _ u ' \ u2062 ' t in Figure 1 corresponds to the best scoring translation for a given source fragment f s This metric
	Effect: effectively prunes weaker alternative translations in the phrase-translation table from being considered if there is a much stronger candidate

CASE: 11
Stag: 46 47 
	Pattern: 5 [['due', 'to']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Nevertheless , it has to be noted that even with u ' \ u039b ' 1 and u ' \ u039b ' 2 , the test set will include a certain amount of errors This is due to the nature of the unsupervised method with which the phrase-translation table is constructed
	Cause: the nature of the unsupervised method with which the phrase-translation table is constructed
	Effect: Nevertheless , it has to be noted that even with u ' \ u039b ' 1 and u ' \ u039b ' 2 , the test set will include a certain amount of errors

CASE: 12
Stag: 51 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Whilst other thresholds may possibly produce cleaner sets , this is hard to evaluate as finding optimal values causes a prohibitive increase in complexity of the search space , and again this is not necessary to test our hypothesis
	Cause: finding optimal values causes a prohibitive increase in complexity of the search space ,
	Effect: other thresholds may possibly produce cleaner sets , this is hard to evaluate

CASE: 13
Stag: 55 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: This ensures complete independence of training and test data
	Cause: This
	Effect: complete independence of training and test data

CASE: 14
Stag: 57 
	Pattern: 2 [['for', 'the'], ['reason']]---- [['&R', '(,)', '(&ADV)'], ['(&ADJ)'], ['(that)', '&C']]
	sentTXT: The fact that a phrase-translation table needs to be constructed for the test data is also the reason that the parallel corpus split from which the test data is derived has to be large enough , ensuring better quality
	Cause: the parallel corpus split from which the test data is derived has to be large enough , ensuring better quality
	Effect: The fact that a phrase-translation table needs to be constructed

CASE: 15
Stag: 59 60 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: An ideal test corpus would consist of L2 sentences with L1 fallback as crafted by L2 language learners with an L1 background However , such corpora do not exist as yet
	Cause: crafted by L2 language learners with an L1 background However , such corpora do not exist as yet
	Effect: An ideal test corpus would consist of L2 sentences with L1 fallback

CASE: 16
Stag: 63 64 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Numerous classifiers are trained and each is an expert in translating a single word or phrase In other words , for each word type or phrase type that occurs as a fragment in the training set , and which does not map to just a single translation , a classifier is trained
	Cause: a fragment in the training set ,
	Effect: Numerous classifiers are trained and each is an expert in translating a single word or phrase In other words , for each word type or phrase type that occurs

CASE: 17
Stag: 66 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Words or phrases that always map to a single translation are stored in a simple mapping table , as a classifier would have no added value in such cases
	Cause: a classifier would have no added value in such cases
	Effect: Words or phrases that always map to a single translation are stored in a simple mapping table

CASE: 18
Stag: 67 68 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The classifiers use the IB1 algorithm -LSB- -RSB- as implemented in TiMBL -LSB- -RSB- 1 1 http://ilk.uvt.nl/timbl IB1 implements k - nearest neighbour classification
	Cause: implemented in TiMBL -LSB- -RSB- 1 1 http://ilk.uvt.nl/timbl IB1 implements k -
	Effect: The classifiers use the IB1 algorithm -LSB- -RSB-

CASE: 19
Stag: 69 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The choice for this algorithm is motivated by the fact that it handles multiple classes with ease , but first and foremost because it has been successfully employed for word sense disambiguation in other studies -LSB- -RSB- , in particular in cross-lingual word sense disambiguation , a task closely resembling our current task -LSB- -RSB-
	Cause: it has been successfully employed for word sense disambiguation in other studies -LSB- -RSB- , in particular in cross-lingual word sense disambiguation , a task closely resembling our current task -LSB- -RSB-
	Effect: The choice for this algorithm is motivated by the fact that it handles multiple classes with ease , but first and foremost

CASE: 20
Stag: 77 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: When presented with test data , in which the L1 fragment is explicitly marked , we first check whether there is ambiguity for this L1 fragment and if a direct translation is available in our simple mapping table
	Cause: a direct translation is available in our simple mapping table
	Effect: presented with test data , in which the L1 fragment is explicitly marked , we first check whether there is ambiguity for this L1 fragment and

CASE: 21
Stag: 77 78 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: When presented with test data , in which the L1 fragment is explicitly marked , we first check whether there is ambiguity for this L1 fragment and if a direct translation is available in our simple mapping table If so , we are done quickly and need not rely on context information
	Cause: with test data , in which the L1 fragment is explicitly marked , we first check whether there is ambiguity for this L1 fragment and if a direct translation is available in our simple mapping table If
	Effect: we are done quickly and need not rely on context information

CASE: 22
Stag: 79 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: If not , we check for the presence of a classifier expert for the offered L1 fragment ; only then we can proceed by extracting the desired number of L2 local context words to the immediate left and right of this fragment and adding those to the feature vector
	Cause: not , we check for the presence of a classifier expert for the offered L1 fragment ; only
	Effect: we can proceed by extracting the desired number of L2 local context words to the immediate left and right of this fragment and adding those to the feature vector

CASE: 23
Stag: 79 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: we can proceed by extracting the desired number of L2 local context words to the immediate left and right of this fragment and adding those to the feature vector
	Cause: extracting the desired number of L2 local context words to the immediate left and right of this fragment and adding those to the feature vector
	Effect: we can proceed

CASE: 24
Stag: 85 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The experiments however showed that inclusion of such keywords did not make any noticeable impact on any of the results , so we restrict ourselves to mentioning this negative result
	Cause: The experiments however showed that inclusion of such keywords did not make any noticeable impact on any of the results
	Effect: we restrict ourselves to mentioning this negative result

CASE: 25
Stag: 86 87 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Our full system , including the scripts for data preparation , training , and evaluation , is implemented in Python and freely available as open-source from http://github.com/proycon/colibrita/ Version tag v0 .2.1 is representative for the version used in this research
	Cause: open-source from http://github.com/proycon/colibrita/ Version tag v0 .2.1 is representative for the version used in this
	Effect: Our full system , including the scripts for data preparation , training , and evaluation , is implemented in Python and freely available

CASE: 26
Stag: 89 90 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The language model is a trigram-based back-off language model with Kneser-Ney smoothing , computed using SRILM -LSB- -RSB- and trained on the same training data as the translation model No additional external data was brought in , to keep the comparison fair
	Cause: the translation model No additional external data was brought in , to keep the comparison
	Effect: The language model is a trigram-based back-off language model with Kneser-Ney smoothing , computed using SRILM -LSB- -RSB- and trained on the same training data

CASE: 27
Stag: 92 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: We do so by normalising the class probability from the classifier -LRB- s u ' \ u2062 ' c u ' \ u2062 ' o u ' \ u2062 ' r u ' \ u2062 ' e T u ' \ u2062 ' -LRB- H -RRB- -RRB- , which is our translation model , and the language model -LRB- s u ' \ u2062 ' c u ' \ u2062 ' o u ' \ u2062 ' r u ' \ u2062 ' e l u ' \ u2062 ' m u ' \ u2062 ' -LRB- H -RRB- -RRB- , in such a way that the highest classifier score for the alternatives under consideration is always 1.0 , and the highest language model score of the sentence is always 1.0
	Cause: We do
	Effect: by normalising the class probability from the classifier -LRB- s u ' \ u2062 ' c u ' \ u2062 ' o u ' \ u2062 ' r u ' \ u2062 ' e T u ' \ u2062 ' -LRB- H -RRB- -RRB- , which is our translation model , and the language model -LRB- s u ' \ u2062 ' c u ' \ u2062 ' o u ' \ u2062 ' r u ' \ u2062 ' e l u ' \ u2062 ' m u ' \ u2062 ' -LRB- H -RRB- -RRB- , in such a way that the highest classifier score for the alternatives under consideration is always 1.0 , and the highest language model score of the sentence is always

CASE: 28
Stag: 92 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: by normalising the class probability from the classifier -LRB- s u ' \ u2062 ' c u ' \ u2062 ' o u ' \ u2062 ' r u ' \ u2062 ' e T u ' \ u2062 ' -LRB- H -RRB- -RRB- , which is our translation model , and the language model -LRB- s u ' \ u2062 ' c u ' \ u2062 ' o u ' \ u2062 ' r u ' \ u2062 ' e l u ' \ u2062 ' m u ' \ u2062 ' -LRB- H -RRB- -RRB- , in such a way that the highest classifier score for the alternatives under consideration is always 1.0 , and the highest language model score of the sentence is always
	Cause: normalising the class probability from the classifier -LRB- s u ' \ u2062 ' c u ' \ u2062 ' o u ' \ u2062 ' r u ' \ u2062 ' e T u ' \ u2062 ' -LRB- H -RRB- -RRB- , which is our translation model , and the language model -LRB- s u ' \ u2062 ' c u ' \ u2062 ' o u ' \ u2062 ' r u ' \ u2062 ' e l u ' \ u2062 ' m u ' \ u2062 ' -LRB- H -RRB- -RRB-
	Effect: , in such a way that the highest classifier score for the alternatives under consideration is always 1.0 , and the highest language model score of the sentence is always

CASE: 29
Stag: 97 98 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We first measure absolute accuracy by simply counting all output fragments that exactly match the reference fragments , as a fraction of the total amount of fragments This measure may be too strict , so we add a more flexible word accuracy measure which takes into account partial matches at the word level
	Cause: a fraction of the total amount of fragments This measure may be too strict , so we add a more flexible word accuracy measure which takes into account partial matches at the word
	Effect: We first measure absolute accuracy by simply counting all output fragments that exactly match the reference fragments

CASE: 30
Stag: 98 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: This measure may be too strict , so we add a more flexible word accuracy measure which takes into account partial matches at the word level
	Cause: This measure may be too strict
	Effect: we add a more flexible word accuracy measure which takes into account partial matches at the word level

CASE: 31
Stag: 99 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: If output o is a subset of reference r then a score of o r is assigned for that sentence pair
	Cause: output o is a subset of reference r
	Effect: a score of o r is assigned for that sentence pair

CASE: 32
Stag: 100 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: If instead , r is a subset of o , then a score of r o will be assigned
	Cause: instead , r is a subset of o
	Effect: a score of r o will be assigned

CASE: 33
Stag: 102 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The word accuracy for the entire set is then computed by taking the sum of the word accuracies per sentence pair , divided by the total number of sentence pairs
	Cause: taking the sum of the word accuracies per sentence pair , divided by the total number of sentence pairs
	Effect: The word accuracy for the entire set is then computed

CASE: 34
Stag: 109 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The baseline selects the most probable L1 fragment per L2 fragment according to the phrase-translation table
	Cause: the phrase-translation table
	Effect: The baseline selects the most probable L1 fragment per L2 fragment

CASE: 35
Stag: 109 110 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The baseline selects the most probable L1 fragment per L2 fragment according to the phrase-translation table This baseline , henceforth referred to as the u ' \ u2019 ' most likely fragment u ' \ u2019 ' baseline -LRB- MLF -RRB- is analogous to the u ' \ u2019 ' most frequent sense u ' \ u2019 ' - baseline common in evaluating WSD systems
	Cause: the u ' \ u2019 ' most likely fragment u ' \ u2019 ' baseline -LRB- MLF -RRB- is analogous to the u ' \ u2019 ' most frequent sense u ' \ u2019 ' - baseline common in evaluating WSD systems
	Effect: The baseline selects the most probable L1 fragment per L2 fragment according to the phrase-translation table This baseline , henceforth referred to

CASE: 36
Stag: 111 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: A second baseline was constructed by weighing the probabilities from the translation table directly with the L2 language model described earlier
	Cause: weighing the probabilities from the translation table directly with the L2 language model described earlier
	Effect: A second baseline was constructed

CASE: 37
Stag: 121 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This number is much larger than the 200 , 000 we mentioned before because single sentence pairs may be reused multiple times with different marked fragments
	Cause: single sentence pairs may be reused multiple times with different marked fragments
	Effect: This number is much larger than the 200 , 000 we mentioned before

CASE: 38
Stag: 125 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Among the classifier experts are only words and phrases that are ambiguous and may thus map to multiple translations
	Cause: Among the classifier experts are only words and phrases that are ambiguous and may
	Effect: map to multiple translations

CASE: 39
Stag: 125 126 
	Pattern: 0 [[['imply', 'implies', 'implied', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(that)', '&R@Complete@']]
	sentTXT: Among the classifier experts are only words and phrases that are ambiguous and may thus map to multiple translations This implies that such words and phrases must have occurred at least twice in the corpus , though this threshold is made configurable and could have been set higher to limit the number of classifiers
	Cause: Among the classifier experts are only words and phrases that are ambiguous and may thus map to multiple translations
	Effect: such words and phrases must have occurred at least twice in the corpus , though this threshold is made configurable and could have been set higher to limit the number of classifiers

CASE: 40
Stag: 137 138 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This shall be further discussed in Section 6.1 As expected , the LM baseline substantially outperforms the context-insensitive MLF baseline
	Cause: expected , the LM baseline substantially outperforms the context-insensitive MLF baseline
	Effect: This shall be further discussed in Section 6.1

CASE: 41
Stag: 140 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Third , we observe that adding the language model to our classifier leads to another significant gain -LRB- configuration l1r1 + LM in the results in Table 2
	Cause: adding the language model to our classifier
	Effect: another significant gain -LRB- configuration l1r1 + LM in the results in Table 2

CASE: 42
Stag: 148 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Conclusions with regard to context width may have to be tempered somewhat , as the performance of the l1r1 configuration was found to not be significantly better than that of the l2r2 configuration
	Cause: the performance of the l1r1 configuration was found to not be significantly better than that of the l2r2 configuration
	Effect: Conclusions with regard to context width may have to be tempered somewhat

CASE: 43
Stag: 195 196 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: This intuitively makes sense ; a context of one may seem to be better than any other when uniformly applied to all classifier experts , but it may well be that certain classifiers benefit from different feature selections We therefore proceed with this line of investigation as well
	Cause: intuitively makes sense ; a context of one may seem to be better than any other when uniformly applied to all classifier experts , but it may well be that certain classifiers benefit from different feature selections We
	Effect: proceed with this line of investigation as well

CASE: 44
Stag: 197 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Automatic configuration selection was done by performing leave-one-out testing -LRB- for small number of instances -RRB- or 10-fold-cross validation -LRB- for larger number of instances , n u ' \ u2265 ' 20 -RRB- on the training data per classifier expert
	Cause: performing leave-one-out testing -LRB- for small number of instances -RRB- or 10-fold-cross validation -LRB- for larger number of instances , n u ' \ u2265 ' 20 -RRB- on the training data per classifier expert
	Effect: Automatic configuration selection was done

CASE: 45
Stag: 199 200 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Per classifier expert , the best scoring configuration was selected , referred to as the auto configuration in Table 2 The auto configuration improves results over the uniformly applied feature selection
	Cause: the auto configuration in Table 2 The auto configuration improves results over the uniformly applied feature
	Effect: Per classifier expert , the best scoring configuration was selected , referred to

CASE: 46
Stag: 201 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However , if we enable the language model as we do in the auto + LM configuration we do not notice an improvement over l1r1 + LM , surprisingly
	Cause: we do in the auto + LM configuration we do not notice an improvement over l1r1 + LM , surprisingly
	Effect: we enable the language model

CASE: 47
Stag: 204 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: A context size of one prevails in the vast majority of cases , which is not surprising considering the good results we have already seen with this configuration
	Cause: A context size of one prevails in the vast majority of cases , which is not surprising considering
	Effect: configuration

CASE: 48
Stag: 207 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: In earlier work , we reported a decrease in performance due to overfitting when this is done , so we do not expect it to make a positive impact
	Cause: In earlier work , we reported a decrease in performance due to overfitting when this is done
	Effect: we do not expect it to make a positive impact

CASE: 49
Stag: 213 214 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: In order to draw accurate conclusions , experiments on a single data set and language pair are not sufficient We therefore conducted a number of experiments with other language pairs , and present the abridged results in Table 6
	Cause: order to draw accurate conclusions , experiments on a single data set and language pair are not sufficient We
	Effect: conducted a number of experiments with other language pairs , and present the abridged results in Table 6

CASE: 50
Stag: 216 217 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We see that the language model baseline for English u ' \ u2192 ' French shows the same substantial improvement over the baseline as our English u ' \ u2192 ' Spanish results The same holds for the Chinese u ' \ u2192 ' English experiment
	Cause: our English u ' \ u2192 ' Spanish results The same holds for the Chinese u ' \ u2192 ' English
	Effect: We see that the language model baseline for English u ' \ u2192 ' French shows the same substantial improvement over the baseline

CASE: 51
Stag: 223 224 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: The error rate metrics show improvement as well We therefore attach low importance to this deviation in BLEU here
	Cause: error rate metrics show improvement as well We
	Effect: attach low importance to this deviation in BLEU here

CASE: 52
Stag: 225 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: In all of the aforementioned experiments , the system produced a single solution for each of the fragments , the one it deemed best , or no solution at all if it could not find any
	Cause: it could not find any
	Effect: In all of the aforementioned experiments , the system produced a single solution for each of the fragments , the one it deemed best , or no solution at all

CASE: 53
Stag: 228 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: In all of our experiments recall is high -LRB- well above 90 u ' \ u2062 ' % -RRB- , mostly because train and test data lie in the same domain and have been generated in the same fashion , lower recall is expected with more real-world data
	Cause: train and test data lie in the same domain and have been generated in the same fashion
	Effect: lower recall is expected with more real-world data

CASE: 54
Stag: 238 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: There are more NLP components that might play a role if such a system were to find practical application
	Cause: such a system were to find practical application
	Effect: There are more NLP components that might play a role

CASE: 55
Stag: 242 243 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Our classification-based approach may be able to resolve some of these cases operating as an add-on to a regular MT system u ' \ u2013 ' or as a independent post-correction system Our system allows L1 fragments to be of arbitrary length
	Cause: an add-on to a regular MT system u ' \ u2013 ' or as a independent post-correction system Our system allows L1 fragments to be of arbitrary
	Effect: Our classification-based approach may be able to resolve some of these cases operating

CASE: 56
Stag: 244 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: If a fragment was not seen during training stage , and is therefore not covered by a classifier expert , then the system will be unable to translate it
	Cause: If a fragment was not seen during training stage , and is
	Effect: not covered by a classifier expert , then the system will be unable to translate it

CASE: 57
Stag: 244 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If a fragment was not seen during training stage , and is
	Cause: a fragment was not seen during training stage
	Effect: and is

CASE: 58
Stag: 245 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Nevertheless , if a longer L1 fragment can be decomposed into subfragments that are known , then some recombination of the translations of said sub-fragments may be a good translation for the whole
	Cause: a longer L1 fragment can be decomposed into subfragments that are known
	Effect: then some recombination of the translations of said sub-fragments may be a good translation for the whole

