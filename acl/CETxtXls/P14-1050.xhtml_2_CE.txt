************************************************************
P14-1050.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 21 22 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the previous example , u ' \ u201d ' u ' \ u7ed9 ' u ' \ u529b ' -LRB- cool ; powerful -RRB- u ' \ u201d ' is a strong feature for classification models while each single character is not Adding new words as feature in classification models will improve the performance of polarity classification , as demonstrated later in this paper
	Cause: feature in classification models will improve the performance of polarity classification , as demonstrated later in this paper
	Effect: the previous example , u ' \ u201d ' u ' \ u7ed9 ' u ' \ u529b ' -LRB- cool ; powerful -RRB- u ' \ u201d ' is a strong feature for classification models while each single character is not Adding new words

CASE: 1
Stag: 27 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Moreover , existing lexical resources never have adequate and timely coverage since new words appear constantly
	Cause: new words appear constantly
	Effect: Moreover , existing lexical resources never have adequate and timely coverage

CASE: 2
Stag: 27 28 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Moreover , existing lexical resources never have adequate and timely coverage since new words appear constantly People thus resort to statistical methods such as Pointwise Mutual Information -LSB- 6 -RSB- , Symmetrical Conditional Probability -LSB- 7 -RSB- , Mutual Expectation -LSB- 8 -RSB- , Enhanced Mutual Information -LSB- 22 -RSB- , and Multi-word Expression Distance -LSB- 2 -RSB-
	Cause: , existing lexical resources never have adequate and timely coverage since new words appear constantly People
	Effect: resort to statistical methods such as Pointwise Mutual Information -LSB- 6 -RSB- , Symmetrical Conditional Probability -LSB- 7 -RSB- , Mutual Expectation -LSB- 8 -RSB- , Enhanced Mutual Information -LSB- 22 -RSB- , and Multi-word Expression Distance -LSB- 2 -RSB-

CASE: 3
Stag: 40 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We will describe the proposed method in Section 3 , including definitions , the overview of the algorithm , and the statistical measures for addressing the two key issues
	Cause: addressing the two key issues
	Effect: We will describe the proposed method in Section 3 , including definitions , the overview of the algorithm , and the statistical measures

CASE: 4
Stag: 44 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In these works , new word detection is considered as an integral part of segmentation , where new words are identified as the most probable segments inferred by the probabilistic models ; and the detected new word can be further used to improve word segmentation
	Cause: an integral part of segmentation , where new words are identified as the most probable segments inferred by the probabilistic models ; and the detected new word can be further used to improve word
	Effect: In these works , new word detection is considered

CASE: 5
Stag: 44 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: an integral part of segmentation , where new words are identified as the most probable segments inferred by the probabilistic models ; and the detected new word can be further used to improve word
	Cause: the most probable segments inferred by the probabilistic
	Effect: new words are identified

CASE: 6
Stag: 45 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Typical models include conditional random fields proposed by -LSB- 14 -RSB- , and a joint model trained with adaptive online gradient descent based on feature frequency information -LSB- 18 -RSB-
	Cause: feature frequency information -LSB- 18 -RSB-
	Effect: Typical models include conditional random fields proposed by -LSB- 14 -RSB- , and a joint model trained with adaptive online gradient descent

CASE: 7
Stag: 46 47 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Another line is to treat new word detection as a separate task , usually preceded by part-of-speech tagging The first genre of such studies is to leverage complex linguistic rules or knowledge
	Cause: a separate task , usually preceded by part-of-speech tagging The first genre of such studies is to leverage complex linguistic rules or
	Effect: Another line is to treat new word detection

CASE: 8
Stag: 52 53 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The second genre of the studies is to treat new word detection as a classification problem Zhou -LSB- 25 -RSB- proposed a discriminative Markov Model to detect new words by chunking one or more separated words
	Cause: a classification problem Zhou -LSB- 25 -RSB- proposed a discriminative Markov Model to detect new words by chunking one or more separated
	Effect: The second genre of the studies is to treat new word detection

CASE: 9
Stag: 54 55 
	Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
	sentTXT: In -LSB- 12 -RSB- , new word detection was viewed as a binary classification problem However , these supervised models requires not only heavy engineering of linguistic features , but also expensive annotation of training data
	Cause: not only heavy engineering of linguistic features , but also expensive annotation of training data
	Effect: -LSB- 12 -RSB- , new word detection was viewed as a binary classification problem However

CASE: 10
Stag: 56 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: User behavior data has recently been explored for finding new words
	Cause: finding new words
	Effect: User behavior data has recently been explored

CASE: 11
Stag: 61 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: However , both of the work are limited due to the public unavailability of expensive commercial resources
	Cause: the public unavailability of expensive commercial resources
	Effect: However , both of the work are limited

CASE: 12
Stag: 63 64 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In this setting , new word detection is mostly known as multi-word expression extraction To measure multi-word association , the first model is Pointwise Mutual Information -LRB- PMI -RRB- -LSB- 6 -RSB-
	Cause: multi-word expression extraction To measure multi-word association ,
	Effect: In this setting , new word detection is mostly known

CASE: 13
Stag: 64 65 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: To measure multi-word association , the first model is Pointwise Mutual Information -LRB- PMI -RRB- -LSB- 6 -RSB- Since then , a variety of statistical methods have been proposed to measure b u ' \ u2062 ' i - gram association , such as Log-likelihood -LSB- 9 -RSB- and Symmetrical Conditional Probability -LRB- SCP -RRB- -LSB- 7 -RSB-
	Cause: then , a variety of statistical methods have been proposed to measure b u ' \ u2062 ' i - gram association , such as Log-likelihood -LSB- 9 -RSB- and Symmetrical Conditional Probability -LRB- SCP -RRB- -LSB- 7 -RSB-
	Effect: To measure multi-word association , the first model is Pointwise Mutual Information -LRB- PMI -RRB- -LSB- 6 -RSB-

CASE: 14
Stag: 67 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: In order to measure arbitrary n - grams , most common strategies are to separate n - gram into two parts X and Y so that existing b u ' \ u2062 ' i - gram methods can be used -LSB- 7 , 8 , 16 -RSB-
	Cause: In order to measure arbitrary n - grams , most common strategies are to separate n - gram into two parts X and Y
	Effect: existing b u ' \ u2062 ' i - gram methods can be used -LSB- 7 , 8 , 16 -RSB-

CASE: 15
Stag: 74 75 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: In Chinese , such words are like u ' \ u201d ' u ' \ u7740 ' , u ' \ u4e86 ' , u ' \ u5566 ' , u ' \ u7684 ' , u ' \ u554a ' u ' \ u201d ' , and punctuation marks include u ' \ u201d ' u ' \ uff0c ' u ' \ u3002 ' u ' \ uff01 ' u ' \ uff1f ' u ' \ uff1b ' u ' \ uff1a ' u ' \ u201d ' and so on A lexical pattern is a triplet A D , * , A U , where A u ' \ u2062 ' D is an adverbial word , the wildcard * means an arbitrary number of words 1 1 We set the number to 3 words in this work considering computation costs and A u ' \ u2062 ' U denotes an auxiliary word
	Cause: In Chinese , such words are like u ' \ u201d ' u ' \ u7740 ' , u ' \ u4e86 ' , u ' \ u5566 ' , u ' \ u7684 ' , u ' \ u554a ' u ' \ u201d ' , and punctuation marks include u ' \ u201d ' u ' \ uff0c ' u ' \ u3002 ' u ' \ uff01 ' u ' \ uff1f ' u ' \ uff1b ' u ' \ uff1a ' u ' \ u201d '
	Effect: punctuation marks include u ' \ u201d ' u ' \ uff0c ' u ' \ u3002 ' u ' \ uff01 ' u ' \ uff1f ' u ' \ uff1b ' u ' \ uff1a ' u ' \ u201d ' and so on A lexical pattern is a triplet A D , * , A U , where A u ' \ u2062 ' D is an adverbial word , the wildcard * means an arbitrary number of words 1 1 We set the number to 3 words in this work considering computation costs and A u ' \ u2062 ' U denotes an auxiliary

CASE: 16
Stag: 77 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: In order to obtain lexical patterns , we can define regular expressions with POS tags 2 2 Such expressions are very simple and easy to write because we only need to consider POS tags of adverbial and auxiliary word and apply the regular expressions on POS tagged texts
	Cause: we only need to consider POS tags of adverbial and auxiliary word and apply the regular expressions on POS tagged texts
	Effect: In order to obtain lexical patterns , we can define regular expressions with POS tags 2 2 Such expressions are very simple and easy to write

CASE: 17
Stag: 78 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the tags of adverbial and auxiliary words are relatively static and can be easily identified , such a method can safely obtain lexical patterns
	Cause: the tags of adverbial and auxiliary words are relatively static and can be easily identified
	Effect: such a method can safely obtain lexical patterns

CASE: 18
Stag: 83 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Note that we do not augment the pattern set -LRB- u ' \ ud835 ' u ' \ udcab ' -RRB- at each iteration , instead , we keep a fixed small number of patterns during iteration because this strategy produces optimal results
	Cause: this strategy produces optimal results
	Effect: Note that we do not augment the pattern set -LRB- u ' \ ud835 ' u ' \ udcab ' -RRB- at each iteration , instead , we keep a fixed small number of patterns during iteration

CASE: 19
Stag: 84 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: From linguistic perspectives , new sentiment words are commonly modified by adverbial words and thus can be extracted by lexical patterns
	Cause: From linguistic perspectives , new sentiment words are commonly modified by adverbial words
	Effect: can be extracted by lexical patterns

CASE: 20
Stag: 84 85 
	Pattern: 10 [['the'], [['reason', 'reasons'], 'why']]---- [['&C', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&OF)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: From linguistic perspectives , new sentiment words are commonly modified by adverbial words and thus can be extracted by lexical patterns This is the reason why the algorithm will work
	Cause: From linguistic perspectives , new sentiment words are commonly modified by adverbial words and thus can be extracted by lexical patterns
	Effect: the algorithm will work

CASE: 21
Stag: 96 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In our problem , LRT computes a contingency table of a pattern p and a word w , derived from the corpus statistics , as given in Table 3 , where k 1 u ' \ u2062 ' -LRB- w , p -RRB- is the number of documents that w matches pattern p , k 2 u ' \ u2062 ' -LRB- w , p -RRB- is the number of documents that w occurs while p does not , k 3 u ' \ u2062 ' -LRB- w , p -RRB- is the number of documents that p occurs while w does not , and k 4 u ' \ u2062 ' -LRB- w , p -RRB- is the number of documents containing neither p nor w
	Cause: given in Table 3 , where k 1 u ' \ u2062 ' -LRB- w , p -RRB- is the number of documents that w matches pattern p , k 2 u ' \ u2062 ' -LRB- w , p -RRB- is the number of documents that w occurs while p does not , k 3 u ' \ u2062 ' -LRB- w , p -RRB- is the number of documents that p occurs while w does not
	Effect: In our problem , LRT computes a contingency table of a pattern p and a word w , derived from the corpus statistics

CASE: 22
Stag: 97 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on the statistics shown in Table 3 , the likelihood ratio tests -LRB- LRT -RRB- model captures the statistical association between a pattern p and a word w by employing the following formula
	Cause: the statistics shown in Table 3
	Effect: the likelihood ratio tests -LRB- LRT -RRB- model captures the statistical association between a pattern p and a word w by employing the following formula

CASE: 23
Stag: 97 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: the likelihood ratio tests -LRB- LRT -RRB- model captures the statistical association between a pattern p and a word w by employing the following formula
	Cause: employing the following formula
	Effect: the likelihood ratio tests -LRB- LRT -RRB- model captures the statistical association between a pattern p and a word w

CASE: 24
Stag: 99 100 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: L u ' \ u2062 ' -LRB- u ' \ u03a1 ' , k , n -RRB- = u ' \ u03a1 ' k * -LRB- 1 - u ' \ u03a1 ' -RRB- n - k ; n 1 = k 1 + k 3 ; n 2 = k 2 + k 4 ; u ' \ u03a1 ' 1 = k 1 / n 1 ; u ' \ u03a1 ' 2 = k 2 / n 2 ; u ' \ u03a1 ' = -LRB- k 1 + k 2 -RRB- / -LRB- n 1 + n 2 -RRB- Thus , the utility of a pattern can be measured as follows
	Cause: L u ' \ u2062 ' -LRB- u ' \ u03a1 ' , k , n -RRB- = u ' \ u03a1 ' k * -LRB- 1 - u ' \ u03a1 ' -RRB- n - k ; n 1 = k 1 + k 3 ; n 2 = k 2 + k 4 ; u ' \ u03a1 ' 1 = k 1 / n 1 ; u ' \ u03a1 ' 2 = k 2 / n 2 ; u ' \ u03a1 ' = -LRB- k 1 + k 2 -RRB- / -LRB- n 1 + n 2 -RRB-
	Effect: , the utility of a pattern can be measured as follows

CASE: 25
Stag: 108 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: This has linguistic interpretations because new sentiment words are commonly modified by adverbial words and thus should have close association with lexical patterns
	Cause: This has linguistic interpretations because new sentiment words are commonly modified by adverbial words
	Effect: should have close association with lexical patterns

CASE: 26
Stag: 108 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This has linguistic interpretations because new sentiment words are commonly modified by adverbial words
	Cause: new sentiment words are commonly modified by adverbial words
	Effect: This has linguistic interpretations

CASE: 27
Stag: 110 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: If a candidate word is a new word , it will be more commonly used with diversified lexical patterns since the non-compositionality of new word means that the word can be used in many different linguistic scenarios
	Cause: the non-compositionality of new word means that the word can be used in many different linguistic scenarios
	Effect: If a candidate word is a new word , it will be more commonly used with diversified lexical patterns

CASE: 28
Stag: 110 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If a candidate word is a new word , it will be more commonly used with diversified lexical patterns
	Cause: a candidate word is a new word
	Effect: it will be more commonly used with diversified lexical patterns

CASE: 29
Stag: 113 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Note that we use u ' \ ud835 ' u ' \ udcab ' c , instead of u ' \ ud835 ' u ' \ udcab ' , because the latter set is very small while computing entropy needs a large number of patterns
	Cause: the latter set is very small while computing entropy needs a large number of patterns
	Effect: Note that we use u ' \ ud835 ' u ' \ udcab ' c , instead of u ' \ ud835 ' u ' \ udcab '

CASE: 30
Stag: 116 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: For example , u ' \ u201d ' u ' \ u7231 ' u ' \ u5403 ' -LRB- love to eat -RRB- u ' \ u201d ' and u ' \ u201d ' u ' \ u7231 ' u ' \ u8bf4 ' -LRB- love to talk -RRB- u ' \ u201d ' can be matched by many lexical patterns , however , they are not new words due to the lack of non-compositionality
	Cause: the lack of non-compositionality
	Effect: For example , u ' \ u201d ' u ' \ u7231 ' u ' \ u5403 ' -LRB- love to eat -RRB- u ' \ u201d ' and u ' \ u201d ' u ' \ u7231 ' u ' \ u8bf4 ' -LRB- love to talk -RRB- u ' \ u201d ' can be matched by many lexical patterns , however , they are not new words

CASE: 31
Stag: 117 118 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In such words , each single character has high probability to be a word Thus , we design the following measure to favor this observation
	Cause: In such words , each single character has high probability to be a word
	Effect: , we design the following measure to favor this observation

CASE: 32
Stag: 119 120 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where w = w 1 u ' \ u2062 ' w 2 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' w n , each w i is a single character , and p u ' \ u2062 ' -LRB- w i -RRB- is the probability of the character w i being a word , as computed as follows where a u ' \ u2062 ' l u ' \ u2062 ' l u ' \ u2062 ' -LRB- w i -RRB- is the total frequency of w i , and s u ' \ u2062 ' -LRB- w i -RRB- is the frequency of w i being a single character word
	Cause: computed as follows where a u ' \ u2062 ' l u ' \ u2062 ' l u ' \ u2062 ' -LRB- w i -RRB- is the total frequency of w i ,
	Effect: 1 u ' \ u2062 ' w 2 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' w n , each w i is a single character , and p u ' \ u2062 ' -LRB- w i -RRB- is the probability of the character w i being a word

CASE: 33
Stag: 123 124 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: New words are usually multi-word expressions , where a variety of statistical measures have been proposed to detect multi-word expressions Thus , such measures can be naturally incorporated into our algorithm
	Cause: New words are usually multi-word expressions , where a variety of statistical measures have been proposed to detect multi-word expressions
	Effect: , such measures can be naturally incorporated into our algorithm

CASE: 34
Stag: 130 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: where u ' \ u039c ' u ' \ u2062 ' -LRB- w -RRB- is the set of documents in which all single words in w = w 1 u ' \ u2062 ' w 2 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' w n co-occur , u ' \ u03a6 ' u ' \ u2062 ' -LRB- w -RRB- is the set of documents in which word w occurs as a whole , and N is the total number of documents
	Cause: a whole , and N is the total number of
	Effect: u ' \ u039c ' u ' \ u2062 ' -LRB- w -RRB- is the set of documents in which all single words in w = w 1 u ' \ u2062 ' w 2 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' w n co-occur , u ' \ u03a6 ' u ' \ u2062 ' -LRB- w -RRB- is the set of documents in which word w occurs

CASE: 35
Stag: 131 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Different from EMI , this measure is a strict distance metric , meaning that a smaller value indicates a larger possibility of being a multi-word expression
	Cause: Different from EMI
	Effect: this measure is a strict distance metric , meaning that a smaller value indicates a larger possibility of being a multi-word expression

CASE: 36
Stag: 131 132 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Different from EMI , this measure is a strict distance metric , meaning that a smaller value indicates a larger possibility of being a multi-word expression As can be seen from the formula , the key idea of this metric is to compute the ratio of the co-occurrence of all words in a multi-word expressions to the occurrence of the whole expression
	Cause: can be seen from the formula , the key idea of this metric is to compute the ratio of the co-occurrence of all words in a multi-word expressions to the occurrence of the whole expression
	Effect: Different from EMI , this measure is a strict distance metric , meaning that a smaller value indicates a larger possibility of being a multi-word expression

CASE: 37
Stag: 133 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Taking into account the aforementioned factors , we have different settings to score a new word , as follows
	Cause: Taking into account the aforementioned factors
	Effect: we have different settings to score a new word , as follows

CASE: 38
Stag: 140 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If there is a disagreement on either of the two tasks , discussions are required to make the final decision
	Cause: there is a disagreement on either of the two tasks
	Effect: discussions are required to make the final decision

CASE: 39
Stag: 141 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: The annotation led to 323 new words , among which there are 116 positive words , 112 negative words , and 95 neutral words 3 3 All the resources are available upon request
	Cause: The annotation
	Effect: 323 new words , among which there are 116 positive words , 112 negative words , and 95 neutral words 3 3 All the resources are available upon request

CASE: 40
Stag: 141 142 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The annotation led to 323 new words , among which there are 116 positive words , 112 negative words , and 95 neutral words 3 3 All the resources are available upon request As our algorithm outputs a ranked list of words , we adapt average precision to evaluate the performance of new sentiment word detection
	Cause: our algorithm outputs a ranked list of words , we adapt average precision to evaluate the performance of new sentiment word detection
	Effect: The annotation led to 323 new words , among which there are 116 positive words , 112 negative words , and 95 neutral words 3 3 All the resources are available upon request

CASE: 41
Stag: 144 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: where P u ' \ u2062 ' -LRB- k -RRB- is the precision at cut-off k , r u ' \ u2062 ' e u ' \ u2062 ' l u ' \ u2062 ' -LRB- k -RRB- is 1 if the word at position k is a new word and 0 otherwise , and K is the number of words in the ranked list
	Cause: the word at position k is a new word and 0 otherwise , and
	Effect: where P u ' \ u2062 ' -LRB- k -RRB- is the precision at cut-off k , r u ' \ u2062 ' e u ' \ u2062 ' l u ' \ u2062 ' -LRB- k -RRB- is 1

CASE: 42
Stag: 146 147 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First , we assess the influence of likelihood ratio test , which measures the association of a word to the pattern set As can be seen from Table 4 , the association model -LRB- LRT -RRB- remarkably boosts the performance of new word detection , indicating LRT is a key factor for new sentiment word extraction
	Cause: can be seen from Table 4 , the association model -LRB- LRT -RRB- remarkably boosts the performance of new word detection , indicating LRT is a key factor for new sentiment word extraction
	Effect: First , we assess the influence of likelihood ratio test , which measures the association of a word to the pattern set

CASE: 43
Stag: 148 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: From linguistic perspectives , new sentiment words are commonly modified by adverbial words and thus should have close association with lexical patterns
	Cause: From linguistic perspectives , new sentiment words are commonly modified by adverbial words
	Effect: should have close association with lexical patterns

CASE: 44
Stag: 151 152 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The results are shown in Figure 1 As can be seen , all the proposed measures outperform the two baselines -LRB- E u ' \ u2062 ' M u ' \ u2062 ' I and N u ' \ u2062 ' M u ' \ u2062 ' E u ' \ u2062 ' D -RRB- remarkably and consistently
	Cause: can be seen , all the proposed measures outperform the two baselines -LRB- E u ' \ u2062 '
	Effect: The results are shown in Figure 1

CASE: 45
Stag: 154 155 
	Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
	sentTXT: Adding N u ' \ u2062 ' M u ' \ u2062 ' E u ' \ u2062 ' D or E u ' \ u2062 ' M u ' \ u2062 ' I leads to remarkable improvements because of their capability of measuring non-compositionality of new words Only using L u ' \ u2062 ' R u ' \ u2062 ' T can obtain a fairly good results when K is small , however , the performance drops sharply because it u ' \ u2019 ' s unable to measure non-compositionality
	Cause: Adding N u ' \ u2062 ' M u ' \ u2062 ' E u ' \ u2062 ' D or E u ' \ u2062 ' M u ' \ u2062 ' I leads to remarkable improvements
	Effect: Only using L u ' \ u2062 ' R u ' \ u2062 ' T can obtain a fairly good results when K is small , however , the performance drops sharply because it u ' \ u2019 ' s unable to measure non-compositionality

CASE: 46
Stag: 155 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Only using L u ' \ u2062 ' R u ' \ u2062 ' T can obtain a fairly good results when K is small , however , the performance drops sharply because it u ' \ u2019 ' s unable to measure non-compositionality
	Cause: it u ' \ u2019 ' s unable to measure non-compositionality
	Effect: Only using L u ' \ u2062 ' R u ' \ u2062 ' T can obtain a fairly good results when K is small , however , the performance drops sharply

CASE: 47
Stag: 161 162 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The measure setting we take here is F N u ' \ u2062 ' M u ' \ u2062 ' E u ' \ u2062 ' D u ' \ u2062 ' -LRB- w -RRB- , as shown in Formula -LRB- 12 Again , we choose only one seed word u ' \ u201d ' u ' \ u5751 ' u ' \ u7239 ' -LRB- reverse one u ' \ u2019 ' s expectation -RRB- u ' \ u201d ' , and the number of words returned is set to K = 300
	Cause: shown in Formula -LRB- 12 Again , we choose only one seed word u ' \ u201d ' u ' \ u5751 ' u ' \ u7239 ' -LRB- reverse one u ' \ u2019 ' s expectation -RRB- u ' \ u201d ' , and the number of words returned is set to K =
	Effect: The measure setting we take here is F N u ' \ u2062 ' M u ' \ u2062 ' E u ' \ u2062 ' D u ' \ u2062 ' -LRB- w -RRB-

CASE: 48
Stag: 164 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Note that at the early stage of Algorithm 1 , larger k p -LRB- perhaps with noisy patterns -RRB- may lead to lower quality of new words ; while larger k w -LRB- perhaps with noisy seed words -RRB- may lead to lower quality of lexical patterns
	Cause: larger k w -LRB- perhaps with noisy seed words -RRB-
	Effect: lower quality of lexical patterns

CASE: 49
Stag: 164 165 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Note that at the early stage of Algorithm 1 , larger k p -LRB- perhaps with noisy patterns -RRB- may lead to lower quality of new words ; while larger k w -LRB- perhaps with noisy seed words -RRB- may lead to lower quality of lexical patterns Therefore , we choose the optimal setting to small numbers , as k p = 5 , k w = 10
	Cause: Note that at the early stage of Algorithm 1 , larger k p -LRB- perhaps with noisy patterns -RRB- may lead to lower quality of new words ; while larger k w -LRB- perhaps with noisy seed words -RRB- may lead to lower quality of lexical patterns
	Effect: we choose the optimal setting to small numbers , as k p = 5 , k w = 10

CASE: 50
Stag: 171 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By looking into the pattern set and the selected words at each iteration , we found that the pattern set -LRB- u ' \ ud835 ' u ' \ udcab ' -RRB- converges soon to the same set after a few iterations ; and at the beginning several iterations , the selected words are almost the same although the order of adding the words is different
	Cause: looking into the pattern set and the selected words at each iteration
	Effect: , we found that the pattern set -LRB- u ' \ ud835 ' u ' \ udcab ' -RRB- converges soon to the same set after a few iterations ; and at the beginning several iterations , the selected words are almost the same although the order of adding the words is different

CASE: 51
Stag: 172 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the algorithm will finally sort the words at step -LRB- 11 -RRB- and u ' \ ud835 ' u ' \ udcab ' is the same , the ranking of the words becomes all the same
	Cause: the algorithm will finally sort the words at step -LRB- 11 -RRB- and u ' \ ud835 ' u ' \ udcab ' is the same
	Effect: the ranking of the words becomes all the same

CASE: 52
Stag: 173 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Lastly , we need to decide the optimal number of patterns in u ' \ ud835 ' u ' \ udcab ' c -LRB- that is , k c in Algorithm 1 -RRB- because the set has been used in computing left pattern entropy , see Formula -LRB- 4
	Cause: the set has been used in computing left pattern entropy
	Effect: see Formula -LRB- 4

CASE: 53
Stag: 174 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Too small size of u ' \ ud835 ' u ' \ udcab ' c may lead to insufficient estimation of left pattern entropy
	Cause: Too small size of u ' \ ud835 ' u ' \ udcab ' c
	Effect: insufficient estimation of left pattern entropy

CASE: 54
Stag: 175 176 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Results in Table 7 shows that larger u ' \ ud835 ' u ' \ udcab ' c decrease the performance , particularly when the number of words returned -LRB- K -RRB- becomes larger Therefore , we set u ' \ ud835 ' u ' \ udcab ' c
	Cause: Results in Table 7 shows that larger u ' \ ud835 ' u ' \ udcab ' c decrease the performance , particularly when the number of words returned -LRB- K -RRB- becomes larger
	Effect: we set u ' \ ud835 ' u ' \ udcab ' c

CASE: 55
Stag: 183 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The polarity is judged according to this rule if M u ' \ u2062 ' V u ' \ u2062 ' -LRB- w -RRB- t u ' \ u2062 ' h 1 , the word w is positive ; if M u ' \ u2062 ' V u ' \ u2062 ' -LRB- w -RRB- - t u ' \ u2062 ' h 1 the word negative ; otherwise neutral
	Cause: M u ' \ u2062 ' V u ' \ u2062 ' -LRB- w -RRB- t u ' \ u2062 ' h 1 , the word w is positive ; if M u ' \ u2062 ' V u ' \ u2062 ' -LRB- w -RRB- - t u ' \ u2062 ' h 1 the word negative ; otherwise neutral
	Effect: The polarity is judged according to this rule

CASE: 56
Stag: 183 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: M u ' \ u2062 ' V u ' \ u2062 ' -LRB- w -RRB- t u ' \ u2062 ' h 1 , the word w is positive ; if M u ' \ u2062 ' V u ' \ u2062 ' -LRB- w -RRB- - t u ' \ u2062 ' h 1 the word negative ; otherwise neutral
	Cause: M u ' \ u2062 ' V u ' \ u2062 ' -LRB- w -RRB- - t u ' \ u2062 ' h 1 the word negative ; otherwise neutral
	Effect: M u ' \ u2062 ' V u ' \ u2062 ' -LRB- w -RRB- t u ' \ u2062 ' h 1 , the word w is positive ;

CASE: 57
Stag: 183 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The polarity is judged according to this rule
	Cause: this rule
	Effect: The polarity is judged

CASE: 58
Stag: 187 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The polarity is judged according to the rule if P u ' \ u2062 ' M u ' \ u2062 ' I u ' \ u2062 ' -LRB- w -RRB- t u ' \ u2062 ' h 2 , w is positive ; if P u ' \ u2062 ' M u ' \ u2062 ' I u ' \ u2062 ' -LRB- w -RRB- - t u ' \ u2062 ' h 2 negative ; otherwise neutral
	Cause: P u ' \ u2062 ' M u ' \ u2062 ' I u ' \ u2062 ' -LRB- w -RRB- t u ' \ u2062 ' h 2 , w is positive ; if P u ' \ u2062 ' M u ' \ u2062 '
	Effect: The polarity is judged according to the rule

CASE: 59
Stag: 187 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The polarity is judged according to the rule
	Cause: the rule
	Effect: The polarity is judged

CASE: 60
Stag: 188 189 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The threshold t u ' \ u2062 ' h 2 is manually tuned As for the resources P u ' \ u2062 ' W and N u ' \ u2062 ' W , we have three settings
	Cause: for the resources P u ' \ u2062 ' W and N u ' \ u2062 ' W , we have three settings
	Effect: The threshold t u ' \ u2062 ' h 2 is manually tuned

CASE: 61
Stag: 196 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We conjecture that this may be because new sentiment words are more frequently co-occurring with emoticons than with these opinion words
	Cause: new sentiment words are more frequently co-occurring with emoticons than with these opinion words
	Effect: We conjecture that this may be

CASE: 62
Stag: 197 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The second observation is that three-class polarity classification is much more difficult than two-class polarity classification because many extracted new words are nouns such as u ' \ u201d ' u ' \ u57fa ' u ' \ u53cb ' -LRB- gay -RRB- u ' \ u201d ' , u ' \ u201d ' u ' \ u83c7 ' u ' \ u51c9 ' -LRB- girl -RRB- u ' \ u201d ' , and u ' \ u201d ' u ' \ u76c6 ' u ' \ u53cb ' -LRB- friend -RRB- u ' \ u201d '
	Cause: many extracted new words are nouns such as u ' \ u201d ' u ' \ u57fa ' u ' \ u53cb ' -LRB- gay -RRB- u ' \ u201d ' , u ' \ u201d ' u ' \ u83c7 ' u ' \ u51c9 ' -LRB- girl -RRB- u ' \ u201d ' , and u ' \ u201d ' u ' \ u76c6 ' u ' \ u53cb ' -LRB- friend -RRB- u ' \ u201d '
	Effect: The second observation is that three-class polarity classification is much more difficult than two-class polarity classification

CASE: 63
Stag: 202 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The first model is a lexicon-based model -LRB- denoted by L u ' \ u2062 ' e u ' \ u2062 ' x u ' \ u2062 ' i u ' \ u2062 ' c u ' \ u2062 ' o u ' \ u2062 ' n -RRB- that counts the number of positive and negative opinion words in a post respectively , and classifies a post to be positive if there are more positive words than negative ones , and to be negative otherwise
	Cause: there are more positive words than negative ones , and to be negative otherwise
	Effect: The first model is a lexicon-based model -LRB- denoted by L u ' \ u2062 ' e u ' \ u2062 ' x u ' \ u2062 ' i u ' \ u2062 ' c u ' \ u2062 ' o u ' \ u2062 ' n -RRB- that counts the number of positive and negative opinion words in a post respectively , and classifies a post to be positive

CASE: 64
Stag: 203 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The second model is a SVM model in which opinion words are used as feature , and 5-fold cross validation is conducted
	Cause: feature , and 5-fold cross validation is
	Effect: The second model is a SVM model in which opinion words are used

CASE: 65
Stag: 211 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: All words in the top 100 words can be used as feature we thus manually label the polarity of all top 100 words -LRB- we did NOT remove incorrect new word
	Cause: All words in the top 100 words can be used as feature we
	Effect: manually label the polarity of all top 100 words -LRB- we did NOT remove incorrect new word

CASE: 66
Stag: 216 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: Note , that T u ' \ u2062 ' 100 is automatically obtained from Algorithm 1 so that it may contain words that are not new sentiment words , but the resource also improves performance remarkably
	Cause: Note , that T u ' \ u2062 ' 100 is automatically obtained from Algorithm 1
	Effect: it may contain words that are not new sentiment words , but the resource also improves performance remarkably

CASE: 67
Stag: 223 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: From linguistic perspectives , our framework is capable to extract adjective new words because the lexical patterns usually modify adjective words
	Cause: the lexical patterns usually modify adjective words
	Effect: From linguistic perspectives , our framework is capable to extract adjective new words

CASE: 68
Stag: 223 224 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: From linguistic perspectives , our framework is capable to extract adjective new words because the lexical patterns usually modify adjective words As future work , we are considering how to extract other types of new sentiment words , such as nounal new words that can express sentiment
	Cause: future work , we are considering how to extract other types of new sentiment words , such
	Effect: From linguistic perspectives , our framework is capable to extract adjective new words because the lexical patterns usually modify adjective words

