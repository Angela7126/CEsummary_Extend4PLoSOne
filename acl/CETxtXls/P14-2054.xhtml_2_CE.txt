************************************************************
P14-2054.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 2 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: It extends Eisner u ' \ u2019 ' s cubic time parsing algorithm by using virtual dependency arcs to link deleted words
	Cause: using virtual dependency arcs to link deleted words
	Effect: It extends Eisner u ' \ u2019 ' s cubic time parsing algorithm

CASE: 1
Stag: 7 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Sentence compression aims to shorten a sentence by removing uninformative words to reduce reading time
	Cause: removing uninformative words to reduce reading time
	Effect: Sentence compression aims to shorten a sentence

CASE: 2
Stag: 10 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Recent studies used a subtree deletion model for compression -LSB- 1 , 13 , 15 -RSB- , which deletes a word only if its modifier in the parse tree is deleted
	Cause: its modifier in the parse tree is deleted
	Effect: Recent studies used a subtree deletion model for compression -LSB- 1 , 13 , 15 -RSB- , which deletes a word only

CASE: 3
Stag: 14 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Trevor et al. proposed synchronous tree substitution grammar -LSB- 5 -RSB- , which allows local distortion of the tree topology and can thus naturally capture structural mismatches
	Cause: Trevor et al. proposed synchronous tree substitution grammar -LSB- 5 -RSB- , which allows local distortion of the tree topology and can
	Effect: naturally capture structural mismatches

CASE: 4
Stag: 16 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: However , the time complexity greatly increases since the parse tree dynamically depends on the compression
	Cause: the parse tree dynamically depends on the compression
	Effect: complexity greatly increases

CASE: 5
Stag: 19 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Our method extends Eisner u ' \ u2019 ' s cubic time parsing algorithm by adding signatures to each span , which indicate the number of deleted words and the rightmost kept word within the span , resulting in O u ' \ u2062 ' -LRB- n 6 -RRB- time complexity and O u ' \ u2062 ' -LRB- n 4 -RRB- space complexity
	Cause: adding signatures to each span , which indicate the number of deleted words and the rightmost kept word within the span , resulting in O u ' \ u2062 ' -LRB- n 6 -RRB- time complexity and O u ' \ u2062 ' -LRB- n 4 -RRB- space complexity
	Effect: Our method extends Eisner u ' \ u2019 ' s cubic time parsing algorithm

CASE: 6
Stag: 20 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: We further propose a faster approximate algorithm based on Lagrangian relaxation , which has T u ' \ u2062 ' O u ' \ u2062 ' -LRB- n 4 -RRB- running time and O u ' \ u2062 ' -LRB- n 3 -RRB- space complexity -LRB- T is the iteration number in the subgradient decent algorithm
	Cause: Lagrangian relaxation
	Effect: which has T u ' \ u2062 ' O u ' \ u2062 ' -LRB- n 4 -RRB- running time and O u ' \ u2062 ' -LRB- n 3 -RRB- space complexity -LRB- T is the iteration number in the subgradient decent algorithm

CASE: 7
Stag: 22 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: We define the sentence compression task as given a sentence composed of n words , u ' \ ud835 ' u ' \ udc31 ' = x 1 , u ' \ u2026 ' , x n , and a length L u ' \ u2264 ' n , we need to remove -LRB- n - L -RRB- words from u ' \ ud835 ' u ' \ udc31 ' , so that the sum of the weights of the dependency tree and word bigrams of the remaining part is maximized
	Cause: We define the sentence compression task as given a sentence composed of n words , u ' \ ud835 ' u ' \ udc31 ' = x 1 , u ' \ u2026 ' , x n , and a length L u ' \ u2264 ' n , we need to remove -LRB- n - L -RRB- words from u ' \ ud835 ' u ' \ udc31 ' ,
	Effect: the sum of the weights of the dependency tree and word bigrams of the remaining part is maximized

CASE: 8
Stag: 24 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: where u ' \ ud835 ' u ' \ udc33 ' is a binary vector , z i indicates x i is kept or not u ' \ ud835 ' u ' \ udc32 ' is a square matrix denoting the projective dependency parse tree over the remaining words , y i u ' \ u2062 ' j indicates if x i is the head of x j -LRB- note that each word has exactly one head w i tok is the informativeness of x i , w i u ' \ u2062 ' j bgr is the score of bigram x i u ' \ u2062 ' x j in an n-gram model , w dep is the score of dependency arc x i u ' \ u2192 ' x j in an arc-factored dependency parsing model
	Cause: x i is the head of x j -LRB- note that each word has exactly one head w i tok is the informativeness of x i
	Effect: w i u ' \ u2062 ' j bgr is the score of bigram x i u ' \ u2062 ' x j in an n-gram model , w dep is the score of dependency arc x i

CASE: 9
Stag: 24 25 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: where u ' \ ud835 ' u ' \ udc33 ' is a binary vector , z i indicates x i is kept or not u ' \ ud835 ' u ' \ udc32 ' is a square matrix denoting the projective dependency parse tree over the remaining words , y i u ' \ u2062 ' j indicates if x i is the head of x j -LRB- note that each word has exactly one head w i tok is the informativeness of x i , w i u ' \ u2062 ' j bgr is the score of bigram x i u ' \ u2062 ' x j in an n-gram model , w dep is the score of dependency arc x i u ' \ u2192 ' x j in an arc-factored dependency parsing model Hence , the first part of the objective function is the total score of the kept words , the second and third parts are the scores of the parse tree and bigrams of the compressed sentence , z i u ' \ u2062 ' z j u ' \ u2062 ' u ' \ u220f ' i k j -LRB- 1 - z k -RRB- = 1 indicates both x i and x j are kept , and are adjacent after compression
	Cause: ' \ ud835 ' u ' \ udc33 ' is a binary vector , z i indicates x i is kept or not u ' \ ud835 ' u ' \ udc32 ' is a square matrix denoting the projective dependency parse tree over the remaining words , y i u ' \ u2062 ' j indicates if x i is the head of x j -LRB- note that each word has exactly one head w i tok is the informativeness of x i , w i u ' \ u2062 ' j bgr is the score of bigram x i u ' \ u2062 ' x j in an n-gram model , w dep is the score of dependency arc x i u ' \ u2192 ' x j in an arc-factored dependency parsing model
	Effect: the first part of the objective function is the total score of the kept words , the second and third parts are the scores of the parse tree and bigrams of the compressed sentence , z i u ' \ u2062 ' z j u ' \ u2062 ' u ' \ u220f ' i k j -LRB- 1 - z k -RRB- = 1 indicates both x i and x j are kept , and are adjacent after compression

CASE: 10
Stag: 29 30 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: A span is a subtree over a number of consecutive words , with the leftmost or the rightmost word as its root An incomplete span denoted as I j i is a subtree inside a single arc x i u ' \ u2192 ' x j , with root x i
	Cause: its root An incomplete span denoted as I j i is a subtree inside a single arc x i u ' \ u2192 ' x j , with root
	Effect: A span is a subtree over a number of consecutive words , with the leftmost or the rightmost word

CASE: 11
Stag: 34 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: There are two rules for merging spans one merges two complete spans into an incomplete span , the other merges an incomplete span and a complete span into a large complete span
	Cause: merging spans one merges two complete spans into an incomplete span , the other merges an incomplete span and a complete span into a large complete span
	Effect: There are two rules

CASE: 12
Stag: 36 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: The scores of unigrams w i tok can be transfered to the dependency arcs , so that we can remove all linear terms w i tok u ' \ u2062 ' z i from the objective function
	Cause: The scores of unigrams w i tok can be transfered to the dependency arcs ,
	Effect: we can remove all linear terms w i tok u ' \ u2062 ' z i from the objective function

CASE: 13
Stag: 39 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: If z j = 0 , then in both equations , all terms having z j are zero ; If z j = 1 , i.e. , , x j is kept , since it has exactly one head word x k in the compressed sentence , the sum of the terms having z j is w j tok + w k u ' \ u2062 ' j dep for both equations
	Cause: it has exactly one head word x k in the compressed sentence ,
	Effect: having z j are zero ; If z j = 1 , i.e. , , x j is kept

CASE: 14
Stag: 39 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: having z j are zero ; If z j = 1 , i.e. , , x j is kept
	Cause: having z j
	Effect: are zero ;

CASE: 15
Stag: 39 40 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: If z j = 0 , then in both equations , all terms having z j are zero ; If z j = 1 , i.e. , , x j is kept , since it has exactly one head word x k in the compressed sentence , the sum of the terms having z j is w j tok + w k u ' \ u2062 ' j dep for both equations Therefore , we only need to consider the scores of arcs
	Cause: If z j = 0 , then in both equations , all terms having z j are zero ; If z j = 1 , i.e. , , x j is kept , since it has exactly one head word x k in the compressed sentence , the sum of the terms having z j is w j tok + w k u ' \ u2062 ' j dep for both equations
	Effect: we only need to consider the scores of arcs

CASE: 16
Stag: 41 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: For any compressed sentence , we could augment its dependency tree by adding a virtual arc i - 1 u ' \ u2192 ' i for each deleted word x i
	Cause: adding a virtual arc i - 1 u ' \ u2192 ' i for each deleted word x i
	Effect: For any compressed sentence , we could augment its dependency tree

CASE: 17
Stag: 42 43 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If the first word x 1 is deleted , we connect it to the root of the parse tree x 0 , as shown in Figure 3 In this way , we derive a full parse tree of the original sentence
	Cause: shown in Figure 3 In this way , we derive a full parse tree of the original sentence
	Effect: If the first word x 1 is deleted , we connect it to the root of the parse tree x 0

CASE: 18
Stag: 45 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We can reversely get the the compressed parse tree by removing all virtual arcs from the full parse tree
	Cause: removing all virtual arcs from the full parse tree
	Effect: We can reversely get the the compressed parse tree

CASE: 19
Stag: 46 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: We restrict the score of all the virtual arcs to be zero , so that scores of the two parse trees are equivalent
	Cause: We restrict the score of all the virtual arcs to be zero ,
	Effect: scores of the two parse trees are equivalent

CASE: 20
Stag: 53 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The two complete spans must be single words , as the length of the virtual arc is 1
	Cause: the length of the virtual arc is 1
	Effect: The two complete spans must be single words

CASE: 21
Stag: 59 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: The number of the virtual arcs within C j i + 1 must be j - i - 1 , since the descendants of the modifier of a virtual arc x j must be removed
	Cause: the descendants of the modifier of a virtual arc x j must be removed
	Effect: The number of the virtual arcs within C j i + 1 must be j - i - 1

CASE: 22
Stag: 65 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The root node is allowed to have two modifiers one is the modifier in the compressed sentence , the other is the first word if it is removed
	Cause: it is removed
	Effect: The root node is allowed to have two modifiers one is the modifier in the compressed sentence , the other is the first word

CASE: 23
Stag: 66 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: For each combination , the algorithm enumerates the number of virtual arcs in the left and right spans , and the split position -LRB- e.g. , , k u ' \ u2032 ' , k u ' \ u2032 ' u ' \ u2032 ' , r in case 2 -RRB- , thus it takes O u ' \ u2062 ' -LRB- n 3 -RRB- running time
	Cause: each combination , the algorithm enumerates the number of virtual arcs in the left and right spans , and the split position -LRB- e.g. , , k u ' \ u2032 ' , k u ' \ u2032 ' u ' \ u2032 ' , r in case 2 -RRB-
	Effect: it takes O u ' \ u2062 ' -LRB- n 3 -RRB- running time

CASE: 24
Stag: 71 72 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Suppose x j is removed , there must be a virtual arc j - 1 u ' \ u2192 ' j which is a conflict with the fact that x j is the leftmost word As x j is a descendant of x i , x i must be kept u ' \ u220e '
	Cause: x j is a descendant of x i , x i must be kept u ' \ u220e '
	Effect: 1 u ' \ u2192 ' j which is a conflict with the fact that x j is the leftmost word

CASE: 25
Stag: 74 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: According to the proposition above , if the right span is right-headed , its leftmost word is kept
	Cause: the right span is right-headed
	Effect: its leftmost word is kept

CASE: 26
Stag: 75 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the right span is left-headed , there are two cases its leftmost word is kept , or no word in the span is kept
	Cause: the right span is left-headed
	Effect: there are two cases its leftmost word is kept , or

CASE: 27
Stag: 78 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to the proposition above , we have , for any right-headed span p = i
	Cause: the proposition above
	Effect: we have , for any right-headed span p = i

CASE: 28
Stag: 89 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Fixing u ' \ u039b ' , the optimal u ' \ ud835 ' u ' \ udc33 ' , u ' \ ud835 ' u ' \ udc32 ' can be found using a simpler version of the algorithm above
	Cause: Fixing u ' \ u039b ' , the optimal u '
	Effect: \ ud835 ' u ' \ udc33 ' , u ' \ ud835 ' u ' \ udc32 ' can be found using a simpler version of the algorithm above

CASE: 29
Stag: 90 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We drop the signature of the virtual arc number from each span , and thus obtain an O u ' \ u2062 ' -LRB- n 4 -RRB- time algorithm
	Cause: We drop the signature of the virtual arc number from each span
	Effect: obtain an O u ' \ u2062 ' -LRB- n 4 -RRB- time algorithm

CASE: 30
Stag: 92 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Fixing u ' \ ud835 ' u ' \ udc33 ' , u ' \ ud835 ' u ' \ udc32 ' , the dual variable is updated by
	Cause: Fixing u ' \ ud835 ' u ' \ udc33 ' , u ' \ ud835 ' u ' \ udc32 '
	Effect: the dual variable is updated by

CASE: 31
Stag: 97 98 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use the same partitions as -LSB- 10 -RSB- , i.e. , , 1,188 sentences for training and 441 for testing Our model is discriminative u ' \ u2013 ' the scores of the unigrams , bigrams and dependency arcs are the linear functions of features , that is , w i tok = u ' \ ud835 ' u ' \ udc2f ' T u ' \ u2062 ' u ' \ ud835 ' u ' \ udc1f ' u ' \ u2062 ' -LRB- x i -RRB- , where u ' \ ud835 ' u ' \ udc1f ' is the feature vector of x i , and u ' \ ud835 ' u ' \ udc2f ' is the weight vector of features
	Cause: -LSB- 10 -RSB- , i.e. , , 1,188 sentences for training and 441 for testing Our model is discriminative u ' \ u2013 ' the scores of the unigrams , bigrams and dependency arcs are the linear functions of features , that is , w i tok = u ' \ ud835 ' u ' \ udc2f ' T u ' \ u2062 ' u ' \ ud835 ' u ' \ udc1f ' u ' \ u2062 ' -LRB- x i -RRB- , where u ' \ ud835 ' u ' \ udc1f ' is the feature vector of x i , and u ' \ ud835 ' u ' \ udc2f '
	Effect: We use the same partitions

CASE: 32
Stag: 99 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The learning task is to estimate the feature weight vector based on the manually compressed sentences
	Cause: the manually compressed sentences
	Effect: The learning task is to estimate the feature weight vector

CASE: 33
Stag: 101 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Then we augment these parse trees by adding virtual arcs and get the full parse trees of their corresponding original sentences
	Cause: adding virtual arcs
	Effect: and get the full parse trees of their corresponding original sentences

CASE: 34
Stag: 107 108 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The first is linear chain CRFs , where the compression task is casted as a binary sequence labeling problem It usually achieves high unigram F1 score but low grammatical relation F1 score since it only considers the local interdependence between adjacent words
	Cause: a binary sequence labeling problem It usually achieves high unigram F1 score but low grammatical relation F1 score since it only considers the local interdependence between adjacent
	Effect: The first is linear chain CRFs , where the compression task is casted

CASE: 35
Stag: 108 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: It usually achieves high unigram F1 score but low grammatical relation F1 score since it only considers the local interdependence between adjacent words
	Cause: it only considers the local interdependence between adjacent words
	Effect: It usually achieves high unigram F1 score but low grammatical relation F1 score

CASE: 36
Stag: 109 110 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The second is the subtree deletion model -LSB- 1 -RSB- which is solved by integer linear programming -LRB- ILP -RRB- 2 2 We use Gurobi as the ILP solver in the paper http://www.gurobi.com/ The third one is the bigram model proposed by McDonald -LSB- 12 -RSB- which adopts dynamic programming for efficient inference
	Cause: the ILP solver in the paper http://www.gurobi.com/ The third one is the bigram model proposed by McDonald -LSB- 12 -RSB- which adopts dynamic programming for efficient
	Effect: The second is the subtree deletion model -LSB- 1 -RSB- which is solved by integer linear programming -LRB- ILP -RRB- 2 2 We use Gurobi

CASE: 37
Stag: 116 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: As expected , the joint models -LRB- ours and TM13 -RRB- consistently outperform the subtree deletion model , since the joint models do not suffer from the subtree restriction
	Cause: the joint models do not suffer from the subtree restriction
	Effect: As expected , the joint models -LRB- ours and TM13 -RRB- consistently outperform the subtree deletion model

CASE: 38
Stag: 118 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: It is not surprising that CRFs achieve high unigram F scores but low syntactic F scores as they do not consider the fluency of the compressed sentence
	Cause: they do not consider the fluency of the compressed sentence
	Effect: It is not surprising that CRFs achieve high unigram F scores but low syntactic F scores

CASE: 39
Stag: 119 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: Compared with TM13 u ' \ u2019 ' s system , our model with exact decoding is not significantly faster due to the high order of the time complexity
	Cause: the high order of the time complexity
	Effect: Compared with TM13 u ' \ u2019 ' s system , our model with exact decoding is not significantly faster

CASE: 40
Stag: 127 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In practice it achieves nearly the same accuracy as the exact one , but is much faster
	Cause: the exact one , but is much faster
	Effect: In practice it achieves nearly the same accuracy

CASE: 41
Stag: 131 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In the future , we will study the non-projective cases based on the recent parsing techniques for 1-endpoint-crossing trees -LSB- 14 -RSB-
	Cause: the recent parsing techniques for 1-endpoint-crossing trees -LSB- 14 -RSB-
	Effect: In the future , we will study the non-projective cases

