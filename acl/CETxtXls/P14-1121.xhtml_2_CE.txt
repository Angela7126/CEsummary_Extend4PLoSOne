************************************************************
P14-1121.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: The main work in bilingual lexicon extraction from comparable corpora is based on the implicit hypothesis that corpora are balanced
	Cause: the implicit hypothesis that corpora are balanced
	Effect: The main work in bilingual lexicon extraction from comparable corpora

CASE: 1
Stag: 5 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The bilingual lexicon extraction task from bilingual corpora was initially addressed by using parallel corpora -LRB- i.e. , a corpus that contains source texts and their translation
	Cause: using parallel corpora -LRB- i.e. , a corpus that contains source texts and their translation
	Effect: The bilingual lexicon extraction task from bilingual corpora was initially addressed

CASE: 2
Stag: 6 7 
	Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
	sentTXT: However , despite good results in the compilation of bilingual lexicons , parallel corpora are scarce resources , especially for technical domains and for language pairs not involving English For these reasons , research in bilingual lexicon extraction has focused on another kind of bilingual corpora comprised of texts sharing common features such as domain , genre , sampling period , etc. without having a source text/target text relationship -LSB- 21 -RSB-
	Cause: However , despite good results in the compilation of bilingual lexicons , parallel corpora are scarce resources , especially for technical domains and for language pairs not involving English
	Effect: research in bilingual lexicon extraction has focused on another kind of bilingual corpora comprised of texts sharing common features such as domain , genre , sampling period , etc. without having a source text/target text relationship -LSB- 21 -RSB-

CASE: 3
Stag: 9 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to Fung and Cheung -LRB- 2004 -RRB- , who range bilingual corpora from parallel corpora to quasi-comparable corpora going through comparable corpora , there is a continuum from parallel to comparable corpora -LRB- i.e. , a kind of filiation
	Cause: Fung and Cheung -LRB- 2004 -RRB-
	Effect: who range bilingual corpora from parallel corpora to quasi-comparable corpora going through comparable corpora , there is a continuum from parallel to comparable corpora -LRB- i.e. , a kind of filiation

CASE: 4
Stag: 10 11 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The bilingual lexicon extraction task from comparable corpora inherits this filiation For instance , the historical context-based projection method -LSB- 11 , 28 -RSB- , known as the standard approach , dedicated to this task seems implicitly to lead to work with balanced comparable corpora in the same way as for parallel corpora -LRB- i.e. , each part of the corpus is composed of the same amount of data
	Cause: the standard approach , dedicated to this task seems implicitly to lead to work with balanced comparable corpora in the same way as for parallel corpora -LRB- i.e. , each part of the corpus is composed of the same amount of data
	Effect: The bilingual lexicon extraction task from comparable corpora inherits this filiation For instance , the historical context-based projection method -LSB- 11 , 28 -RSB- , known

CASE: 5
Stag: 13 14 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Moreover , this assumption is prejudicial for specialized comparable corpora , especially when involving the English language for which many documents are available due the prevailing position of this language as a standard for international scientific publications Within this context , our main contribution consists in a re-reading of the standard approach putting emphasis on the unfounded assumption of the balance of the specialized comparable corpora
	Cause: a standard for international scientific publications Within this context , our main contribution consists in a re-reading of the standard approach putting emphasis on the unfounded assumption of the balance of the specialized comparable
	Effect: Moreover , this assumption is prejudicial for specialized comparable corpora , especially when involving the English language for which many documents are available due the prevailing position of this language

CASE: 6
Stag: 15 16 
	Pattern: 9 [['consequently']]---- [['&C', '(,/;/./--)'], ['(,)', '&R']]
	sentTXT: In specialized domains , the comparable corpora are traditionally of small size -LRB- around 1 million words -RRB- in comparison with comparable corpus-based general language -LRB- up to 100 million words Consequently , the observations of word co-occurrences which is the basis of the standard approach are unreliable
	Cause: In specialized domains , the comparable corpora are traditionally of small size -LRB- around 1 million words -RRB- in comparison with comparable corpus-based general language -LRB- up to 100 million words
	Effect: the observations of word co-occurrences which is the basis of the standard approach are unreliable

CASE: 7
Stag: 20 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We then present an extension of this approach based on regression models
	Cause: regression models
	Effect: We then present an extension of this approach

CASE: 8
Stag: 22 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: The main work in bilingual lexicon extraction from comparable corpora is based on lexical context analysis and relies on the simple observation that a word and its translation tend to appear in the same lexical contexts
	Cause: lexical context analysis and relies on the simple observation that a word and its translation tend to appear in the same lexical contexts
	Effect: The main work in bilingual lexicon extraction from comparable corpora

CASE: 9
Stag: 25 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: In order to emphasize significant words in the context vector and to reduce word-frequency effects , the context vectors are normalized according to an association measure
	Cause: an association measure
	Effect: In order to emphasize significant words in the context vector and to reduce word-frequency effects , the context vectors are normalized

CASE: 10
Stag: 26 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Then , the translation is obtained by comparing the source context vector to each translation candidate vector after having translated each element of the source vector with a general dictionary
	Cause: comparing the source context vector to each translation candidate vector after having translated each element of the source vector with a general dictionary
	Effect: Then , the translation is obtained

CASE: 11
Stag: 27 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The implementation of the standard approach can be carried out by applying the following three steps -LSB- 29 , 3 , 7 , 22 , 18 , among others -RSB-
	Cause: applying the following three steps -LSB- 29 , 3 , 7 , 22 , 18 , among others -RSB-
	Effect: The implementation of the standard approach can be carried out

CASE: 12
Stag: 32 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the bilingual dictionary provides several translations for an element , we consider all of them but weight the different translations according to their frequency in the target language
	Cause: the bilingual dictionary provides several translations for an element
	Effect: we consider all of them but weight the different translations according to their frequency in the target language

CASE: 13
Stag: 32 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: we consider all of them but weight the different translations according to their frequency in the target language
	Cause: their frequency in the target language
	Effect: we consider all of them but weight the different translations

CASE: 14
Stag: 37 
	Pattern: 47 [['so'], ['that']]---- [['&C'], ['&adj/&adv@C@'], ['&R']]
	sentTXT: The standard approach is used by most researchers so far -LSB- 28 , 12 , 25 , 29 , 3 , 7 , 13 , 22 , 18 , 26 , 2 , among others -RSB- with the implicit hypothesis that comparable corpora are balanced
	Cause: The standard approach is used by most researchers so far
	Effect: comparable corpora are balanced

CASE: 15
Stag: 39 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: 21 -RRB- observe , a specialized comparable corpus is built as balanced by analogy with a parallel corpus u ' \ u201c ' Therefore , in relation to parallel corpora , it is more likely for comparable corpora to be designed as general balanced corpora u ' \ u201d '
	Cause: 21 -RRB- observe , a specialized comparable corpus is built as balanced by analogy with a parallel corpus u ' \ u201c '
	Effect: in relation to parallel corpora , it is more likely for comparable corpora to be designed as general balanced corpora u ' \ u201d

CASE: 16
Stag: 39 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: in relation to parallel corpora , it is more likely for comparable corpora to be designed as general balanced corpora u ' \ u201d
	Cause: general balanced corpora u '
	Effect: in relation to parallel corpora , it is more likely for comparable corpora to be designed

CASE: 17
Stag: 43 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the context vectors are computed from each part of the comparable corpus rather than through the parts of the comparable corpora , the standard approach is relatively insensitive to differences in corpus sizes
	Cause: the context vectors are computed from each part of the comparable corpus rather than through the parts of the comparable corpora
	Effect: the standard approach is relatively insensitive to differences in corpus sizes

CASE: 18
Stag: 44 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The only precaution for using the standard approach with unbalanced corpora is to normalize the association measure -LRB- for instance , this can be done by dividing each entry of a given context vector by the sum of its association scores
	Cause: dividing each entry of a given context vector
	Effect: The only precaution for using the standard approach with unbalanced corpora is to normalize the association measure -LRB- for instance , this can be done

CASE: 19
Stag: 45 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since comparable corpora are usually small in specialized domains -LRB- see Table 2 -RRB- , the discriminative power of context vectors -LRB- i.e. , the observations of word co-occurrences -RRB- is reduced
	Cause: comparable corpora are usually small in specialized domains -LRB- see Table 2 -RRB-
	Effect: the discriminative power of context vectors -LRB- i.e. , the observations of word co-occurrences -RRB- is reduced

CASE: 20
Stag: 47 48 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This consists in assigning to each observed co-occurrence count of a small comparable corpora , a new value learned beforehand from a large training corpus In order to make co-occurrence counts more discriminant and in the same way as Hazem and Morin -LSB- 15 -RSB- , one strategy consists in addressing this problem through regression given training corpora of small and large size -LRB- abundant in the general domain -RRB- , we predict word co-occurrence counts in order to make them more reliable
	Cause: Hazem and Morin -LSB- 15 -RSB- , one strategy consists in addressing this problem through regression given training corpora of small and large size -LRB- abundant in the general domain -RRB- , we predict word co-occurrence counts in order to make them more reliable
	Effect: This consists in assigning to each observed co-occurrence count of a small comparable corpora , a new value learned beforehand from a large training corpus In order to make co-occurrence counts more discriminant and in the same way

CASE: 21
Stag: 49 50 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We then apply the resulting regression function to each word co-occurrence count as a pre-processing step of the standard approach Our work differs from Hazem and Morin -LSB- 15 -RSB- in two ways
	Cause: a pre-processing step of the standard approach Our work differs from Hazem and Morin -LSB- 15 -RSB- in two
	Effect: We then apply the resulting regression function to each word co-occurrence count

CASE: 22
Stag: 53 54 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use regression analysis to describe the relationship between word co-occurrence counts in a large corpus -LRB- the response variable -RRB- and word co-occurrence counts in a small corpus -LRB- the predictor variable As most regression models have already been described in great detail -LSB- 5 , 1 -RSB- , the derivation of most models is only briefly introduced in this work
	Cause: most regression models have already been described in great detail -LSB- 5 , 1 -RSB- , the derivation of most models is only briefly introduced in this work
	Effect: We use regression analysis to describe the relationship between word co-occurrence counts in a large corpus -LRB- the response variable -RRB- and word co-occurrence counts in a small corpus -LRB- the predictor variable

CASE: 23
Stag: 54 55 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: As most regression models have already been described in great detail -LSB- 5 , 1 -RSB- , the derivation of most models is only briefly introduced in this work As we can not claim that the prediction of word co-occurrence counts is a linear problem , we consider in addition to the simple linear regression model -LRB- L u ' \ u2062 ' i u ' \ u2062 ' n -RRB- , a generalized linear model which is the logistic regression model -LRB- L u ' \ u2062 ' o u ' \ u2062 ' g u ' \ u2062 ' i u ' \ u2062 ' t -RRB- and non linear regression models such as polynomial regression model -LRB- P u ' \ u2062 ' o u ' \ u2062 ' l u ' \ u2062 ' y n -RRB- of order n
	Cause: we can not claim that the prediction of word co-occurrence counts is a linear problem , we consider in addition to the simple linear regression model -LRB- L u ' \ u2062 ' i u ' \ u2062 ' n -RRB- , a generalized linear model which is the logistic regression model -LRB- L u ' \ u2062 ' o u ' \ u2062 ' g u ' \ u2062 ' i u ' \ u2062 ' t -RRB- and non linear regression models such as polynomial regression model -LRB- P u ' \ u2062 ' o u ' \ u2062 ' l u ' \ u2062 ' y n -RRB- of order n
	Effect: As most regression models have already been described in great detail -LSB- 5 , 1 -RSB- , the derivation of most models is only briefly introduced in this work

CASE: 24
Stag: 61 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Prochasson et al. -LRB- 2009 -RRB- enhance the representativeness of the context vector by strengthening the context words that happen to be transliterated words and scientific compound words in the target language
	Cause: strengthening the context words that happen to be transliterated words and scientific compound words in the target language
	Effect: Prochasson et al. -LRB- 2009 -RRB- enhance the representativeness of the context vector

CASE: 25
Stag: 62 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Ismail and Manandhar -LRB- 2010 -RRB- also suggest that context vectors should be based on the most important contextually relevant words -LRB- in-domain terms -RRB- , and thus propose a method for filtering the noise of the context vectors
	Cause: Ismail and Manandhar -LRB- 2010 -RRB- also suggest that context vectors should be based on the most important contextually relevant words -LRB- in-domain terms -RRB-
	Effect: propose a method for filtering the noise of the context vectors

CASE: 26
Stag: 62 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Ismail and Manandhar -LRB- 2010 -RRB- also suggest that context vectors should be based on the most important contextually relevant words -LRB- in-domain terms -RRB-
	Cause: the most important contextually relevant words -LRB- in-domain terms -RRB-
	Effect: Ismail and Manandhar -LRB- 2010 -RRB- also suggest that context vectors should be

CASE: 27
Stag: 62 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: propose a method for filtering the noise of the context vectors
	Cause: filtering the noise of the context vectors
	Effect: propose a method

CASE: 28
Stag: 63 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In another way , Rubino and Linar s -LRB- 2011 -RRB- improve the context words based on the hypothesis that a word and its candidate translations share thematic similarities
	Cause: the hypothesis that a word and its candidate translations share thematic similarities
	Effect: In another way , Rubino and Linar s -LRB- 2011 -RRB- improve the context words

CASE: 29
Stag: 66 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Koehn and Knight -LRB- 2002 -RRB- automatically induce the initial seed bilingual dictionary by using identical spelling features such as cognates and similar contexts
	Cause: using identical spelling features such as cognates and similar contexts
	Effect: Koehn and Knight -LRB- 2002 -RRB- automatically induce the initial seed bilingual dictionary

CASE: 30
Stag: 66 67 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Koehn and Knight -LRB- 2002 -RRB- automatically induce the initial seed bilingual dictionary by using identical spelling features such as cognates and similar contexts As regards the problem of words ambiguities , Bouamor et al. -LRB- 2013 -RRB- carried out word sense disambiguation process only in the target language whereas Gaussier et al. -LRB- 2004 -RRB- solve the problem through the source and target languages by using approaches based on CCA -LRB- Canonical Correlation Analysis -RRB- and multilingual PLSA -LRB- Probabilistic Latent Semantic Analysis
	Cause: regards the problem of words ambiguities , Bouamor et al. -LRB- 2013 -RRB- carried out word sense disambiguation process only in the target language whereas Gaussier et al.
	Effect: Koehn and Knight -LRB- 2002 -RRB- automatically induce the initial seed bilingual dictionary by using identical spelling features such as cognates and similar contexts

CASE: 31
Stag: 68 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The rank of candidate translations can be improved by integrating different heuristics
	Cause: integrating different heuristics
	Effect: The rank of candidate translations can be improved

CASE: 32
Stag: 69 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: For instance , Chiao and Zweigenbaum -LRB- 2002 -RRB- introduce a heuristic based on word distribution symmetry
	Cause: word distribution symmetry
	Effect: For instance , Chiao and Zweigenbaum -LRB- 2002 -RRB- introduce a heuristic

CASE: 33
Stag: 72 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Laroche and Langlais -LRB- 2010 -RRB- suggest a heuristic based on the graphic similarity between source and target terms
	Cause: the graphic similarity between source and target terms
	Effect: Laroche and Langlais -LRB- 2010 -RRB- suggest a heuristic

CASE: 34
Stag: 82 83 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: After a manual selection , we only kept the documents which were relative to the medical domain As a result , 65 French documents were extracted -LRB- about 257,000 words
	Cause: After a manual selection , we only kept the documents which were relative to the medical domain
	Effect: 65 French documents were extracted -LRB- about 257,000 words

CASE: 35
Stag: 85 86 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: We only kept the free fulltext available documents As a result , 2,339 English documents were extracted -LRB- about 3,5 million words
	Cause: We only kept the free fulltext available documents
	Effect: 2,339 English documents were extracted -LRB- about 3,5 million words

CASE: 36
Stag: 93 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The comparability measure -LSB- 19 -RSB- is based on the expectation of finding the translation for each word in the corpus and gives a good idea about how two corpora are comparable
	Cause: the expectation of finding the translation for each word in the corpus and gives a good idea about how two corpora are comparable
	Effect: The comparability measure -LSB- 19 -RSB- is

CASE: 37
Stag: 102 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: For instance , Prochasson and Fung -LRB- 2011 -RRB- showed that the standard approach is not relevant for infrequent words -LRB- since the context vectors are very unrepresentative i.e. , poor in information
	Cause: the context vectors are very unrepresentative i.e. , poor in
	Effect: For instance , Prochasson and Fung -LRB- 2011 -RRB- showed that the standard approach is not relevant for infrequent words -LRB-

CASE: 38
Stag: 103 
	Pattern: 0 [['as', 'a', ['result', 'consequence'], 'of'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: As a result of filtering , 169 French/English single words were extracted for the breast cancer corpus and 244 French/English single words were extracted for the diabetes corpus
	Cause: filtering
	Effect: 169 French/English single words were extracted for the breast cancer corpus and 244 French/English single words were extracted for the diabetes corpus

CASE: 39
Stag: 113 114 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We first performed an experiment using each comparable corpus independently of the others -LRB- we refer to these corpora as balanced corpora We then conducted a second experiment where we varied the size of the English part of the comparable corpus , from 530,000 to 7.4 million words for the breast cancer corpus in 530,000 words steps , and from 250,000 to 3.5 million words for the diabetes corpus in 250,000 words steps -LRB- we refer to these corpora as unbalanced corpora
	Cause: balanced corpora We then conducted a second experiment where we varied the size of the English part of the comparable corpus , from 530,000 to 7.4 million words for the breast cancer corpus in 530,000 words steps , and from 250,000 to 3.5 million words for the diabetes corpus in 250,000 words steps -LRB- we refer to these corpora as unbalanced
	Effect: We first performed an experiment using each comparable corpus independently of the others -LRB- we refer to these corpora

CASE: 40
Stag: 120 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: For instance , the column 3 indicates the MAP obtained by using a comparable corpus that is composed i -RRB- only of -LSB- breast cancer corpus 3 -RSB- -LRB- MAP of 21.0 % -RRB- , and ii -RRB- of -LSB- breast cancer corpus 1 , 2 and 3 -RSB- -LRB- MAP of 34.7 %
	Cause: instance , the column 3
	Effect: the MAP obtained by using a comparable corpus that is composed i -RRB- only of -LSB- breast cancer corpus 3 -RSB- -LRB- MAP of 21.0 % -RRB- , and ii -RRB- of -LSB- breast cancer corpus 1 , 2 and 3 -RSB- -LRB- MAP of 34.7 %

CASE: 41
Stag: 120 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: the MAP obtained by using a comparable corpus that is composed i -RRB- only of -LSB- breast cancer corpus 3 -RSB- -LRB- MAP of 21.0 % -RRB- , and ii -RRB- of -LSB- breast cancer corpus 1 , 2 and 3 -RSB- -LRB- MAP of 34.7 %
	Cause: using a comparable corpus that is composed
	Effect: i -RRB- only of -LSB- breast cancer corpus 3 -RSB- -LRB- MAP of 21.0 % -RRB- , and ii -RRB- of -LSB- breast cancer corpus 1 , 2 and 3 -RSB- -LRB- MAP of 34.7 %

CASE: 42
Stag: 120 121 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For instance , the column 3 indicates the MAP obtained by using a comparable corpus that is composed i -RRB- only of -LSB- breast cancer corpus 3 -RSB- -LRB- MAP of 21.0 % -RRB- , and ii -RRB- of -LSB- breast cancer corpus 1 , 2 and 3 -RSB- -LRB- MAP of 34.7 % As a preliminary remark , we can notice that the results differ noticeably according to the comparable corpus used individually -LRB- MAP variation between 21.0 % and 29.6 % for the breast cancer corpora and between 10.5 % and 16.5 % for the diabetes corpora
	Cause: a preliminary remark , we can notice that the results differ noticeably according to the comparable corpus used individually -LRB- MAP variation between 21.0 % and 29.6 % for the breast cancer corpora and between 10.5 % and 16.5 % for the diabetes corpora
	Effect: instance , the column 3 indicates the MAP obtained by using a comparable corpus that is composed i -RRB- only of -LSB- breast cancer corpus 3 -RSB- -LRB- MAP of 21.0 % -RRB- , and ii -RRB- of -LSB- breast cancer corpus 1 , 2 and 3 -RSB- -LRB- MAP of 34.7 %

CASE: 43
Stag: 122 123 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We can also note that the MAP of all the unbalanced comparable corpora is always higher than any individual comparable corpus Overall , starting with a MAP of 26.1 % as provided by the balanced -LSB- breast cancer corpus 1 -RSB- , we are able to increase it to 42.3 % with the unbalanced -LSB- breast cancer corpus 12 -RSB- -LRB- the variation observed for some unbalanced corpora such as -LSB- diabetes corpus 12 , 13 and 14 -RSB- can be explained by the fact that adding more data in the source language increases the error rate of the translation phase of the standard approach , which leads to the introduction of additional noise in the translated context vectors
	Cause: provided by the balanced -LSB- breast cancer corpus 1 -RSB- , we are able to increase it to 42.3 % with the unbalanced -LSB- breast cancer corpus 12 -RSB- -LRB- the variation observed for some unbalanced corpora such as -LSB- diabetes corpus 12 , 13 and 14 -RSB- can be explained by the fact that adding more data in the source language increases the error rate of the translation phase of the standard approach , which leads to the introduction of additional noise in the translated context vectors
	Effect: MAP of all the unbalanced comparable corpora is always higher than any individual comparable corpus Overall , starting with a MAP of 26.1 %

CASE: 44
Stag: 125 126 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We contrast the prediction models presented in Section 2.2 to findout which is the most appropriate model to use as a pre-processing step of the standard approach We chose the balanced corpora where the standard approach has shown the best results in the previous experiment , namely -LSB- breast cancer corpus 12 -RSB- and -LSB- diabetes corpus 7 -RSB-
	Cause: a pre-processing step of the standard approach We chose the balanced corpora where the standard approach has shown the best results in the previous experiment , namely -LSB- breast cancer corpus 12 -RSB- and -LSB- diabetes corpus 7
	Effect: We contrast the prediction models presented in Section 2.2 to findout which is the most appropriate model to use

CASE: 45
Stag: 129 130 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We can notice that except for the L u ' \ u2062 ' o u ' \ u2062 ' g u ' \ u2062 ' i u ' \ u2062 ' t model , all the regression models outperform the baseline -LRB- N u ' \ u2062 ' o p u ' \ u2062 ' r u ' \ u2062 ' e u ' \ u2062 ' d u ' \ u2062 ' i u ' \ u2062 ' c u ' \ u2062 ' t u ' \ u2062 ' i u ' \ u2062 ' o u ' \ u2062 ' n Also , as we can see , the results obtained with the linear and polynomial regressions are very close
	Cause: we can see , the results obtained with the linear and polynomial
	Effect: the L u ' \ u2062 ' o u ' \ u2062 ' g u ' \ u2062 ' i u ' \ u2062 ' t model , all the regression models outperform the baseline -LRB- N u ' \ u2062 ' o p u ' \ u2062 ' r u ' \ u2062 ' e u ' \ u2062 ' d u ' \ u2062 ' i u ' \ u2062 ' c u ' \ u2062 ' t u ' \ u2062 ' i u ' \ u2062 ' o u ' \ u2062 ' n Also

CASE: 46
Stag: 131 
	Pattern: 3 [[[',', '.', ';', 'and']], ['as', 'a'], ['result']]---- [['&C'], ['&R'], ['(&ADJ)']]
	sentTXT: This suggests that both linear and polynomial regressions are suitable as a pre-processing step of the standard approach , while the logistic regression seems to be inappropriate according to the results shown in Table 6
	Cause: This suggests that both linear
	Effect: polynomial regressions are suitable

CASE: 47
Stag: 133 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: This may be due to the regression parameters that have been learned from a training corpus of the general domain
	Cause: the regression parameters that have been learned from a training corpus of the general domain
	Effect: This may be

CASE: 48
Stag: 138 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If prediction can not replace a large amount of data , it aims at increasing co-occurrence counts as if large amounts of data were at our disposal
	Cause: prediction can not replace a large amount of data
	Effect: it aims at increasing co-occurrence counts as if large amounts of data were at our disposal

CASE: 49
Stag: 138 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: it aims at increasing co-occurrence counts as if large amounts of data were at our disposal
	Cause: large amounts of data were at our disposal
	Effect: it aims at increasing co-occurrence counts as

CASE: 50
Stag: 143 144 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: That said , the other regression models have shown the same behavior as L u ' \ u2062 ' i u ' \ u2062 ' n We can see that the best results are obtained by the S u ' \ u2062 ' o u ' \ u2062 ' u u ' \ u2062 ' r u ' \ u2062 ' c u ' \ u2062 ' e p u ' \ u2062 ' r u ' \ u2062 ' e u ' \ u2062 ' d approach for both comparable corpora
	Cause: L u ' \ u2062 ' i u ' \ u2062 ' n We can see that the best results are obtained by the S u ' \ u2062 ' o u ' \ u2062 ' u u ' \ u2062 ' r u ' \ u2062 ' c u ' \ u2062 ' e p u ' \ u2062 ' r u ' \ u2062 ' e u ' \ u2062 '
	Effect: That said , the other regression models have shown the same behavior

CASE: 51
Stag: 146 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: It is not surprising that predicting the target side only leads to lower results , since it is well known that a better characterization of a word to translate -LRB- given from the source side -RRB- leads to better results
	Cause: it is well known that a better characterization of a word to translate -LRB- given from the source side -RRB- leads to better results
	Effect: It is not surprising that predicting the target side only leads to lower results

CASE: 52
Stag: 146 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: it is well known that a better characterization of a word to translate -LRB- given from the source side -RRB- leads to better results
	Cause: a better characterization of a word to translate -LRB- given from the source side -RRB-
	Effect: better results

CASE: 53
Stag: 156 157 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The results of the experiments conducted on the diabetes corpus are shown in Figure 1 As for the previous experiment , we can see that the U u ' \ u2062 ' n u ' \ u2062 ' b u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' a u ' \ u2062 ' n u ' \ u2062 ' c u ' \ u2062 ' e u ' \ u2062 ' d approach significantly outperforms the B u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' a u ' \ u2062 ' n u ' \ u2062 ' c u ' \ u2062 ' e u ' \ u2062 ' d approach
	Cause: for the previous experiment , we can see that the U u ' \ u2062 ' n u ' \ u2062 ' b u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' a u ' \ u2062 ' n u ' \ u2062 ' c u ' \ u2062 ' e u ' \ u2062 ' d approach significantly outperforms the B u ' \ u2062 ' a u ' \ u2062 ' l u ' \ u2062 ' a u ' \ u2062 ' n u ' \ u2062 ' c u ' \ u2062 ' e u ' \ u2062 ' d approach
	Effect: The results of the experiments conducted on the diabetes corpus are shown in Figure 1

CASE: 54
Stag: 163 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This aspect represents a significant interest when working with specialized comparable corpora for which the quantity of the data collected may differ depending on the languages involved , especially when involving the English language as many scientific documents are available
	Cause: many scientific documents are available
	Effect: This aspect represents a significant interest when working with specialized comparable corpora for which the quantity of the data collected may differ depending on the languages involved , especially when involving the English language

CASE: 55
Stag: 164 165 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: More precisely , our different experiments show that using an unbalanced specialized comparable corpus always improves the quality of word translations Thus , the MAP goes up from 29.6 % -LRB- best result on the balanced corpora -RRB- to 42.3 % -LRB- best result on the unbalanced corpora -RRB- in the breast cancer domain , and from 16.5 % to 26.0 % in the diabetes domain
	Cause: More precisely , our different experiments show that using an unbalanced specialized comparable corpus always improves the quality of word translations
	Effect: , the MAP goes up from 29.6 % -LRB- best result on the balanced corpora -RRB- to 42.3 % -LRB- best result on the unbalanced corpora -RRB- in the breast cancer domain , and from 16.5 % to 26.0 % in the diabetes domain

CASE: 56
Stag: 166 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Additionally , these results can be improved by using a prediction model of the word co-occurrence counts
	Cause: using a prediction model of the word co-occurrence counts
	Effect: Additionally , these results can be improved

CASE: 57
Stag: 168 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We hope that this study will pave the way for using specialized unbalanced comparable corpora for bilingual lexicon extraction
	Cause: using specialized unbalanced comparable corpora for bilingual lexicon extraction
	Effect: We hope that this study will pave the way

