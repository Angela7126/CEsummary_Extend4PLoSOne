************************************************************
P14-1067.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 9 
	Pattern: 7 [['due', 'to']]---- [['&V-ing/&NP@R@', '&BE'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Such variability is due to two main reasons
	Cause: [(0, 5), (0, 7)]
	Effect: [(0, 0), (0, 1)]

CASE: 1
Stag: 11 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the quality standards of individual users may vary considerably ( e.g., according to their knowledge of the source and target languages), the estimates of a static QE model trained with data collected from a group of post-editors might not fit with the actual judgements of a new user;
	Cause: [(0, 1), (0, 11)]
	Effect: [(0, 13), (0, 52)]

CASE: 2
Stag: 11 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: Since the quality standards of individual users may vary considerably ( e.g., according to their knowledge of the source and target languages), the estimates of a static QE model trained with data collected from a group of post-editors might not fit with the actual judgements of a new user;
	Cause: [(0, 2), (0, 9)]
	Effect: [(0, 12), (0, 39)]

CASE: 3
Stag: 13 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since data from a new job may differ from those used to train the QE model, its estimates on the new instances might result to be biased or uninformative
	Cause: [(0, 1), (0, 15)]
	Effect: [(0, 17), (0, 29)]

CASE: 4
Stag: 17 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Our approach is based on the online learning paradigm and exploits a key difference between such framework and the batch learning methods currently used
	Cause: [(0, 5), (0, 23)]
	Effect: [(0, 0), (0, 1)]

CASE: 5
Stag: 20 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: On the other side, online learning techniques are designed to learn in a stepwise manner (either from scratch, or by refining an existing model) from new, unseen test instances by taking advantage of external feedback
	Cause: [(0, 23), (0, 26)]
	Effect: [(0, 0), (0, 21)]

CASE: 6
Stag: 22 23 
	Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
	sentTXT: To develop our approach, different online algorithms have been embedded in the backbone of a QE system This required the adaptation of its standard batch learning workflow to
	Cause: [(1, 2), (1, 9)]
	Effect: [(0, 0), (0, 17)]

CASE: 7
Stag: 26 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Gather user feedback for the instance ( i.e., calculating a u'\u201c' true label u'\u201d' based on the amount of user post-editions);
	Cause: [(0, 25), (0, 29)]
	Effect: [(0, 0), (0, 22)]

CASE: 8
Stag: 28 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Focusing on the adaptability to user and domain changes, we report the results of comparative experiments with two online algorithms and the standard batch approach
	Cause: [(0, 0), (0, 8)]
	Effect: [(0, 10), (0, 25)]

CASE: 9
Stag: 29 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The evaluation is carried out by measuring the global error of each algorithm on test sets featuring different degrees of similarity with the data used for training
	Cause: [(0, 6), (0, 26)]
	Effect: [(0, 0), (0, 4)]

CASE: 10
Stag: 33 
	Pattern: 5 [['so'], ['as', 'to']]---- [['&C', '(,)'], ['(&adj/&adv@C@)'], ['&R']]
	sentTXT: QE is generally cast as a supervised machine learning task, where a model trained from a collection of ( source, target, label ) instances is used to predict labels 1 1 Possible label types include post-editing effort scores ( e.g., 1-5 Likert scores indicating the estimated percentage of MT output that has to be corrected), HTER values [ 28 ] , and post-editing time ( e.g., seconds per word for new, unseen test items [ 31 ]
	Cause: [(0, 0), (0, 19)]
	Effect: [(0, 57), (0, 84)]

CASE: 11
Stag: 35 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Current approaches to the tasks proposed at WMT have mainly focused on three main directions, namely i) feature engineering, as in [ 12 , 10 , 11 , 26 ] , ii) model learning with a variety of classification and regression algorithms, as in [ 3 , 1 , 29 ] , and iii) feature selection as a way to overcome sparsity and overfitting issues, as in [ 29 ]
	Cause: [(0, 23), (0, 69)]
	Effect: [(0, 0), (0, 20)]

CASE: 12
Stag: 36 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Being optimized to perform well on specific WMT sub-tasks and datasets, current systems reflect variations along these directions but leave important aspects of the QE problem still partially investigated or totally unexplored
	Cause: [(0, 0), (0, 10)]
	Effect: [(0, 12), (0, 32)]

CASE: 13
Stag: 38 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Among these, the necessity to model the diversity of human quality judgements and correction strategies [ 16 , 15 ] calls for solutions that i) account for annotator-specific behaviour, thus being capable of learning from inherently noisy datasets produced by multiple annotators, and ii) self-adapt to changes in data distribution, learning from user feedback on new, unseen test items
	Cause: [(0, 0), (0, 30)]
	Effect: [(0, 33), (0, 65)]

CASE: 14
Stag: 40 41 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The first aspect, modelling annotators u'\u2019' individual behaviour and interdependences, has been addressed by Cohn and Specia [ 8 ] , who explored multi-task Gaussian Processes as a way to jointly learn from the output of multiple annotations This technique is suitable to cope with the unbalanced distribution of training instances and yields better models when heterogeneous training datasets are available
	Cause: [(0, 33), (1, 17)]
	Effect: [(0, 0), (0, 31)]

CASE: 15
Stag: 47 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: As regards QE models, our work represents the first investigation on incremental adaptation by exploiting users feedback to provide targeted (system, user, or project specific) quality judgements
	Cause: [(0, 15), (0, 31)]
	Effect: [(0, 0), (0, 13)]

CASE: 16
Stag: 53 54 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the online framework, differently from the batch mode, the learning algorithm sequentially processes an unknown sequence of instances X = x 1 , x 2 , u'\u2026' , x n , returning a prediction p u'\u2062' ( x i ) as output at each step Differences between p u'\u2062' ( x i ) and the true label p ^ u'\u2062' ( x i ) obtained as feedback are used by the learner to refine the next prediction p u'\u2062' ( x i + 1 )
	Cause: [(0, 52), (1, 49)]
	Effect: [(0, 0), (0, 50)]

CASE: 17
Stag: 54 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Differences between p u'\u2062' ( x i ) and the true label p ^ u'\u2062' ( x i ) obtained as feedback are used by the learner to refine the next prediction p u'\u2062' ( x i + 1 )
	Cause: [(0, 29), (0, 51)]
	Effect: [(0, 0), (0, 27)]

CASE: 18
Stag: 56 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 5 5 Edit distance is calculated as the number of edits (word insertions, deletions, substitutions, and shifts) divided by the number of words in the reference
	Cause: [(0, 7), (0, 22)]
	Effect: [(0, 0), (0, 5)]

CASE: 19
Stag: 57 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Lower HTER values indicate better translations
	Cause: [(0, 0), (0, 2)]
	Effect: [(0, 4), (0, 5)]

CASE: 20
Stag: 62 63 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: At each step of the process, the goal of the learner is to exploit user post-editions to reduce the difference between the predicted HTER values and the true labels for the following ( source, target ) pairs As depicted in Figure 1 , this is done as follows
	Cause: [(1, 1), (1, 10)]
	Effect: [(0, 0), (0, 38)]

CASE: 21
Stag: 68 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on the post-edition done by the user, the true HTER label p ^ u'\u2062' ( x i ) is calculated by means of the TERCpp 7 7 goo.gl/nkh2rE open source tool;
	Cause: [(0, 2), (0, 7)]
	Effect: [(0, 9), (0, 39)]

CASE: 22
Stag: 72 
	Pattern: 2 [['for', 'the', 'sake', 'of'], [',']]---- [[], ['&V-ing/&NP@C@'], ['&R']]
	sentTXT: For the sake of clarity it is worth observing that, at least in principle, a model built in a batch fashion could also be adapted to new test data
	Cause: [(0, 4), (0, 4)]
	Effect: [(0, 11), (0, 30)]

CASE: 23
Stag: 73 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: For instance, this could be done by running periodic re-training routines once a certain amount of new labelled instances has been collected ( de facto mimicking an online process
	Cause: [(0, 8), (0, 29)]
	Effect: [(0, 0), (0, 6)]

CASE: 24
Stag: 77 78 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In our experiments, the degree of similarity is measured in terms of u'\u0394' HTER, which is computed as the absolute value of the difference between the average HTER of the training and test sets Large values indicate a low similarity between training and test data and a more challenging scenario for the learning algorithms
	Cause: [(0, 24), (1, 18)]
	Effect: [(0, 0), (0, 22)]

CASE: 25
Stag: 78 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Large values indicate a low similarity between training and test data and a more challenging scenario for the learning algorithms
	Cause: [(0, 0), (0, 1)]
	Effect: [(0, 3), (0, 19)]

CASE: 26
Stag: 87 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: The batch model is built by learning only from the training data and is evaluated on the test set without exploiting information from the test instances
	Cause: [(0, 6), (0, 11)]
	Effect: [(0, 12), (0, 25)]

CASE: 27
Stag: 89 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This baseline ( u'\u039c' henceforth) is calculated by labelling each instance of the test set with the mean HTER score of the training set
	Cause: [(0, 13), (0, 28)]
	Effect: [(0, 0), (0, 11)]

CASE: 28
Stag: 92 93 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The MAE is the average of the absolute errors e i f i - y i where f i is the prediction of the model and y i is the true value for the i t u'\u2062' h instance As our focus is on the algorithmic aspect, in all experiments we use the same feature set, which consists of the seventeen features proposed in [ 30 ]
	Cause: [(1, 1), (1, 28)]
	Effect: [(0, 27), (0, 42)]

CASE: 29
Stag: 96 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In our experiments we evaluate two online algorithms, OnlineSVR [ 24 ] 8 8 http://www2.imperial.ac.uk/~gmontana/onlinesvr.htm and Passive-Aggressive Perceptron [ 9 ] , 9 9 https://code.google.com/p/sofia-ml/ by comparing their performance with a batch learning strategy based on the Scikit-learn implementation of Support Vector Regression (SVR
	Cause: [(0, 37), (0, 45)]
	Effect: [(0, 0), (0, 34)]

CASE: 30
Stag: 98 99 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The choice of the OnlineSVR and Passive-Aggressive (OSVR and PA henceforth) is motivated by different considerations From a performance point of view, as an adaptation of u'\u0395' -SVR which proved to be one of the top performing algorithms in the regression QE tasks at WMT, OSVR seems to be the best candidate
	Cause: [(1, 8), (1, 42)]
	Effect: [(0, 1), (1, 5)]

CASE: 31
Stag: 99 100 
	Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
	sentTXT: From a performance point of view, as an adaptation of u'\u0395' -SVR which proved to be one of the top performing algorithms in the regression QE tasks at WMT, OSVR seems to be the best candidate For this reason, we use the online adaptation of u'\u0395' -SVR proposed by [ 18 ]
	Cause: [(0, 0), (0, 42)]
	Effect: [(1, 4), (1, 21)]

CASE: 32
Stag: 101 102 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The goal of OnlineSVR is to find a way to add each new sample to one of three sets (support, empty, error) maintaining the consistency of a set of conditions known as Karush-Kuhn Tucker (KKT) conditions For each new point, OSVR starts a cycle where the samples are moved across the three sets until the KKT conditions are verified and the new point is assigned to one of the sets
	Cause: [(0, 36), (1, 33)]
	Effect: [(0, 0), (0, 34)]

CASE: 33
Stag: 103 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If the point is identified as a support vector, the parameters of the model are updated
	Cause: [(0, 6), (0, 16)]
	Effect: [(0, 1), (0, 4)]

CASE: 34
Stag: 107 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If its value is larger than the tolerance parameter ( u'\u0395' ), the weights of the model are updated as much as the aggressiveness parameter C allows
	Cause: [(0, 1), (0, 15)]
	Effect: [(0, 17), (0, 31)]

CASE: 35
Stag: 109 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Although it makes PA faster than OSVR, this is a riskier strategy because it may lead the algorithm to change the model to adapt to outlier points
	Cause: [(0, 14), (0, 27)]
	Effect: [(0, 0), (0, 12)]

CASE: 36
Stag: 111 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: First, since in this artificial scenario adaptation capabilities are not required for the QE component, batch methods operate in the ideal conditions (as training and test are independent and identically distributed
	Cause: [(0, 3), (0, 15)]
	Effect: [(0, 17), (0, 33)]

CASE: 37
Stag: 111 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First, since in this artificial scenario adaptation capabilities are not required for the QE component, batch methods operate in the ideal conditions (as training and test are independent and identically distributed
	Cause: [(0, 9), (0, 16)]
	Effect: [(0, 0), (0, 7)]

CASE: 38
Stag: 113 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Second, this scenario provides the fairest conditions for such comparison because, in principle, online algorithms are not favoured by the possibility to learn from the diversity of the test instances
	Cause: [(0, 12), (0, 32)]
	Effect: [(0, 0), (0, 10)]

CASE: 39
Stag: 118 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Evaluation is carried out by measuring the performance of the batch (learning only from the training set), the adaptive (learning from the training set and adapting to the test set), and the empty (learning from scratch from the test set) models in terms of global MAE scores on the test set
	Cause: [(0, 5), (0, 58)]
	Effect: [(0, 0), (0, 3)]

CASE: 40
Stag: 119 120 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Table 1 reports the results achieved by the best performing algorithm for each type of model ( batch , adaptive , empty As can be seen, close MAE values show a similar behaviour for the three types of models
	Cause: [(1, 1), (1, 17)]
	Effect: [(0, 0), (0, 21)]

CASE: 41
Stag: 124 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This demonstrates that, as expected, the online algorithms do not take advantage of test data with a label distribution similar to the training set
	Cause: [(0, 5), (0, 25)]
	Effect: [(0, 0), (0, 2)]

CASE: 42
Stag: 125 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: All the models outperform the baseline, even if the minimal differences confirm the competitiveness of such a simple approach
	Cause: [(0, 9), (0, 19)]
	Effect: [(0, 0), (0, 7)]

CASE: 43
Stag: 133 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The source sentences were translated with two SMT systems built by training the Moses toolkit [ 14 ] on parallel data from the two domains (about 2M sentences for IT and 1.5M for L
	Cause: [(0, 11), (0, 35)]
	Effect: [(0, 0), (0, 9)]

CASE: 44
Stag: 135 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to the way they are created, the two datasets allow us to evaluate the adaptability of different QE models with respect to user changes within the same domain (ยง 6.1 ), as well as user and domain changes at the same time (ยง 6.2
	Cause: [(0, 2), (0, 6)]
	Effect: [(0, 8), (0, 46)]

CASE: 45
Stag: 136 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: For each document D (L or IT), these two scenarios are obtained by dividing D into two parts of equal size (80 instances for L and 140 for IT
	Cause: [(0, 16), (0, 32)]
	Effect: [(0, 0), (0, 14)]

CASE: 46
Stag: 136 137 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: For each document D (L or IT), these two scenarios are obtained by dividing D into two parts of equal size (80 instances for L and 140 for IT The result is one training set and one test set for each post-editor within the same domain
	Cause: [(0, 0), (0, 32)]
	Effect: [(1, 3), (1, 16)]

CASE: 47
Stag: 142 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: For each domain, these respectively involve the most dissimilar and the most similar post-editors according to the u'\u0394' HTER
	Cause: [(0, 17), (0, 23)]
	Effect: [(0, 0), (0, 14)]

CASE: 48
Stag: 144 145 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The first scenario defines a challenging situation where two post-editors ( rad and cons ) are characterized by opposite behaviour As evidenced by the high u'\u0394' HTER values, one of them ( rad ) is the most u'\u201c' radical u'\u201d' post-editor (performing more corrections) while the other ( cons ) is the most u'\u201c' conservative u'\u201d' one
	Cause: [(1, 1), (1, 58)]
	Effect: [(0, 0), (0, 19)]

CASE: 49
Stag: 145 146 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: As evidenced by the high u'\u0394' HTER values, one of them ( rad ) is the most u'\u201c' radical u'\u201d' post-editor (performing more corrections) while the other ( cons ) is the most u'\u201c' conservative u'\u201d' one As shown in Table 2 , global MAE scores for the online algorithms (both adaptive and empty ) indicate their good adaptation capabilities
	Cause: [(1, 1), (1, 23)]
	Effect: [(0, 0), (0, 59)]

CASE: 50
Stag: 149 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: These results (MAE reductions are always statistically significant) suggest that, when dealing with datasets with very different label distributions, the evident limitations of batch methods are more easily overcome by learning from scratch from the feedback of a new post-editor
	Cause: [(0, 34), (0, 43)]
	Effect: [(0, 0), (0, 32)]

CASE: 51
Stag: 150 151 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This also holds when the amount of test points to learn from is limited, as in the L domain where the test set contains only 80 instances From the application-oriented perspective that motivates our work, considering the high costs of acquiring large and representative QE training data, this is an important finding
	Cause: [(0, 16), (1, 25)]
	Effect: [(0, 0), (0, 13)]

CASE: 52
Stag: 156 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: A closer look at the behaviour of the online algorithms in the two domains leads to other observations
	Cause: [(0, 0), (0, 13)]
	Effect: [(0, 16), (0, 17)]

CASE: 53
Stag: 160 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: For OSVR the addition of new points to the support set may have a limited effect on the whole model, in particular if the number of points in the set is large
	Cause: [(0, 24), (0, 32)]
	Effect: [(0, 1), (0, 22)]

CASE: 54
Stag: 168 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: In the table, results are ordered according to the u'\u0394' HTER computed between the selected post-editor in the training domain ( e.g., L cons ) and the selected post-editor in the test domain ( e.g., IT rad
	Cause: [(0, 9), (0, 24)]
	Effect: [(0, 28), (0, 33)]

CASE: 55
Stag: 169 
	Pattern: 2 [['for', 'the', 'sake', 'of'], [',']]---- [[], ['&V-ing/&NP@C@'], ['&R']]
	sentTXT: For the sake of comparison, we also report (grey rows) the results of the experiments within the same domain presented in ยง 6.1
	Cause: [(0, 4), (0, 4)]
	Effect: [(0, 6), (0, 24)]

CASE: 56
Stag: 175 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: This is a strong evidence of the fact that, in case of domain changes, online models can still learn from new test instances even if they have a label distribution similar to the training set
	Cause: [(0, 27), (0, 36)]
	Effect: [(0, 0), (0, 25)]

CASE: 57
Stag: 182 183 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This suggests that, although PA is potentially capable of achieving higher results and better adapt to the new test points, its instability makes it less reliable for practical use As a final analysis of our results, we investigated how the performance of the different types of models ( batch , adaptive , empty ) relates to the distance between training and test sets
	Cause: [(1, 1), (1, 34)]
	Effect: [(0, 0), (0, 30)]

CASE: 58
Stag: 188 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: As expected, the results of the empty models are completely uncorrelated with the u'\u0394' HTER since they only use the test set
	Cause: [(0, 21), (0, 26)]
	Effect: [(0, 0), (0, 19)]

