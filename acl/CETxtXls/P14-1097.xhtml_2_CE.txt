************************************************************
P14-1097.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We present an unsupervised method for inducing verb classes from verb uses in giga-word corpora
	Cause: inducing verb classes from verb uses in giga-word corpora
	Effect: We present an unsupervised method

CASE: 1
Stag: 1 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Our method consists of two clustering steps verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames
	Cause: clustering verb uses in a corpus
	Effect: and then verb classes are induced by clustering these frames

CASE: 2
Stag: 1 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: and then verb classes are induced by clustering these frames
	Cause: clustering these frames
	Effect: classes are induced

CASE: 3
Stag: 2 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: By taking this step-wise approach , we can not only generate verb classes based on a massive amount of verb uses in a scalable manner , but also deal with verb polysemy , which is bypassed by most of the previous studies on verb clustering
	Cause: a massive amount of verb uses in a scalable manner
	Effect: but also deal with verb polysemy , which is bypassed by most of the previous studies on verb clustering

CASE: 4
Stag: 4 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The effectiveness of our approach is verified through quantitative evaluations based on polysemy-aware gold-standard data
	Cause: polysemy-aware gold-standard data
	Effect: The effectiveness of our approach is verified through quantitative evaluations

CASE: 5
Stag: 6 7 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Capturing the sense of a verb is essential for natural language processing -LRB- NLP -RRB- , and thus lexical resources for verbs play an important role in NLP Verb classes are one such lexical resource
	Cause: Capturing the sense of a verb is essential for natural language processing -LRB- NLP -RRB-
	Effect: lexical resources for verbs play an important role in NLP Verb classes are one such lexical

CASE: 6
Stag: 12 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This monosemous assumption , however , is not realistic because many frequent verbs actually have multiple senses
	Cause: many frequent verbs actually have multiple senses
	Effect: This monosemous assumption , however , is not realistic

CASE: 7
Stag: 14 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this paper , we propose an unsupervised method for inducing verb classes that is aware of verb polysemy
	Cause: inducing verb classes that is aware of verb polysemy
	Effect: In this paper , we propose an unsupervised method

CASE: 8
Stag: 15 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Our method consists of two clustering steps verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames
	Cause: clustering verb uses in a corpus
	Effect: and then verb classes are induced by clustering these frames

CASE: 9
Stag: 15 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: and then verb classes are induced by clustering these frames
	Cause: clustering these frames
	Effect: classes are induced

CASE: 10
Stag: 16 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By taking this step-wise approach , we can not only induce verb classes with frequency information from a massive amount of verb uses in a scalable manner , but also deal with verb polysemy
	Cause: taking this step-wise approach
	Effect: , we can not only induce verb classes with frequency information from a massive amount of verb uses in a scalable manner , but also deal with verb polysemy

CASE: 11
Stag: 28 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2009 -RRB- proposed a Dirichlet process mixture model -LRB- DPMM ; Neal -LRB- 2000 -RRB- -RRB- to cluster verbs based on subcategorization frame distributions
	Cause: subcategorization frame distributions
	Effect: 2009 -RRB- proposed a Dirichlet process mixture model -LRB- DPMM ; Neal -LRB- 2000 -RRB- -RRB- to cluster verbs

CASE: 12
Stag: 31 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: 2006 -RRB- -RRB- model to jointly learn argument structures -LRB- subcategorization frames -RRB- and verb classes by using syntactic features
	Cause: using syntactic features
	Effect: 2006 -RRB- -RRB- model to jointly learn argument structures -LRB- subcategorization frames -RRB- and verb classes

CASE: 13
Stag: 32 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Parisien and Stevenson -LRB- 2011 -RRB- extended their model by adding semantic features
	Cause: adding semantic features
	Effect: Parisien and Stevenson -LRB- 2011 -RRB- extended their model

CASE: 14
Stag: 35 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: 2012 -RRB- extended the model of Titov and Klementiev -LRB- 2012 -RRB- , which is an unsupervised model for inducing semantic roles , to jointly induce semantic roles and frames across verbs using the Chinese Restaurant Process -LSB- 1 -RSB-
	Cause: inducing semantic roles
	Effect: 2012 -RRB- extended the model of Titov and Klementiev -LRB- 2012 -RRB- , which is an unsupervised model

CASE: 15
Stag: 46 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: In particular , they tried to consider verb polysemy by using the IB method , which is a soft clustering method -LSB- 43 -RSB-
	Cause: using the IB method , which is a soft clustering method -LSB- 43 -RSB-
	Effect: In particular , they tried to consider verb polysemy

CASE: 16
Stag: 47 48 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: However , the verb itself is still represented as a single data point After performing soft clustering , they noted that most verbs fell into a single class , and they decided to assign a single class to each verb by hardening the clustering
	Cause: a single data point After performing soft clustering , they noted that most verbs fell into a single
	Effect: However , the verb itself is still represented

CASE: 17
Stag: 48 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: After performing soft clustering , they noted that most verbs fell into a single class , and they decided to assign a single class to each verb by hardening the clustering
	Cause: hardening the clustering
	Effect: a single class , and they decided to assign a single class to each verb

CASE: 18
Stag: 51 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Lapata and Brew -LRB- 2004 -RRB- and Li and Brew -LRB- 2007 -RRB- proposed probabilistic models for calculating prior probabilities of verb classes for a verb
	Cause: calculating prior probabilities of verb classes for a verb
	Effect: Lapata and Brew -LRB- 2004 -RRB- and Li and Brew -LRB- 2007 -RRB- proposed probabilistic models

CASE: 19
Stag: 52 53 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: These models are approximated to condition not on verbs but on subcategorization frames As mentioned in Li and Brew -LRB- 2007 -RRB- , it is desirable to extend the model to depend on verbs to further improve accuracy
	Cause: mentioned in Li and Brew -LRB- 2007 -RRB- , it is desirable to extend the model to depend on verbs to further improve accuracy
	Effect: These models are approximated to condition not on verbs but on subcategorization frames

CASE: 20
Stag: 56 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2008 -RRB- also applied probabilistic soft clustering to verbs by incorporating subcategorization frames and selectional preferences based on WordNet
	Cause: WordNet
	Effect: 2008 -RRB- also applied probabilistic soft clustering to verbs by incorporating subcategorization frames and selectional preferences

CASE: 21
Stag: 56 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: 2008 -RRB- also applied probabilistic soft clustering to verbs by incorporating subcategorization frames and selectional preferences
	Cause: incorporating subcategorization frames
	Effect: and selectional preferences

CASE: 22
Stag: 57 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: This model is based on the Expectation-Maximization algorithm and the Minimum Description Length principle
	Cause: the Expectation-Maximization algorithm and the Minimum Description Length principle
	Effect: This model

CASE: 23
Stag: 58 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since they focused on the incorporation of selectional preferences , they did not evaluate verb classes but evaluated only selectional preferences using a language model-based measure
	Cause: they focused on the incorporation of selectional preferences
	Effect: they did not evaluate verb classes but evaluated only selectional preferences using a language model-based measure

CASE: 24
Stag: 61 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: He used a model based on latent Dirichlet allocation -LRB- LDA ; Blei et al
	Cause: latent Dirichlet allocation -LRB- LDA ; Blei et al
	Effect: He used a model

CASE: 25
Stag: 63 64 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Both of these are represented as a probabilistic distribution of words across verbs He applied this method to the BNC and acquired 1,200 frames and 400 roles -LSB- 21 -RSB-
	Cause: a probabilistic distribution of words across verbs He applied this method to the BNC and acquired 1,200 frames and 400 roles -LSB-
	Effect: Both of these are represented

CASE: 26
Stag: 68 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Although Bayesian approaches are a possible solution to simultaneously induce frames and verb classes from a corpus as used in previous studies , it has prohibitive computational cost
	Cause: used in previous studies , it has prohibitive computational cost
	Effect: Bayesian approaches are a possible solution to simultaneously induce frames and verb classes from a corpus

CASE: 27
Stag: 75 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this paper , we propose a two-step approach for inducing semantic frames and verb classes
	Cause: inducing semantic frames and verb classes
	Effect: In this paper , we propose a two-step approach

CASE: 28
Stag: 76 77 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First , we make multiple data points for each verb to deal with verb polysemy -LRB- cf polysemy-aware previous studies still represented a verb as one data point -LSB- 14 , 23 -RSB- To do that , we induce verb-specific semantic frames by clustering verb uses
	Cause: one data point -LSB- 14 , 23 -RSB- To do that , we induce verb-specific semantic frames by clustering verb uses
	Effect: First , we make multiple data points for each verb to deal with verb polysemy -LRB- cf polysemy-aware previous studies still represented a verb

CASE: 29
Stag: 78 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Then , we induce verb classes by clustering these verb-specific semantic frames across verbs
	Cause: clustering these verb-specific semantic frames across verbs
	Effect: Then , we induce verb classes

CASE: 30
Stag: 81 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: induce verb-specific semantic frames by clustering predicate-argument structures for each verb extracted from automatic parses as shown in the lower part of Figure 1 , and
	Cause: clustering predicate-argument structures for each verb extracted from automatic parses
	Effect: as shown in the lower part of Figure 1 , and

CASE: 31
Stag: 82 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: induce verb classes by clustering the induced semantic frames across verbs as shown in the upper part of Figure 1
	Cause: clustering the induced semantic frames across verbs
	Effect: as shown in the upper part of Figure 1

CASE: 32
Stag: 84 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We induce verb-specific semantic frames from verb uses based on the method of Kawahara et al
	Cause: the method of Kawahara et al
	Effect: We induce verb-specific semantic frames from verb uses

CASE: 33
Stag: 89 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: merge the predicate-argument structures that have presumably the same meaning based on the assumption of one sense per collocation -LSB- 46 -RSB- to get a set of initial frames , and
	Cause: the assumption of one sense per collocation -LSB- 46 -RSB- to get a set of initial frames , and
	Effect: merge the predicate-argument structures that have presumably the same meaning

CASE: 34
Stag: 90 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: apply clustering to the initial frames based on the Chinese Restaurant Process -LSB- 1 -RSB- to produce verb-specific semantic frames
	Cause: the Chinese Restaurant Process -LSB- 1 -RSB- to produce verb-specific semantic frames
	Effect: apply clustering to the initial frames

CASE: 35
Stag: 104 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We select an argument in the following order by considering the degree of effect on the verb sense
	Cause: considering the degree of effect on the verb sense
	Effect: We select an argument in the following order

CASE: 36
Stag: 105 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: 3 3 If a predicate-argument structure has multiple prepositional phrases , one of them is randomly selected
	Cause: a predicate-argument structure has multiple prepositional phrases
	Effect: one of them is randomly selected

CASE: 37
Stag: 113 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: P -LRB- f i c j -RRB- is defined based on the Dirichlet-Multinomial distribution as follows
	Cause: the Dirichlet-Multinomial distribution as follows
	Effect: P -LRB- f i c j -RRB- is defined

CASE: 38
Stag: 115 116 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The original method in Kawahara et al 2014 -RRB- defined w as pairs of slots and words , e.g. , , u ' \ u201c ' nsubj : child u ' \ u201d ' and u ' \ u201c ' dobj : bird , u ' \ u201d ' but does not consider slot-only features , e.g. , , u ' \ u201c ' nsubj u ' \ u201d ' and u ' \ u201c ' dobj , u ' \ u201d ' which ignore lexical information
	Cause: pairs of slots and words , e.g. , , u ' \ u201c ' nsubj : child u ' \ u201d ' and u ' \ u201c ' dobj : bird , u ' \ u201d ' but does not consider slot-only features , e.g. , , u ' \ u201c ' nsubj u ' \ u201d ' and u ' \ u201c ' dobj , u ' \ u201d ' which ignore lexical information
	Effect: Kawahara et al 2014 -RRB- defined w

CASE: 39
Stag: 122 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We regard each output cluster as a semantic frame , by merging the initial frames in a cluster into a semantic frame
	Cause: merging the initial frames in a cluster into a semantic frame
	Effect: We regard each output cluster as a semantic frame ,

CASE: 40
Stag: 126 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We can use exactly the same clustering method as described in Section 3.2.3 by using semantic frames for multiple verbs as an input instead of initial frames for a single verb
	Cause: using semantic frames for multiple verbs as an input instead of initial frames for a single verb
	Effect: We can use exactly the same clustering method as described in Section 3.2.3

CASE: 41
Stag: 127 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: This is because an initial frame has the same structure as a semantic frame , which is produced by merging initial frames
	Cause: an initial frame has the same structure as a semantic frame
	Effect: which is produced by merging initial frames

CASE: 42
Stag: 128 129 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We regard each output cluster as a verb class this time For the features , w , in equation -LRB- 2 -RRB- , we try the two representations again slot-only features and slot-word pair features
	Cause: a verb class this time For the features , w , in equation -LRB- 2 -RRB- , we try the two representations again slot-only features and slot-word pair
	Effect: We regard each output cluster

CASE: 43
Stag: 131 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: The other representation using the slot-word pairs means that semantic similarity based on word overlap is naturally considered by looking at lexical information
	Cause: word overlap is naturally considered by looking at lexical information
	Effect: The other representation using the slot-word pairs means that semantic similarity

CASE: 44
Stag: 131 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: word overlap is naturally considered by looking at lexical information
	Cause: looking at lexical information
	Effect: word overlap is naturally considered

CASE: 45
Stag: 135 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: These two levels of evaluations are performed by considering the work of Reichart et al
	Cause: considering the work of Reichart et al
	Effect: These two levels of evaluations are performed

CASE: 46
Stag: 139 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: To prepare a web corpus , we extracted sentences from crawled web pages that are judged to be written in English based on the encoding information
	Cause: the encoding information
	Effect: To prepare a web corpus , we extracted sentences from crawled web pages that are judged to be written in English

CASE: 47
Stag: 153 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: However , since these measures are only applicable to a hard clustering , it is necessary to extend them to be applicable to a soft clustering , because in our task a verb can belong to multiple clusters or classes
	Cause: these measures are only applicable to a hard clustering
	Effect: it is necessary to extend them to be applicable to a soft clustering , because in our task a verb can belong to multiple clusters or classes

CASE: 48
Stag: 153 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: it is necessary to extend them to be applicable to a soft clustering , because in our task a verb can belong to multiple clusters or classes
	Cause: in our task a verb can belong to multiple clusters or classes
	Effect: it is necessary to extend them to be applicable to a soft clustering

CASE: 49
Stag: 155 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: 2003 -RRB- evaluated hard clusterings based on a gold standard with multiple classes per verb
	Cause: a gold standard with multiple classes per verb
	Effect: 2003 -RRB- evaluated hard clusterings

CASE: 50
Stag: 166 167 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In addition , to penalize clusters that consist of only one verb , such singleton clusters in K are considered as errors , as is usual with modified purity The normalized modified purity -LRB- nmPU -RRB- can then be written as follows
	Cause: errors , as is usual with modified purity The normalized modified purity -LRB- nmPU -RRB- can then be written as
	Effect: In addition , to penalize clusters that consist of only one verb , such singleton clusters in K are considered

CASE: 51
Stag: 169 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: K i denotes the number of positive components in K i , and c i u ' \ u2062 ' v denotes the v - th component of K i u ' \ u0394 ' K i u ' \ u2062 ' -LRB- K i u ' \ u2229 ' G j -RRB- means the total mass of the set of verbs in K i u ' \ u2229 ' G j , given by summing up the values in K i
	Cause: summing up the values in K i
	Effect: the number of positive components in K i , and c i u ' \ u2062 ' v denotes the v - th component of K i u ' \ u0394 ' K i u ' \ u2062 ' -LRB- K i u ' \ u2229 ' G j -RRB- means the total mass of the set of verbs in K i u ' \ u2229 ' G j , given

CASE: 52
Stag: 171 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: K i u ' \ u2229 ' G j because all the values of c i u ' \ u2062 ' v are equal to 1
	Cause: all the values of c i u ' \ u2062 ' v are equal to 1
	Effect: K i u ' \ u2229 ' G j

CASE: 53
Stag: 171 172 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: K i u ' \ u2229 ' G j because all the values of c i u ' \ u2062 ' v are equal to 1 As usual , the following normalized inverse purity -LRB- niPU -RRB- is used to measure the recall of a clustering
	Cause: usual , the following normalized inverse purity -LRB- niPU -RRB- is used to measure the recall of a clustering
	Effect: K i u ' \ u2229 ' G j because all the values of c i u ' \ u2062 ' v are equal to 1

CASE: 54
Stag: 173 174 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Finally , we use the harmonic mean -LRB- F 1 -RRB- of nmPU and niPU as a single measure of clustering quality We first evaluate our induced verb classes on the test set created by Korhonen et al
	Cause: a single measure of clustering quality We first evaluate our induced verb classes on the test set created by Korhonen et
	Effect: Finally , we use the harmonic mean -LRB- F 1 -RRB- of nmPU and niPU

CASE: 55
Stag: 175 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: 2003 -RRB- -LRB- Table 1 of their paper -RRB- which was created by considering verb polysemy on the basis of Levin u ' \ u2019 ' s classes and the LCS database -LSB- 6 -RSB-
	Cause: considering verb polysemy on the basis
	Effect: of Levin u ' \ u2019 ' s classes and

CASE: 56
Stag: 178 179 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: An excerpt from this data is shown in Table 1 As our baselines , we adopt two previously proposed methods
	Cause: our baselines , we adopt two previously proposed methods
	Effect: An excerpt from this data is shown in Table 1

CASE: 57
Stag: 187 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 2003 -RRB- , prepositional phrases -LRB- pp -RRB- are parameterized for two frequent subcategorization frames -LRB- NP and NP_PP -RRB- , and the unfiltered raw frequencies of subcategorization frames are used as features to represent a verb
	Cause: features to represent
	Effect: for two frequent subcategorization frames -LRB- NP and NP_PP -RRB- , and the unfiltered raw frequencies of subcategorization frames are used

CASE: 58
Stag: 188 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: It is necessary to specify the number of clusters , k , for the IB method beforehand , and we adopt 35 and 42 clusters according to their reported high accuracies
	Cause: their reported high accuracies
	Effect: It is necessary to specify the number of clusters , k , for the IB method beforehand , and we adopt 35 and 42 clusters

CASE: 59
Stag: 200 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The results of the IB baseline and our methods are obtained by averaging five runs
	Cause: averaging five runs
	Effect: The results of the IB baseline and our methods are obtained

CASE: 60
Stag: 201 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We can see that u ' \ u201c ' web/SW-S u ' \ u201d ' achieved the best performance and obtained a higher F 1 than the baselines by more than nine points u ' \ u201c ' Web/SW-S u ' \ u201d ' uses the combination of slot-word pair features for clustering verb-specific frames and slot-only features for clustering across verbs
	Cause: clustering verb-specific frames
	Effect: We can see that u ' \ u201c ' web/SW-S u ' \ u201d ' achieved the best performance and obtained a higher F 1 than the baselines by more than nine points u ' \ u201c ' Web/SW-S u ' \ u201d ' uses the combination of slot-word pair features

CASE: 61
Stag: 201 202 
	Pattern: 0 [[['imply', 'implies', 'implied', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(that)', '&R@Complete@']]
	sentTXT: We can see that u ' \ u201c ' web/SW-S u ' \ u201d ' achieved the best performance and obtained a higher F 1 than the baselines by more than nine points u ' \ u201c ' Web/SW-S u ' \ u201d ' uses the combination of slot-word pair features for clustering verb-specific frames and slot-only features for clustering across verbs Interestingly , this result indicates that slot distributions are more effective than lexical information in slot-word pairs for inducing verb classes similar to the gold standard
	Cause: can see that u ' \ u201c ' web/SW-S u ' \ u201d ' achieved the best performance and obtained a higher F 1 than the baselines by more than nine points u ' \ u201c ' Web/SW-S u ' \ u201d ' uses the combination of slot-word pair features for clustering verb-specific frames and slot-only features for clustering across verbs Interestingly
	Effect: slot distributions are more effective than lexical information in slot-word pairs for inducing verb classes similar to the gold standard

CASE: 62
Stag: 203 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: This result is consistent with expectations , given a gold standard based on Levin u ' \ u2019 ' s verb classes , which are organized according to the syntactic behavior of verbs
	Cause: Levin u ' \ u2019 ' s verb classes
	Effect: which are organized according to the syntactic behavior of verbs

CASE: 63
Stag: 203 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: which are organized according to the syntactic behavior of verbs
	Cause: the syntactic behavior of verbs
	Effect: which are organized

CASE: 64
Stag: 208 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since we focus on the handling of verb polysemy , predominant class induction for each verb is not our main objective
	Cause: we focus on the handling of verb polysemy
	Effect: predominant class induction for each verb is not our main objective

CASE: 65
Stag: 210 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: To output a single class for each verb by using our proposed method , we skip the induction of verb-specific semantic frames and instead create a single frame for each verb by merging all predicate-argument structures of the verb
	Cause: using our proposed method
	Effect: , we skip the induction of verb-specific semantic frames and instead create a single frame for each verb by merging all predicate-argument structures of the verb

CASE: 66
Stag: 213 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: We evaluate the single-class output for each verb based on the predominant gold-standard classes , which are defined for each verb in the test set of Korhonen et al
	Cause: the predominant gold-standard classes
	Effect: which are defined for each verb in the test set of Korhonen et al

CASE: 67
Stag: 217 218 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 2003 -RRB- , using the gold standard with multiple classes , which we also use for our multi-class evaluations As we did with the multi-class evaluations , we adopt modified purity -LRB- mPU -RRB- , inverse purity -LRB- iPU -RRB- and their harmonic mean -LRB- F 1 -RRB- as the metrics for the evaluation with predominant classes
	Cause: we did with the multi-class evaluations , we adopt modified purity -LRB- mPU -RRB- , inverse purity -LRB- iPU -RRB- and their harmonic mean -LRB- F 1 -RRB- as the metrics for the evaluation with predominant classes
	Effect: we also use for our multi-class evaluations

CASE: 68
Stag: 219 220 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: It is not necessary to normalize these metrics when we treat verbs as monosemous , and evaluate against the predominant sense When we evaluate against the multiple classes in the gold standard , we do normalize the inverse purity
	Cause: monosemous , and evaluate against the predominant sense When we evaluate against the multiple classes in the gold standard , we do normalize the inverse purity
	Effect: It is not necessary to normalize these metrics when we treat verbs

CASE: 69
Stag: 223 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The clusterings with the NN and IB methods are obtained by using the VALEX subcategorization lexicon
	Cause: using the VALEX subcategorization lexicon
	Effect: The clusterings with the NN and IB methods are obtained

CASE: 70
Stag: 227 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: Note that our results of the NN and IB methods are different from those reported in their paper since the data source is different
	Cause: the data source is different
	Effect: Note that our results of the NN and IB methods are different from those reported in their paper

CASE: 71
Stag: 233 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: From the result , we can see that the induced verb classes based on slot-only features did not achieve a higher F 1 than those based on slot-word pair features in many cases
	Cause: slot-word pair features in many cases
	Effect: From the result , we can see that the induced verb classes based on slot-only features did not achieve a higher F 1 than those

CASE: 72
Stag: 233 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: From the result , we can see that the induced verb classes based on slot-only features did not achieve a higher F 1 than those
	Cause: slot-only features did not achieve a higher F 1 than those
	Effect: From the result , we can see that the induced verb classes

CASE: 73
Stag: 235 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We speculate that slot distributions are not so different among verbs when all uses of a verb are merged into one frame , and thus their discrimination power is lower than that in the intermediate construction of semantic frames
	Cause: We speculate that slot distributions are not so different among verbs when all uses of a verb are merged into one frame
	Effect: their discrimination power is lower than that in the intermediate construction of semantic frames

CASE: 74
Stag: 235 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: We speculate that slot distributions are not so different among verbs when all uses of a verb are merged into one frame
	Cause: We speculate that slot distributions are not
	Effect: different among verbs when all uses of a verb are merged into one

CASE: 75
Stag: 242 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: It is not necessary to normalize these metrics because the clustering of these instances is hard
	Cause: the clustering of these instances is hard
	Effect: It is not necessary to normalize these metrics

CASE: 76
Stag: 244 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The results of these methods are obtained by averaging five runs
	Cause: averaging five runs
	Effect: The results of these methods are obtained

CASE: 77
Stag: 251 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: 9 9 Since FrameNet frames are not assigned to all verbs of SemLink , the number of verbs is different from the evaluations against VerbNet classes
	Cause: FrameNet frames are not assigned to all verbs of SemLink
	Effect: the number of verbs is different from the evaluations against VerbNet classes

CASE: 78
Stag: 255 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on the best results in the above evaluations , we induced semantic frames using slot-word pair features , and then induced verb classes using slot-only features
	Cause: the best results in the above evaluations
	Effect: we induced semantic frames using slot-word pair features , and then induced verb classes using slot-only features

CASE: 79
Stag: 260 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: For instance , u ' \ u201c ' Class 2 u ' \ u201d ' consists of the semantic frames u ' \ u201c ' need :2 u ' \ u201d ' and u ' \ u201c ' say :2 u ' \ u201d ' These frames were merged due to the high syntactic similarity of constituting slot distributions , which are comprised of a subject and a sentential complement
	Cause: the high syntactic similarity of constituting slot distributions
	Effect: which are comprised of a subject and a sentential complement

CASE: 80
Stag: 262 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: We presented a step-wise unsupervised method for inducing verb classes from instances in giga-word corpora
	Cause: inducing verb classes from instances in giga-word corpora
	Effect: We presented a step-wise unsupervised method

CASE: 81
Stag: 264 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Both clustering steps are performed with exactly the same method , which is based on the Chinese Restaurant Process
	Cause: the Chinese Restaurant Process
	Effect: Both clustering steps are performed with exactly the same method , which is

CASE: 82
Stag: 267 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: From the results , we can see that the combination of the slot-word pair features for clustering verb-specific frames and the slot-only features for clustering across verbs is the most effective and outperforms the baselines by approximately 10 points
	Cause: clustering verb-specific frames
	Effect: From the results , we can see that the combination of the slot-word pair features

CASE: 83
Stag: 267 268 
	Pattern: 0 [[['imply', 'implies', 'implied', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(that)', '&R@Complete@']]
	sentTXT: From the results , we can see that the combination of the slot-word pair features for clustering verb-specific frames and the slot-only features for clustering across verbs is the most effective and outperforms the baselines by approximately 10 points This indicates that slot distributions are more effective than lexical information in slot-word pairs for the induction of verb classes , when Levin-style classes are used for evaluation
	Cause: From the results , we can see that the combination of the slot-word pair features for clustering verb-specific frames and the slot-only features for clustering across verbs is the most effective and outperforms the baselines by approximately 10 points
	Effect: slot distributions are more effective than lexical information in slot-word pairs for the induction of verb classes , when Levin-style classes are used for evaluation

CASE: 84
Stag: 269 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: This is consistent with Levin u ' \ u2019 ' s principle of organizing verb classes according to the syntactic behavior of verbs
	Cause: the syntactic behavior of verbs
	Effect: This is consistent with Levin u ' \ u2019 ' s principle of organizing verb classes

CASE: 85
Stag: 269 270 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This is consistent with Levin u ' \ u2019 ' s principle of organizing verb classes according to the syntactic behavior of verbs As applications of the resulting semantic frames and verb classes , we plan to integrate them into syntactic parsing , semantic role labeling and verb sense disambiguation
	Cause: applications of the resulting semantic frames and verb classes , we plan to integrate them into syntactic parsing , semantic role labeling and verb sense disambiguation
	Effect: This is consistent with Levin u ' \ u2019 ' s principle of organizing verb classes according to the syntactic behavior of verbs

CASE: 86
Stag: 271 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: For instance , Kawahara and Kurohashi -LRB- 2006 -RRB- improved accuracy of dependency parsing based on Japanese semantic frames automatically induced from a raw corpus
	Cause: Japanese semantic frames automatically induced from a raw corpus
	Effect: For instance , Kawahara and Kurohashi -LRB- 2006 -RRB- improved accuracy of dependency parsing

