************************************************************
P14-1020.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 
	Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
	sentTXT: Due to their origin in computer graphics , graphics processing units -LRB- GPUs -RRB- are highly optimized for dense problems , where the exact same operation is applied repeatedly to all data points
	Cause: their origin in computer graphics
	Effect: graphics processing units -LRB- GPUs -RRB- are highly optimized for dense problems , where the exact same operation is applied repeatedly to all data points

CASE: 1
Stag: 4 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: In this work , we reintroduce sparsity to GPU parsing by adapting a coarse-to-fine pruning approach to the constraints of a GPU
	Cause: adapting a coarse-to-fine pruning approach to the constraints of a GPU
	Effect: In this work , we reintroduce sparsity to GPU parsing

CASE: 2
Stag: 7 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because NLP models typically treat sentences independently , NLP problems have long been seen as u ' \ u201c ' embarrassingly parallel u ' \ u201d ' u ' \ u2013 ' large corpora can be processed arbitrarily fast by simply sending different sentences to different machines
	Cause: NLP models typically treat sentences independently
	Effect: NLP problems have long been seen as u ' \ u201c ' embarrassingly parallel u ' \ u201d ' u ' \ u2013 ' large corpora can be processed arbitrarily fast by simply sending different sentences to different machines

CASE: 3
Stag: 7 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: NLP problems have long been seen as u ' \ u201c ' embarrassingly parallel u ' \ u201d ' u ' \ u2013 ' large corpora can be processed arbitrarily fast by simply sending different sentences to different machines
	Cause: simply sending different sentences to different machines
	Effect: NLP problems have long been seen as u ' \ u201c ' embarrassingly parallel u ' \ u201d ' u ' \ u2013 ' large corpora can be processed arbitrarily fast

CASE: 4
Stag: 9 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: First , classic single-core processors and main memory architectures are no longer getting substantially faster over time , so speed gains must now come from parallelism within a single machine
	Cause: First , classic single-core processors and main memory architectures are no longer getting substantially faster over time
	Effect: speed gains must now come from parallelism within a single machine

CASE: 5
Stag: 11 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since tasks like parsing boil down to repeated read-multiply-write loops , GPUs should be many times more efficient in time , power , or cost
	Cause: tasks like parsing boil down to repeated read-multiply-write loops
	Effect: GPUs should be many

CASE: 6
Stag: 15 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Their system uses a grammar based on the Berkeley parser -LSB- 9 -RSB- -LRB- which is particularly amenable to GPU processing -RRB- , u ' \ u201c ' compiling u ' \ u201d ' the grammar into a sequence of GPU kernels that are applied densely to every item in the parse chart
	Cause: the Berkeley parser -LSB- 9 -RSB- -LRB- which is particularly amenable to GPU processing -RRB-
	Effect: u ' \ u201c ' compiling u ' \ u201d ' the grammar into a sequence of GPU kernels that are applied densely to every item in the parse chart

CASE: 7
Stag: 18 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: In this paper , we develop algorithms that can exploit sparsity on a GPU by adapting coarse-to-fine pruning to a GPU setting
	Cause: adapting coarse-to-fine pruning to a GPU setting
	Effect: In this paper , we develop algorithms that can exploit sparsity on a GPU

CASE: 8
Stag: 20 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Such extreme speedups over a dense GPU baseline currently seem unlikely because fine-grained sparsity appears to be directly at odds with dense parallelism
	Cause: fine-grained sparsity appears to be directly at odds with dense parallelism
	Effect: Such extreme speedups over a dense GPU baseline currently seem unlikely

CASE: 9
Stag: 22 23 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We use a coarse-to-fine approach as in Petrov and Klein -LRB- 2007 -RRB- , but with only one coarse pass Figure 1 shows an overview of the approach we first parse densely with a coarse grammar and then parse sparsely with the fine grammar , skipping symbols that the coarse pass deemed sufficiently unlikely
	Cause: in Petrov and Klein -LRB- 2007 -RRB- , but with only one coarse pass Figure 1 shows an overview of the approach we first parse densely with a coarse grammar and then parse sparsely with the fine grammar ,
	Effect: We use a coarse-to-fine approach

CASE: 10
Stag: 24 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using this approach , we see gains of nearly 2.5 x over the dense GPU implementation , resulting in overall speeds of up to 404 sentences per second
	Cause: Using this approach
	Effect: we see gains of nearly 2.5 x over the dense GPU implementation , resulting in overall speeds of up to 404 sentences per second

CASE: 11
Stag: 37 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Unless otherwise noted , all experiments are conducted on sentences of length u ' \ u2264 ' 40 words , and we estimate times based on batches of 20K sentences
	Cause: batches of 20K sentences
	Effect: Unless otherwise noted , all experiments are conducted on sentences of length u ' \ u2264 ' 40 words , and we estimate times

CASE: 12
Stag: 45 46 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: For instance , in a latent variable parser , the coarse grammar would have symbols like N u ' \ u2062 ' P , V u ' \ u2062 ' P , etc. , and the fine pass would have refined symbols N u ' \ u2062 ' P 0 , N u ' \ u2062 ' P 1 , V u ' \ u2062 ' P 4 , and so on In coarse-to-fine inference , one applies the grammars in sequence , computing inside and outside scores
	Cause: For instance , in a latent variable parser , the coarse grammar would have symbols like N u ' \ u2062 ' P , V u ' \ u2062 ' P , etc. , and the fine pass would have refined symbols N u ' \ u2062 ' P 0 , N u ' \ u2062 ' P 1 , V u ' \ u2062 ' P 4
	Effect: on In coarse-to-fine inference , one applies the grammars in sequence , computing inside and outside

CASE: 13
Stag: 51 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: This approach works because a low quality coarse grammar can still reliably be used to prune many symbols from the fine chart without loss of accuracy
	Cause: a low quality coarse grammar can still reliably be used to prune many symbols from the fine chart without loss of accuracy
	Effect: This approach works

CASE: 14
Stag: 53 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Thus , the vast majority of rules can be skipped , and therefore most computation can be avoided
	Cause: Thus , the vast majority of rules can be skipped
	Effect: most computation can be avoided

CASE: 15
Stag: 54 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: It is worth pointing out that although 98 % of labeled spans can be skipped due to X-bar pruning , we found that only about 79 % of binary rule applications can be skipped , because the unpruned symbols tend to be the ones with a larger grammar footprint
	Cause: the unpruned symbols tend to be the ones with a larger grammar footprint
	Effect: It is worth pointing out that although 98 % of labeled spans can be skipped due to X-bar pruning , we found that only about 79 % of binary rule applications can be skipped

CASE: 16
Stag: 54 
	Pattern: 1 [['it', 'is'], ['due', 'to'], ['that']]---- [[], ['(&ADV)'], ['&NP@C@'], ['&R']]
	sentTXT: It is worth pointing out that although 98 % of labeled spans can be skipped due to X-bar pruning , we found that only about 79 % of binary rule applications can be skipped
	Cause: X-bar pruning
	Effect: only about 79 % of binary rule applications can be skipped

CASE: 17
Stag: 56 57 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: GPUs work by executing thousands of threads at once , but impose the constraint that large blocks of threads must be executing the same instructions in lockstep , differing only in their input data Thus sparsely skipping rules and symbols will not save any work
	Cause: GPUs work by executing thousands of threads at once , but impose the constraint that large blocks of threads must be executing the same instructions in lockstep , differing only in their input data
	Effect: sparsely skipping rules and symbols will not save any

CASE: 18
Stag: 61 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: All threads in a warp must execute the same instruction at every clock cycle if one thread takes a branch the others do not , then all threads in the warp must follow both code paths
	Cause: one thread takes a branch the others do not
	Effect: then all threads in the warp must follow both code

CASE: 19
Stag: 63 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because all threads execute all code paths that any thread takes , time can only be saved if an entire warp agrees to skip any particular branch
	Cause: all threads execute all code paths that any thread takes
	Effect: time can only be saved if an entire warp agrees to skip any particular branch

CASE: 20
Stag: 63 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: time can only be saved if an entire warp agrees to skip any particular branch
	Cause: an entire warp agrees to skip any particular branch
	Effect: time can only be saved

CASE: 21
Stag: 67 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: Each SM can process up to 48 different warps at a time it interleaves the execution of each warp , so that when one warp is stalled another warp can execute
	Cause: Each SM can process up to 48 different warps at a time it interleaves the execution of each warp ,
	Effect: when one warp is stalled another warp can execute

CASE: 22
Stag: 71 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: On the 600 series , maximum occupancy can only be achieved if each thread uses at most 63 registers -LSB- 8 -RSB-
	Cause: each thread uses at most 63 registers -LSB- 8 -RSB-
	Effect: On the 600 series , maximum occupancy can only be achieved

CASE: 23
Stag: 72 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: 2 2 A thread can use more registers than this , but the full complement of 48 warps can not execute if too many are used
	Cause: too many are used
	Effect: can use more registers than this , but the full complement of 48 warps can not execute

CASE: 24
Stag: 73 74 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Registers are many times faster than variables located in thread-local memory , which is actually the same speed as global memory This architecture environment puts very different constraints on parsing algorithms from a CPU environment
	Cause: global memory This architecture environment puts very different constraints on parsing algorithms from a CPU
	Effect: Registers are many times faster than variables located in thread-local memory , which is actually the same speed

CASE: 25
Stag: 78 79 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In this section , we describe their dense algorithm , which we take as the baseline for our work ; we present it in a way that sets up the changes to follow At the top level , the CPU and GPU communicate via a work queue of parse items of the form -LRB- s , i , k , j -RRB- , where s is an identifier of a sentence , i is the start of a span , k is the split point , and j is the end point
	Cause: the baseline for our work ; we present it in a way that sets up the changes to follow At the top level , the CPU and GPU communicate via a work queue of parse items of the form -LRB- s , i , k , j -RRB- , where s is an identifier of a sentence , i is the start of a span , k is the split
	Effect: In this section , we describe their dense algorithm , which we take

CASE: 26
Stag: 83 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because all rules are applied to all parse items , all threads are executing the same sequence of instructions
	Cause: all rules are applied to all parse items
	Effect: all threads are executing the same sequence of instructions

CASE: 27
Stag: 83 84 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Because all rules are applied to all parse items , all threads are executing the same sequence of instructions Thus , there is no concern of warp divergence
	Cause: Because all rules are applied to all parse items , all threads are executing the same sequence of instructions
	Effect: , there is no concern of warp divergence

CASE: 28
Stag: 87 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Because registers are so much faster than thread-local memory , it is critical to keep as many variables in registers as possible
	Cause: Because registers are
	Effect: much faster than thread-local memory , it is critical to keep as many variables in registers as possible

CASE: 29
Stag: 88 89 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: One way to accomplish this is to unroll loops at compilation time Therefore , they inlined the iteration over the grammar directly into the GPU kernels -LRB- i.e. , the code itself -RRB- , which allows the compiler to more effectively use all of its registers
	Cause: One way to accomplish this is to unroll loops at compilation time
	Effect: they inlined the iteration over the grammar directly into the GPU kernels -LRB- i.e. , the code itself -RRB- , which allows the compiler to more effectively use all of its registers

CASE: 30
Stag: 91 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Because the Berkeley grammar is so large , the compiler is not able to efficiently schedule all of the operations in the grammar , resulting in register spills
	Cause: Because the Berkeley grammar is
	Effect: large , the compiler is not able to efficiently schedule all of the operations in the grammar , resulting in register spills

CASE: 31
Stag: 102 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: The natural implementation would be for each thread to check if each rule is licensed before applying it
	Cause: each rule is licensed before applying it
	Effect: The natural implementation would be for each thread to check

CASE: 32
Stag: 103 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: However , we would only avoid the work of applying the rule if all threads in the warp agreed to skip it
	Cause: all threads in the warp agreed to skip it
	Effect: However , we would only avoid the work of applying the rule

CASE: 33
Stag: 104 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since each thread in the warp is processing a different span -LRB- perhaps even from a different sentence -RRB- , consensus from all 32 threads on any skip would be unlikely
	Cause: each thread in the warp is processing a different span -LRB- perhaps even from a different sentence -RRB-
	Effect: consensus from all 32 threads on any skip would be unlikely

CASE: 34
Stag: 107 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because of the overhead associated with creating pruning masks and the further overhead of GPU communication , we found that this method did not actually produce any time savings at all
	Cause: of the overhead associated with creating pruning masks and the further overhead of GPU
	Effect: we found that this method did not actually produce any time savings at all

CASE: 35
Stag: 107 108 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Because of the overhead associated with creating pruning masks and the further overhead of GPU communication , we found that this method did not actually produce any time savings at all The result is a parsing speed of 185.5 sentences per second , as shown in Table 1 on the row labeled u ' \ u2018 ' Reimpl u ' \ u2019 ' with u ' \ u2018 ' Empty , Coarse u ' \ u2019 ' pruning
	Cause: Because of the overhead associated with creating pruning masks and the further overhead of GPU communication , we found that this method did not actually produce any time savings at all
	Effect: a parsing speed of 185.5 sentences per second , as shown in Table 1 on the row labeled u ' \ u2018 ' Reimpl u ' \ u2019 ' with u ' \ u2018 ' Empty , Coarse u ' \ u2019 ' pruning

CASE: 36
Stag: 113 114 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: We call the set of coarse symbols for a partition -LRB- and therefore the corresponding labeled work queue -RRB- a signature During parsing , we only enqueue items -LRB- s , i , k , j -RRB- to a labeled queue if two conditions are met
	Cause: We call the set of coarse symbols for a partition -LRB-
	Effect: the corresponding labeled work queue -RRB- a signature During parsing , we only enqueue items -LRB- s , i , k , j -RRB- to a labeled queue if two conditions are

CASE: 37
Stag: 114 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: During parsing , we only enqueue items -LRB- s , i , k , j -RRB- to a labeled queue if two conditions are met
	Cause: two conditions are met
	Effect: During parsing , we only enqueue items -LRB- s , i , k , j -RRB- to a labeled queue

CASE: 38
Stag: 119 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because the entire partition -LRB- though not necessarily the entire grammar -RRB- is applied to each item in the queue , we still do not need to worry about warp divergence
	Cause: the entire partition -LRB- though not necessarily the entire grammar -RRB- is applied to each item in the queue
	Effect: we still do not need to worry about warp divergence

CASE: 39
Stag: 124 125 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We tested our new pruning approach using an X-bar grammar as the coarse pass The resulting speed is 187.5 sentences per second , labeled in Table 1 as row labeled u ' \ u2018 ' Reimpl u ' \ u2019 ' with u ' \ u2018 ' Labeled , Coarse u ' \ u2019 ' pruning
	Cause: the coarse pass The resulting speed is 187.5 sentences per second , labeled in Table 1 as row labeled u ' \ u2018 ' Reimpl u ' \ u2019 ' with u ' \ u2018 ' Labeled , Coarse u ' \ u2019 '
	Effect: We tested our new pruning approach using an X-bar grammar

CASE: 40
Stag: 124 125 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: We tested our new pruning approach using an X-bar grammar as the coarse pass The resulting speed is 187.5 sentences per second , labeled in Table 1 as row labeled u ' \ u2018 ' Reimpl u ' \ u2019 ' with u ' \ u2018 ' Labeled , Coarse u ' \ u2019 ' pruning
	Cause: We tested our new pruning approach using an X-bar grammar as the coarse pass
	Effect: 187.5 sentences per second , labeled in Table 1 as row labeled u ' \ u2018 ' Reimpl u ' \ u2019 ' with u ' \ u2018 ' Labeled , Coarse u ' \ u2019 ' pruning

CASE: 41
Stag: 129 
	Pattern: 5 [['so'], ['as', 'to']]---- [['&C', '(,)'], ['(&adj/&adv@C@)'], ['&R']]
	sentTXT: How can we best cluster and subcluster the grammar so as to maximize performance
	Cause: How can we best cluster and subcluster the grammar
	Effect: maximize performance

CASE: 42
Stag: 130 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: A good clustering will group rules together that use the same symbols , since this means fewer memory accesses to read and write scores for symbols
	Cause: this means fewer memory accesses to read and write scores for symbols
	Effect: A good clustering will group rules together that use the same symbols

CASE: 43
Stag: 133 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Finally , when pruning , it is best if symbols that have the same coarse projection are clustered together
	Cause: symbols that have the same coarse projection are clustered together
	Effect: Finally , when pruning , it is best

CASE: 44
Stag: 134 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: That way , we are more likely to be able to skip a subcluster , since fewer distinct symbols need to be u ' \ u201c ' off u ' \ u201d ' for a parse item to be skipped in a given subcluster
	Cause: fewer distinct symbols need to be u ' \ u201c ' off u ' \ u201d ' for a parse item to be skipped in a given subcluster
	Effect: That way , we are more likely to be able to skip a subcluster

CASE: 45
Stag: 141 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Clustering using this method is labeled u ' \ u2018 ' Reimplementation u ' \ u2019 ' in Table 1
	Cause: Clustering using this method
	Effect: is labeled u ' \ u2018 ' Reimplementation u '

CASE: 46
Stag: 144 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Second , we are able to skip a parse item for an entire cluster if that item u ' \ u2019 ' s pruning mask does not intersect the cluster u ' \ u2019 ' s signature
	Cause: that item u ' \ u2019 ' s pruning mask does not intersect the cluster u ' \ u2019 ' s signature
	Effect: Second , we are able to skip a parse item for an entire cluster

CASE: 47
Stag: 145 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Spreading symbols across clusters may be inefficient if a parse item licenses a given symbol , we will have to enqueue that item to any queue that has the symbol in its signature , no matter how many other symbols are in that cluster
	Cause: a parse item licenses a given symbol
	Effect: we will have to enqueue that item to any queue that has the symbol in its signature , no matter how many other symbols are in that cluster

CASE: 48
Stag: 145 146 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Spreading symbols across clusters may be inefficient if a parse item licenses a given symbol , we will have to enqueue that item to any queue that has the symbol in its signature , no matter how many other symbols are in that cluster Thus , it makes sense to choose a clustering algorithm that exploits the structure introduced by the pruning masks
	Cause: Spreading symbols across clusters may be inefficient if a parse item licenses a given symbol , we will have to enqueue that item to any queue that has the symbol in its signature , no matter how many other symbols are in that cluster
	Effect: , it makes sense to choose a clustering algorithm that exploits the structure introduced by the pruning masks

CASE: 49
Stag: 148 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: When coarse symbols are extremely unlikely -LRB- and therefore have few corresponding rules -RRB- , we merge their clusters to avoid the overhead of beginning work on clusters where little work has to be done
	Cause: When coarse symbols are extremely unlikely -LRB-
	Effect: have few corresponding rules -RRB- , we merge their clusters to avoid the overhead of beginning work on clusters where little work has to be done

CASE: 50
Stag: 149 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: 3 3 Specifically , after clustering based on the coarse parent symbol , we merge all clusters with less than 300 rules in them into one large cluster
	Cause: the coarse parent symbol
	Effect: we merge all clusters with less than 300 rules in them into one large cluster

CASE: 51
Stag: 150 
	Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
	sentTXT: In order to subcluster , we divde up rules among subclusters so that each subcluster has the same number of active parent symbols
	Cause: In order to subcluster , we divde up rules among subclusters
	Effect: each subcluster has the same number of active parent symbols

CASE: 52
Stag: 152 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Clustering using this method is labeled u ' \ u2018 ' Parent u ' \ u2019 ' in Table 1
	Cause: Clustering using this method
	Effect: is labeled u ' \ u2018 ' Parent u '

CASE: 53
Stag: 160 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The coarse to fine pruning approach of Petrov and Klein -LRB- 2007 -RRB- employs an X-bar grammar as its first pruning phase , but there is no reason why we can not begin with a more complex grammar for our initial pass
	Cause: its first pruning phase , but there is no reason why we can not begin with a more complex grammar for our initial pass
	Effect: The coarse to fine pruning approach of Petrov and Klein -LRB- 2007 -RRB- employs an X-bar grammar

CASE: 54
Stag: 160 161 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The coarse to fine pruning approach of Petrov and Klein -LRB- 2007 -RRB- employs an X-bar grammar as its first pruning phase , but there is no reason why we can not begin with a more complex grammar for our initial pass As Petrov and Klein -LRB- 2007 -RRB- have shown , intermediate-sized Berkeley grammars prune many more symbols than the X-bar system
	Cause: Petrov and Klein -LRB- 2007 -RRB- have shown , intermediate-sized Berkeley grammars prune many more symbols than the X-bar system
	Effect: The coarse to fine pruning approach of Petrov and Klein -LRB- 2007 -RRB- employs an X-bar grammar as its first pruning phase , but there is no reason why we can not begin with a more complex grammar for our initial pass

CASE: 55
Stag: 162 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: However , they are slower to parse with in a CPU context , and so they begin with an X-bar grammar
	Cause: However , they are slower to parse with in a CPU context
	Effect: they begin with an X-bar grammar

CASE: 56
Stag: 163 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because of the overhead associated with transferring work items to GPU , using a very small grammar may not be an efficient use of the GPU u ' \ u2019 ' s computational resources
	Cause: of the overhead associated with transferring work items to
	Effect: using a very small grammar may not be an efficient use of the GPU u ' \ u2019 ' s computational resources

CASE: 57
Stag: 166 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because parsing with these grammars is still quite fast , we tried using them as the coarse pass instead
	Cause: parsing with these grammars is still quite fast
	Effect: we tried using them as the coarse pass instead

CASE: 58
Stag: 172 173 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: MBR algorithms for parsing do not compute the best derivation , as in Viterbi parsing , but instead the parse tree that maximizes the expected count of some figure of merit For instance , one might want to maximize the expected number of correct constituents -LSB- 3 -RSB- , or the expected rule counts -LSB- 10 , 9 -RSB-
	Cause: in Viterbi parsing , but instead the parse tree that maximizes the expected count of some figure of merit For instance , one might want to maximize the expected number of correct constituents -LSB- 3 -RSB- , or the expected rule counts -LSB- 10 , 9
	Effect: MBR algorithms for parsing do not compute the best derivation

CASE: 59
Stag: 183 184 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We should expect this algorithm to be at least a factor of two slower the outside pass performs at least as much work as the inside pass Moreover , it typically has worse memory access patterns , leading to slower performance
	Cause: much work as the inside pass Moreover , it typically has worse memory access patterns , leading to
	Effect: We should expect this algorithm to be at least a factor of two slower the outside pass performs at least

CASE: 60
Stag: 188 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because the grammars are compiled into code , the additional operations are all inlined into the kernels , producing much larger kernels
	Cause: the grammars are compiled into code
	Effect: the additional operations are all inlined into the kernels , producing much larger kernels

CASE: 61
Stag: 189 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Indeed , in practice the compiler will often hang if we use the same size grammar clusters as we did for Viterbi
	Cause: we did for Viterbi
	Effect: in practice the compiler will often hang if we use the same size grammar clusters

CASE: 62
Stag: 189 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: in practice the compiler will often hang if we use the same size grammar clusters
	Cause: we use the same size grammar clusters
	Effect: in practice the compiler will often hang

CASE: 63
Stag: 192 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Because so many labeled spans are pruned , we are able to skip many of the grammar clusters and thus avoid many of the expensive operations
	Cause: Because so many labeled spans are pruned , we are able to skip many of the grammar clusters
	Effect: avoid many of the expensive operations

CASE: 64
Stag: 192 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because so many labeled spans are pruned , we are able to skip many of the grammar clusters
	Cause: so many labeled spans are pruned
	Effect: we are able to skip many of the grammar clusters

CASE: 65
Stag: 193 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using coarse pruning and log domain calculations , our system produces MBR trees at a rate of 130.4 sentences per second , a four-fold increase
	Cause: Using coarse pruning and log domain calculations
	Effect: our system produces MBR trees at a rate of 130.4 sentences per second , a four-fold increase

CASE: 66
Stag: 199 200 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: That is , the number is represented as f u ' \ u2032 ' = f u ' \ u22c5 ' exp u ' \ u2061 ' -LRB- s Whenever f becomes either too big or too small , the number is rescaled back to a less u ' \ u201c ' dangerous u ' \ u201d ' range by shifting mass from the exponent e to the scaling factor s
	Cause: f u ' \ u2032 ' = f u ' \ u22c5 ' exp u ' \ u2061 ' -LRB- s Whenever f becomes either too big or too small , the number is rescaled back to a less u ' \ u201c ' dangerous u ' \ u201d '
	Effect: That is , the number is represented

CASE: 67
Stag: 200 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Whenever f becomes either too big or too small , the number is rescaled back to a less u ' \ u201c ' dangerous u ' \ u201d ' range by shifting mass from the exponent e to the scaling factor s
	Cause: shifting mass from the exponent e to the scaling factor s
	Effect: Whenever f becomes either too big or too small , the number is rescaled back to a less u ' \ u201c ' dangerous u ' \ u201d ' range

CASE: 68
Stag: 202 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: In our GPU system , multiple scores in any given span are being updated at the same time , which makes this dynamic rescaling tricky and expensive , especially since inter-warp communication is fairly limited
	Cause: inter-warp communication is fairly limited
	Effect: , which makes this dynamic rescaling tricky and expensive , especially

CASE: 69
Stag: 205 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because the grammar used in the coarse pass is a projection of the grammar used in the fine pass , these coarse scores correlate reasonably closely with the probabilities computed in the fine pass
	Cause: the grammar used in the coarse pass is a projection of the grammar used in the fine pass
	Effect: these coarse scores correlate reasonably closely with the probabilities computed in the fine pass

CASE: 70
Stag: 206 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If a span has a very high or very low score in the coarse pass , it typically has a similar score in the fine pass
	Cause: a span has a very high or very low score in the coarse pass
	Effect: it typically has a similar score in the fine pass

CASE: 71
Stag: 206 207 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: If a span has a very high or very low score in the coarse pass , it typically has a similar score in the fine pass Thus , we can use the coarse pass u ' \ u2019 ' s inside and outside scores as the scaling values for the fine pass u ' \ u2019 ' s scores
	Cause: If a span has a very high or very low score in the coarse pass , it typically has a similar score in the fine pass
	Effect: , we can use the coarse pass u ' \ u2019 ' s inside and outside scores as the scaling values for the fine pass u ' \ u2019 ' s scores

CASE: 72
Stag: 209 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Then , when applying rules in the fine pass , each fine inside score over a split span -LRB- i , k , j -RRB- is scaled to the appropriate s i , j I by multiplying the score by exp u ' \ u2061 ' -LRB- s i , k I + s k , j I - s i , j I -RRB- , where s i , k I , s k , j I , s i , j I are the scaling factors for the left child , right child , and parent , respectively
	Cause: multiplying the score by exp u ' \ u2061 ' -LRB- s i , k I + s k , j I - s i , j I -RRB-
	Effect: , where s i , k I , s k , j I , s i , j I are the scaling factors for the left child , right child , and parent , respectively

CASE: 73
Stag: 213 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Because we are summing instead of maxing scores in the fine pass , the scaling factors computed using max scores are not quite large enough , and so the rescaled inside probabilities grow too large when multiplied together
	Cause: Because we are summing instead of maxing scores in the fine pass , the scaling factors computed using max scores are not quite large enough
	Effect: the rescaled inside probabilities grow too large when multiplied together

CASE: 74
Stag: 213 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because we are summing instead of maxing scores in the fine pass , the scaling factors computed using max scores are not quite large enough
	Cause: we are summing instead of maxing scores in the fine pass
	Effect: the scaling factors computed using max scores are not quite large enough

CASE: 75
Stag: 214 215 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Most of this difference arises at the leaves , where the lexicon typically has more uncertainty than higher up in the tree Therefore , in the fine pass , we normalize the inside scores at the leaves to sum to 1.0
	Cause: Most of this difference arises at the leaves , where the lexicon typically has more uncertainty than higher up in the tree
	Effect: in the fine pass , we normalize the inside scores at the leaves to sum to 1.0

CASE: 76
Stag: 216 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 4 4 One can instead interpret this approach as changing the scaling factors to s i , j I u ' \ u2032 ' = s i , j I u ' \ u22c5 ' u ' \ u220f ' i u ' \ u2264 ' k j u ' \ u2211 ' A inside u ' \ u2062 ' -LRB- A , k , k + 1 -RRB- , where inside is the array of scores for the fine pass
	Cause: changing the scaling factors to s i , j I u ' \ u2032 ' = s i , j I u ' \ u22c5 ' u ' \ u220f ' i u ' \ u2264 ' k j u ' \ u2211 ' A inside u ' \ u2062 ' -LRB- A , k ,
	Effect: 4 4 One can instead interpret this approach

CASE: 77
Stag: 216 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: changing the scaling factors to s i , j I u ' \ u2032 ' = s i , j I u ' \ u22c5 ' u ' \ u220f ' i u ' \ u2264 ' k j u ' \ u2211 ' A inside u ' \ u2062 ' -LRB- A , k ,
	Cause: changing the scaling factors to s i
	Effect: j I u ' \ u2032 ' = s i , j I u ' \ u22c5 ' u ' \ u220f ' i u ' \ u2264 ' k j u ' \ u2211 ' A inside u ' \ u2062 ' -LRB-

CASE: 78
Stag: 219 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Using scaling , we are able to push our parser to 190.6 sentences/second for MBR extraction , just under half the speed of the Viterbi system
	Cause: Using scaling
	Effect: we are able to push our parser to 190.6 sentences/second for MBR extraction , just under half the speed of the Viterbi system

CASE: 79
Stag: 220 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: It is of course important verify the correctness of our system ; one easy way to do so is to examine parsing accuracy , as compared to the original Berkeley parser
	Cause: It is of course important verify the correctness of our system ; one easy way to do
	Effect: is to examine parsing accuracy , as compared to the original Berkeley parser

CASE: 80
Stag: 230 231 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: These timing numbers are computed using the built-in profiling capabilities of the programming environment As usual , profiles exhibit an observer effect , where the act of measuring the system changes the execution
	Cause: usual , profiles exhibit an observer effect , where the act of measuring
	Effect: These timing numbers are computed using the built-in profiling capabilities of the programming environment

CASE: 81
Stag: 232 233 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Nevertheless , the general trends should more or less be preserved as compared to the unprofiled code To begin , we can compute the number of seconds needed to parse 1000 sentences
	Cause: compared to the unprofiled code To begin , we can compute the number of seconds needed to parse 1000
	Effect: Nevertheless , the general trends should more or less be preserved

CASE: 82
Stag: 234 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We use seconds per sentence rather than sentences per second because the former measure is additive . -RRB- The results are in Table 3
	Cause: the former measure is additive . -RRB- The results are in Table 3
	Effect: We use seconds per sentence rather than sentences per second

CASE: 83
Stag: 236 237 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In Table 4 , we break down the time taken by our system into individual components As expected , binary rules account for the vast majority of the time in the unpruned Viterbi case , but much less time in the pruned case , with the total time taken for binary rules in the coarse and fine passes taking about 1/5 of the time taken by binaries in the unpruned version
	Cause: expected , binary rules account for the vast majority of the time in the unpruned Viterbi case , but much less time in the pruned case , with the total time taken for binary rules in the coarse and fine passes taking about 1/5 of the time taken by binaries in the unpruned version
	Effect: In Table 4 , we break down the time taken by our system into individual components

CASE: 84
Stag: 240 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: There is greater overhead in the scaling system , because scaling factors are copied to the CPU between the coarse and fine passes
	Cause: scaling factors are copied to the CPU between the coarse and fine passes
	Effect: There is greater overhead in the scaling system

CASE: 85
Stag: 245 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: Throughput increases through parsing 10,000 sentences , and then levels off by the time it reaches 100,000 sentences
	Cause: parsing 10,000 sentences
	Effect: , and then levels off by the time it reaches 100,000

CASE: 86
Stag: 259 260 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Our system is available as open-source at https://www.github.com/dlwh/puck This work was partially supported by BBN under DARPA contract HR0011-12-C-0014 , by a Google PhD fellowship to the first author , and an NSF fellowship to the second
	Cause: open-source at https://www.github.com/dlwh/puck This work was partially supported by BBN under DARPA contract HR0011-12-C-0014 , by a Google PhD fellowship to the first author ,
	Effect: Our system is available

