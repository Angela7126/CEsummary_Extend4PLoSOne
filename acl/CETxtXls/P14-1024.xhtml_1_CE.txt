************************************************************
P14-1024.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Lakoff and Johnson ( 1980 ) characterize metaphor as reasoning about one thing in terms of another, i.e.,, a metaphor is a type of conceptual mapping , where words or phrases are applied to objects and actions in ways that do not permit a literal interpretation
	Cause: [(0, 9), (0, 47)]
	Effect: [(0, 0), (0, 7)]

CASE: 1
Stag: 7 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: On one hand, there is a subjective component humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language [ 32 ]
	Cause: [(0, 23), (0, 35)]
	Effect: [(0, 0), (0, 20)]

CASE: 2
Stag: 13 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: 1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses; 2 2 https://github.com/ytsvetko/metaphor (2) we create new metaphor-annotated corpora for Russian and English; 3 3 http://www.cs.cmu.edu/~ytsvetko/metaphor/datasets.zip (3) using a paradigm of model transfer [ 21 , 41 , 15 ] , we provide support for the hypothesis that metaphors are conceptual (rather than lexical) in nature by showing that our English-trained model can detect metaphors in Spanish, Farsi, and Russian
	Cause: [(0, 81), (0, 95)]
	Effect: [(0, 1), (0, 79)]

CASE: 3
Stag: 19 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: According to Wilks [ 42 ] , this metaphor represents a violation of selectional preferences for the verb drink , which is normally associated with animate subjects (the car is inanimate and, hence, cannot drink in the literal sense of the verb
	Cause: [(0, 0), (0, 32)]
	Effect: [(0, 36), (0, 45)]

CASE: 4
Stag: 19 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to Wilks [ 42 ] , this metaphor represents a violation of selectional preferences for the verb drink , which is normally associated with animate subjects (the car is inanimate and, hence, cannot drink in the literal sense of the verb
	Cause: [(0, 2), (0, 5)]
	Effect: [(0, 7), (0, 32)]

CASE: 5
Stag: 31 
	Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
	sentTXT: 6 6 If word one is represented by features u'\ud835' u'\udc2e' u'\u2208' u'\u211d' n and word two by features u'\ud835' u'\udc2f' u'\u2208' u'\u211d' m then the conjunction feature vector is the vectorization of the outer product u'\ud835' u'\udc2e' u'\ud835' u'\udc2f' u'\u22a4'
	Cause: [(0, 3), (0, 55)]
	Effect: [(0, 57), (0, 92)]

CASE: 6
Stag: 45 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: English adjectives do not, as yet, have a similar high-level semantic partitioning in WordNet, thus we use a 13-class taxonomy of adjective supersenses constructed by Tsvetkov et al
	Cause: [(0, 0), (0, 15)]
	Effect: [(0, 18), (0, 30)]

CASE: 7
Stag: 47 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Supersenses are particularly attractive features for metaphor detection coarse sense taxonomies can be viewed as semantic concepts, and since concept mapping is a process in which metaphors are born, we expect different supersense co-occurrences in metaphoric and literal combinations
	Cause: [(0, 20), (0, 29)]
	Effect: [(0, 31), (0, 40)]

CASE: 8
Stag: 54 55 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: 2013 ) reveal an interesting cross-lingual property of distributed word representations there is a strong similarity between the vector spaces across languages that can be easily captured by linear mapping Thus, vector space models can also be seen as vectors of (latent) semantic concepts, that preserve their u'\u201c' meaning u'\u201d' across languages
	Cause: [(0, 0), (0, 29)]
	Effect: [(1, 1), (1, 33)]

CASE: 9
Stag: 59 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Random forest ensembles are particularly suitable for our resource-scarce scenario rather than overfitting, they produce a limiting value of the generalization error as the number of trees increases, 8 8 See Theorem 1.2 in [ 3 ] for details and no hyperparameter tuning is required
	Cause: [(0, 24), (0, 45)]
	Effect: [(0, 0), (0, 22)]

CASE: 10
Stag: 63 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If this probability is above a threshold, the relation is classified as metaphoric, otherwise it is literal
	Cause: [(0, 1), (0, 6)]
	Effect: [(0, 8), (0, 18)]

CASE: 11
Stag: 74 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: They were chosen empirically based on accuracy during cross-validation
	Cause: [(0, 6), (0, 8)]
	Effect: [(0, 0), (0, 3)]

CASE: 12
Stag: 97 98 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: A Russian word u'\u0413' u'\u041e' u'\u041b' u'\u041e' u'\u0412' u'\u0410' is translated as head and brain Hence, we select all the synsets of the nouns head and brain
	Cause: [(0, 0), (0, 38)]
	Effect: [(1, 2), (1, 12)]

CASE: 13
Stag: 100 101 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Four of these synsets are associated with the supersense noun.body Therefore, the value of the feature noun.body is 4 / 38 u'\u2248' 0.11
	Cause: [(0, 0), (0, 9)]
	Effect: [(1, 2), (1, 17)]

CASE: 14
Stag: 108 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: After filtering, there are 953 metaphorical and 656 literal SVO relations which we use as a training set
	Cause: [(0, 16), (0, 18)]
	Effect: [(0, 0), (0, 14)]

CASE: 15
Stag: 111 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: At least one additional person carefully examined and culled the collected metaphors, by removing duplicates, weak metaphors, and metaphorical phrases (such as drowning students ) whose interpretation depends on the context
	Cause: [(0, 14), (0, 34)]
	Effect: [(0, 1), (0, 12)]

CASE: 16
Stag: 112 113 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We collect and annotate metaphoric and literal test sentences in four languages Thus, we compile eight test datasets, four for SVO relations, and four for AN relations
	Cause: [(0, 0), (0, 11)]
	Effect: [(1, 1), (1, 17)]

CASE: 17
Stag: 121 122 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Our test sentence domains are, therefore, diverse economic, political, sports, etc Then she used the SketchEngine, which provides searching capability for the TenTen Web corpus, 19 19 http://trac.sketchengine.co.uk/wiki/Corpora/enTenTen to extract sentences with words that frequently co-occurred with words from the seed lists
	Cause: [(0, 0), (0, 4)]
	Effect: [(0, 8), (1, 31)]

CASE: 18
Stag: 129 130 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: No English annotators of the test set, and only one Russian annotator out of 6 participated in the selection of the training samples Thus, we trust that annotator judgments were not biased towards the cases that the system is trained to process
	Cause: [(0, 0), (0, 23)]
	Effect: [(1, 1), (1, 19)]

CASE: 19
Stag: 134 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This is done by computing an accuracy in the 10-fold cross validation
	Cause: [(0, 4), (0, 11)]
	Effect: [(0, 0), (0, 2)]

CASE: 20
Stag: 144 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Yet, combining all features leads to even higher accuracy during cross-validation
	Cause: [(0, 2), (0, 4)]
	Effect: [(0, 7), (0, 11)]

CASE: 21
Stag: 146 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Although the first experiment shows very high scores, the 10-fold cross-validation cannot fully reflect the generality of the model, because all folds are parts of the same corpus
	Cause: [(0, 23), (0, 30)]
	Effect: [(0, 0), (0, 20)]

CASE: 22
Stag: 147 148 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: They are collected by the same human judges and belong to the same domain Therefore, experiments on out-of-domain data are crucial
	Cause: [(0, 0), (0, 13)]
	Effect: [(1, 2), (1, 7)]

CASE: 23
Stag: 155 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: It is possible to trade precision for recall by choosing a different threshold
	Cause: [(0, 9), (0, 12)]
	Effect: [(0, 0), (0, 7)]

CASE: 24
Stag: 155 156 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: It is possible to trade precision for recall by choosing a different threshold Thus, in addition to giving a single f -score value for balanced thresholds, we present a Receiver Operator Characteristic (ROC) curve, where we plot a fraction of true positives against the fraction of false positives for 100 threshold values in the range from zero to one
	Cause: [(0, 0), (0, 12)]
	Effect: [(1, 1), (1, 51)]

CASE: 25
Stag: 157 158 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The area under the ROC curve (AUC) can be interpreted as the probability that a classifier will assign a higher score to a randomly chosen positive example than to a randomly chosen negative example 20 20 Assuming that positive examples are labeled by ones, and negative examples are labeled by zeros
	Cause: [(0, 13), (1, 16)]
	Effect: [(0, 0), (0, 11)]

CASE: 26
Stag: 161 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to ROC plots in Figure 3 , all three feature sets are effective, both for SVO and for AN tasks
	Cause: [(0, 2), (0, 6)]
	Effect: [(0, 8), (0, 21)]

CASE: 27
Stag: 178 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to Table 3 , we obtain higher performance scores for both Russian and English
	Cause: [(0, 2), (0, 3)]
	Effect: [(0, 5), (0, 14)]

CASE: 28
Stag: 190 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to results in Table 4 , almost all of the judge-specific f -scores are slightly higher for our system, as well as the overall average f -score
	Cause: [(0, 2), (0, 5)]
	Effect: [(0, 7), (0, 27)]

CASE: 29
Stag: 202 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: We hypothesize that this happens due to a higher-quality translation dictionary (which allows a more accurate model transfer
	Cause: [(0, 7), (0, 18)]
	Effect: [(0, 0), (0, 4)]

CASE: 30
Stag: 203 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Relatively lower (yet reasonable) results for Farsi can be explained by a smaller size of the bilingual dictionary (thus, fewer feature projections can be obtained
	Cause: [(0, 0), (0, 20)]
	Effect: [(0, 22), (0, 28)]

CASE: 31
Stag: 204 205 
	Pattern: 10 [['why']]---- [['&C', '(,/./;/--)', '(&AND)', '&THIS', '&BE'], ['&R']]
	sentTXT: Also note that, in our experience, most of Farsi metaphors are adjective-noun constructions This is why the AN fa dataset in Table 1 is significantly larger than SVO fa
	Cause: [(0, 0), (0, 14)]
	Effect: [(1, 3), (1, 15)]

CASE: 32
Stag: 208 209 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We view this result as a strong evidence of language-independent nature of our metaphor detection method In particular, this shows that proposed conceptual features can be used to detect selectional preferences violation across languages
	Cause: [(0, 5), (1, 17)]
	Effect: [(0, 0), (0, 3)]

CASE: 33
Stag: 212 213 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For example, in English we classify as metaphoric dirty word and cloudy future Word pairs dirty diaper and cloudy weather have same adjectives
	Cause: [(0, 8), (1, 8)]
	Effect: [(0, 0), (0, 6)]

CASE: 34
Stag: 214 215 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Yet they are classified as literal Indeed, diaper is a more concrete term than word and weather is more concrete than future
	Cause: [(0, 5), (1, 15)]
	Effect: [(0, 0), (0, 3)]

CASE: 35
Stag: 233 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If this adjective modifies a noun with the supersense noun.feeling , we conclude that a metaphor is found
	Cause: [(0, 1), (0, 9)]
	Effect: [(0, 11), (0, 17)]

CASE: 36
Stag: 242 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because they heavily rely on WordNet and availability of imageability scores, their approach may not be applicable to low-resource languages
	Cause: [(0, 1), (0, 10)]
	Effect: [(0, 12), (0, 20)]

CASE: 37
Stag: 246 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: We cannot compare directly our model with this work because our classifier is restricted to detection of only SVO and AN metaphors
	Cause: [(0, 11), (0, 22)]
	Effect: [(0, 0), (0, 9)]

CASE: 38
Stag: 252 253 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Current work builds on this study, and incorporates new syntactic relations as metaphor candidates, adds several new feature sets and different, more reliable datasets for evaluating results We demonstrate results on two new languages, Spanish and Farsi, to emphasize the generality of the method
	Cause: [(0, 13), (1, 18)]
	Effect: [(0, 0), (0, 11)]

