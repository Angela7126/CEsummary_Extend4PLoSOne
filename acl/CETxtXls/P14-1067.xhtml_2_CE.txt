************************************************************
P14-1067.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 15 
	Pattern: 7 [['due', 'to']]---- [['&V-ing/&NP@R@', '&BE'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Such variability is due to two main reasons
	Cause: two main reasons
	Effect: Such variability

CASE: 1
Stag: 17 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the quality standards of individual users may vary considerably -LRB- e.g. , according to their knowledge of the source and target languages -RRB- , the estimates of a static QE model trained with data collected from a group of post-editors might not fit with the actual judgements of a new user ;
	Cause: the quality standards of individual users may vary considerably -LRB- e.g.
	Effect: according to their knowledge of the source and target languages -RRB- , the estimates of a static QE model trained with data collected from a group of post-editors might not fit with the actual judgements of a new user ;

CASE: 2
Stag: 17 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: according to their knowledge of the source and target languages -RRB- , the estimates of a static QE model trained with data collected from a group of post-editors might not fit with the actual judgements of a new user ;
	Cause: their knowledge of the source and target languages
	Effect: the estimates of a static QE model trained with data collected from a group of post-editors might not fit with the actual judgements of a new user ;

CASE: 3
Stag: 19 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since data from a new job may differ from those used to train the QE model , its estimates on the new instances might result to be biased or uninformative
	Cause: data from a new job may differ from those used to train the QE model
	Effect: its estimates on the new instances might result to be biased or uninformative

CASE: 4
Stag: 23 
	Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
	sentTXT: Our approach is based on the online learning paradigm and exploits a key difference between such framework and the batch learning methods currently used
	Cause: the online learning paradigm and exploits a key difference between such framework and the batch learning methods currently used
	Effect: Our approach

CASE: 5
Stag: 26 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: On the other side , online learning techniques are designed to learn in a stepwise manner -LRB- either from scratch , or by refining an existing model -RRB- from new , unseen test instances by taking advantage of external feedback
	Cause: refining an existing model
	Effect: On the other side , online learning techniques are designed to learn in a stepwise manner -LRB- either from scratch , or

CASE: 6
Stag: 28 29 
	Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
	sentTXT: To develop our approach , different online algorithms have been embedded in the backbone of a QE system This required the adaptation of its standard batch learning workflow to
	Cause: the adaptation of its standard batch learning workflow
	Effect: To develop our approach , different online algorithms have been embedded in the backbone of a QE system

CASE: 7
Stag: 32 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Gather user feedback for the instance -LRB- i.e. , calculating a u ' \ u201c ' true label u ' \ u201d ' based on the amount of user post-editions -RRB- ;
	Cause: the amount of user post-editions
	Effect: Gather user feedback for the instance -LRB- i.e. , calculating a u ' \ u201c ' true label u ' \ u201d '

CASE: 8
Stag: 34 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Focusing on the adaptability to user and domain changes , we report the results of comparative experiments with two online algorithms and the standard batch approach
	Cause: Focusing on the adaptability to user and domain changes
	Effect: we report the results of comparative experiments with two online algorithms and the standard batch approach

CASE: 9
Stag: 35 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The evaluation is carried out by measuring the global error of each algorithm on test sets featuring different degrees of similarity with the data used for training
	Cause: measuring the global error of each algorithm on test sets featuring different degrees of similarity with the data used for training
	Effect: The evaluation is carried out

CASE: 10
Stag: 39 
	Pattern: 5 [['so'], ['as', 'to']]---- [['&C', '(,)'], ['(&adj/&adv@C@)'], ['&R']]
	sentTXT: QE is generally cast as a supervised machine learning task , where a model trained from a collection of -LRB- source , target , label -RRB- instances is used to predict labels 1 1 Possible label types include post-editing effort scores -LRB- e.g. , 1-5 Likert scores indicating the estimated percentage of MT output that has to be corrected -RRB- , HTER values -LSB- 28 -RSB- , and post-editing time -LRB- e.g. , seconds per word for new , unseen test items -LSB- 31 -RSB-
	Cause: QE is generally cast as a supervised machine learning task , where a model trained from a collection of -LRB-
	Effect: be corrected -RRB- , HTER values -LSB- 28 -RSB- , and post-editing time -LRB- e.g. , seconds per word for new , unseen test items -LSB- 31 -RSB-

CASE: 11
Stag: 41 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Current approaches to the tasks proposed at WMT have mainly focused on three main directions , namely i -RRB- feature engineering , as in -LSB- 12 , 10 , 11 , 26 -RSB- , ii -RRB- model learning with a variety of classification and regression algorithms , as in -LSB- 3 , 1 , 29 -RSB- , and iii -RRB- feature selection as a way to overcome sparsity and overfitting issues , as in -LSB- 29 -RSB-
	Cause: in -LSB- 12 , 10 , 11 , 26 -RSB- , ii -RRB- model learning with a variety of classification and regression algorithms , as in -LSB- 3 , 1 , 29 -RSB- , and iii -RRB- feature selection as a way to overcome sparsity and overfitting
	Effect: Current approaches to the tasks proposed at WMT have mainly focused on three main directions , namely i -RRB- feature engineering

CASE: 12
Stag: 42 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Being optimized to perform well on specific WMT sub-tasks and datasets , current systems reflect variations along these directions but leave important aspects of the QE problem still partially investigated or totally unexplored
	Cause: Being optimized to perform well on specific WMT sub-tasks and datasets
	Effect: current systems reflect variations along these directions but leave important aspects of the QE problem still partially investigated or totally unexplored

CASE: 13
Stag: 44 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Among these , the necessity to model the diversity of human quality judgements and correction strategies -LSB- 16 , 15 -RSB- calls for solutions that i -RRB- account for annotator-specific behaviour , thus being capable of learning from inherently noisy datasets produced by multiple annotators , and ii -RRB- self-adapt to changes in data distribution , learning from user feedback on new , unseen test items
	Cause: Among these , the necessity to model the diversity of human quality judgements and correction strategies -LSB- 16 , 15 -RSB- calls for solutions that i -RRB- account for annotator-specific behaviour
	Effect: being capable of learning from inherently noisy datasets produced by multiple annotators , and ii -RRB- self-adapt to changes in data distribution , learning from user feedback on new , unseen test items

CASE: 14
Stag: 46 47 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The first aspect , modelling annotators u ' \ u2019 ' individual behaviour and interdependences , has been addressed by Cohn and Specia -LSB- 8 -RSB- , who explored multi-task Gaussian Processes as a way to jointly learn from the output of multiple annotations This technique is suitable to cope with the unbalanced distribution of training instances and yields better models when heterogeneous training datasets are available
	Cause: a way to jointly learn from the output of multiple annotations This technique is suitable to cope with the unbalanced distribution of training instances and yields better models when
	Effect: The first aspect , modelling annotators u ' \ u2019 ' individual behaviour and interdependences , has been addressed by Cohn and Specia -LSB- 8 -RSB- , who explored multi-task Gaussian Processes

CASE: 15
Stag: 53 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: As regards QE models , our work represents the first investigation on incremental adaptation by exploiting users feedback to provide targeted -LRB- system , user , or project specific -RRB- quality judgements
	Cause: exploiting users feedback to provide targeted -LRB- system , user , or project specific -RRB- quality judgements
	Effect: As regards QE models , our work represents the first investigation on incremental adaptation

CASE: 16
Stag: 59 60 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the online framework , differently from the batch mode , the learning algorithm sequentially processes an unknown sequence of instances X = x 1 , x 2 , u ' \ u2026 ' , x n , returning a prediction p u ' \ u2062 ' -LRB- x i -RRB- as output at each step Differences between p u ' \ u2062 ' -LRB- x i -RRB- and the true label p ^ u ' \ u2062 ' -LRB- x i -RRB- obtained as feedback are used by the learner to refine the next prediction p u ' \ u2062 ' -LRB- x i + 1 -RRB-
	Cause: output at each step Differences between p u ' \ u2062 ' -LRB- x i -RRB- and the true label p ^ u ' \ u2062 ' -LRB- x i -RRB- obtained as feedback are used by the learner to refine the next prediction p u ' \ u2062 ' -LRB- x i +
	Effect: In the online framework , differently from the batch mode , the learning algorithm sequentially processes an unknown sequence of instances X = x 1 , x 2 , u ' \ u2026 ' , x n , returning a prediction p u ' \ u2062 ' -LRB- x i -RRB-

CASE: 17
Stag: 60 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Differences between p u ' \ u2062 ' -LRB- x i -RRB- and the true label p ^ u ' \ u2062 ' -LRB- x i -RRB- obtained as feedback are used by the learner to refine the next prediction p u ' \ u2062 ' -LRB- x i + 1 -RRB-
	Cause: feedback are used by the learner to refine the next prediction p u ' \ u2062 ' -LRB- x i + 1 -RRB-
	Effect: Differences between p u ' \ u2062 ' -LRB- x i -RRB- and the true label p ^ u ' \ u2062 ' -LRB- x i -RRB- obtained

CASE: 18
Stag: 62 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 5 5 Edit distance is calculated as the number of edits -LRB- word insertions , deletions , substitutions , and shifts -RRB- divided by the number of words in the reference
	Cause: the number of edits -LRB- word insertions , deletions , substitutions , and shifts -RRB- divided
	Effect: 5 5 Edit distance is calculated

CASE: 19
Stag: 63 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Lower HTER values indicate better translations
	Cause: Lower HTER values
	Effect: better translations

CASE: 20
Stag: 68 69 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: At each step of the process , the goal of the learner is to exploit user post-editions to reduce the difference between the predicted HTER values and the true labels for the following -LRB- source , target -RRB- pairs As depicted in Figure 1 , this is done as follows
	Cause: depicted in Figure 1 , this is done as follows
	Effect: At each step of the process , the goal of the learner is to exploit user post-editions to reduce the difference between the predicted HTER values and the true labels for the following -LRB- source , target -RRB- pairs

CASE: 21
Stag: 74 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Based on the post-edition done by the user , the true HTER label p ^ u ' \ u2062 ' -LRB- x i -RRB- is calculated by means of the TERCpp 7 7 goo.gl / nkh2rE open source tool ;
	Cause: the post-edition done by the user
	Effect: the true HTER label p ^ u ' \ u2062 ' -LRB- x i -RRB- is calculated by means of the TERCpp 7 7 goo.gl / nkh2rE open source tool ;

CASE: 22
Stag: 78 
	Pattern: 2 [['for', 'the', 'sake', 'of'], [',']]---- [[], ['&V-ing/&NP@C@'], ['&R']]
	sentTXT: For the sake of clarity it is worth observing that , at least in principle , a model built in a batch fashion could also be adapted to new test data
	Cause: clarity
	Effect: at least in principle , a model built in a batch fashion could also be adapted to new test data

CASE: 23
Stag: 79 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: For instance , this could be done by running periodic re-training routines once a certain amount of new labelled instances has been collected -LRB- de facto mimicking an online process
	Cause: running periodic re-training routines once a certain amount of new labelled instances has been collected -LRB- de facto mimicking an online process
	Effect: For instance , this could be done

CASE: 24
Stag: 83 84 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In our experiments , the degree of similarity is measured in terms of u ' \ u0394 ' HTER , which is computed as the absolute value of the difference between the average HTER of the training and test sets Large values indicate a low similarity between training and test data and a more challenging scenario for the learning algorithms
	Cause: the absolute value of the difference between the average HTER of the training and test sets Large values indicate a low similarity between training and test data and a more challenging scenario for the learning
	Effect: In our experiments , the degree of similarity is measured in terms of u ' \ u0394 ' HTER , which is computed

CASE: 25
Stag: 84 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Large values indicate a low similarity between training and test data and a more challenging scenario for the learning algorithms
	Cause: Large values
	Effect: a low similarity between training and test data and a more challenging scenario for the learning algorithms

CASE: 26
Stag: 93 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: The batch model is built by learning only from the training data and is evaluated on the test set without exploiting information from the test instances
	Cause: learning only from the training data
	Effect: and is evaluated on the test set without exploiting information from the test instances

CASE: 27
Stag: 95 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: This baseline -LRB- u ' \ u039c ' henceforth -RRB- is calculated by labelling each instance of the test set with the mean HTER score of the training set
	Cause: labelling each instance of the test set with the mean HTER score of the training set
	Effect: This baseline -LRB- u ' \ u039c ' henceforth -RRB- is calculated

CASE: 28
Stag: 98 99 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The MAE is the average of the absolute errors e i f i - y i where f i is the prediction of the model and y i is the true value for the i t u ' \ u2062 ' h instance As our focus is on the algorithmic aspect , in all experiments we use the same feature set , which consists of the seventeen features proposed in -LSB- 30 -RSB-
	Cause: our focus is on the algorithmic aspect , in all experiments we use the same feature set , which consists of the seventeen features proposed in -LSB- 30
	Effect: i is the true value for the i t u ' \ u2062 ' h instance

CASE: 29
Stag: 102 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In our experiments we evaluate two online algorithms , OnlineSVR -LSB- 24 -RSB- 8 8 http://www2.imperial.ac.uk/~gmontana/onlinesvr.htm and Passive-Aggressive Perceptron -LSB- 9 -RSB- , 9 9 https://code.google.com/p/sofia-ml/ by comparing their performance with a batch learning strategy based on the Scikit-learn implementation of Support Vector Regression -LRB- SVR
	Cause: the Scikit-learn implementation of Support Vector Regression -LRB- SVR
	Effect: In our experiments we evaluate two online algorithms , OnlineSVR -LSB- 24 -RSB- 8 8 http://www2.imperial.ac.uk/~gmontana/onlinesvr.htm and Passive-Aggressive Perceptron -LSB- 9 -RSB- , 9 9 https://code.google.com/p/sofia-ml/ by comparing their performance with a batch learning strategy

CASE: 30
Stag: 104 105 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The choice of the OnlineSVR and Passive-Aggressive -LRB- OSVR and PA henceforth -RRB- is motivated by different considerations From a performance point of view , as an adaptation of u ' \ u0395 ' - SVR which proved to be one of the top performing algorithms in the regression QE tasks at WMT , OSVR seems to be the best candidate
	Cause: an adaptation of u ' \ u0395 ' - SVR which proved to be one of the top performing algorithms in the regression QE tasks at WMT , OSVR seems to be the best candidate
	Effect: choice of the OnlineSVR and Passive-Aggressive -LRB- OSVR and PA henceforth -RRB- is motivated by different considerations From a performance point of view

CASE: 31
Stag: 105 106 
	Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
	sentTXT: From a performance point of view , as an adaptation of u ' \ u0395 ' - SVR which proved to be one of the top performing algorithms in the regression QE tasks at WMT , OSVR seems to be the best candidate For this reason , we use the online adaptation of u ' \ u0395 ' - SVR proposed by -LSB- 18 -RSB-
	Cause: From a performance point of view , as an adaptation of u ' \ u0395 ' - SVR which proved to be one of the top performing algorithms in the regression QE tasks at WMT , OSVR seems to be the best candidate
	Effect: we use the online adaptation of u ' \ u0395 ' - SVR proposed by -LSB- 18 -RSB-

CASE: 32
Stag: 107 108 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The goal of OnlineSVR is to find a way to add each new sample to one of three sets -LRB- support , empty , error -RRB- maintaining the consistency of a set of conditions known as Karush-Kuhn Tucker -LRB- KKT -RRB- conditions For each new point , OSVR starts a cycle where the samples are moved across the three sets until the KKT conditions are verified and the new point is assigned to one of the sets
	Cause: Karush-Kuhn Tucker -LRB- KKT -RRB- conditions For each new point , OSVR starts a cycle where the samples are moved across the three sets until the KKT conditions are verified and the new point is assigned to one of the
	Effect: The goal of OnlineSVR is to find a way to add each new sample to one of three sets -LRB- support , empty , error -RRB- maintaining the consistency of a set of conditions known

CASE: 33
Stag: 109 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If the point is identified as a support vector , the parameters of the model are updated
	Cause: a support vector , the parameters of the model are updated
	Effect: the point is identified

CASE: 34
Stag: 113 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If its value is larger than the tolerance parameter -LRB- u ' \ u0395 ' -RRB- , the weights of the model are updated as much as the aggressiveness parameter C allows
	Cause: its value is larger than the tolerance parameter -LRB- u ' \ u0395 ' -RRB-
	Effect: the weights of the model are updated as much as the aggressiveness parameter C allows

CASE: 35
Stag: 115 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Although it makes PA faster than OSVR , this is a riskier strategy because it may lead the algorithm to change the model to adapt to outlier points
	Cause: it may lead the algorithm to change the model to adapt to outlier points
	Effect: Although it makes PA faster than OSVR , this is a riskier strategy

CASE: 36
Stag: 117 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: First , since in this artificial scenario adaptation capabilities are not required for the QE component , batch methods operate in the ideal conditions -LRB- as training and test are independent and identically distributed
	Cause: in this artificial scenario adaptation capabilities are not required for the QE component
	Effect: batch methods operate in the ideal conditions -LRB- as training and test are independent and identically distributed

CASE: 37
Stag: 117 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: batch methods operate in the ideal conditions -LRB- as training and test are independent and identically distributed
	Cause: training and test are independent and identically distributed
	Effect: batch methods operate in the ideal conditions -LRB-

CASE: 38
Stag: 119 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Second , this scenario provides the fairest conditions for such comparison because , in principle , online algorithms are not favoured by the possibility to learn from the diversity of the test instances
	Cause: , in principle , online algorithms are not favoured by the possibility to learn from the diversity of the test instances
	Effect: Second , this scenario provides the fairest conditions for such comparison

CASE: 39
Stag: 124 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Evaluation is carried out by measuring the performance of the batch -LRB- learning only from the training set -RRB- , the adaptive -LRB- learning from the training set and adapting to the test set -RRB- , and the empty -LRB- learning from scratch from the test set -RRB- models in terms of global MAE scores on the test set
	Cause: measuring the performance of the batch -LRB- learning only from the training set -RRB- , the adaptive -LRB- learning from the training set and adapting to the test set -RRB- , and the empty -LRB- learning from scratch from the test set -RRB- models in terms of global MAE scores on the test set
	Effect: Evaluation is carried out

CASE: 40
Stag: 125 126 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Table 1 reports the results achieved by the best performing algorithm for each type of model -LRB- batch , adaptive , empty As can be seen , close MAE values show a similar behaviour for the three types of models
	Cause: can be seen , close MAE values show a similar behaviour for the three types of models
	Effect: Table 1 reports the results achieved by the best performing algorithm for each type of model -LRB- batch , adaptive , empty

CASE: 41
Stag: 130 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This demonstrates that , as expected , the online algorithms do not take advantage of test data with a label distribution similar to the training set
	Cause: expected , the online algorithms do not take advantage of test data with a label distribution similar to the training set
	Effect: This demonstrates that

CASE: 42
Stag: 131 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: All the models outperform the baseline , even if the minimal differences confirm the competitiveness of such a simple approach
	Cause: the minimal differences confirm the competitiveness of such a simple approach
	Effect: All the models outperform the baseline , even

CASE: 43
Stag: 139 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The source sentences were translated with two SMT systems built by training the Moses toolkit -LSB- 14 -RSB- on parallel data from the two domains -LRB- about 2M sentences for IT and 1.5 M for L
	Cause: training the Moses toolkit -LSB- 14 -RSB- on parallel data from the two domains -LRB- about 2M sentences for IT and 1.5 M for L
	Effect: The source sentences were translated with two SMT systems built

CASE: 44
Stag: 141 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to the way they are created , the two datasets allow us to evaluate the adaptability of different QE models with respect to user changes within the same domain -LRB- 6.1 -RRB- , as well as user and domain changes at the same time -LRB- 6.2
	Cause: the way they are created
	Effect: the two datasets allow us to evaluate the adaptability of different QE models with respect to user changes within the same domain -LRB- 6.1 -RRB- , as well as user and domain changes at the same time -LRB- 6.2

CASE: 45
Stag: 142 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: For each document D -LRB- L or IT -RRB- , these two scenarios are obtained by dividing D into two parts of equal size -LRB- 80 instances for L and 140 for IT
	Cause: dividing D into two parts of equal size -LRB- 80 instances for L and 140 for IT
	Effect: For each document D -LRB- L or IT -RRB- , these two scenarios are obtained

CASE: 46
Stag: 142 143 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: For each document D -LRB- L or IT -RRB- , these two scenarios are obtained by dividing D into two parts of equal size -LRB- 80 instances for L and 140 for IT The result is one training set and one test set for each post-editor within the same domain
	Cause: For each document D -LRB- L or IT -RRB- , these two scenarios are obtained by dividing D into two parts of equal size -LRB- 80 instances for L and 140 for IT
	Effect: one training set and one test set for each post-editor within the same domain

CASE: 47
Stag: 148 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: For each domain , these respectively involve the most dissimilar and the most similar post-editors according to the u ' \ u0394 ' HTER
	Cause: the u ' \ u0394 ' HTER
	Effect: For each domain , these respectively involve the most dissimilar and the most similar post-editors

CASE: 48
Stag: 150 151 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The first scenario defines a challenging situation where two post-editors -LRB- rad and cons -RRB- are characterized by opposite behaviour As evidenced by the high u ' \ u0394 ' HTER values , one of them -LRB- rad -RRB- is the most u ' \ u201c ' radical u ' \ u201d ' post-editor -LRB- performing more corrections -RRB- while the other -LRB- cons -RRB- is the most u ' \ u201c ' conservative u ' \ u201d ' one
	Cause: evidenced by the high u ' \ u0394 ' HTER values , one of them -LRB- rad -RRB- is the most u ' \ u201c ' radical u ' \ u201d ' post-editor -LRB- performing more corrections -RRB- while the other -LRB- cons -RRB- is the most u ' \ u201c ' conservative u ' \ u201d '
	Effect: The first scenario defines a challenging situation where two post-editors -LRB- rad and cons -RRB- are characterized by opposite behaviour

CASE: 49
Stag: 151 152 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: As evidenced by the high u ' \ u0394 ' HTER values , one of them -LRB- rad -RRB- is the most u ' \ u201c ' radical u ' \ u201d ' post-editor -LRB- performing more corrections -RRB- while the other -LRB- cons -RRB- is the most u ' \ u201c ' conservative u ' \ u201d ' one As shown in Table 2 , global MAE scores for the online algorithms -LRB- both adaptive and empty -RRB- indicate their good adaptation capabilities
	Cause: shown in Table 2 , global MAE scores for the online algorithms -LRB- both adaptive and empty -RRB- indicate their good adaptation capabilities
	Effect: As evidenced by the high u ' \ u0394 ' HTER values , one of them -LRB- rad -RRB- is the most u ' \ u201c ' radical u ' \ u201d ' post-editor -LRB- performing more corrections -RRB- while the other -LRB- cons -RRB- is the most u ' \ u201c ' conservative u ' \ u201d ' one

CASE: 50
Stag: 155 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: These results -LRB- MAE reductions are always statistically significant -RRB- suggest that , when dealing with datasets with very different label distributions , the evident limitations of batch methods are more easily overcome by learning from scratch from the feedback of a new post-editor
	Cause: learning from scratch from the feedback of a new post-editor
	Effect: These results -LRB- MAE reductions are always statistically significant -RRB- suggest that , when dealing with datasets with very different label distributions , the evident limitations of batch methods are more easily overcome

CASE: 51
Stag: 156 157 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This also holds when the amount of test points to learn from is limited , as in the L domain where the test set contains only 80 instances From the application-oriented perspective that motivates our work , considering the high costs of acquiring large and representative QE training data , this is an important finding
	Cause: in the L domain where the test set contains only 80 instances From the application-oriented perspective that motivates our work , considering the high costs of acquiring large and representative QE training data , this is an important
	Effect: This also holds when the amount of test points to learn from is limited

CASE: 52
Stag: 162 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: A closer look at the behaviour of the online algorithms in the two domains leads to other observations
	Cause: A closer look at the behaviour of the online algorithms in the two domains
	Effect: other observations

CASE: 53
Stag: 166 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: For OSVR the addition of new points to the support set may have a limited effect on the whole model , in particular if the number of points in the set is large
	Cause: the number of points in the set is large
	Effect: OSVR the addition of new points to the support set may have a limited effect on the whole model , in particular

CASE: 54
Stag: 174 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: In the table , results are ordered according to the u ' \ u0394 ' HTER computed between the selected post-editor in the training domain -LRB- e.g. , L cons -RRB- and the selected post-editor in the test domain -LRB- e.g. , IT rad
	Cause: the u ' \ u0394 ' HTER computed between the selected post-editor in the training domain
	Effect: L cons -RRB- and the selected

CASE: 55
Stag: 175 
	Pattern: 2 [['for', 'the', 'sake', 'of'], [',']]---- [[], ['&V-ing/&NP@C@'], ['&R']]
	sentTXT: For the sake of comparison , we also report -LRB- grey rows -RRB- the results of the experiments within the same domain presented in 6.1
	Cause: comparison
	Effect: we also report -LRB- grey rows -RRB- the results of the experiments within the same domain presented in 6.1

CASE: 56
Stag: 181 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: This is a strong evidence of the fact that , in case of domain changes , online models can still learn from new test instances even if they have a label distribution similar to the training set
	Cause: they have a label distribution similar to the training set
	Effect: This is a strong evidence of the fact that , in case of domain changes , online models can still learn from new test instances even

CASE: 57
Stag: 188 189 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This suggests that , although PA is potentially capable of achieving higher results and better adapt to the new test points , its instability makes it less reliable for practical use As a final analysis of our results , we investigated how the performance of the different types of models -LRB- batch , adaptive , empty -RRB- relates to the distance between training and test sets
	Cause: a final analysis of our results , we investigated how the performance of the different types of models -LRB- batch , adaptive , empty -RRB- relates to the distance between training and test sets
	Effect: This suggests that , although PA is potentially capable of achieving higher results and better adapt to the new test points , its instability makes it less reliable for practical use

CASE: 58
Stag: 194 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: As expected , the results of the empty models are completely uncorrelated with the u ' \ u0394 ' HTER since they only use the test set
	Cause: they only use the test set
	Effect: As expected , the results of the empty models are completely uncorrelated with the u ' \ u0394 ' HTER

CASE: 59
Stag: 197 198 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: In the CAT scenario , each translation job can be seen as a complex situation where the user -LRB- his personal style and background -RRB- , the source document -LRB- the language and the domain -RRB- and the underlying technology -LRB- the translation memory and the MT engine that generate translation suggestions -RRB- contribute to make the task unique So far , the adaptability to such specificities -LRB- a major challenge for CAT technology -RRB- has been mainly supported by the evolution of translation memories , which incrementally store translated segments incorporating the user style
	Cause: a complex situation where the user -LRB- his personal style and background -RRB- , the source document -LRB- the language and the domain -RRB- and the underlying technology -LRB- the translation memory and the MT engine that generate translation suggestions -RRB- contribute to make the task unique So far , the adaptability to such specificities -LRB- a major challenge for CAT technology -RRB- has been mainly supported by the evolution of translation memories , which
	Effect: In the CAT scenario , each translation job can be seen

CASE: 60
Stag: 203 204 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Our results show that the wealth of dynamic knowledge brought by user corrections can be exploited to refine in a stepwise fashion the quality judgements in different testing conditions -LRB- user changes as well as simultaneous user and domain changes As an additional contribution , to spark further research on this facet of the QE problem , our adaptive QE infrastructure -LRB- integrating all the components and the algorithms described in this paper -RRB- has been released as open source
	Cause: an additional contribution , to spark further research on this facet of the QE problem , our adaptive QE infrastructure -LRB- integrating all the components and the algorithms described in this paper -RRB- has been released as open source
	Effect: Our results show that the wealth of dynamic knowledge brought by user corrections can be exploited to refine in a stepwise fashion the quality judgements in different testing conditions -LRB- user changes as well as simultaneous user and domain changes

