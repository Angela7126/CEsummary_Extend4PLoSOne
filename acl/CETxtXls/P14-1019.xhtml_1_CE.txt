************************************************************
P14-1019.xhtml_1_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 0 1 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Dependency parsing is commonly cast as a maximization problem over a parameterized scoring function In this view, the use of more expressive scoring functions leads to more challenging combinatorial problems of finding the maximizing parse
	Cause: [(0, 6), (1, 20)]
	Effect: [(0, 0), (0, 4)]

CASE: 1
Stag: 1 
	Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: In this view, the use of more expressive scoring functions leads to more challenging combinatorial problems of finding the maximizing parse
	Cause: [(0, 4), (0, 10)]
	Effect: [(0, 13), (0, 21)]

CASE: 2
Stag: 2 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Much of the recent work on parsing has been focused on improving methods for solving the combinatorial maximization inference problems
	Cause: [(0, 14), (0, 19)]
	Effect: [(0, 0), (0, 12)]

CASE: 3
Stag: 3 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Indeed, state-of-the-art results have been obtained by adapting powerful tools from optimization [ 16 , 17 , 27 ]
	Cause: [(0, 8), (0, 19)]
	Effect: [(0, 0), (0, 6)]

CASE: 4
Stag: 6 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Our combination outperforms the state-of-the-art parsers and remains comparable even if we adopt their scoring functions
	Cause: [(0, 11), (0, 15)]
	Effect: [(0, 0), (0, 9)]

CASE: 5
Stag: 8 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: They first appeared in the context of reranking [ 6 ] , where a simple parser is used to generate a candidate list which is then reranked according to the scoring function
	Cause: [(0, 29), (0, 31)]
	Effect: [(0, 0), (0, 26)]

CASE: 6
Stag: 9 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because the number of alternatives is small, the scoring function could in principle involve arbitrary (global) features of parse trees
	Cause: [(0, 1), (0, 6)]
	Effect: [(0, 8), (0, 22)]

CASE: 7
Stag: 16 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because the steps are small, the complexity of the scoring function has limited impact on the computational cost of the procedure
	Cause: [(0, 1), (0, 4)]
	Effect: [(0, 6), (0, 21)]

CASE: 8
Stag: 21 
	Pattern: 47 [['so'], ['that']]---- [['&C'], ['&adj/&adv@C@'], ['&R']]
	sentTXT: Because the inference procedure is so simple, it is important that the parameters of the scoring function are chosen in a manner that facilitates how we climb the scoring function in small steps
	Cause: [(0, 0), (0, 6)]
	Effect: [(0, 12), (0, 33)]

CASE: 9
Stag: 23 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: This approach was suggested in the SampleRank framework [ 32 ] for training structured prediction models
	Cause: [(0, 12), (0, 15)]
	Effect: [(0, 0), (0, 10)]

CASE: 10
Stag: 29 30 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: When proposing a small move, i.e.,, sampling a head of the word, we can also jointly sample its POS tag from a set of alternatives provided by the tagger As a result, the selected tag is influenced by a broad syntactic context above and beyond the initial tagging model and is directly optimized to improve parsing performance
	Cause: [(0, 0), (0, 32)]
	Effect: [(1, 4), (1, 28)]

CASE: 11
Stag: 35 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: Our method provides a more effective mechanism for handling global features than reranking, outperforming it by 1.3%
	Cause: [(0, 8), (0, 18)]
	Effect: [(0, 0), (0, 6)]

CASE: 12
Stag: 42 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Reranking can be combined with an arbitrary scoring function, and thus can easily incorporate global features over the entire parse tree
	Cause: [(0, 0), (0, 8)]
	Effect: [(0, 12), (0, 21)]

CASE: 13
Stag: 45 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: For instance, Nakagawa ( 2007 ) deals with tractability issues by using sampling to approximate marginals
	Cause: [(0, 12), (0, 16)]
	Effect: [(0, 3), (0, 10)]

CASE: 14
Stag: 53 
	Pattern: 5 [['so'], ['as', 'to']]---- [['&C', '(,)'], ['(&adj/&adv@C@)'], ['&R']]
	sentTXT: In SampleRank, the parameters are adjusted so as to guide the sequence of candidates closer to the target structure along the search path
	Cause: [(0, 0), (0, 6)]
	Effect: [(0, 10), (0, 23)]

CASE: 15
Stag: 55 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: In this paper, we demonstrate how to adapt the method for parsing with rich scoring functions
	Cause: [(0, 12), (0, 16)]
	Effect: [(0, 0), (0, 10)]

CASE: 16
Stag: 62 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: A training set of size N is given as a set of pairs u'\ud835' u'\udc9f' = { ( x ( i ) , y ( i ) ) } i = 1 N where y ( i ) is the ground truth parse for sentence x ( i )
	Cause: [(0, 9), (0, 54)]
	Effect: [(0, 0), (0, 7)]

CASE: 17
Stag: 68 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: Similarly, parsers based on dual decomposition [ 17 , 14 ] assume that s u'\u2062' ( x , y ) decomposes into a sum of terms where each term can be maximized over y efficiently
	Cause: [(0, 5), (0, 7)]
	Effect: [(0, 10), (0, 39)]

CASE: 18
Stag: 71 
	Pattern: 5 [['so'], ['as', 'to']]---- [['&C', '(,)'], ['(&adj/&adv@C@)'], ['&R']]
	sentTXT: We find a high scoring tree through sampling, and (later) learn the parameters u'\u0398' so as to further guide this process
	Cause: [(0, 0), (0, 20)]
	Effect: [(0, 24), (0, 27)]

CASE: 19
Stag: 71 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: We find a high scoring tree through sampling, and (later) learn the parameters u'\u0398' so as to further guide this process
	Cause: [(0, 7), (0, 7)]
	Effect: [(0, 8), (0, 20)]

CASE: 20
Stag: 72 73 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: Our sampler generates a sequence of dependency structures so as to approximate independent samples from The temperature parameter T controls how concentrated the samples are around the maximum of s u'\u2062' ( x , y ) (e.g.,, see Geman and Geman ( 1984 )
	Cause: [(0, 0), (0, 7)]
	Effect: [(0, 9), (1, 34)]

CASE: 21
Stag: 78 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The target distribution p folds into the procedure by defining the probability that we will accept the proposed move
	Cause: [(0, 9), (0, 18)]
	Effect: [(0, 0), (0, 7)]

CASE: 22
Stag: 117 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: This is feasible if we restrict the proposed moves to only small changes in the current tree
	Cause: [(0, 4), (0, 16)]
	Effect: [(0, 0), (0, 2)]

CASE: 23
Stag: 118 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: In our case, we choose a word j randomly, and then sample its head h j according to p with the constraint that we obtain a valid tree (when projective trees are sought, this constraint is also incorporated
	Cause: [(0, 20), (0, 24)]
	Effect: [(0, 37), (0, 41)]

CASE: 24
Stag: 119 120 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: For this choice of q , the probability of accepting the new tree ( u'\u0391' in Figure 1 ) is identically one Thus new moves are always accepted
	Cause: [(0, 0), (0, 25)]
	Effect: [(1, 1), (1, 4)]

CASE: 25
Stag: 124 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: While in general this is increasingly difficult with more heads, it is indeed tractable if the model corresponds to a first-order parser
	Cause: [(0, 16), (0, 22)]
	Effect: [(0, 0), (0, 14)]

CASE: 26
Stag: 127 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: where y corresponds to a tree with a spcified root and w i u'\u2062' j is the exponential of the first-order score y is always a valid parse tree if we allow multiple children of the root and do not impose projective constraint
	Cause: [(0, 34), (0, 46)]
	Effect: [(0, 1), (0, 32)]

CASE: 27
Stag: 128 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: The algorithm in Wilson ( 1996 ) iterates over all the nodes, and for each node performs a random walk according to the weights w i u'\u2062' j until the walk creates a loop or hits a tree
	Cause: [(0, 23), (0, 24)]
	Effect: [(0, 0), (0, 20)]

CASE: 28
Stag: 130 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If the walk hits the current tree, the walk path is added to form a new tree with more nodes
	Cause: [(0, 1), (0, 6)]
	Effect: [(0, 8), (0, 20)]

CASE: 29
Stag: 133 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since our features do not by design correspond to a first-order parser, we cannot use the Wilson algorithm as it is
	Cause: [(0, 1), (0, 11)]
	Effect: [(0, 13), (0, 22)]

CASE: 30
Stag: 133 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Since our features do not by design correspond to a first-order parser, we cannot use the Wilson algorithm as it is
	Cause: [(0, 8), (0, 9)]
	Effect: [(0, 0), (0, 6)]

CASE: 31
Stag: 134 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Instead we use it as the proposal function and sample a subset of the dependencies from the first-order distribution of our model, while fixing the others
	Cause: [(0, 5), (0, 26)]
	Effect: [(0, 1), (0, 3)]

CASE: 32
Stag: 136 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: Note that blocked Gibbs sampling would be exponential in K , and is thus very slow already at K = 4
	Cause: [(0, 0), (0, 12)]
	Effect: [(0, 14), (0, 20)]

CASE: 33
Stag: 144 145 
	Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
	sentTXT: Moreover, alternatives that are far from the gold parse should score even lower As a result, we require that
	Cause: [(0, 0), (0, 13)]
	Effect: [(1, 4), (1, 6)]

CASE: 34
Stag: 153 154 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We cannot necessarily assume that s u'\u2062' ( x , y ) is greater than s u'\u2062' ( x , y u'\u2032' ) without additional encouragement Thus, we can complement the constraints in Equation 4 with additional pairwise constraints [ 32 ]
	Cause: [(0, 0), (0, 38)]
	Effect: [(1, 1), (1, 16)]

CASE: 35
Stag: 160 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: Specifically, if the current parameters are u'\u0398' t , and we enforce constraint Equation 5 for a particular pair y , y u'\u2032' , then we will find u'\u0398' t + 1 that minimizes
	Cause: [(0, 3), (0, 12)]
	Effect: [(0, 14), (0, 31)]

CASE: 36
Stag: 163 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: We repeatedly generate parses based on the current parameters u'\u0398' t for each sentence x ( i ) , and use successive samples to enforce constraints in Equation 4 and Equation 5 one at a time
	Cause: [(0, 6), (0, 21)]
	Effect: [(0, 23), (0, 39)]

CASE: 37
Stag: 191 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: We generate the POS candidate list for each word based on the confusion matrix on the training set
	Cause: [(0, 11), (0, 17)]
	Effect: [(0, 0), (0, 8)]

CASE: 38
Stag: 193 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: For each word w , we first prune out its POS candidates by using the vocabulary from the training set
	Cause: [(0, 13), (0, 19)]
	Effect: [(0, 0), (0, 11)]

CASE: 39
Stag: 194 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: We don u'\u2019' t prune anything if w is unseen
	Cause: [(0, 11), (0, 13)]
	Effect: [(0, 0), (0, 9)]

CASE: 40
Stag: 195 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Assuming that the predicted tag for w is t p , we further remove those tags t if their counts are smaller than some threshold c u'\u2062' ( t , t p ) u'\u0391' u'\u22c5' c u'\u2062' ( t p , t p ) 2 2 In our work we choose u'\u0391' = 0.003 , which gives a 98.9% oracle POS tagging accuracy on the CATiB development set
	Cause: [(0, 18), (0, 87)]
	Effect: [(0, 2), (0, 16)]

CASE: 41
Stag: 202 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: We also define features based on consecutive sibling, grandparent, arbitrary sibling, head bigram, grand-sibling and tri-siblings, which are also used in the Turbo parser [ 16 ]
	Cause: [(0, 6), (0, 7)]
	Effect: [(0, 9), (0, 31)]

CASE: 42
Stag: 210 211 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: For instance, in cats and dogs , the conjuncts are both short noun phrases Therefore, we add different features to capture POS tag and span length consistency in a coordinate structure
	Cause: [(0, 0), (0, 14)]
	Effect: [(1, 2), (1, 17)]

CASE: 43
Stag: 213 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: Generally, this feature can be defined based on an instance of grandparent structure
	Cause: [(0, 9), (0, 13)]
	Effect: [(0, 0), (0, 6)]

CASE: 44
Stag: 223 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Non-projective Arcs A flag indicating if a dependency is projective or not (i.e., if it spans a word that does not descend from its head) [ 17 ]
	Cause: [(0, 6), (0, 26)]
	Effect: [(0, 0), (0, 4)]

CASE: 45
Stag: 223 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: Non-projective Arcs A flag indicating if a dependency is projective or not (i.e., if it spans a word that does not descend from its head) [ 17 ]
	Cause: [(0, 10), (0, 20)]
	Effect: [(0, 0), (0, 8)]

CASE: 46
Stag: 227 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: However, we are free to add higher order features because we do not rely on dynamic programming decoding
	Cause: [(0, 11), (0, 18)]
	Effect: [(0, 0), (0, 9)]

CASE: 47
Stag: 241 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We handle long sentences during testing by applying a simple split-merge strategy
	Cause: [(0, 7), (0, 11)]
	Effect: [(0, 0), (0, 5)]

CASE: 48
Stag: 242 
	Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
	sentTXT: We split the sentence based on the ending punctuation, predict the parse tree for each segment and group the roots of resulting trees into a single node
	Cause: [(0, 6), (0, 8)]
	Effect: [(0, 10), (0, 27)]

CASE: 49
Stag: 243 244 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Evaluation Measures Following standard practice, we use Unlabeled Attachment Score (UAS) as the evaluation metric in all our experiments We report UAS excluding punctuation on CoNLL datasets, following Martins et al
	Cause: [(0, 15), (1, 8)]
	Effect: [(0, 0), (0, 13)]

CASE: 50
Stag: 251 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: The reranker operates over the top-50 list obtained from the MST parser 4 4 The MST parser is trained in projective mode for reranking because generating top-k list from second-order non-projective model is intractable
	Cause: [(0, 25), (0, 33)]
	Effect: [(0, 0), (0, 23)]

CASE: 51
Stag: 253 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: We then train the reranker by running 10 epochs of cost-augmented MIRA
	Cause: [(0, 6), (0, 11)]
	Effect: [(0, 0), (0, 4)]

CASE: 52
Stag: 254 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The reranker uses the same features as our model, along with the tree scores obtained from the MST parser (which is a standard practice in reranking
	Cause: [(0, 7), (0, 26)]
	Effect: [(0, 0), (0, 5)]

CASE: 53
Stag: 260 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: Because the CoNLL datasets do not have a standard development set, we randomly select a held out of 200 sentences from the training set
	Cause: [(0, 1), (0, 10)]
	Effect: [(0, 12), (0, 24)]

CASE: 54
Stag: 264 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: However, for the joint parsing and POS correction on the CATiB dataset we do not use the Random Walk method because the first-order features in normal parsing are no longer first-order when POS tags are also variables
	Cause: [(0, 22), (0, 37)]
	Effect: [(0, 0), (0, 20)]

CASE: 55
Stag: 264 265 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: However, for the joint parsing and POS correction on the CATiB dataset we do not use the Random Walk method because the first-order features in normal parsing are no longer first-order when POS tags are also variables Therefore, the first-order distribution is not well-defined and we only employ Gibbs sampling for simplicity
	Cause: [(0, 0), (0, 37)]
	Effect: [(1, 2), (1, 15)]

CASE: 56
Stag: 266 267 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: On the CATiB dataset, we restrict the sample trees to always be projective as described in Section 3.2.1 However, we do not impose this constraint for the CoNLL datasets
	Cause: [(0, 15), (1, 11)]
	Effect: [(0, 0), (0, 13)]

CASE: 57
Stag: 272 273 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This suggests that our learning and inference procedures are as effective as the dual decomposition method in the Turbo parser Next, we add global features that are not used by the Turbo parser
	Cause: [(0, 10), (1, 12)]
	Effect: [(0, 0), (0, 8)]

CASE: 58
Stag: 278 
	Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
	sentTXT: Comparison with Reranking As column 6 of Table 2 shows, our model outperforms the reranker by 1.3% 5 5 Note that the comparison is conservative because we can also add MST scores as features in our model as in reranker
	Cause: [(0, 28), (0, 41)]
	Effect: [(0, 0), (0, 26)]

CASE: 59
Stag: 282 
	Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
	sentTXT: 6 6 We ran this experiment on 5 languages with small datasets due to the scalability issues associated with reranking top-500 list
	Cause: [(0, 14), (0, 21)]
	Effect: [(0, 0), (0, 11)]

CASE: 60
Stag: 282 283 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 6 6 We ran this experiment on 5 languages with small datasets due to the scalability issues associated with reranking top-500 list As column 7 shows, this increase in the list size does not change the relative performance of the reranker and our model
	Cause: [(1, 1), (1, 22)]
	Effect: [(0, 2), (0, 21)]

CASE: 61
Stag: 284 285 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Joint Parsing and POS Correction Table 3 shows the results of joint parsing and POS correction on the CATiB dataset, for our model and state-of-the-art systems As the upper part of the table shows, the parser with corrected tags reaches 88.38% compared to the accuracy of 88.46% on the gold tags
	Cause: [(1, 1), (1, 27)]
	Effect: [(0, 0), (0, 26)]

CASE: 62
Stag: 289 290 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Impact of Sampling Methods We compare two sampling methods introduced in Section 3.2 with respect to their decoding efficiency Specifically, we measure the score of the retrieved trees in testing as a function of the decoding speed, measured by the number of tokens per second
	Cause: [(1, 13), (1, 26)]
	Effect: [(0, 0), (1, 11)]

CASE: 63
Stag: 294 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We select these two languages as they correspond to two extremes in sentence length
	Cause: [(0, 6), (0, 13)]
	Effect: [(0, 0), (0, 4)]

CASE: 64
Stag: 305 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Decoding Speed Our sampling-based parser is an anytime algorithm, and therefore its running time can be traded for performance
	Cause: [(0, 0), (0, 8)]
	Effect: [(0, 12), (0, 19)]

CASE: 65
Stag: 305 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Decoding Speed Our sampling-based parser is an anytime algorithm, and therefore its running time can be traded for performance
	Cause: [(0, 0), (0, 1)]
	Effect: [(0, 2), (0, 8)]

