************************************************************
P14-1136.xhtml_2_CE.txt: Cause-Effect links
************************************************************

CASE: 0
Stag: 5 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: By providing richer representations of meaning than what can be encompassed in a discrete representation , such approaches have successfully been applied to tasks such as sentiment analysis -LSB- 24 -RSB- , topic classification -LSB- 16 -RSB- or word-word similarity -LSB- 20 -RSB-
	Cause: providing richer representations of meaning than what can be encompassed in a discrete representation , such approaches have successfully been applied to tasks such as sentiment analysis
	Effect: -LSB- 24 -RSB- , topic classification -LSB- 16 -RSB- or word-word similarity -LSB- 20 -RSB-

CASE: 1
Stag: 7 
	Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
	sentTXT: According to the theory of frame semantics -LSB- 12 -RSB- , a semantic frame represents an event or scenario , and possesses frame elements -LRB- or semantic roles -RRB- that participate in the event
	Cause: the theory of frame semantics
	Effect: a semantic frame represents an event or scenario , and possesses frame elements -LRB- or semantic roles -RRB- that participate in the

CASE: 2
Stag: 13 
	Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: Moreover , for full frame-semantic parsing , with the presented frame identification technique followed by our argument identification method , we report the best results on this task to date
	Cause: Moreover , for full frame-semantic parsing , with the presented frame identification technique followed by our argument identification method , we report
	Effect: task to date

CASE: 3
Stag: 17 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the CoNLL 2004-2005 shared tasks -LSB- 4 , 5 -RSB- on PropBank semantic role labeling -LRB- SRL -RRB- , it has been treated as an important NLP problem
	Cause: the CoNLL 2004-2005 shared tasks -LSB- 4
	Effect: 5 -RSB- on PropBank semantic role labeling -LRB- SRL -RRB- , it has been treated as an important NLP problem

CASE: 4
Stag: 24 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: FrameNet The FrameNetproject -LSB- 2 -RSB- is a lexical database that contains information about words and phrases -LRB- represented as lemmas conjoined with a coarse part-of-speech tag -RRB- termed as lexical units , with a set of semantic frames that they could evoke
	Cause: lemmas conjoined with a coarse part-of-speech tag -RRB- termed as lexical units , with a set of semantic frames that they could evoke
	Effect: The FrameNetproject -LSB- 2 -RSB- is a lexical database that contains information about words and phrases -LRB- represented

CASE: 5
Stag: 25 26 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: For each frame , there is a list of associated frame elements -LRB- or roles , henceforth -RRB- , that are also distinguished as core or non-core 2 2 Additional information such as finer distinction of the coreness properties of roles , the relationship between frames , and that of roles are also present , but we do not leverage that information in this work
	Cause: core or non-core 2 2 Additional information such as finer distinction of the coreness properties of roles , the relationship between frames , and that of roles are also
	Effect: For each frame , there is a list of associated frame elements -LRB- or roles , henceforth -RRB- , that are also distinguished

CASE: 6
Stag: 54 55 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: A word embedding is a distributed representation of meaning where each word is represented as a vector in u ' \ u211d ' n Such representations allow a model to share meaning between similar words , and have been used to capture semantic , syntactic and morphological content -LSB- 6 , 25 , inter alia -RSB-
	Cause: a vector in u ' \ u211d ' n Such representations allow a model to share meaning between similar words , and have been used to capture semantic , syntactic and morphological content -LSB- 6 , 25 , inter alia
	Effect: A word embedding is a distributed representation of meaning where each word is represented

CASE: 7
Stag: 58 59 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: We could represent the syntactic context of runs as a vector with blocks for all the possible dependents warranted by a syntactic parser ; for example , we could assume that positions 0 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' n in the vector correspond to the subject dependent , n + 1 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' 2 u ' \ u2062 ' n correspond to the clausal complement dependent , and so forth Thus , the context is a vector in u ' \ u211d ' n u ' \ u2062 ' k with the embedding of He at the subject position , the embedding of company in direct object position and zeros everywhere else
	Cause: We could represent the syntactic context of runs as a vector with blocks for all the possible dependents warranted by a syntactic parser ; for example , we could assume that positions 0 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' n in the vector correspond to the subject dependent , n + 1 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' 2 u ' \ u2062 ' n correspond to the clausal complement dependent
	Effect: forth Thus , the context is a vector in u ' \ u211d ' n u ' \ u2062 ' k with the embedding of He at the subject position , the embedding of company in direct object position and zeros everywhere

CASE: 8
Stag: 58 59 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: We could represent the syntactic context of runs as a vector with blocks for all the possible dependents warranted by a syntactic parser ; for example , we could assume that positions 0 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' n in the vector correspond to the subject dependent , n + 1 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' 2 u ' \ u2062 ' n correspond to the clausal complement dependent , and so forth Thus , the context is a vector in u ' \ u211d ' n u ' \ u2062 ' k with the embedding of He at the subject position , the embedding of company in direct object position and zeros everywhere else
	Cause: We could represent the syntactic context of runs as a vector with blocks for all the possible dependents warranted by a syntactic parser ; for example , we could assume that positions 0 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' n in the vector correspond to the subject dependent , n + 1 u ' \ u2062 ' u ' \ u2026 ' u ' \ u2062 ' 2 u ' \ u2062 ' n correspond to the clausal complement dependent , and so forth
	Effect: , the context is a vector in u ' \ u211d ' n u ' \ u2062 ' k with the embedding of He at the subject position , the embedding of company in direct object position and zeros everywhere else

CASE: 9
Stag: 66 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: The model computes a composed representation of the predicate instance by using distributed vector representations for words -LRB- 3 -RRB- u ' \ u2013 ' the -LRB- red -RRB- vertical embedding vectors for each word are concatenated into a long vector
	Cause: using distributed vector representations for words -LRB- 3 -RRB- u ' \ u2013 ' the -LRB- red -RRB- vertical embedding vectors for each word are concatenated into a long vector
	Effect: The model computes a composed representation of the predicate instance

CASE: 10
Stag: 69 70 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: First , we extract the words in the syntactic context of runs ; next , we concatenate their word embeddings as described in 2.2 to create an initial vector space representation Subsequently , we learn a mapping from this initial representation into a low-dimensional space ; we also learn an embedding for each possible frame label in the same low-dimensional space
	Cause: described in 2.2 to create an initial vector space representation Subsequently , we learn a mapping from this initial representation into a low-dimensional space ; we also
	Effect: in the syntactic context of runs ; next , we concatenate their word embeddings

CASE: 11
Stag: 84 85 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: If we have F possible frames we can store those parameters in an F m matrix , one m - dimensional point for each frame , which we will refer to as the linear mapping Y Let the lexical unit -LRB- the lemma conjoined with a coarse POS tag -RRB- for the marked predicate be u ' \ u2113 '
	Cause: the linear mapping Y Let the lexical unit -LRB- the lemma conjoined with a coarse POS tag -RRB- for the marked predicate be u ' \ u2113 '
	Effect: If we have F possible frames we can store those parameters in an F m matrix , one m - dimensional point for each frame , which we will refer to

CASE: 12
Stag: 86 87 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We denote the frames that associate with u ' \ u2113 ' in the frame lexicon 5 5 The frame lexicon stores the frames , corresponding semantic roles and the lexical units associated with the frame and our training corpus as F u ' \ u2113 ' Wsabie performs gradient-based updates on an objective that tries to minimize the distance between M u ' \ u2062 ' -LRB- g u ' \ u2062 ' -LRB- x -RRB- -RRB- and the embedding of the correct label Y u ' \ u2062 ' -LRB- y -RRB- , while maintaining a large distance between M u ' \ u2062 ' -LRB- g u ' \ u2062 ' -LRB- x -RRB- -RRB- and the other possible labels Y u ' \ u2062 ' -LRB- y -RRB- in the confusion set F u ' \ u2113 '
	Cause: F u ' \ u2113 ' Wsabie performs gradient-based updates on an objective that tries to minimize the distance between M u ' \ u2062 ' -LRB- g u ' \ u2062 ' -LRB- x -RRB- -RRB- and the embedding of the correct label Y u ' \ u2062 ' -LRB- y -RRB- , while maintaining a large distance between M u ' \ u2062 ' -LRB- g u ' \ u2062 ' -LRB- x -RRB- -RRB- and the other possible labels Y u ' \ u2062 ' -LRB- y -RRB- in the confusion set F u ' \ u2113
	Effect: We denote the frames that associate with u ' \ u2113 ' in the frame lexicon 5 5 The frame lexicon stores the frames , corresponding semantic roles and the lexical units associated with the frame and our training corpus

CASE: 13
Stag: 88 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: At disambiguation time , we use a simple dot product similarity as our distance metric , meaning that the model chooses a label by computing the argmax y u ' \ u2062 ' s u ' \ u2062 ' -LRB- x , y -RRB- where s u ' \ u2062 ' -LRB- x , y -RRB- = M u ' \ u2062 ' -LRB- g u ' \ u2062 ' -LRB- x -RRB- -RRB- u ' \ u22c5 ' Y u ' \ u2062 ' -LRB- y -RRB- , where the argmax iterates over the possible frames y u ' \ u2208 ' F u ' \ u2113 ' if u ' \ u2113 ' was seen in the lexicon or the training data , or y u ' \ u2208 ' F , if it was unseen
	Cause: our distance metric , meaning that the model chooses a label by computing the argmax y u ' \ u2062 ' s u ' \ u2062 ' -LRB- x , y -RRB- where s u ' \ u2062 ' -LRB- x , y -RRB- = M u ' \ u2062 ' -LRB- g u ' \ u2062 ' -LRB- x -RRB- -RRB- u ' \ u22c5 ' Y u ' \ u2062 ' -LRB- y -RRB- , where the argmax iterates over the possible frames y u ' \ u2208 ' F u ' \ u2113 ' if u ' \ u2113 ' was seen in the lexicon or the training data , or y u ' \ u2208 ' F , if it was unseen
	Effect: At disambiguation time , we use a simple dot product similarity

CASE: 14
Stag: 88 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: our distance metric , meaning that the model chooses a label by computing the argmax y u ' \ u2062 ' s u ' \ u2062 ' -LRB- x , y -RRB- where s u ' \ u2062 ' -LRB- x , y -RRB- = M u ' \ u2062 ' -LRB- g u ' \ u2062 ' -LRB- x -RRB- -RRB- u ' \ u22c5 ' Y u ' \ u2062 ' -LRB- y -RRB- , where the argmax iterates over the possible frames y u ' \ u2208 ' F u ' \ u2113 ' if u ' \ u2113 ' was seen in the lexicon or the training data , or y u ' \ u2208 ' F , if it was unseen
	Cause: u ' \ u2113 ' was seen in the lexicon or the training data , or y u ' \ u2208 ' F , if it was
	Effect: our distance metric , meaning that the model chooses a label by computing the argmax y u ' \ u2062 ' s u ' \ u2062 ' -LRB- x , y -RRB- where s u ' \ u2062 ' -LRB- x , y -RRB- = M u ' \ u2062 ' -LRB- g u ' \ u2062 ' -LRB- x -RRB- -RRB- u ' \ u22c5 ' Y u ' \ u2062 ' -LRB- y -RRB- , where the argmax iterates over the possible frames y u ' \ u2208 ' F u ' \ u2113 '

CASE: 15
Stag: 88 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: u ' \ u2113 ' was seen in the lexicon or the training data , or y u ' \ u2208 ' F , if it was
	Cause: it was
	Effect: ' \ u2113 ' was seen in the lexicon or the training data , or y u ' \ u2208 ' F ,

CASE: 16
Stag: 88 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: our distance metric , meaning that the model chooses a label by computing the argmax y u ' \ u2062 ' s u ' \ u2062 ' -LRB- x , y -RRB- where s u ' \ u2062 ' -LRB- x , y -RRB- = M u ' \ u2062 ' -LRB- g u ' \ u2062 ' -LRB- x -RRB- -RRB- u ' \ u22c5 ' Y u ' \ u2062 ' -LRB- y -RRB- , where the argmax iterates over the possible frames y u ' \ u2208 ' F u ' \ u2113 '
	Cause: computing the argmax y u ' \ u2062
	Effect: ' s u ' \ u2062 ' -LRB- x , y -RRB- where s u ' \ u2062 ' -LRB- x , y -RRB- = M u ' \ u2062 ' -LRB- g u ' \ u2062 ' -LRB- x -RRB- -RRB- u ' \ u22c5 ' Y u ' \ u2062 ' -LRB- y -RRB- , where the argmax iterates over the possible frames y u ' \ u2208 ' F u ' \ u2113 '

CASE: 17
Stag: 93 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since Wsabie learns a single mapping from g u ' \ u2062 ' -LRB- x -RRB- to u ' \ u211d ' m , parameters are shared between different words and different frames
	Cause: Wsabie learns a single mapping from g u ' \ u2062 ' -LRB- x -RRB- to u ' \ u211d ' m
	Effect: parameters are shared between different words and different frames

CASE: 18
Stag: 94 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: So for example u ' \ u201c ' He runs the company u ' \ u201d ' could help the model disambiguate u ' \ u201c ' He owns the company u ' \ u201d ' Moreover , since g u ' \ u2062 ' -LRB- x -RRB- relies on word embeddings rather than word identities , information is shared between words
	Cause: g u ' \ u2062 ' -LRB- x -RRB- relies on word embeddings rather than word identities
	Effect: information is shared between words

CASE: 19
Stag: 99 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: To elaborate , the positions of interest are the labels of the direct dependents of the predicate , so k is the number of labels that the dependency parser can produce
	Cause: To elaborate , the positions of interest are the labels of the direct dependents of the predicate
	Effect: k is the number of labels that the dependency parser can produce

CASE: 20
Stag: 100 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: For example , if the label on the edge between runs and He is nsubj , we would put the embedding of He in the block corresponding to nsubj
	Cause: the label on the edge between runs and He is nsubj
	Effect: we would put the embedding of He in the block corresponding to nsubj

CASE: 21
Stag: 101 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If a label occurs multiple times , then the embeddings of the words below this label are averaged
	Cause: a label occurs multiple times
	Effect: then the embeddings of the words below this label are averaged

CASE: 22
Stag: 109 110 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: This set of dependency paths were deemed as possible positions in the initial vector space representation In addition , akin to the first context function , we also added all dependency labels to the context set
	Cause: possible positions in the initial vector space representation In addition , akin to the first context function , we also added all dependency labels to the context
	Effect: This set of dependency paths were deemed

CASE: 23
Stag: 110 111 
	Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
	sentTXT: In addition , akin to the first context function , we also added all dependency labels to the context set Thus for this context function , the block cardinality k was the sum of the number of scanned gold dependency path types and the number of dependency labels
	Cause: In addition , akin to the first context function , we also added all dependency labels to the context set
	Effect: for this context function , the block cardinality k was the sum of the number of scanned gold dependency path types and the number of dependency labels

CASE: 24
Stag: 111 112 
	Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: Thus for this context function , the block cardinality k was the sum of the number of scanned gold dependency path types and the number of dependency labels Given a predicate in its sentential context , we therefore extract only those context words that appear in positions warranted by the above set
	Cause: for this context function , the block cardinality k was the sum of the number of scanned gold dependency path types and the number of dependency labels Given a predicate in its sentential context , we
	Effect: extract only those context words that appear in positions warranted by the above set

CASE: 25
Stag: 115 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: For all our experiments , setting 3 -RRB- which concatenates the direct dependents and dependency path always dominated the other two , so we only report results for this setting
	Cause: 3 -RRB- which concatenates the direct dependents and dependency path always dominated the other two
	Effect: we only report results for this setting

CASE: 26
Stag: 118 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The mapping from g u ' \ u2062 ' -LRB- x -RRB- to the low dimensional space u ' \ u211d ' m is a linear transformation , so the model parameters to be learnt are the matrix M u ' \ u2208 ' u ' \ u211d ' n u ' \ u2062 ' k m as well as the embedding of each possible frame label , represented as another matrix Y u ' \ u2208 ' u ' \ u211d ' F m where there are F frames in total
	Cause: The mapping from g u ' \ u2062 ' -LRB- x -RRB- to the low dimensional space u ' \ u211d ' m is a linear transformation
	Effect: the model parameters to be learnt are the matrix M u ' \ u2208 ' u ' \ u211d ' n u ' \ u2062 ' k m as well as the embedding of each possible frame label , represented as another matrix Y u ' \ u2208 ' u ' \ u211d ' F m where there are F frames in total

CASE: 27
Stag: 123 
	Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
	sentTXT: Choosing L u ' \ u2062 ' -LRB- u ' \ u0397 ' -RRB- = C u ' \ u2062 ' u ' \ u0397 ' for any positive constant C optimizes the mean rank , whereas a weighting such as L u ' \ u2062 ' -LRB- u ' \ u0397 ' -RRB- = u ' \ u2211 ' i = 1 u ' \ u0397 ' 1 / i -LRB- adopted here -RRB- optimizes the top of the ranked list , as described in -LSB- 26 -RSB-
	Cause: Choosing L u ' \ u2062 ' -LRB- u ' \ u0397 ' -RRB-
	Effect: = C u ' \ u2062 ' u ' \ u0397 ' for any positive constant C optimizes the mean rank , whereas a weighting such as L u ' \ u2062 ' -LRB- u ' \ u0397 ' -RRB- = u ' \ u2211 ' i = 1 u ' \ u0397 ' 1 / i -LRB- adopted here -RRB- optimizes the top of the ranked list , as described in -LSB- 26 -RSB-

CASE: 28
Stag: 130 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Additionally , since we use a frame lexicon that gives us the possible frames for a given predicate , we usually only consider a handful of candidate labels
	Cause: we use a frame lexicon that gives us the possible frames for a given predicate
	Effect: we usually only consider a handful of candidate labels

CASE: 29
Stag: 131 
	Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
	sentTXT: If we used all training examples for a given predicate for finding a nearest-neighbor match at inference time , we would have to consider many more candidates , making the process very slow
	Cause: we used all training examples for a given predicate for finding a nearest-neighbor match at inference time
	Effect: we would have to consider many more candidates , making the process very slow

CASE: 30
Stag: 136 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: From x , a rule-based candidate argument extraction algorithm extracts a set of spans u ' \ ud835 ' u ' \ udc9c ' that could potentially serve as the overt 7 7 By overtness , we mean the non-null instantiation of a semantic role in a frame-semantic parse arguments u ' \ ud835 ' u ' \ udc9c ' y for y -LRB- see 5.4 - 5.5 for the details of the candidate argument extraction algorithms
	Cause: the overt 7 7 By overtness , we mean the non-null instantiation of a semantic role in a frame-semantic parse arguments u ' \ ud835 ' u ' \ udc9c ' y for y -LRB- see 5.4 - 5.5 for the
	Effect: x , a rule-based candidate argument extraction algorithm extracts a set of spans u ' \ ud835 ' u ' \ udc9c ' that could potentially serve

CASE: 31
Stag: 138 
	Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
	sentTXT: a set of tuples that associates each role r in u ' \ u211b ' y with a span a according to the gold data
	Cause: the gold data
	Effect: a

CASE: 32
Stag: 143 
	Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
	sentTXT: Inference Although our learning mechanism uses a local log-linear model , we perform inference globally on a per-frame basis by applying hard structural constraints
	Cause: applying hard structural constraints
	Effect: Although our learning mechanism uses a local log-linear model , we perform inference globally on a per-frame basis

CASE: 33
Stag: 146 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 2008 -RRB- we use the log-probability of the local classifiers as a score in an integer linear program -LRB- ILP -RRB- to assign roles subject to hard constraints described in 5.4 and 5.5
	Cause: a score in an integer linear program -LRB- ILP -RRB- to assign roles subject to hard constraints described in 5.4 and 5.5
	Effect: we use the log-probability of the local classifiers

CASE: 34
Stag: 152 153 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We used the same test set as Das et al containing 23 documents with 4,458 predicates Of the remaining 55 documents , 16 documents were randomly chosen for development
	Cause: Das et al containing 23 documents with 4,458 predicates Of the remaining 55 documents , 16 documents were randomly chosen for development
	Effect: We used the same test set

CASE: 35
Stag: 158 
	Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
	sentTXT: All the verb frame files in Ontonotes were used for creating our frame lexicon
	Cause: creating our frame lexicon
	Effect: All the verb frame files in Ontonotes were used

CASE: 36
Stag: 161 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: At test time , this model chooses the best frame as argmax y u ' \ u2062 ' u ' \ ud835 ' u ' \ udf4d ' u ' \ u22c5 ' u ' \ ud835 ' u ' \ udc1f ' u ' \ u2062 ' -LRB- y , x , u ' \ u2113 ' -RRB- where argmax iterates over the possible frames y u ' \ u2208 ' F u ' \ u2113 ' if u ' \ u2113 ' was seen in the lexicon or the training data , or y u ' \ u2208 ' F , if it was unseen , like the disambiguation scheme of 3
	Cause: argmax y u ' \ u2062 ' u ' \ ud835 ' u ' \ udf4d ' u ' \ u22c5 ' u ' \ ud835 ' u ' \ udc1f ' u ' \ u2062 ' -LRB- y , x , u ' \ u2113 ' -RRB- where argmax iterates over the possible frames y u ' \ u2208 ' F u ' \ u2113 ' if u ' \ u2113 ' was seen in the lexicon or the training data , or y u ' \ u2208 ' F , if it
	Effect: At test time , this model chooses the best frame

CASE: 37
Stag: 161 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: argmax y u ' \ u2062 ' u ' \ ud835 ' u ' \ udf4d ' u ' \ u22c5 ' u ' \ ud835 ' u ' \ udc1f ' u ' \ u2062 ' -LRB- y , x , u ' \ u2113 ' -RRB- where argmax iterates over the possible frames y u ' \ u2208 ' F u ' \ u2113 ' if u ' \ u2113 ' was seen in the lexicon or the training data , or y u ' \ u2208 ' F , if it
	Cause: u ' \ u2113 ' was seen in the lexicon or the training data , or
	Effect: ' \ u2062 ' u ' \ ud835 ' u ' \ udf4d ' u ' \ u22c5 ' u ' \ ud835 ' u ' \ udc1f ' u ' \ u2062 ' -LRB- y , x , u ' \ u2113 ' -RRB- where argmax iterates over the possible frames y u ' \ u2208 ' F u ' \ u2113 '

CASE: 38
Stag: 162 
	Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
	sentTXT: We train this model by maximizing L 2 regularized log-likelihood , using L-BFGS ; the regularization constant was set to 0.1 in all experiments
	Cause: maximizing L 2 regularized log-likelihood , using L-BFGS
	Effect: ; the regularization constant was set to 0.1 in all experiments

CASE: 39
Stag: 165 166 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: The first one computes the direct dependents and dependency paths as described in 3.1 but conjoins them with the word identity rather than a word embedding Additionally , this model uses the un-conjoined words as backoff features
	Cause: described in 3.1 but conjoins them with the word identity rather than a word embedding Additionally , this model uses the un-conjoined words as backoff features
	Effect: The first one computes the direct dependents and dependency paths

CASE: 40
Stag: 166 167 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Additionally , this model uses the un-conjoined words as backoff features This would be a standard NLP approach for the frame identification problem , but is surprisingly competitive with the state of the art
	Cause: backoff features This would be a standard NLP approach for the frame identification problem , but is surprisingly competitive
	Effect: Additionally , this model uses the un-conjoined words

CASE: 41
Stag: 169 170 
	Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
	sentTXT: The second baseline , tries to decouple the Wsabie training from the embedding input , and trains a log linear model using the embeddings So the second baseline has the same input representation as Wsabie Embedding but uses a log-linear model instead of Wsabie
	Cause: The second baseline , tries to decouple the Wsabie training from the embedding input , and trains a log linear model using the embeddings
	Effect: the second baseline has the same input representation as Wsabie Embedding but uses a log-linear model instead of Wsabie

CASE: 42
Stag: 183 
	Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
	sentTXT: We search for the stochastic gradient learning rate in -LCB- 0.0001 , 0.001 , 0.01 -RCB- , the margin u ' \ u0393 ' u ' \ u2208 ' -LCB- 0.001 , 0.01 , 0.1 , 1 -RCB- and the dimensionality of the final vector space m u ' \ u2208 ' -LCB- 256 , 512 -RCB- , to maximize the frame identification accuracy of ambiguous lexical units ; by ambiguous , we imply lexical units that appear in the training data or the lexicon with more than one semantic frame
	Cause: We search for the stochastic gradient learning rate in -LCB- 0.0001 , 0.001 , 0.01 -RCB- , the margin u ' \ u0393 ' u ' \ u2208 ' -LCB- 0.001 , 0.01 , 0.1 , 1 -RCB- and the dimensionality of the final vector space m u ' \ u2208 ' -LCB- 256 , 512 -RCB- , to maximize the frame identification accuracy of ambiguous lexical units ; by ambiguous , we
	Effect: lexical units that appear in the training data or the lexicon with more than one semantic frame

CASE: 43
Stag: 185 186 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: Argument Candidates The candidate argument extraction method used for the FrameNet data , -LRB- as mentioned in 4 -RRB- was adapted from the algorithm of Xue and Palmer -LRB- 2004 -RRB- applied to dependency trees Since the original algorithm was designed for verbs , we added a few extra rules to handle non-verbal predicates we added 1 -RRB- the predicate itself as a candidate argument , 2 -RRB- the span ranging from the sentence position to the right of the predicate to the rightmost index of the subtree headed by the predicate u ' \ u2019 ' s head ; this helped capture cases like u ' \ u201c ' a few months u ' \ u201d ' -LRB- where few is the predicate and months is the argument -RRB- , and 3 -RRB- the span ranging from the leftmost index of the subtree headed by the predicate u ' \ u2019 ' s head to the position immediately before the predicate , for cases like u ' \ u201c ' your gift to Goodwill u ' \ u201d ' -LRB- where to is the predicate and your gift is the argument
	Cause: mentioned in 4 -RRB- was adapted from the algorithm of Xue and Palmer -LRB- 2004 -RRB- applied to dependency trees Since the original algorithm was designed for verbs , we added a few extra rules to handle non-verbal predicates we added 1 -RRB- the predicate itself as a candidate argument , 2 -RRB- the span ranging from the sentence position to the right of the predicate to the rightmost index of the subtree headed by the predicate u ' \ u2019 ' s head ; this helped capture cases like u ' \ u201c ' a few months u ' \ u201d ' -LRB- where few is the predicate and months is the argument -RRB- , and 3 -RRB- the span ranging from the leftmost index of the subtree headed by the predicate u ' \ u2019 '
	Effect: argument extraction method used for the FrameNet data , -LRB-

CASE: 44
Stag: 186 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the original algorithm was designed for verbs , we added a few extra rules to handle non-verbal predicates we added 1 -RRB- the predicate itself as a candidate argument , 2 -RRB- the span ranging from the sentence position to the right of the predicate to the rightmost index of the subtree headed by the predicate u ' \ u2019 ' s head ; this helped capture cases like u ' \ u201c ' a few months u ' \ u201d ' -LRB- where few is the predicate and months is the argument -RRB- , and 3 -RRB- the span ranging from the leftmost index of the subtree headed by the predicate u ' \ u2019 ' s head to the position immediately before the predicate , for cases like u ' \ u201c ' your gift to Goodwill u ' \ u201d ' -LRB- where to is the predicate and your gift is the argument
	Cause: the original algorithm was designed for verbs
	Effect: we added a few extra rules to handle non-verbal predicates we added 1 -RRB- the predicate itself as a candidate argument , 2 -RRB- the span ranging from the sentence position to the right of the predicate to the rightmost index of the subtree headed by the predicate u ' \ u2019 '

CASE: 45
Stag: 190 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We noted that this renders every lexical unit as seen ; in other words , at frame disambiguation time on our test set , for all instances , we only had to score the frames in F u ' \ u2113 ' for a predicate with lexical unit u ' \ u2113 ' -LRB- see 3 and 5.2
	Cause: seen ; in other words , at frame disambiguation time on our test set , for all instances , we only had to score the frames in F u ' \ u2113 ' for a predicate with lexical unit u ' \ u2113 '
	Effect: We noted that this renders every lexical unit

CASE: 46
Stag: 195 
	Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
	sentTXT: For fair comparison , we took the lexical units for the predicates that Das et al. considered as seen , and constructed a lexicon with only those ; training instances , if any , for the unseen predicates under Das et al u ' \ u2019 ' s setup were thrown out as well
	Cause: any , for the unseen predicates under Das et al u ' \ u2019 ' s setup
	Effect: For fair comparison , we took the lexical units for the predicates that Das et al. considered as seen , and constructed a lexicon with only those ; training instances ,

CASE: 47
Stag: 200 201 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 1 -RRB- each span could have only one role , 2 -RRB- each core role could be present only once , and 3 -RRB- all overt arguments had to be non-overlapping Hyperparameters As in 5.4 , we made a hyperparameter sweep in the same space
	Cause: in 5.4 , we made a hyperparameter sweep in the same space
	Effect: -RRB- all overt arguments had to be non-overlapping Hyperparameters

CASE: 48
Stag: 225 226 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: We see the same trend as in Table 4 Finally , Table 6 presents SRL results that measures argument performance only , irrespective of the frame ; we use the evaluation script from CoNLL 2005 -LSB- 5 -RSB-
	Cause: in Table 4 Finally , Table 6 presents SRL results that measures argument performance only , irrespective of the
	Effect: We see the same trend

CASE: 49
Stag: 229 230 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: 14 14 The last row of Table 6 refers to a system which used the combination of two syntactic parsers as input For FrameNet , the Wsabie Embedding model we propose strongly outperforms the baselines on all metrics , and sets a new state of the art
	Cause: input For FrameNet , the Wsabie Embedding model we propose strongly outperforms the baselines on all metrics , and sets a new state of the
	Effect: 14 14 The last row of Table 6 refers to a system which used the combination of two syntactic parsers

CASE: 50
Stag: 231 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: We believe that the Wsabie Embedding model performs better than the Log-Linear Embedding baseline -LRB- that uses the same input representation -RRB- because the former setting allows examples with different labels and confusion sets to share information ; this is due to the fact that all labels live in the same label space , and a single projection matrix is shared across the examples to map the input features to this space
	Cause: the former setting allows examples with different labels and confusion sets to share information ; this is due to the fact that all labels live in the same label space
	Effect: and a single projection matrix is shared across the examples to map the input features to this space

CASE: 51
Stag: 231 
	Pattern: 0 [['due', 'to', 'the', 'fact', 'that']]---- [['&R', '(,)'], ['&C']]
	sentTXT: the former setting allows examples with different labels and confusion sets to share information ; this is due to the fact that all labels live in the same label space
	Cause: all labels live in the same label space
	Effect: the former setting allows examples with different labels and confusion sets to share information ; this is

CASE: 52
Stag: 231 232 
	Pattern: 9 [['consequently']]---- [['&C', '(,/;/./--)'], ['(,)', '&R']]
	sentTXT: We believe that the Wsabie Embedding model performs better than the Log-Linear Embedding baseline -LRB- that uses the same input representation -RRB- because the former setting allows examples with different labels and confusion sets to share information ; this is due to the fact that all labels live in the same label space , and a single projection matrix is shared across the examples to map the input features to this space Consequently , the Wsabie Embedding model can share more information between different examples in the training data than the Log-Linear Embedding model
	Cause: We believe that the Wsabie Embedding model performs better than the Log-Linear Embedding baseline -LRB- that uses the same input representation -RRB- because the former setting allows examples with different labels and confusion sets to share information ; this is due to the fact that all labels live in the same label space , and a single projection matrix is shared across the examples to map the input features to this space
	Effect: the Wsabie Embedding model can share more information between different examples in the training data than the Log-Linear Embedding model

CASE: 53
Stag: 233 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: Since the Log-Linear Words model always performs better than the Log-Linear Embedding model , we conclude that the primary benefit does not come from the input embedding representation
	Cause: the Log-Linear Words model always performs better than the Log-Linear Embedding model
	Effect: we conclude that the primary benefit does not come from the input embedding representation

CASE: 54
Stag: 235 236 
	Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
	sentTXT: On the PropBankdata , we see that the Log-Linear Words baseline has roughly the same performance as our model on most metrics slightly better on the test data and slightly worse on the development data This can be partially explained with the significantly larger training set size for PropBank , making features based on words more useful
	Cause: our model on most metrics slightly better on the test data and slightly worse on the development data This can be partially explained with the significantly larger training set size for PropBank , making features based on words more
	Effect: On the PropBankdata , we see that the Log-Linear Words baseline has roughly the same performance

CASE: 55
Stag: 236 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: This can be partially explained with the significantly larger training set size for PropBank , making features based on words more useful
	Cause: words more useful
	Effect: This can be partially explained with the significantly larger training set size for PropBank , making features

CASE: 56
Stag: 242 
	Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
	sentTXT: In other words , it must estimate 512 parameters based on at most 10 training examples
	Cause: at most 10 training examples
	Effect: In other words , it must estimate 512 parameters

CASE: 57
Stag: 243 
	Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
	sentTXT: However , since the input representation is shared across all frames , every other training example from all the lexical units affects the optimal estimate , since they all modify the joint parameter matrix M
	Cause: the input representation is shared across all frames
	Effect: every other training example from all the lexical units affects the optimal estimate , since they all modify the joint parameter matrix M

CASE: 58
Stag: 243 
	Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
	sentTXT: every other training example from all the lexical units affects the optimal estimate , since they all modify the joint parameter matrix M
	Cause: they all modify the joint parameter matrix M
	Effect: every other training example from all the lexical units affects the optimal estimate

CASE: 59
Stag: 247 
	Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
	sentTXT: For FrameNet , estimating the label embedding is not as much of a problem because even if a lexical unit is rare , the potential frames can be frequent
	Cause: even if a lexical unit is rare
	Effect: the potential frames can be frequent

CASE: 60
Stag: 259 
	Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
	sentTXT: 2014 -RRB- , our model does not rely on heuristics to construct a similarity graph and leverage WordNet ; hence , in principle it is generalizable to varying domains , and to other languages
	Cause: 2014 -RRB- , our model does not rely on heuristics to construct a similarity graph and leverage WordNet
	Effect: in principle it is generalizable to varying domains , and to other languages

