Current File: P14-2098.xhtml_2 P14-2098.xhtml

Section 0:  Abstract
	SentNum: 3
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

Section 1:  1 Introduction
	SentNum: 20
	CENum: 6
	SentCovered: 6
	Covered_Rate: 30.0000%

Section 2:  2 Correction Detection
	SentNum: 31
	CENum: 8
	SentCovered: 11
	Covered_Rate: 35.4839%

Section 3:  3 A Classifier for Merging Basic-Edits
	SentNum: 18
	CENum: 4
	SentCovered: 5
	Covered_Rate: 27.7778%

Section 4:  4 Experimental Setup
	SentNum: 22
	CENum: 2
	SentCovered: 3
	Covered_Rate: 13.6364%

Section 5:  5 Experiments
	SentNum: 23
	CENum: 5
	SentCovered: 6
	Covered_Rate: 26.0870%

Section 6:  6 Conclusions
	SentNum: 7
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

Section 7:  Acknowledgements
	SentNum: 3
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-2098.xhtml_2's CE cases

Section 0:  Abstract has 0 CE cases
Section 1:  1 Introduction has 6 CE cases
	CASE: 1
	Stag: 5 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: Because this is time consuming, tutors often just rewrite the sentences without giving any explanations [ 5 ]. 
		Cause: [(0, 1), (0, 4)]
		Effect: [(0, 6), (0, 18)]

	CASE: 2
	Stag: 6 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: Due to the effort involved in comparing revisions with the original texts, students often fail to learn from these revisions [ 16 ]. 
		Cause: [(0, 2), (0, 11)]
		Effect: [(0, 13), (0, 23)]

	CASE: 3
	Stag: 7 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: Computer aided language learning tools offer a solution for providing more detailed feedback. 
		Cause: [(0, 9), (0, 12)]
		Effect: [(0, 0), (0, 7)]

	CASE: 4
	Stag: 15 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Furthermore, it is not clear if the heuristics will work as well for tutors trained to mark up revisions under different guidelines. 
		Cause: [(0, 7), (0, 22)]
		Effect: [(0, 0), (0, 5)]

	CASE: 5
	Stag: 16 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We propose to improve upon the correction detection component by training a classifier that determines which edits in a revised sentence address the same error in the original sentence. 
		Cause: [(0, 10), (0, 28)]
		Effect: [(0, 0), (0, 8)]

	CASE: 6
	Stag: 18 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: Because the classifier were trained on revisions where corrections are explicitly marked by English experts, it is also possible to build systems adjusted to different annotation standards. 
		Cause: [(0, 1), (0, 14)]
		Effect: [(0, 16), (0, 27)]

Section 2:  2 Correction Detection has 8 CE cases
	CASE: 1
	Stag: 23 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Comparing a student-written sentence with its revision, we observe that each correction can be decomposed into a set of more basic edits such as word insertions, word deletions and word substitutions. 
		Cause: [(0, 0), (0, 6)]
		Effect: [(0, 8), (0, 32)]

	CASE: 2
	Stag: 24 25 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: In the example shown in Figure 1 , the correction u'\u201c' to change u'\u21d2' changing u'\u201d' is composed of a deletion of to and a substitution from change to changing ; the correction u'\u201c' moment u'\u21d2' minute u'\u201d' is itself a single word substitution. Thus, we can build systems to detect corrections which operates in two steps. 
		Cause: [(0, 0), (0, 67)]
		Effect: [(1, 1), (1, 13)]

	CASE: 3
	Stag: 28 
		Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
		sentTXT: In practice, however, this two-step approach may result in mis-detections due to ambiguities. 
		Cause: [(0, 14), (0, 14)]
		Effect: [(0, 0), (0, 11)]

	CASE: 4
	Stag: 31 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: Because the Levenshtein algorithm only tries to minimize the number of edits, it does not care whether the edits make any linguistic sense. 
		Cause: [(0, 1), (0, 11)]
		Effect: [(0, 13), (0, 23)]

	CASE: 5
	Stag: 37 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since mis-detected corrections cannot be analyzed down the pipeline, the correction detection component became the bottle-neck of their overall system. 
		Cause: [(0, 1), (0, 9)]
		Effect: [(0, 11), (0, 21)]

	CASE: 6
	Stag: 43 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If the resulting basic edits do not match with those that compose the actual corrections, we attribute the error to the first step. 
		Cause: [(0, 1), (0, 14)]
		Effect: [(0, 16), (0, 23)]

	CASE: 7
	Stag: 45 46 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: Our analysis confirms that the merging step is the bottleneck in the current correction detection system u'\u2013' it accounts for 75% of the mis-detections. Therefore, to effectively reduce the algorithm u'\u2019' s mis-detection errors, we propose to build a classifier to merge with better accuracies. 
		Cause: [(0, 0), (0, 28)]
		Effect: [(1, 2), (1, 26)]

	CASE: 8
	Stag: 52 53 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: A bigger concern is to guarantee the extracted phrase pairs are indeed translations or paraphrases. Recent work therefore focuses on identifying the alignment/edits between two sentences [ 13 , 8 ]. 
		Cause: [(0, 1), (1, 1)]
		Effect: [(1, 3), (1, 15)]

Section 3:  3 A Classifier for Merging Basic-Edits has 4 CE cases
	CASE: 1
	Stag: 57 58 
		Pattern: 8 [['because']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&ADV)'], ['&C']]
		sentTXT: For example, in Figure 11 , when the insertion of one word is followed by the deletion of the same word, the insertion and deletion are likely addressing one single error. This is because these two edits would combine together as a word-order change. 
		Cause: [(1, 3), (1, 12)]
		Effect: [(0, 0), (0, 32)]

	CASE: 2
	Stag: 59 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: On the other hand, in Figure 11 , if one edit includes a substitution between words with the same POS u'\u2019' s, then it is likely fixing a word choice error by itself. 
		Cause: [(0, 10), (0, 26)]
		Effect: [(0, 28), (0, 38)]

	CASE: 3
	Stag: 61 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: To predict whether two basic-edits address the same writing problem more discriminatively, we train a Maximum Entropy binary classifier based on features extracted from relevant contexts for the basic edits. 
		Cause: [(0, 22), (0, 30)]
		Effect: [(0, 0), (0, 19)]

	CASE: 4
	Stag: 70 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: We then create a training instance for each pair of two consecutive basic edits if two consecutive basic edits need to be merged, we will mark the outcome as True , otherwise it is False. 
		Cause: [(0, 15), (0, 22)]
		Effect: [(0, 24), (0, 35)]

Section 4:  4 Experimental Setup has 2 CE cases
	CASE: 1
	Stag: 76 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We simulate the revisions by applying corrections onto the original sentence. 
		Cause: [(0, 5), (0, 10)]
		Effect: [(0, 0), (0, 3)]

	CASE: 2
	Stag: 77 78 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The teachers u'\u2019' annotations are treated as gold standard for the detailed corrections. We considered four corpora with different ESL populations and annotation standards, including FCE corpus [ 17 ] , NUCLE corpus [ 2 ] , UIUC corpus 2 2 UIUC corpus contains annotations of essays collected from ICLE [ 6 ] and CLEC [ 7 ]. 
		Cause: [(0, 11), (1, 44)]
		Effect: [(0, 0), (0, 9)]

Section 5:  5 Experiments has 5 CE cases
	CASE: 1
	Stag: 102 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: First, Table 4 shows that by incorporating correction patterns into the merging algorithm, the errors in correction detection step were reduced. 
		Cause: [(0, 7), (0, 13)]
		Effect: [(0, 14), (0, 22)]

	CASE: 2
	Stag: 102 103 
		Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
		sentTXT: First, Table 4 shows that by incorporating correction patterns into the merging algorithm, the errors in correction detection step were reduced. This led to a significant improvement on the overall system u'\u2019' s F 1 -score on all corpora. 
		Cause: [(0, 0), (0, 22)]
		Effect: [(1, 3), (1, 17)]

	CASE: 3
	Stag: 110 111 
		Pattern: 8 [['because']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&ADV)'], ['&C']]
		sentTXT: The models built on corpora can generally improve the correction detection accuracy 5 5 We currently do not evaluate the end-to-end system over different corpora. This is because different corpora employ different error type categorization standards. 
		Cause: [(1, 3), (1, 10)]
		Effect: [(0, 0), (0, 24)]

	CASE: 4
	Stag: 113 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Also, as suggested by the experimental result, among the four corpora, FCE corpus is a comparably good resource for training correction detection models with our current feature set. 
		Cause: [(0, 0), (0, 4)]
		Effect: [(0, 17), (0, 30)]

	CASE: 5
	Stag: 113 114 
		Pattern: 1 [['reason'], [['that', 'because']]]---- [['&R', '(,/./;/--)', '&ONE', '(&ADJ)'], ['(for &THIS (&NP))', '&BE'], ['&C']]
		sentTXT: Also, as suggested by the experimental result, among the four corpora, FCE corpus is a comparably good resource for training correction detection models with our current feature set. One reason is that FCE corpus has many more training instances, which benefits model training. 
		Cause: [(1, 4), (1, 15)]
		Effect: [(0, 0), (0, 30)]

Section 6:  6 Conclusions has 0 CE cases
Section 7:  Acknowledgements has 0 CE cases
#-------------------------------------------------

