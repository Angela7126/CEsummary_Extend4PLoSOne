Current File: P14-2127.xhtml_2 P14-2127.xhtml

Section 0:  Abstract
	SentNum: 7
	CENum: 5
	SentCovered: 4
	Covered_Rate: 57.1429%

Section 1:  1 Introduction
	SentNum: 43
	CENum: 5
	SentCovered: 6
	Covered_Rate: 13.9535%

Section 2:  2 Review: Syntax-based MT Decoding
	SentNum: 11
	CENum: 3
	SentCovered: 6
	Covered_Rate: 54.5455%

Section 3:  3 Violation-Fixing Perceptron for Hiero
	SentNum: 36
	CENum: 9
	SentCovered: 9
	Covered_Rate: 25.0000%

Section 4:  4 Experiments
	SentNum: 46
	CENum: 11
	SentCovered: 15
	Covered_Rate: 32.6087%

Section 5:  5 Conclusions
	SentNum: 2
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

Section 6:  Acknowledgment
	SentNum: 4
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-2127.xhtml_2's CE cases

Section 0:  Abstract has 5 CE cases
	CASE: 1
	Stag: 0 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: Large-scale discriminative training has become promising for statistical machine translation by leveraging the huge training corpus; for example the recent effort in phrase-based MT [ 21 ] significantly outperforms mainstream methods that only train on small tuning sets. 
		Cause: [(0, 11), (0, 15)]
		Effect: [(0, 16), (0, 38)]

	CASE: 2
	Stag: 1 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: However, phrase-based MT suffers from limited reorderings, and thus its training can only utilize a small portion of the bitext due to the distortion limit. 
		Cause: [(0, 0), (0, 7)]
		Effect: [(0, 11), (0, 26)]

	CASE: 3
	Stag: 1 
		Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
		sentTXT: However, phrase-based MT suffers from limited reorderings, and thus its training can only utilize a small portion of the bitext due to the distortion limit. 
		Cause: [(0, 13), (0, 15)]
		Effect: [(0, 0), (0, 10)]

	CASE: 4
	Stag: 2 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: To address this problem, we extend \newcite yu+:2013 to syntax-based MT by generalizing their latent variable u'\u201c' violation-fixing u'\u201d' perceptron from graphs to hypergraphs. 
		Cause: [(0, 15), (0, 34)]
		Effect: [(0, 0), (0, 13)]

	CASE: 5
	Stag: 3 
		Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Experiments confirm that our method leads to up to +1.2 Bleu improvement over mainstream methods such as Mert and Pro. 
		Cause: [(0, 3), (0, 4)]
		Effect: [(0, 7), (0, 19)]

Section 1:  1 Introduction has 5 CE cases
	CASE: 1
	Stag: 9 10 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: What makes large-scale MT training so hard then. After numerous attempts by various researchers [ 17 , 20 , 1 , 2 , 5 , 9 , 10 ] , the recent work of \newcite yu+:2013 finally reveals a major reason it is the vast amount of (inevitable) search errors in MT decoding that astray learning. 
		Cause: [(0, 0), (0, 4)]
		Effect: [(0, 6), (1, 50)]

	CASE: 2
	Stag: 10 
		Pattern: 1 [['reason'], [['that', 'because']]]---- [['&R', '(,/./;/--)', '&ONE', '(&ADJ)'], ['(for &THIS (&NP))', '&BE'], ['&C']]
		sentTXT: After numerous attempts by various researchers [ 17 , 20 , 1 , 2 , 5 , 9 , 10 ] , the recent work of \newcite yu+:2013 finally reveals a major reason it is the vast amount of (inevitable) search errors in MT decoding that astray learning. 
		Cause: [(0, 50), (0, 51)]
		Effect: [(0, 0), (0, 31)]

	CASE: 3
	Stag: 12 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: However, the underlying phrase-based model suffers from limited distortion and thus can only employ a small portion (about 1/3 in their Ch-En experiments) of the bitext in training. 
		Cause: [(0, 0), (0, 9)]
		Effect: [(0, 12), (0, 30)]

	CASE: 4
	Stag: 46 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We generalize the latent variable violation-fixing perceptron framework to inexact search over hypergraphs, which subsumes previous algorithms for PBMT and bottom-up parsing as special cases (see Fig. 
		Cause: [(0, 24), (0, 28)]
		Effect: [(0, 0), (0, 22)]

	CASE: 5
	Stag: 49 50 
		Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
		sentTXT: Experiments show that our training algorithm outperforms mainstream tuning methods (which optimize on small devsets) by +1.2 Bleu over Mert and Pro on FBIS. For clarity reasons we will describe Hiero decoding as a two-pass process, first without a language model, and then integrating the LM. 
		Cause: [(0, 0), (0, 25)]
		Effect: [(1, 3), (1, 23)]

Section 2:  2 Review: Syntax-based MT Decoding has 3 CE cases
	CASE: 1
	Stag: 54 55 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: To incorporate the language model, each node also needs to remember its target side boundary words. Thus a - u'\u2062' LM node N [ i j ] is split into multiple + u'\u2062' LM nodes of signature N [ i j ] a u'\u22c6' b , where a and b are the boundary words. 
		Cause: [(0, 0), (0, 16)]
		Effect: [(1, 1), (1, 48)]

	CASE: 2
	Stag: 58 59 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: More formally, the whole decoding process can be cast as a deductive system. Take the partial translation of u'\u201c' held talks with Sharon u'\u201d' in Figure 2 (b) for example, the deduction is. 
		Cause: [(0, 11), (1, 27)]
		Effect: [(0, 0), (0, 9)]

	CASE: 3
	Stag: 60 61 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: where s u'\u2062' ( r 5 ) is the score of rule r 5 , and the LM combo score u'\u039b' is log P lm ( talks u'\u2223' held ) P lm ( with u'\u2223' talks ) P lm ( Sharon u'\u2223' with ). As mentioned in Section 1, the key to the success of \newcite yu+:2013 is the adoption of violation-fixing perceptron of \newcite huang+:2012 which is tailored for vastly inexact search. 
		Cause: [(1, 1), (1, 24)]
		Effect: [(0, 2), (0, 63)]

Section 3:  3 Violation-Fixing Perceptron for Hiero has 9 CE cases
	CASE: 1
	Stag: 64 65 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: On the other hand, \newcite zhang+:2013 has generalized \newcite huang+:2012 from graphs to hypergraphs for bottom-up parsing, which resembles Hiero decoding. So we just need to combine the two generalizing directions (latent variable and hypergraph, see Fig. 
		Cause: [(0, 0), (0, 26)]
		Effect: [(1, 1), (1, 17)]

	CASE: 2
	Stag: 71 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: We say D u'\u2208' H u'\u2062' ( x ) if D is a full derivation of decoding x , and D can be derived from the hypergraph. 
		Cause: [(0, 18), (0, 27)]
		Effect: [(0, 0), (0, 16)]

	CASE: 3
	Stag: 75 76 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We further denote the real decoding hypergraph with beam-pruning and cube-pruning as H u'\u2032' u'\u2062' ( x. The set of y -bad derivations is defined as. 
		Cause: [(0, 12), (1, 8)]
		Effect: [(0, 0), (0, 10)]

	CASE: 4
	Stag: 78 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The max-violation method performs the update where the model score difference between the incorrect Viterbi partial derivation and the best y -good partial derivation is maximal, by penalizing the incorrect Viterbi partial derivation and rewarding the y -good partial derivation. 
		Cause: [(0, 29), (0, 42)]
		Effect: [(0, 0), (0, 27)]

	CASE: 5
	Stag: 86 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Such derivations can be generated in way similar to \newcite yu+:2013 by using a language model tailored for forced decoding. 
		Cause: [(0, 14), (0, 21)]
		Effect: [(0, 0), (0, 12)]

	CASE: 6
	Stag: 89 
		Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
		sentTXT: If a boundary word does not occur in the reference, its index is set to u'\u221e' so that its language model score will always be - u'\u221e' ; if a boundary word occurs more than once in the reference, its - u'\u2062' LM node is split into multiple + u'\u2062' LM nodes, one for each such index. 
		Cause: [(0, 0), (0, 20)]
		Effect: [(0, 23), (0, 74)]

	CASE: 7
	Stag: 89 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If a boundary word does not occur in the reference, its index is set to u'\u221e' so that its language model score will always be - u'\u221e' ; if a boundary word occurs more than once in the reference, its - u'\u2062' LM node is split into multiple + u'\u2062' LM nodes, one for each such index. 
		Cause: [(0, 1), (0, 9)]
		Effect: [(0, 11), (0, 20)]

	CASE: 8
	Stag: 89 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: If a boundary word does not occur in the reference, its index is set to u'\u221e' so that its language model score will always be - u'\u221e' ; if a boundary word occurs more than once in the reference, its - u'\u2062' LM node is split into multiple + u'\u2062' LM nodes, one for each such index. 
		Cause: [(0, 15), (0, 51)]
		Effect: [(0, 1), (0, 13)]

	CASE: 9
	Stag: 90 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: 2 2 Our formulation of index-based language model fixes a bug in the word-based LM of \newcite yu+:2013 when a substring appears more than once in the reference (e.g.,Â  u'\u201c' the man u'\u2026' the man u'\u2026' u'\u201d' ); thanks to Dan Gildea for pointing it out. 
		Cause: [(0, 64), (0, 66)]
		Effect: [(0, 20), (0, 62)]

Section 4:  4 Experiments has 11 CE cases
	CASE: 1
	Stag: 97 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Following \newcite yu+:2013, we call our max-violation method MaxForce. 
		Cause: [(0, 0), (0, 4)]
		Effect: [(0, 6), (0, 11)]

	CASE: 2
	Stag: 103 104 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: We find that even simple Word-Edges features boost the performance significantly, and adding complex Word-Edges features from \newcite yu+:2013 brings limited improvement and slows down the decoding. So in the following experiments we only use Word-Edges features consisting of combinations of English and Chinese words, and Chinese characters, and do not use word clusters nor word types. 
		Cause: [(0, 0), (0, 29)]
		Effect: [(1, 1), (1, 30)]

	CASE: 3
	Stag: 104 105 
		Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
		sentTXT: So in the following experiments we only use Word-Edges features consisting of combinations of English and Chinese words, and Chinese characters, and do not use word clusters nor word types. For simplicity and efficiency reasons, we also exclude all non-local features. 
		Cause: [(0, 5), (0, 31)]
		Effect: [(1, 6), (1, 11)]

	CASE: 4
	Stag: 107 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: IWSLT04 is used as development set in MaxForce training, and as tuning set for n -best Mert , Hypergraph Mert , and Pro. 
		Cause: [(0, 4), (0, 7)]
		Effect: [(0, 0), (0, 2)]

	CASE: 5
	Stag: 108 109 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: IWSLT05 is used as test set. Both IWSLT04 and IWSLT05 contain 16 references.We mainly use this corpus to investigate the properties of MaxForce. 
		Cause: [(0, 4), (1, 15)]
		Effect: [(0, 0), (0, 2)]

	CASE: 6
	Stag: 111 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: NIST06 newswire is used as development set for MaxForce training, and as tuning set for all other tuning methods. 
		Cause: [(0, 5), (0, 8)]
		Effect: [(0, 0), (0, 3)]

	CASE: 7
	Stag: 112 113 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: NIST08 newswire is used as test set. Both NIST06 newswire and NIST08 newswire contain 4 references. 
		Cause: [(0, 5), (1, 7)]
		Effect: [(0, 0), (0, 3)]

	CASE: 8
	Stag: 122 123 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: However, in the following experiments, due to efficiency considerations, we use the u'\u201c' tight u'\u201d' rule extraction in cdec that is more strict than the standard u'\u201c' loose u'\u201d' rule extraction, which generates a reduced rule set and, thus, a reduced reachability. We show the reachability distributions of both tight and loose rule extraction in Figure 4. 
		Cause: [(0, 0), (0, 57)]
		Effect: [(0, 60), (1, 13)]

	CASE: 9
	Stag: 125 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The max-violation method is more than 15 Bleu points better than the standard perceptron (also known as u'\u201c' bold-update u'\u201d' in \newcite liang+:2006) which updates at the root of the derivation tree. 
		Cause: [(0, 18), (0, 43)]
		Effect: [(0, 0), (0, 16)]

	CASE: 10
	Stag: 126 
		Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
		sentTXT: 3 3 We find that while MaxForce generates translations of length ratio close to 1 during training, the length ratios on dev/test sets are significantly lower, due to OOVs. 
		Cause: [(0, 30), (0, 30)]
		Effect: [(0, 0), (0, 27)]

	CASE: 11
	Stag: 126 127 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: 3 3 We find that while MaxForce generates translations of length ratio close to 1 during training, the length ratios on dev/test sets are significantly lower, due to OOVs. So we run a binary search for the length penalty weight after each training iteration to tune the length ratio to u'\u223c' 0.97 on dev set. 
		Cause: [(0, 0), (0, 30)]
		Effect: [(1, 1), (1, 29)]

Section 5:  5 Conclusions has 0 CE cases
Section 6:  Acknowledgment has 0 CE cases
#-------------------------------------------------

