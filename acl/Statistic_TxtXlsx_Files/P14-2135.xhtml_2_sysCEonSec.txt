Current File: P14-2135.xhtml_2 P14-2135.xhtml

Section 0:  Abstract
	SentNum: 4
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

Section 1:  1 Introduction
	SentNum: 16
	CENum: 4
	SentCovered: 4
	Covered_Rate: 25.0000%

Section 2:  2 Experimental Approach
	SentNum: 37
	CENum: 12
	SentCovered: 13
	Covered_Rate: 35.1351%

Section 3:  3 Improving Multi-Modal Representations
	SentNum: 10
	CENum: 4
	SentCovered: 6
	Covered_Rate: 60.0000%

Section 4:  4 Concreteness and Image Dispersion
	SentNum: 31
	CENum: 15
	SentCovered: 16
	Covered_Rate: 51.6129%

Section 5:  5 Conclusions
	SentNum: 9
	CENum: 3
	SentCovered: 3
	Covered_Rate: 33.3333%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-2135.xhtml_2's CE cases

Section 0:  Abstract has 0 CE cases
Section 1:  1 Introduction has 4 CE cases
	CASE: 1
	Stag: 13 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since perceptual data sources typically contain information about both abstract and concrete concepts, such information is included for both concept types. 
		Cause: [(0, 1), (0, 12)]
		Effect: [(0, 14), (0, 21)]

	CASE: 2
	Stag: 14 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: The potential effect of this design decision on performance is significant because the vast majority of meaning-bearing words in everyday language correspond to abstract concepts. 
		Cause: [(0, 12), (0, 24)]
		Effect: [(0, 0), (0, 10)]

	CASE: 3
	Stag: 16 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: In light of these considerations, we propose a novel algorithm for approximating conceptual concreteness. 
		Cause: [(0, 12), (0, 14)]
		Effect: [(0, 0), (0, 10)]

	CASE: 4
	Stag: 17 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: Multi-modal models in which perceptual input is filtered according to our algorithm learn higher-quality semantic representations than previous approaches, resulting in a significant performance improvement of up to 17% in capturing the semantic similarity of concepts. 
		Cause: [(0, 10), (0, 11)]
		Effect: [(0, 20), (0, 37)]

Section 2:  2 Experimental Approach has 12 CE cases
	CASE: 1
	Stag: 22 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: They are also more scalable since high-quality tagged images are freely available in several web-scale image datasets. 
		Cause: [(0, 6), (0, 16)]
		Effect: [(0, 0), (0, 4)]

	CASE: 2
	Stag: 23 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We use Google Images as our image source, and extract the first n image results for each concept word. 
		Cause: [(0, 5), (0, 16)]
		Effect: [(0, 0), (0, 3)]

	CASE: 3
	Stag: 29 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: By exploiting this connection, the method approximates the concreteness of concepts, and provides a basis to filter the corresponding perceptual information. 
		Cause: [(0, 1), (0, 3)]
		Effect: [(0, 4), (0, 22)]

	CASE: 4
	Stag: 30 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Formally, we propose a measure, image dispersion d of a concept word w , defined as the average pairwise cosine distance between all the image representations { w 1 u'\u2192' u'\u2062' u'\u2026' u'\u2062' w n u'\u2192' } in the set of images for that concept. 
		Cause: [(0, 18), (0, 57)]
		Effect: [(0, 0), (0, 16)]

	CASE: 5
	Stag: 31 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: We use an average pairwise distance-based metric because this emphasizes the total variation more than e.g., the mean distance from the centroid. 
		Cause: [(0, 8), (0, 22)]
		Effect: [(0, 0), (0, 6)]

	CASE: 6
	Stag: 35 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: Previous NLP-related work uses SIFT [ 11 , 6 ] or SURF [ 22 ] descriptors for identifying points of interest in an image, quantified by 128-dimensional local descriptors. 
		Cause: [(0, 17), (0, 29)]
		Effect: [(0, 0), (0, 15)]

	CASE: 7
	Stag: 36 37 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: We apply Pyramid Histogram Of visual Words (PHOW) descriptors, which are particularly well-suited for object categorization, a key component of image similarity and thus dispersion [ 5 ]. PHOW is roughly equivalent to running SIFT on a dense grid of locations at a fixed scale and orientation and at multiple scales (see Fig 2), but is both more efficient and more accurate than regular (dense) SIFT approaches [ 5 ]. 
		Cause: [(0, 0), (0, 25)]
		Effect: [(0, 28), (1, 45)]

	CASE: 8
	Stag: 42 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: This model learns high quality lexical semantic representations based on the distributional properties of words in text, and has been shown to outperform simple distributional models on applications such as semantic composition and analogical mapping [ 19 ]. 
		Cause: [(0, 10), (0, 16)]
		Effect: [(0, 18), (0, 38)]

	CASE: 9
	Stag: 43 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: We evaluate models by measuring the Spearman correlation of model output with two well-known gold-standards reflecting semantic proximity u'\u2013' a standard measure for evaluating the quality of representations (see e.g., Agirre et al. 
		Cause: [(0, 27), (0, 38)]
		Effect: [(0, 0), (0, 25)]

	CASE: 10
	Stag: 46 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: WordSim has been used as a benchmark for distributional semantic models in numerous studies (see e.g., [ 15 , 6 ]. 
		Cause: [(0, 5), (0, 15)]
		Effect: [(0, 0), (0, 3)]

	CASE: 11
	Stag: 46 47 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: WordSim has been used as a benchmark for distributional semantic models in numerous studies (see e.g., [ 15 , 6 ]. As a complementary gold-standard, we use the University of South Florida Norms (USF) [ 20 ]. 
		Cause: [(1, 1), (1, 18)]
		Effect: [(0, 0), (0, 22)]

	CASE: 12
	Stag: 50 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: The USF evaluation set is particularly appropriate in the present context because concepts in the dataset are also rated for conceptual concreteness by at least 10 human annotators. 
		Cause: [(0, 12), (0, 27)]
		Effect: [(0, 0), (0, 10)]

Section 3:  3 Improving Multi-Modal Representations has 4 CE cases
	CASE: 1
	Stag: 57 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: We apply image dispersion-based filtering as follows if both concepts in an evaluation pair have an image dispersion below a given threshold, both the linguistic and the visual representations are included. 
		Cause: [(0, 8), (0, 21)]
		Effect: [(0, 23), (0, 31)]

	CASE: 2
	Stag: 59 60 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: For both datasets, we set the threshold as the median image dispersion, although performance could in principle be improved by adjusting this parameter. We compare dispersion filtered representations with linguistic, perceptual and standard multi-modal representations (concatenated linguistic and perceptual representations. 
		Cause: [(0, 9), (1, 14)]
		Effect: [(0, 0), (0, 7)]

	CASE: 3
	Stag: 61 62 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Similarity between concept pairs is calculated using cosine similarity. As Figure 3 shows, dispersion-filtered multi-modal representations significantly outperform standard multi-modal representations on both evaluation datasets. 
		Cause: [(1, 1), (1, 13)]
		Effect: [(0, 0), (0, 8)]

	CASE: 4
	Stag: 64 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Based on the correlation comparison method of Steiger ( 1980 ) , both represent significant improvements (WordSim353, t = 2.42 , p 0.05 ; USF, t = 1.86 , p 0.1. 
		Cause: [(0, 2), (0, 10)]
		Effect: [(0, 12), (0, 33)]

Section 4:  4 Concreteness and Image Dispersion has 15 CE cases
	CASE: 1
	Stag: 67 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: The filtering approach described thus far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts. 
		Cause: [(0, 0), (0, 3)]
		Effect: [(0, 5), (0, 22)]

	CASE: 2
	Stag: 67 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: The filtering approach described thus far improves multi-modal representations because image dispersion provides a means to distinguish concrete concepts from more abstract concepts. 
		Cause: [(0, 5), (0, 17)]
		Effect: [(0, 0), (0, 3)]

	CASE: 3
	Stag: 68 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since research has demonstrated the applicability of concreteness to a range of other NLP tasks [ 28 , 16 ] , it is important to examine the connection between image dispersion and concreteness in more detail. 
		Cause: [(0, 1), (0, 16)]
		Effect: [(0, 18), (0, 35)]

	CASE: 4
	Stag: 68 69 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Since research has demonstrated the applicability of concreteness to a range of other NLP tasks [ 28 , 16 ] , it is important to examine the connection between image dispersion and concreteness in more detail. To evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A u'\u222a' C introduced in Section 2. 
		Cause: [(1, 8), (1, 41)]
		Effect: [(0, 0), (1, 6)]

	CASE: 5
	Stag: 73 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: According to the Dual Coding Theory, however, concrete concepts are precisely those with a salient perceptual representation. 
		Cause: [(0, 2), (0, 5)]
		Effect: [(0, 7), (0, 18)]

	CASE: 6
	Stag: 73 74 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: According to the Dual Coding Theory, however, concrete concepts are precisely those with a salient perceptual representation. As illustrated in Figure 4 , our binary classification conforms to this characterization. 
		Cause: [(1, 1), (1, 10)]
		Effect: [(0, 0), (0, 18)]

	CASE: 7
	Stag: 75 76 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The importance of the visual modality is significantly greater when evaluating on pairs for which both concepts are classified as concrete than on pairs of two abstract concepts. Image dispersion is also an effective predictor of concreteness on samples for which the abstract/concrete distinction is less clear. 
		Cause: [(0, 20), (1, 17)]
		Effect: [(0, 0), (0, 18)]

	CASE: 8
	Stag: 78 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: On this more diverse sample, which reflects the range of concepts typically found in linguistic corpora, image dispersion is a particularly useful diagnostic for identifying the very abstract or very concrete concepts. 
		Cause: [(0, 26), (0, 33)]
		Effect: [(0, 0), (0, 24)]

	CASE: 9
	Stag: 78 79 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: On this more diverse sample, which reflects the range of concepts typically found in linguistic corpora, image dispersion is a particularly useful diagnostic for identifying the very abstract or very concrete concepts. As Table 1 illustrates, the concepts with the lowest dispersion in this sample are, without exception, highly concrete, and the concepts of highest dispersion are clearly very abstract. 
		Cause: [(1, 1), (1, 27)]
		Effect: [(0, 0), (0, 33)]

	CASE: 10
	Stag: 81 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Kwong ( 2008 ) proposes a method based on the presence of hard-coded phrasal features in dictionary entries corresponding to each concept. 
		Cause: [(0, 0), (0, 0)]
		Effect: [(0, 1), (0, 6)]

	CASE: 11
	Stag: 83 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: 2011 ) present an approach based on the position of word senses corresponding to each concept in the WordNet ontology [ 10 ]. 
		Cause: [(0, 7), (0, 22)]
		Effect: [(0, 0), (0, 4)]

	CASE: 12
	Stag: 86 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: The Turney et al algorithm quantifies the concreteness of concepts that lack such a rating based on their proximity to rated concepts in a semantic vector space. 
		Cause: [(0, 17), (0, 26)]
		Effect: [(0, 0), (0, 14)]

	CASE: 13
	Stag: 88 89 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: It is therefore more scalable, and instantly applicable to a wide range of languages. Finally, we explored whether image dispersion can be applied to specific NLP tasks as an effective proxy for concreteness. 
		Cause: [(0, 0), (0, 1)]
		Effect: [(0, 3), (1, 18)]

	CASE: 14
	Stag: 91 92 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: 2011 ) showed that concreteness is applicable to the classification of adjective-noun modification as either literal or non-literal. By applying a logistic regression with noun concreteness as the predictor variable, Turney et al achieved a classification accuracy of 79% on this task. 
		Cause: [(0, 14), (1, 24)]
		Effect: [(0, 1), (0, 12)]

	CASE: 15
	Stag: 91 92 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: 2011 ) showed that concreteness is applicable to the classification of adjective-noun modification as either literal or non-literal. By applying a logistic regression with noun concreteness as the predictor variable, Turney et al achieved a classification accuracy of 79% on this task. 
		Cause: [(1, 9), (1, 25)]
		Effect: [(0, 1), (1, 7)]

Section 5:  5 Conclusions has 3 CE cases
	CASE: 1
	Stag: 98 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We presented a novel method, image dispersion-based filtering, that improves multi-modal representations by approximating conceptual concreteness from images and filtering model input. 
		Cause: [(0, 15), (0, 23)]
		Effect: [(0, 0), (0, 13)]

	CASE: 2
	Stag: 102 103 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: To our knowledge, our algorithm constitutes the first unsupervised method for quantifying conceptual concreteness as applied to NLP, although it does, of course, rely on the Google Images retrieval algorithm. Moreover, we presented a method to classify adjective-noun pairs according to modification type that exploits the link between image dispersion and concreteness. 
		Cause: [(0, 16), (1, 21)]
		Effect: [(0, 0), (0, 14)]

	CASE: 3
	Stag: 103 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: Moreover, we presented a method to classify adjective-noun pairs according to modification type that exploits the link between image dispersion and concreteness. 
		Cause: [(0, 12), (0, 22)]
		Effect: [(0, 0), (0, 9)]

#-------------------------------------------------

