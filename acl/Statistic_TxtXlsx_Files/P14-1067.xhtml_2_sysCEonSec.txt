Current File: P14-1067.xhtml_2 P14-1067.xhtml

Section 0:  Abstract
	SentNum: 6
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

Section 1:  1 Introduction
	SentNum: 33
	CENum: 10
	SentCovered: 10
	Covered_Rate: 30.3030%

Section 2:  2 Related work
	SentNum: 15
	CENum: 6
	SentCovered: 7
	Covered_Rate: 46.6667%

Section 3:  3 Online QE for CAT environments
	SentNum: 27
	CENum: 8
	SentCovered: 9
	Covered_Rate: 33.3333%

Section 4:  4 Evaluation framework
	SentNum: 35
	CENum: 12
	SentCovered: 15
	Covered_Rate: 42.8571%

Section 5:  5 Experiments with WMT12 data
	SentNum: 20
	CENum: 7
	SentCovered: 7
	Covered_Rate: 35.0000%

Section 6:  6 Experiments with CAT data
	SentNum: 61
	CENum: 16
	SentCovered: 19
	Covered_Rate: 31.1475%

Section 7:  7 Conclusion
	SentNum: 9
	CENum: 2
	SentCovered: 4
	Covered_Rate: 44.4444%

Section 8:  Acknowledgements
	SentNum: 1
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-1067.xhtml_2's CE cases

Section 0:  Abstract has 0 CE cases
Section 1:  1 Introduction has 10 CE cases
	CASE: 1
	Stag: 15 
		Pattern: 7 [['due', 'to']]---- [['&V-ing/&NP@R@', '&BE'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: Such variability is due to two main reasons. 
		Cause: [(0, 5), (0, 7)]
		Effect: [(0, 0), (0, 1)]

	CASE: 2
	Stag: 17 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since the quality standards of individual users may vary considerably ( e.g., according to their knowledge of the source and target languages), the estimates of a static QE model trained with data collected from a group of post-editors might not fit with the actual judgements of a new user;. 
		Cause: [(0, 1), (0, 11)]
		Effect: [(0, 13), (0, 52)]

	CASE: 3
	Stag: 17 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: Since the quality standards of individual users may vary considerably ( e.g., according to their knowledge of the source and target languages), the estimates of a static QE model trained with data collected from a group of post-editors might not fit with the actual judgements of a new user;. 
		Cause: [(0, 2), (0, 9)]
		Effect: [(0, 12), (0, 39)]

	CASE: 4
	Stag: 19 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since data from a new job may differ from those used to train the QE model, its estimates on the new instances might result to be biased or uninformative. 
		Cause: [(0, 1), (0, 15)]
		Effect: [(0, 17), (0, 29)]

	CASE: 5
	Stag: 23 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: Our approach is based on the online learning paradigm and exploits a key difference between such framework and the batch learning methods currently used. 
		Cause: [(0, 5), (0, 23)]
		Effect: [(0, 0), (0, 1)]

	CASE: 6
	Stag: 26 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: On the other side, online learning techniques are designed to learn in a stepwise manner (either from scratch, or by refining an existing model) from new, unseen test instances by taking advantage of external feedback. 
		Cause: [(0, 23), (0, 26)]
		Effect: [(0, 0), (0, 21)]

	CASE: 7
	Stag: 28 29 
		Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
		sentTXT: To develop our approach, different online algorithms have been embedded in the backbone of a QE system. This required the adaptation of its standard batch learning workflow to. 
		Cause: [(1, 2), (1, 9)]
		Effect: [(0, 0), (0, 17)]

	CASE: 8
	Stag: 32 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Gather user feedback for the instance ( i.e., calculating a u'\u201c' true label u'\u201d' based on the amount of user post-editions);. 
		Cause: [(0, 25), (0, 29)]
		Effect: [(0, 0), (0, 22)]

	CASE: 9
	Stag: 34 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Focusing on the adaptability to user and domain changes, we report the results of comparative experiments with two online algorithms and the standard batch approach. 
		Cause: [(0, 0), (0, 8)]
		Effect: [(0, 10), (0, 25)]

	CASE: 10
	Stag: 35 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The evaluation is carried out by measuring the global error of each algorithm on test sets featuring different degrees of similarity with the data used for training. 
		Cause: [(0, 6), (0, 26)]
		Effect: [(0, 0), (0, 4)]

Section 2:  2 Related work has 6 CE cases
	CASE: 1
	Stag: 39 
		Pattern: 5 [['so'], ['as', 'to']]---- [['&C', '(,)'], ['(&adj/&adv@C@)'], ['&R']]
		sentTXT: QE is generally cast as a supervised machine learning task, where a model trained from a collection of ( source, target, label ) instances is used to predict labels 1 1 Possible label types include post-editing effort scores ( e.g., 1-5 Likert scores indicating the estimated percentage of MT output that has to be corrected), HTER values [ 28 ] , and post-editing time ( e.g., seconds per word for new, unseen test items [ 31 ]. 
		Cause: [(0, 0), (0, 19)]
		Effect: [(0, 57), (0, 84)]

	CASE: 2
	Stag: 41 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Current approaches to the tasks proposed at WMT have mainly focused on three main directions, namely i) feature engineering, as in [ 12 , 10 , 11 , 26 ] , ii) model learning with a variety of classification and regression algorithms, as in [ 3 , 1 , 29 ] , and iii) feature selection as a way to overcome sparsity and overfitting issues, as in [ 29 ]. 
		Cause: [(0, 23), (0, 69)]
		Effect: [(0, 0), (0, 20)]

	CASE: 3
	Stag: 42 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Being optimized to perform well on specific WMT sub-tasks and datasets, current systems reflect variations along these directions but leave important aspects of the QE problem still partially investigated or totally unexplored. 
		Cause: [(0, 0), (0, 10)]
		Effect: [(0, 12), (0, 32)]

	CASE: 4
	Stag: 44 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: Among these, the necessity to model the diversity of human quality judgements and correction strategies [ 16 , 15 ] calls for solutions that i) account for annotator-specific behaviour, thus being capable of learning from inherently noisy datasets produced by multiple annotators, and ii) self-adapt to changes in data distribution, learning from user feedback on new, unseen test items. 
		Cause: [(0, 0), (0, 30)]
		Effect: [(0, 33), (0, 65)]

	CASE: 5
	Stag: 46 47 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The first aspect, modelling annotators u'\u2019' individual behaviour and interdependences, has been addressed by Cohn and Specia [ 8 ] , who explored multi-task Gaussian Processes as a way to jointly learn from the output of multiple annotations. This technique is suitable to cope with the unbalanced distribution of training instances and yields better models when heterogeneous training datasets are available. 
		Cause: [(0, 33), (1, 17)]
		Effect: [(0, 0), (0, 31)]

	CASE: 6
	Stag: 53 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: As regards QE models, our work represents the first investigation on incremental adaptation by exploiting users feedback to provide targeted (system, user, or project specific) quality judgements. 
		Cause: [(0, 15), (0, 31)]
		Effect: [(0, 0), (0, 13)]

Section 3:  3 Online QE for CAT environments has 8 CE cases
	CASE: 1
	Stag: 59 60 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In the online framework, differently from the batch mode, the learning algorithm sequentially processes an unknown sequence of instances X = x 1 , x 2 , u'\u2026' , x n , returning a prediction p u'\u2062' ( x i ) as output at each step. Differences between p u'\u2062' ( x i ) and the true label p ^ u'\u2062' ( x i ) obtained as feedback are used by the learner to refine the next prediction p u'\u2062' ( x i + 1 ). 
		Cause: [(0, 52), (1, 49)]
		Effect: [(0, 0), (0, 50)]

	CASE: 2
	Stag: 60 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Differences between p u'\u2062' ( x i ) and the true label p ^ u'\u2062' ( x i ) obtained as feedback are used by the learner to refine the next prediction p u'\u2062' ( x i + 1 ). 
		Cause: [(0, 29), (0, 51)]
		Effect: [(0, 0), (0, 27)]

	CASE: 3
	Stag: 62 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: 5 5 Edit distance is calculated as the number of edits (word insertions, deletions, substitutions, and shifts) divided by the number of words in the reference. 
		Cause: [(0, 7), (0, 22)]
		Effect: [(0, 0), (0, 5)]

	CASE: 4
	Stag: 63 
		Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Lower HTER values indicate better translations. 
		Cause: [(0, 0), (0, 2)]
		Effect: [(0, 4), (0, 5)]

	CASE: 5
	Stag: 68 69 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: At each step of the process, the goal of the learner is to exploit user post-editions to reduce the difference between the predicted HTER values and the true labels for the following ( source, target ) pairs. As depicted in Figure 1 , this is done as follows. 
		Cause: [(1, 1), (1, 10)]
		Effect: [(0, 0), (0, 38)]

	CASE: 6
	Stag: 74 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Based on the post-edition done by the user, the true HTER label p ^ u'\u2062' ( x i ) is calculated by means of the TERCpp 7 7 goo.gl/nkh2rE open source tool;. 
		Cause: [(0, 2), (0, 7)]
		Effect: [(0, 9), (0, 39)]

	CASE: 7
	Stag: 78 
		Pattern: 2 [['for', 'the', 'sake', 'of'], [',']]---- [[], ['&V-ing/&NP@C@'], ['&R']]
		sentTXT: For the sake of clarity it is worth observing that, at least in principle, a model built in a batch fashion could also be adapted to new test data. 
		Cause: [(0, 4), (0, 4)]
		Effect: [(0, 11), (0, 30)]

	CASE: 8
	Stag: 79 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: For instance, this could be done by running periodic re-training routines once a certain amount of new labelled instances has been collected ( de facto mimicking an online process. 
		Cause: [(0, 8), (0, 29)]
		Effect: [(0, 0), (0, 6)]

Section 4:  4 Evaluation framework has 12 CE cases
	CASE: 1
	Stag: 83 84 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In our experiments, the degree of similarity is measured in terms of u'\u0394' HTER, which is computed as the absolute value of the difference between the average HTER of the training and test sets. Large values indicate a low similarity between training and test data and a more challenging scenario for the learning algorithms. 
		Cause: [(0, 24), (1, 18)]
		Effect: [(0, 0), (0, 22)]

	CASE: 2
	Stag: 84 
		Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Large values indicate a low similarity between training and test data and a more challenging scenario for the learning algorithms. 
		Cause: [(0, 0), (0, 1)]
		Effect: [(0, 3), (0, 19)]

	CASE: 3
	Stag: 93 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: The batch model is built by learning only from the training data and is evaluated on the test set without exploiting information from the test instances. 
		Cause: [(0, 6), (0, 11)]
		Effect: [(0, 12), (0, 25)]

	CASE: 4
	Stag: 95 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: This baseline ( u'\u039c' henceforth) is calculated by labelling each instance of the test set with the mean HTER score of the training set. 
		Cause: [(0, 13), (0, 28)]
		Effect: [(0, 0), (0, 11)]

	CASE: 5
	Stag: 98 99 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The MAE is the average of the absolute errors e i f i - y i where f i is the prediction of the model and y i is the true value for the i t u'\u2062' h instance. As our focus is on the algorithmic aspect, in all experiments we use the same feature set, which consists of the seventeen features proposed in [ 30 ]. 
		Cause: [(1, 1), (1, 28)]
		Effect: [(0, 27), (0, 42)]

	CASE: 6
	Stag: 102 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: In our experiments we evaluate two online algorithms, OnlineSVR [ 24 ] 8 8 http://www2.imperial.ac.uk/~gmontana/onlinesvr.htm and Passive-Aggressive Perceptron [ 9 ] , 9 9 https://code.google.com/p/sofia-ml/ by comparing their performance with a batch learning strategy based on the Scikit-learn implementation of Support Vector Regression (SVR. 
		Cause: [(0, 37), (0, 45)]
		Effect: [(0, 0), (0, 34)]

	CASE: 7
	Stag: 104 105 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The choice of the OnlineSVR and Passive-Aggressive (OSVR and PA henceforth) is motivated by different considerations. From a performance point of view, as an adaptation of u'\u0395' -SVR which proved to be one of the top performing algorithms in the regression QE tasks at WMT, OSVR seems to be the best candidate. 
		Cause: [(1, 8), (1, 42)]
		Effect: [(0, 1), (1, 5)]

	CASE: 8
	Stag: 105 106 
		Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
		sentTXT: From a performance point of view, as an adaptation of u'\u0395' -SVR which proved to be one of the top performing algorithms in the regression QE tasks at WMT, OSVR seems to be the best candidate. For this reason, we use the online adaptation of u'\u0395' -SVR proposed by [ 18 ]. 
		Cause: [(0, 0), (0, 42)]
		Effect: [(1, 4), (1, 21)]

	CASE: 9
	Stag: 107 108 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The goal of OnlineSVR is to find a way to add each new sample to one of three sets (support, empty, error) maintaining the consistency of a set of conditions known as Karush-Kuhn Tucker (KKT) conditions. For each new point, OSVR starts a cycle where the samples are moved across the three sets until the KKT conditions are verified and the new point is assigned to one of the sets. 
		Cause: [(0, 36), (1, 33)]
		Effect: [(0, 0), (0, 34)]

	CASE: 10
	Stag: 109 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: If the point is identified as a support vector, the parameters of the model are updated. 
		Cause: [(0, 6), (0, 16)]
		Effect: [(0, 1), (0, 4)]

	CASE: 11
	Stag: 113 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If its value is larger than the tolerance parameter ( u'\u0395' ), the weights of the model are updated as much as the aggressiveness parameter C allows. 
		Cause: [(0, 1), (0, 15)]
		Effect: [(0, 17), (0, 31)]

	CASE: 12
	Stag: 115 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: Although it makes PA faster than OSVR, this is a riskier strategy because it may lead the algorithm to change the model to adapt to outlier points. 
		Cause: [(0, 14), (0, 27)]
		Effect: [(0, 0), (0, 12)]

Section 5:  5 Experiments with WMT12 data has 7 CE cases
	CASE: 1
	Stag: 117 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: First, since in this artificial scenario adaptation capabilities are not required for the QE component, batch methods operate in the ideal conditions (as training and test are independent and identically distributed. 
		Cause: [(0, 3), (0, 15)]
		Effect: [(0, 17), (0, 33)]

	CASE: 2
	Stag: 117 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: First, since in this artificial scenario adaptation capabilities are not required for the QE component, batch methods operate in the ideal conditions (as training and test are independent and identically distributed. 
		Cause: [(0, 9), (0, 16)]
		Effect: [(0, 0), (0, 7)]

	CASE: 3
	Stag: 119 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: Second, this scenario provides the fairest conditions for such comparison because, in principle, online algorithms are not favoured by the possibility to learn from the diversity of the test instances. 
		Cause: [(0, 12), (0, 32)]
		Effect: [(0, 0), (0, 10)]

	CASE: 4
	Stag: 124 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Evaluation is carried out by measuring the performance of the batch (learning only from the training set), the adaptive (learning from the training set and adapting to the test set), and the empty (learning from scratch from the test set) models in terms of global MAE scores on the test set. 
		Cause: [(0, 5), (0, 58)]
		Effect: [(0, 0), (0, 3)]

	CASE: 5
	Stag: 125 126 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Table 1 reports the results achieved by the best performing algorithm for each type of model ( batch , adaptive , empty. As can be seen, close MAE values show a similar behaviour for the three types of models. 
		Cause: [(1, 1), (1, 17)]
		Effect: [(0, 0), (0, 21)]

	CASE: 6
	Stag: 130 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This demonstrates that, as expected, the online algorithms do not take advantage of test data with a label distribution similar to the training set. 
		Cause: [(0, 5), (0, 25)]
		Effect: [(0, 0), (0, 2)]

	CASE: 7
	Stag: 131 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: All the models outperform the baseline, even if the minimal differences confirm the competitiveness of such a simple approach. 
		Cause: [(0, 9), (0, 19)]
		Effect: [(0, 0), (0, 7)]

Section 6:  6 Experiments with CAT data has 16 CE cases
	CASE: 1
	Stag: 139 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The source sentences were translated with two SMT systems built by training the Moses toolkit [ 14 ] on parallel data from the two domains (about 2M sentences for IT and 1.5M for L. 
		Cause: [(0, 11), (0, 35)]
		Effect: [(0, 0), (0, 9)]

	CASE: 2
	Stag: 141 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: According to the way they are created, the two datasets allow us to evaluate the adaptability of different QE models with respect to user changes within the same domain (§ 6.1 ), as well as user and domain changes at the same time (§ 6.2. 
		Cause: [(0, 2), (0, 6)]
		Effect: [(0, 8), (0, 46)]

	CASE: 3
	Stag: 142 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: For each document D (L or IT), these two scenarios are obtained by dividing D into two parts of equal size (80 instances for L and 140 for IT. 
		Cause: [(0, 16), (0, 32)]
		Effect: [(0, 0), (0, 14)]

	CASE: 4
	Stag: 142 143 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: For each document D (L or IT), these two scenarios are obtained by dividing D into two parts of equal size (80 instances for L and 140 for IT. The result is one training set and one test set for each post-editor within the same domain. 
		Cause: [(0, 0), (0, 32)]
		Effect: [(1, 3), (1, 16)]

	CASE: 5
	Stag: 148 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: For each domain, these respectively involve the most dissimilar and the most similar post-editors according to the u'\u0394' HTER. 
		Cause: [(0, 17), (0, 23)]
		Effect: [(0, 0), (0, 14)]

	CASE: 6
	Stag: 150 151 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The first scenario defines a challenging situation where two post-editors ( rad and cons ) are characterized by opposite behaviour. As evidenced by the high u'\u0394' HTER values, one of them ( rad ) is the most u'\u201c' radical u'\u201d' post-editor (performing more corrections) while the other ( cons ) is the most u'\u201c' conservative u'\u201d' one. 
		Cause: [(1, 1), (1, 58)]
		Effect: [(0, 0), (0, 19)]

	CASE: 7
	Stag: 151 152 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: As evidenced by the high u'\u0394' HTER values, one of them ( rad ) is the most u'\u201c' radical u'\u201d' post-editor (performing more corrections) while the other ( cons ) is the most u'\u201c' conservative u'\u201d' one. As shown in Table 2 , global MAE scores for the online algorithms (both adaptive and empty ) indicate their good adaptation capabilities. 
		Cause: [(1, 1), (1, 23)]
		Effect: [(0, 0), (0, 59)]

	CASE: 8
	Stag: 155 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: These results (MAE reductions are always statistically significant) suggest that, when dealing with datasets with very different label distributions, the evident limitations of batch methods are more easily overcome by learning from scratch from the feedback of a new post-editor. 
		Cause: [(0, 34), (0, 43)]
		Effect: [(0, 0), (0, 32)]

	CASE: 9
	Stag: 156 157 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This also holds when the amount of test points to learn from is limited, as in the L domain where the test set contains only 80 instances. From the application-oriented perspective that motivates our work, considering the high costs of acquiring large and representative QE training data, this is an important finding. 
		Cause: [(0, 16), (1, 25)]
		Effect: [(0, 0), (0, 13)]

	CASE: 10
	Stag: 162 
		Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: A closer look at the behaviour of the online algorithms in the two domains leads to other observations. 
		Cause: [(0, 0), (0, 13)]
		Effect: [(0, 16), (0, 17)]

	CASE: 11
	Stag: 166 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: For OSVR the addition of new points to the support set may have a limited effect on the whole model, in particular if the number of points in the set is large. 
		Cause: [(0, 24), (0, 32)]
		Effect: [(0, 1), (0, 22)]

	CASE: 12
	Stag: 174 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: In the table, results are ordered according to the u'\u0394' HTER computed between the selected post-editor in the training domain ( e.g., L cons ) and the selected post-editor in the test domain ( e.g., IT rad. 
		Cause: [(0, 9), (0, 24)]
		Effect: [(0, 28), (0, 33)]

	CASE: 13
	Stag: 175 
		Pattern: 2 [['for', 'the', 'sake', 'of'], [',']]---- [[], ['&V-ing/&NP@C@'], ['&R']]
		sentTXT: For the sake of comparison, we also report (grey rows) the results of the experiments within the same domain presented in § 6.1. 
		Cause: [(0, 4), (0, 4)]
		Effect: [(0, 6), (0, 24)]

	CASE: 14
	Stag: 181 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: This is a strong evidence of the fact that, in case of domain changes, online models can still learn from new test instances even if they have a label distribution similar to the training set. 
		Cause: [(0, 27), (0, 36)]
		Effect: [(0, 0), (0, 25)]

	CASE: 15
	Stag: 188 189 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This suggests that, although PA is potentially capable of achieving higher results and better adapt to the new test points, its instability makes it less reliable for practical use. As a final analysis of our results, we investigated how the performance of the different types of models ( batch , adaptive , empty ) relates to the distance between training and test sets. 
		Cause: [(1, 1), (1, 34)]
		Effect: [(0, 0), (0, 30)]

	CASE: 16
	Stag: 194 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: As expected, the results of the empty models are completely uncorrelated with the u'\u0394' HTER since they only use the test set. 
		Cause: [(0, 21), (0, 26)]
		Effect: [(0, 0), (0, 19)]

Section 7:  7 Conclusion has 2 CE cases
	CASE: 1
	Stag: 197 198 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In the CAT scenario, each translation job can be seen as a complex situation where the user (his personal style and background), the source document (the language and the domain) and the underlying technology (the translation memory and the MT engine that generate translation suggestions) contribute to make the task unique. So far, the adaptability to such specificities (a major challenge for CAT technology) has been mainly supported by the evolution of translation memories, which incrementally store translated segments incorporating the user style. 
		Cause: [(0, 12), (1, 27)]
		Effect: [(0, 0), (0, 10)]

	CASE: 2
	Stag: 203 204 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Our results show that the wealth of dynamic knowledge brought by user corrections can be exploited to refine in a stepwise fashion the quality judgements in different testing conditions (user changes as well as simultaneous user and domain changes. As an additional contribution, to spark further research on this facet of the QE problem, our adaptive QE infrastructure (integrating all the components and the algorithms described in this paper) has been released as open source. 
		Cause: [(1, 1), (1, 39)]
		Effect: [(0, 0), (0, 39)]

Section 8:  Acknowledgements has 0 CE cases
#-------------------------------------------------

