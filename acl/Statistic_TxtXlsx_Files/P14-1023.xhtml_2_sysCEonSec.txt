Current File: P14-1023.xhtml_2 P14-1023.xhtml

Section 0:  Abstract
	SentNum: 4
	CENum: 1
	SentCovered: 1
	Covered_Rate: 25.0000%

Section 1:  1 Introduction
	SentNum: 38
	CENum: 16
	SentCovered: 15
	Covered_Rate: 39.4737%

Section 2:  2 Distributional semantic models
	SentNum: 36
	CENum: 6
	SentCovered: 6
	Covered_Rate: 16.6667%

Section 3:  3 Evaluation materials
	SentNum: 59
	CENum: 12
	SentCovered: 14
	Covered_Rate: 23.7288%

Section 4:  4 Results
	SentNum: 40
	CENum: 13
	SentCovered: 14
	Covered_Rate: 35.0000%

Section 5:  5 Conclusion
	SentNum: 22
	CENum: 6
	SentCovered: 6
	Covered_Rate: 27.2727%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-1023.xhtml_2's CE cases

Section 0:  Abstract has 1 CE cases
	CASE: 1
	Stag: 3 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The results, to our own surprise, show that the buzz is fully justified, as the context-predicting models obtain a thorough and resounding victory against their count-based counterparts. 
		Cause: [(0, 17), (0, 20)]
		Effect: [(0, 0), (0, 14)]

Section 1:  1 Introduction has 16 CE cases
	CASE: 1
	Stag: 4 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: A long tradition in computational linguistics has shown that contextual information provides a good approximation to word meaning, since semantically similar words tend to have similar contextual distributions [ 36 ]. 
		Cause: [(0, 20), (0, 31)]
		Effect: [(0, 0), (0, 17)]

	CASE: 2
	Stag: 6 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: It has been clear for decades now that raw co-occurrence counts don u'\u2019' t work that well, and DSMs achieve much higher performance when various transformations are applied to the raw vectors, for example by reweighting the counts for context informativeness and smoothing them with dimensionality reduction techniques. 
		Cause: [(0, 41), (0, 53)]
		Effect: [(0, 30), (0, 39)]

	CASE: 3
	Stag: 7 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: This vector optimization process is generally unsupervised, and based on independent considerations (for example, context reweighting is often justified by information-theoretic considerations, dimensionality reduction optimizes the amount of preserved variance, etc. 
		Cause: [(0, 11), (0, 12)]
		Effect: [(0, 17), (0, 35)]

	CASE: 4
	Stag: 9 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Several parameter settings are tried, and the best setting is chosen based on performance on a semantic task that has been selected for tuning. 
		Cause: [(0, 14), (0, 24)]
		Effect: [(0, 0), (0, 11)]

	CASE: 5
	Stag: 10 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The last few years have seen the development of a new generation of DSMs that frame the vector estimation problem directly as a supervised task, where the weights in a word vector are set to maximize the probability of the contexts in which the word is observed in the corpus [ 6 , 15 , 14 , 25 , 32 , 44 ]. 
		Cause: [(0, 22), (0, 53)]
		Effect: [(0, 0), (0, 20)]

	CASE: 6
	Stag: 12 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Instead of first collecting context vectors and then reweighting these vectors based on various criteria, the vector weights are directly set to optimally predict the contexts in which the corresponding words tend to appear. 
		Cause: [(0, 13), (0, 14)]
		Effect: [(0, 16), (0, 34)]

	CASE: 7
	Stag: 13 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since similar words occur in similar contexts, the system naturally learns to assign similar vectors to similar words. 
		Cause: [(0, 1), (0, 6)]
		Effect: [(0, 8), (0, 18)]

	CASE: 8
	Stag: 14 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: This new way to train DSMs is attractive because it replaces the essentially heuristic stacking of vector transforms in earlier models with a single, well-defined supervised learning step. 
		Cause: [(0, 9), (0, 28)]
		Effect: [(0, 0), (0, 7)]

	CASE: 9
	Stag: 17 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: 1 1 The idea to directly learn a parameter vector based on an objective optimum function is shared by Latent Dirichlet Allocation (LDA) models [ 8 , 21 ] , where parameters are set to optimize the joint probability distribution of words and documents. 
		Cause: [(0, 12), (0, 27)]
		Effect: [(0, 29), (0, 44)]

	CASE: 10
	Stag: 19 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: We will refer to DSMs built in the traditional way as count models (since they initialize vectors with co-occurrence counts), and to their training-based alternative as predict(ive) models. 
		Cause: [(0, 15), (0, 20)]
		Effect: [(0, 23), (0, 32)]

	CASE: 11
	Stag: 21 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: Predictive DSMs are also called neural language models, because their supervised context prediction training is performed with neural networks, or, more cryptically, u'\u201c' embeddings u'\u201d'. 
		Cause: [(0, 10), (0, 19)]
		Effect: [(0, 21), (0, 36)]

	CASE: 12
	Stag: 24 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: This is in part due to the fact that context-predicting vectors were first developed as an approach to language modeling and/or as a way to initialize feature vectors in neural-network-based u'\u201c' deep learning u'\u201d' NLP architectures, so their effectiveness as semantic representations was initially seen as little more than an interesting side effect. 
		Cause: [(0, 0), (0, 43)]
		Effect: [(0, 46), (0, 61)]

	CASE: 13
	Stag: 24 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This is in part due to the fact that context-predicting vectors were first developed as an approach to language modeling and/or as a way to initialize feature vectors in neural-network-based u'\u201c' deep learning u'\u201d' NLP architectures, so their effectiveness as semantic representations was initially seen as little more than an interesting side effect. 
		Cause: [(0, 15), (0, 43)]
		Effect: [(0, 0), (0, 13)]

	CASE: 14
	Stag: 24 
		Pattern: 0 [['due', 'to', 'the', 'fact', 'that']]---- [['&R', '(,)'], ['&C']]
		sentTXT: This is in part due to the fact that context-predicting vectors were first developed as an approach to language modeling and/or as a way to initialize feature vectors in neural-network-based u'\u201c' deep learning u'\u201d' NLP architectures, so their effectiveness as semantic representations was initially seen as little more than an interesting side effect. 
		Cause: [(0, 9), (0, 13)]
		Effect: [(0, 0), (0, 3)]

	CASE: 15
	Stag: 32 33 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Blacoe and Lapata ( 2012 ) compare count and predict representations as input to composition functions. Count vectors make for better inputs in a phrase similarity task, whereas the two representations are comparable in a paraphrase classification experiment. 
		Cause: [(0, 12), (1, 21)]
		Effect: [(0, 0), (0, 10)]

	CASE: 16
	Stag: 40 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: In this paper, we overcome the comparison scarcity problem by providing a direct evaluation of count and predict DSMs across many parameter settings and on a large variety of mostly standard lexical semantics benchmarks. 
		Cause: [(0, 11), (0, 16)]
		Effect: [(0, 17), (0, 34)]

Section 2:  2 Distributional semantic models has 6 CE cases
	CASE: 1
	Stag: 42 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Both count and predict models are extracted from a corpus of about 2.8 billion tokens constructed by concatenating ukWaC, 5 5 http://wacky.sslmit.unibo.it the English Wikipedia 6 6 http://en.wikipedia.org and the British National Corpus. 
		Cause: [(0, 17), (0, 33)]
		Effect: [(0, 0), (0, 15)]

	CASE: 2
	Stag: 48 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: The latter were obtained by applying the Singular Value Decomposition [ 20 ] or Non-negative Matrix Factorization [ 29 ] , Lin ( 2007 ) algorithm, with reduced sizes ranging from 200 to 500 in steps of 100. 
		Cause: [(0, 5), (0, 25)]
		Effect: [(0, 26), (0, 28)]

	CASE: 3
	Stag: 57 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: The CBOW model learns to predict the word in the middle of a symmetric window based on the sum of the vector representations of the words in the window. 
		Cause: [(0, 17), (0, 28)]
		Effect: [(0, 0), (0, 14)]

	CASE: 4
	Stag: 62 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: As an alternative, negative sampling estimates the probability of an output word by learning to distinguish it from draws from a noise distribution. 
		Cause: [(0, 14), (0, 23)]
		Effect: [(0, 0), (0, 12)]

	CASE: 5
	Stag: 69 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We train models without subsampling and with subsampling at t = 1 u'\u2062' e - 5 (the toolkit page suggests 1 u'\u2062' e - 3 - 1 u'\u2062' e - 5 as a useful range based on empirical observations. 
		Cause: [(0, 45), (0, 48)]
		Effect: [(0, 0), (0, 43)]

	CASE: 6
	Stag: 72 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: 10 10 http://clic.cimec.unitn.it/dm/ This model, based on the same input corpus we use, exemplifies a u'\u201c' linguistically rich u'\u201d' count-based DSM, that relies on lemmas instead or raw word forms, and has dimensions that encode the syntactic relations and/or lexico-syntactic patterns linking targets and contexts. 
		Cause: [(0, 8), (0, 13)]
		Effect: [(0, 15), (0, 56)]

Section 3:  3 Evaluation materials has 12 CE cases
	CASE: 1
	Stag: 80 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: A first set of semantic benchmarks was constructed by asking human subjects to rate the degree of semantic similarity or relatedness between two words on a numerical scale. 
		Cause: [(0, 9), (0, 27)]
		Effect: [(0, 0), (0, 7)]

	CASE: 2
	Stag: 98 99 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The DSMs compute cosines of each candidate vector with the target, and pick the candidate with largest cosine as their answer. Performance is evaluated in terms of correct-answer accuracy. 
		Cause: [(0, 20), (1, 6)]
		Effect: [(0, 5), (0, 18)]

	CASE: 3
	Stag: 102 103 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Following previous art, we tackle categorization as an unsupervised clustering task. The vectors produced by a model are clustered into n groups (with n determined by the gold standard partition) using the CLUTO toolkit [ 26 ] , with the repeated bisections with global optimization method and CLUTO u'\u2019' s default settings otherwise (these are standard choices in the literature. 
		Cause: [(0, 8), (1, 54)]
		Effect: [(0, 0), (0, 6)]

	CASE: 4
	Stag: 105 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: If the gold partition is reproduced perfectly, purity reaches 100%; it approaches 0 as cluster quality deteriorates. 
		Cause: [(0, 17), (0, 19)]
		Effect: [(0, 13), (0, 15)]

	CASE: 5
	Stag: 107 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: State-of-the-art purity was reached by Rothenhäusler and Schütze ( 2009 ) with a count model based on carefully crafted syntactic links. 
		Cause: [(0, 19), (0, 22)]
		Effect: [(0, 0), (0, 16)]

	CASE: 6
	Stag: 109 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Katrenko and Adriaans ( 2008 ) reached top performance on this set using the full Web as a corpus and manually crafted, linguistically motivated patterns. 
		Cause: [(0, 17), (0, 22)]
		Effect: [(0, 0), (0, 15)]

	CASE: 7
	Stag: 113 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We experiment with two data sets that contain verb-noun pairs that were rated by subjects for the typicality of the noun as a subject or object of the verb (e.g.,, people received a high average score as subject of to eat , and a low score as object of the same verb. 
		Cause: [(0, 22), (0, 42)]
		Effect: [(0, 0), (0, 20)]

	CASE: 8
	Stag: 115 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: For each verb, we use the corpus-based tuples they make available to select the 20 nouns that are most strongly associated to the verb as subjects or objects, and we average the vectors of these nouns to obtain a u'\u201c' prototype u'\u201d' vector for the relevant argument slot. 
		Cause: [(0, 26), (0, 56)]
		Effect: [(0, 0), (0, 24)]

	CASE: 9
	Stag: 126 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Mikolov and colleagues tackle the challenge by subtracting the second example term vector from the first, adding the test term, and looking for the nearest neighbour of the resulting vector (what is the nearest neighbour of b u'\u2062' r u'\u2062' o u'\u2062' t u'\u2062' h u'\u2062' e u'\u2062' r u'\u2192' - s u'\u2062' i u'\u2062' s u'\u2062' t u'\u2062' e u'\u2062' r u'\u2192' + g u'\u2062' r u'\u2062' a u'\u2062' n u'\u2062' d u'\u2062' s u'\u2062' o u'\u2062' n u'\u2192'. 
		Cause: [(0, 0), (0, 28)]
		Effect: [(0, 35), (0, 166)]

	CASE: 10
	Stag: 126 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: Mikolov and colleagues tackle the challenge by subtracting the second example term vector from the first, adding the test term, and looking for the nearest neighbour of the resulting vector (what is the nearest neighbour of b u'\u2062' r u'\u2062' o u'\u2062' t u'\u2062' h u'\u2062' e u'\u2062' r u'\u2192' - s u'\u2062' i u'\u2062' s u'\u2062' t u'\u2062' e u'\u2062' r u'\u2192' + g u'\u2062' r u'\u2062' a u'\u2062' n u'\u2062' d u'\u2062' s u'\u2062' o u'\u2062' n u'\u2192'. 
		Cause: [(0, 7), (0, 15)]
		Effect: [(0, 16), (0, 28)]

	CASE: 11
	Stag: 129 130 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: 2013a ) reach top accuracy on the syntactic subset (ansyn) with a CBOW predict model akin to ours (but trained on a corpus twice as large. Top accuracy on the entire data set (an) and on the semantic subset (ansem) was reached by Mikolov et al. 
		Cause: [(0, 28), (1, 22)]
		Effect: [(0, 3), (0, 26)]

	CASE: 12
	Stag: 132 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: Note however that, because of the way the task is framed, performance also depends on the size of the vocabulary to be searched. 
		Cause: [(0, 5), (0, 10)]
		Effect: [(0, 13), (0, 24)]

Section 4:  4 Results has 13 CE cases
	CASE: 1
	Stag: 139 140 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The latter emerge as clear winners, with a large margin over count vectors in most tasks. Indeed, the predictive models achieve an impressive overall performance, beating the current state of the art in several cases, and approaching it in many more. 
		Cause: [(0, 4), (1, 26)]
		Effect: [(0, 0), (0, 2)]

	CASE: 2
	Stag: 141 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: It is worth stressing that, as reviewed in Section 3 , the state-of-the-art results were obtained in almost all cases using specialized approaches that rely on external knowledge, manually-crafted rules, parsing, larger corpora and/or task-specific tuning. 
		Cause: [(0, 7), (0, 39)]
		Effect: [(0, 0), (0, 4)]

	CASE: 3
	Stag: 142 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Our predict results were instead achieved by simply downloading the word2vec toolkit and running it with a range of parameter choices recommended by the toolkit developers. 
		Cause: [(0, 7), (0, 25)]
		Effect: [(0, 0), (0, 5)]

	CASE: 4
	Stag: 148 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Recall from Section 3 that we tackle selectional preference by creating average vectors representing typical verb arguments. 
		Cause: [(0, 10), (0, 16)]
		Effect: [(0, 5), (0, 8)]

	CASE: 5
	Stag: 150 
		Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
		sentTXT: Are our results robust to parameter choices, or are they due to very specific and brittle settings. 
		Cause: [(0, 13), (0, 17)]
		Effect: [(0, 0), (0, 10)]

	CASE: 6
	Stag: 153 
		Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
		sentTXT: We see that, for both approaches, performance is not seriously affected by using the single best setup rather than task-specific settings, except for a considerable drop in performance for the best predict model on esslli (due to the small size of this data set?), and an even more dramatic drop of the count model on ansem. 
		Cause: [(0, 41), (0, 47)]
		Effect: [(0, 0), (0, 38)]

	CASE: 7
	Stag: 153 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: We see that, for both approaches, performance is not seriously affected by using the single best setup rather than task-specific settings, except for a considerable drop in performance for the best predict model on esslli (due to the small size of this data set?), and an even more dramatic drop of the count model on ansem. 
		Cause: [(0, 14), (0, 22)]
		Effect: [(0, 23), (0, 34)]

	CASE: 8
	Stag: 154 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: A more cogent and interesting evaluation is reported in the third block of Table 2 , where we see what happens if we use the single models with worst performance across tasks (recall from Section 2 above that, in any case, we are exploring a space of reasonable parameter settings, of the sort that an experimenter might be tempted to choose without tuning. 
		Cause: [(0, 22), (0, 38)]
		Effect: [(0, 40), (0, 66)]

	CASE: 9
	Stag: 159 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The fourth block reports performance in what might be the most realistic scenario, namely by tuning the parameters on a development task. 
		Cause: [(0, 16), (0, 22)]
		Effect: [(0, 0), (0, 14)]

	CASE: 10
	Stag: 160 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Specifically, we pick the models that work best on the small rg set, and report their performance on all tasks (we obtained similar results by picking other tuning sets. 
		Cause: [(0, 28), (0, 31)]
		Effect: [(0, 0), (0, 26)]

	CASE: 11
	Stag: 165 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Tables 3 and 4 let us take a closer look at the most important count and predict parameters, by reporting the characteristics of the best models (in terms of average performance-based ranking across tasks) from both classes. 
		Cause: [(0, 20), (0, 39)]
		Effect: [(0, 1), (0, 18)]

	CASE: 12
	Stag: 166 167 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: For the count models, PMI is clearly the better weighting scheme, and SVD outperforms NMF as a dimensionality reduction technique. However, no compression at all (using all 300K original dimensions) works best. 
		Cause: [(0, 18), (1, 13)]
		Effect: [(0, 0), (0, 16)]

	CASE: 13
	Stag: 172 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: We must leave the investigation of the parameters that make our predict vectors so much better than cw (more varied training corpus window size objective function being used subsampling u'\u2026' ) to further work. 
		Cause: [(0, 0), (0, 12)]
		Effect: [(0, 14), (0, 33)]

Section 5:  5 Conclusion has 6 CE cases
	CASE: 1
	Stag: 178 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: As seasoned distributional semanticists with thorough experience in developing and using count vectors, we set out to conduct this study because we were annoyed by the triumphalist overtones often surrounding predict models, despite the almost complete lack of a proper comparison to count vectors. 
		Cause: [(0, 22), (0, 32)]
		Effect: [(0, 34), (0, 44)]

	CASE: 2
	Stag: 181 
		Pattern: 47 [['so'], ['that']]---- [['&C'], ['&adj/&adv@C@'], ['&R']]
		sentTXT: Instead, we found that the predict models are so good that, while the triumphalist overtones still sound excessive, there are very good reasons to switch to the new architecture. 
		Cause: [(0, 0), (0, 10)]
		Effect: [(0, 12), (0, 31)]

	CASE: 3
	Stag: 182 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: However, due to space limitations we have only focused here on quantitative measures. 
		Cause: [(0, 4), (0, 5)]
		Effect: [(0, 6), (0, 13)]

	CASE: 4
	Stag: 188 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Based on the results reported here and the considerations we just made, we would certainly recommend anybody interested in using DSMs for theoretical or practical applications to go for the predict models, with the important caveat that they are not all created equal (cf. the big difference between word2vec and cw models. 
		Cause: [(0, 2), (0, 11)]
		Effect: [(0, 13), (0, 54)]

	CASE: 5
	Stag: 190 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: For example, the developers of Latent Semantic Analysis [ 28 ] , Topic Models [ 21 ] and related DSMs have shown that the dimensions of these models can be interpreted as general u'\u201c' latent u'\u201d' semantic domains, which gives the corresponding models some a priori cognitive plausibility while paving the way for interesting applications. 
		Cause: [(0, 33), (0, 63)]
		Effect: [(0, 0), (0, 31)]

	CASE: 6
	Stag: 197 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Does all of this even matter, or are we on the cusp of discovering radically new ways to tackle the same problems that have been approached as we just sketched in traditional distributional semantics. 
		Cause: [(0, 28), (0, 34)]
		Effect: [(0, 3), (0, 26)]

#-------------------------------------------------

