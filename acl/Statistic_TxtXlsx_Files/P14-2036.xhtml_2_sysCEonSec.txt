Current File: P14-2036.xhtml_2 P14-2036.xhtml

Section 0:  Abstract
	SentNum: 5
	CENum: 2
	SentCovered: 3
	Covered_Rate: 60.0000%

Section 1:  1 Introduction
	SentNum: 20
	CENum: 11
	SentCovered: 12
	Covered_Rate: 60.0000%

Section 2:  2 Related Work
	SentNum: 9
	CENum: 4
	SentCovered: 5
	Covered_Rate: 55.5556%

Section 3:  3 Our Model
	SentNum: 44
	CENum: 17
	SentCovered: 20
	Covered_Rate: 45.4545%

Section 4:  4 Experiment
	SentNum: 35
	CENum: 13
	SentCovered: 16
	Covered_Rate: 45.7143%

Section 5:  5 Conclusion and Future Work
	SentNum: 6
	CENum: 2
	SentCovered: 4
	Covered_Rate: 66.6667%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-2036.xhtml_2's CE cases

Section 0:  Abstract has 2 CE cases
	CASE: 1
	Stag: 0 1 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: In this paper, we propose a novel model for enriching the content of microblogs by exploiting external knowledge, thus improving the data sparseness problem in short text classification. We assume that microblogs share the same topics with external knowledge. 
		Cause: [(0, 0), (0, 18)]
		Effect: [(0, 21), (1, 10)]

	CASE: 2
	Stag: 2 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We first build an optimization model to infer the topics of microblogs by employing the topic-word distribution of the external knowledge. 
		Cause: [(0, 13), (0, 20)]
		Effect: [(0, 0), (0, 11)]

Section 1:  1 Introduction has 11 CE cases
	CASE: 1
	Stag: 6 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: Previous researches [ Phan et al.2008 , Guo and Diab2012 ] show that while traditional methods are not so powerful due to the data sparseness problem, some semantic analysis based approaches are proposed and proved effective, and various topic models are among the most frequently used techniques in this area. 
		Cause: [(0, 0), (0, 18)]
		Effect: [(0, 20), (0, 52)]

	CASE: 2
	Stag: 6 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: Previous researches [ Phan et al.2008 , Guo and Diab2012 ] show that while traditional methods are not so powerful due to the data sparseness problem, some semantic analysis based approaches are proposed and proved effective, and various topic models are among the most frequently used techniques in this area. 
		Cause: [(0, 3), (0, 12)]
		Effect: [(0, 13), (0, 32)]

	CASE: 3
	Stag: 7 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Meanwhile, external knowledge has been found helpful [ Hu et al.2009 ] in tackling the data scarcity problem by enriching short texts with informative context. 
		Cause: [(0, 21), (0, 26)]
		Effect: [(0, 0), (0, 19)]

	CASE: 4
	Stag: 9 10 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Nowadays, most of the work on short text focuses on microblog. As a new form of short text, microblog has some unique features like informal spelling and emerging words, and many microblogs are strongly related to up-to-date topics as well. 
		Cause: [(1, 1), (1, 22)]
		Effect: [(0, 0), (0, 11)]

	CASE: 5
	Stag: 11 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: Every day, a great quantity of microblogs more than we can read is pushed to us, and finding what we are interested in becomes rather difficult, so the ability of choosing what kind of microblogs to read is urgently demanded by common user. 
		Cause: [(0, 0), (0, 27)]
		Effect: [(0, 30), (0, 45)]

	CASE: 6
	Stag: 13 14 
		Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
		sentTXT: Treating microblogs as standard texts and directly classifying them cannot achieve the goal of effective classification because of sparseness problem. On the other hand, news on the Internet is of information abundance and many microblogs are news-related. 
		Cause: [(0, 0), (0, 16)]
		Effect: [(1, 4), (1, 17)]

	CASE: 7
	Stag: 15 16 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: They share up-to-date topics and sometimes quote each other. Thus, external knowledge, such as news, provides rich supplementary information for analysing and mining microblogs. 
		Cause: [(0, 0), (0, 8)]
		Effect: [(1, 1), (1, 17)]

	CASE: 8
	Stag: 19 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: We first infer the topic distribution of each microblog based on the topic-word distribution of news corpus obtained by the LDA estimation. 
		Cause: [(0, 11), (0, 21)]
		Effect: [(0, 0), (0, 8)]

	CASE: 9
	Stag: 20 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: With the above two distributions, we then add a number of words from news as additional information to microblogs by evaluating the relatedness of between each word and microblog, since words not appearing in the microblog may still be highly relevant. 
		Cause: [(0, 32), (0, 42)]
		Effect: [(0, 0), (0, 29)]

	CASE: 10
	Stag: 20 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: With the above two distributions, we then add a number of words from news as additional information to microblogs by evaluating the relatedness of between each word and microblog, since words not appearing in the microblog may still be highly relevant. 
		Cause: [(0, 21), (0, 29)]
		Effect: [(0, 0), (0, 19)]

	CASE: 11
	Stag: 23 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We enrich the content of microblogs by inferring the association between microblogs and external words in a probabilistic perspective. 
		Cause: [(0, 7), (0, 18)]
		Effect: [(0, 0), (0, 5)]

Section 2:  2 Related Work has 4 CE cases
	CASE: 1
	Stag: 25 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Based on the idea of exploiting external knowledge, many methods are proposed to improve the representation of short texts for classification and clustering. 
		Cause: [(0, 2), (0, 7)]
		Effect: [(0, 9), (0, 23)]

	CASE: 2
	Stag: 27 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Banerjee et al.2007 use the title and the description of news article as two separate query strings to select related concepts as additional feature. 
		Cause: [(0, 14), (0, 24)]
		Effect: [(0, 1), (0, 12)]

	CASE: 3
	Stag: 28 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Hu et al.2009 present a framework to improve the performance of short text clustering by mining informative context with the integration of Wikipedia and WordNet. 
		Cause: [(0, 16), (0, 25)]
		Effect: [(0, 1), (0, 14)]

	CASE: 4
	Stag: 30 31 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Phan et al.2008 present a framework including an approach for short text topic inference and adds abstract words as extra feature. Guo and Diab2012 modify classic topic models and proposes a matrix-factorization based model for sentence similarity calculation tasks. 
		Cause: [(0, 20), (1, 17)]
		Effect: [(0, 0), (0, 18)]

Section 3:  3 Our Model has 17 CE cases
	CASE: 1
	Stag: 38 
		Pattern: 5 [['so'], ['as', 'to']]---- [['&C', '(,)'], ['(&adj/&adv@C@)'], ['&R']]
		sentTXT: Our task is to enrich each microblog with additional information so as to improve microblog u'\u2019' s representation. 
		Cause: [(0, 0), (0, 9)]
		Effect: [(0, 13), (0, 21)]

	CASE: 2
	Stag: 43 
		Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
		sentTXT: We do topic analysis for E u'\u2062' K using LDA estimation [ Blei et al.2003 ] in this section and we choose LDA as the topic analysis model because of its broadly proved effectivity and ease of understanding. 
		Cause: [(0, 0), (0, 32)]
		Effect: [(0, 39), (0, 42)]

	CASE: 3
	Stag: 45 46 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The optimization problem is formulated as maximizing the log likelihood on the corpus. In this formulation, X i u'\u2062' j represents the term frequency of word w i in document d j. 
		Cause: [(0, 6), (1, 10)]
		Effect: [(0, 0), (0, 4)]

	CASE: 4
	Stag: 48 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: Estimating parameters for LDA by directly and exactly maximizing the likelihood of the corpus in (1) is intractable, so we use Gibbs Sampling for estimation. 
		Cause: [(0, 0), (0, 19)]
		Effect: [(0, 22), (0, 27)]

	CASE: 5
	Stag: 52 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: Because of the assumption that microblogs share the same topics with external corpus, the u'\u201c' topic distribution u'\u201d' here refers to a distribution over all topics on E u'\u2062' K. 
		Cause: [(0, 1), (0, 12)]
		Effect: [(0, 14), (0, 42)]

	CASE: 6
	Stag: 57 58 
		Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
		sentTXT: Compared with the original LDA optimization problem (1), the topic inference problem for microblog (2) follows the idea of document generation process, but replaces topics to be estimated with known topics from other corpus. As a result, parameters to be inferred are only the topic distribution of every microblog. 
		Cause: [(0, 0), (0, 39)]
		Effect: [(1, 4), (1, 15)]

	CASE: 7
	Stag: 59 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: It is noteworthy that since the word distribution of every topic P ( w i e z k e ) is known, Formula ( 2 ) can be further solved by separating it into M m subproblems. 
		Cause: [(0, 5), (0, 20)]
		Effect: [(0, 23), (0, 37)]

	CASE: 8
	Stag: 59 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: It is noteworthy that since the word distribution of every topic P ( w i e z k e ) is known, Formula ( 2 ) can be further solved by separating it into M m subproblems. 
		Cause: [(0, 9), (0, 14)]
		Effect: [(0, 0), (0, 7)]

	CASE: 9
	Stag: 63 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Based on the results of step (a) (b), we calculate the word distributions of microblogs as follows. 
		Cause: [(0, 2), (0, 11)]
		Effect: [(0, 13), (0, 21)]

	CASE: 10
	Stag: 65 66 
		Pattern: 0 [[['imply', 'implies', 'implied', 'mean', 'means', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
		sentTXT: In other words, though some words may not actually appears in a microblog, there is still a probability that it is highly relevant to the microblog. Intuitively, this probability indicates the strength of association between a word and a microblog. 
		Cause: [(0, 1), (1, 0)]
		Effect: [(1, 5), (1, 14)]

	CASE: 11
	Stag: 67 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: The word distribution of every microblog is based on topic analysis and its accuracy relies heavily on the accuracy of topic inference in step (b. 
		Cause: [(0, 9), (0, 25)]
		Effect: [(0, 0), (0, 5)]

	CASE: 12
	Stag: 70 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Having known the top L relevant words according to the result of sorting, we redefine the u'\u201c' term frequency u'\u201d' of every word after adding these L words to microblog d j m as additional content. 
		Cause: [(0, 0), (0, 12)]
		Effect: [(0, 14), (0, 44)]

	CASE: 13
	Stag: 70 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: Having known the top L relevant words according to the result of sorting, we redefine the u'\u201c' term frequency u'\u201d' of every word after adding these L words to microblog d j m as additional content. 
		Cause: [(0, 9), (0, 12)]
		Effect: [(0, 0), (0, 6)]

	CASE: 14
	Stag: 72 73 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: where R u'\u2062' T u'\u2062' F u'\u2062' ( u'\u22c5' ) is the revised term frequency. As the Equation ( 5 ) shows, the revised term frequency of every word is proportional to probability P ( w i d j m ) rather than a constant. 
		Cause: [(1, 1), (1, 30)]
		Effect: [(0, 1), (0, 30)]

	CASE: 15
	Stag: 74 75 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: So far, we can add these L words and their revised term frequency as additional information to microblog d j m. The revised term frequency plays the same role as TF in common text representation vector, so we calculate the TFIDF of the added words as. 
		Cause: [(0, 15), (1, 24)]
		Effect: [(0, 0), (0, 13)]

	CASE: 16
	Stag: 75 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: The revised term frequency plays the same role as TF in common text representation vector, so we calculate the TFIDF of the added words as. 
		Cause: [(0, 0), (0, 14)]
		Effect: [(0, 17), (0, 25)]

	CASE: 17
	Stag: 76 77 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Note that I u'\u2062' D u'\u2062' F u'\u2062' ( w ) is changed as arrival of new words for each microblog. The TFIDF vector of a microblog with additional words is called enhanced vector. 
		Cause: [(0, 26), (1, 11)]
		Effect: [(0, 2), (0, 24)]

Section 4:  4 Experiment has 13 CE cases
	CASE: 1
	Stag: 80 81 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: After preprocessing, these news documents are used as external knowledge. As for microblog, we crawl a number of microblogs from Sina Weibo u'\u2020' u'\u2020' Sina Weibo http://www.weibo.com/ , and ask unbiased assessors to manually classify them into 9 categories following the column setting of Sina News. 
		Cause: [(0, 9), (1, 22)]
		Effect: [(0, 0), (0, 7)]

	CASE: 2
	Stag: 80 81 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: After preprocessing, these news documents are used as external knowledge. As for microblog, we crawl a number of microblogs from Sina Weibo u'\u2020' u'\u2020' Sina Weibo http://www.weibo.com/ , and ask unbiased assessors to manually classify them into 9 categories following the column setting of Sina News. 
		Cause: [(1, 1), (1, 27)]
		Effect: [(0, 0), (0, 10)]

	CASE: 3
	Stag: 83 84 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Finally, we get 1671 classified microblogs as our microblog dataset. The size of each category is shown in Table 1. 
		Cause: [(0, 8), (1, 8)]
		Effect: [(0, 0), (0, 6)]

	CASE: 4
	Stag: 95 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: By studying some cases, we find out that if we add too many words, the proportion of u'\u201c' noisy words u'\u201d' will increase. 
		Cause: [(0, 10), (0, 14)]
		Effect: [(0, 16), (0, 32)]

	CASE: 5
	Stag: 96 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: We reach the best result when number of added words is 300. 
		Cause: [(0, 0), (0, 1)]
		Effect: [(0, 11), (0, 11)]

	CASE: 6
	Stag: 97 98 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The experiment corresponding to Figure 2 is to discover how the classification accuracy changes when we fix the number of added words ( L = 300 ) and change the number of topics ( K ) in our method. As we can see, the accuracy does not grow monotonously as the number of topics increases. 
		Cause: [(1, 1), (1, 16)]
		Effect: [(0, 0), (0, 38)]

	CASE: 7
	Stag: 101 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The experiment corrsponding to Figure 3 is to discover whether our redefining u'\u201c' term frequency u'\u201d' as revised term frequency in step (c) of Section 3.3 will affect the classification accuracy and how. 
		Cause: [(0, 25), (0, 42)]
		Effect: [(0, 0), (0, 23)]

	CASE: 8
	Stag: 103 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: On one hand, without redefinition, the accuracy remains in a stable high level and tends to decrease as we add more words. 
		Cause: [(0, 20), (0, 23)]
		Effect: [(0, 0), (0, 18)]

	CASE: 9
	Stag: 104 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: One reason for the decreasing is that u'\u201c' noisy words u'\u201d' have a increasing negative impact on the accuracy as the proportion of u'\u201c' noisy words u'\u201d' grows with the number of added words. 
		Cause: [(0, 28), (0, 49)]
		Effect: [(0, 0), (0, 26)]

	CASE: 10
	Stag: 108 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: In the first case, we successfully find the country name according to its leader u'\u2019' s name and limited information in the sentence. 
		Cause: [(0, 13), (0, 27)]
		Effect: [(0, 0), (0, 10)]

	CASE: 11
	Stag: 109 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Other related countries and events are also selected by our model as they often appear together in news. 
		Cause: [(0, 12), (0, 17)]
		Effect: [(0, 0), (0, 10)]

	CASE: 12
	Stag: 110 111 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In the other case, relevant words are among the most frequently used words in news and have close semantic relations with the microblogs in certain aspects. As we can see, based on topic analysis, our model shows strong ability of mining relevant words. 
		Cause: [(1, 1), (1, 18)]
		Effect: [(0, 0), (0, 26)]

	CASE: 13
	Stag: 112 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Other cases show that the model can be further improved by removing the noisy and meaningless ones among added words. 
		Cause: [(0, 11), (0, 19)]
		Effect: [(0, 0), (0, 9)]

Section 5:  5 Conclusion and Future Work has 2 CE cases
	CASE: 1
	Stag: 114 115 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: News corpus is exploited as external knowledge. As for techniques, our method uses LDA as its topic analysis model and formulates topic inference for new data as convex optimization problems. 
		Cause: [(1, 1), (1, 23)]
		Effect: [(0, 0), (0, 6)]

	CASE: 2
	Stag: 116 117 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Compared with traditional representation, enriched microblog shows great improvement in classification tasks. As we do not control the quality of added words, our future work starts from building a filter to select better additional information. 
		Cause: [(1, 1), (1, 23)]
		Effect: [(0, 0), (0, 12)]

#-------------------------------------------------

