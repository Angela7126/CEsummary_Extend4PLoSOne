Current File: P14-2052.xhtml_2 P14-2052.xhtml

Section 0:  Abstract
	SentNum: 5
	CENum: 3
	SentCovered: 3
	Covered_Rate: 60.0000%

Section 1:  1 Introduction
	SentNum: 22
	CENum: 10
	SentCovered: 12
	Covered_Rate: 54.5455%

Section 2:  2 Related work
	SentNum: 10
	CENum: 2
	SentCovered: 3
	Covered_Rate: 30.0000%

Section 3:  3 Generating summary from nested tree
	SentNum: 43
	CENum: 11
	SentCovered: 12
	Covered_Rate: 27.9070%

Section 4:  4 Experiment
	SentNum: 48
	CENum: 17
	SentCovered: 22
	Covered_Rate: 45.8333%

Section 5:  5 Conclusion
	SentNum: 12
	CENum: 4
	SentCovered: 5
	Covered_Rate: 41.6667%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-2052.xhtml_2's CE cases

Section 0:  Abstract has 3 CE cases
	CASE: 1
	Stag: 2 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We used both dependency between words and dependency between sentences by constructing a nested tree, in which nodes in the document tree representing dependency between sentences were replaced by a sentence tree representing dependency between words. 
		Cause: [(0, 11), (0, 36)]
		Effect: [(0, 0), (0, 9)]

	CASE: 2
	Stag: 3 4 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We formulated a summarization task as a combinatorial optimization problem, in which the nested tree was trimmed without losing important content in the source document. The results from an empirical evaluation revealed that our method based on the trimming of the nested tree significantly improved the summarization of texts. 
		Cause: [(0, 6), (1, 22)]
		Effect: [(0, 0), (0, 4)]

	CASE: 3
	Stag: 4 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: The results from an empirical evaluation revealed that our method based on the trimming of the nested tree significantly improved the summarization of texts. 
		Cause: [(0, 12), (0, 23)]
		Effect: [(0, 0), (0, 9)]

Section 1:  1 Introduction has 10 CE cases
	CASE: 1
	Stag: 5 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Extractive summarization is one well-known approach to text summarization and extractive methods represent a document (or a set of documents) as a set of some textual units (e.g.,, sentences, clauses, and words) and select their subset as a summary. 
		Cause: [(0, 23), (0, 42)]
		Effect: [(0, 1), (0, 21)]

	CASE: 2
	Stag: 5 6 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Extractive summarization is one well-known approach to text summarization and extractive methods represent a document (or a set of documents) as a set of some textual units (e.g.,, sentences, clauses, and words) and select their subset as a summary. Formulating extractive summarization as a combinational optimization problem greatly improves the quality of summarization [ 16 , 8 , 20 ]. 
		Cause: [(1, 4), (1, 20)]
		Effect: [(0, 1), (1, 2)]

	CASE: 3
	Stag: 8 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We can only extract important content by trimming redundant parts from sentences. 
		Cause: [(0, 7), (0, 11)]
		Effect: [(0, 0), (0, 5)]

	CASE: 4
	Stag: 13 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: They formulated the summarization problem as a tree knapsack problem with constraints represented by the dependency trees. 
		Cause: [(0, 6), (0, 15)]
		Effect: [(0, 0), (0, 4)]

	CASE: 5
	Stag: 16 17 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: First, we represent a document as a nested tree , which is composed of two types of tree structures a document tree and a sentence tree. The document tree is a tree that has sentences as nodes and head modifier relationships between sentences obtained by RST as edges. 
		Cause: [(0, 7), (1, 20)]
		Effect: [(0, 0), (0, 5)]

	CASE: 6
	Stag: 17 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The document tree is a tree that has sentences as nodes and head modifier relationships between sentences obtained by RST as edges. 
		Cause: [(0, 10), (0, 20)]
		Effect: [(0, 0), (0, 8)]

	CASE: 7
	Stag: 18 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The sentence tree is a tree that has words as nodes and head modifier relationships between words obtained by the dependency parser as edges. 
		Cause: [(0, 10), (0, 22)]
		Effect: [(0, 0), (0, 8)]

	CASE: 8
	Stag: 19 20 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We can build the nested tree by regarding each node of the document tree as a sentence tree. Finally, we formulate the problem of single document summarization as that of combinatorial optimization, which is based on the trimming of the nested tree. 
		Cause: [(0, 15), (1, 24)]
		Effect: [(0, 0), (0, 13)]

	CASE: 9
	Stag: 20 21 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Finally, we formulate the problem of single document summarization as that of combinatorial optimization, which is based on the trimming of the nested tree. Our method jointly utilizes relations between sentences and relations between words, and extracts a rooted document subtree from a document tree whose nodes are arbitrary subtrees of the sentence tree. 
		Cause: [(0, 11), (1, 27)]
		Effect: [(0, 0), (0, 9)]

	CASE: 10
	Stag: 25 26 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: We converted the rhetorical relations between EDUs to the relations between sentences to build the nested tree structure. We could thus take into account both relations between sentences and relations between words. 
		Cause: [(0, 1), (1, 1)]
		Effect: [(1, 3), (1, 13)]

Section 2:  2 Related work has 2 CE cases
	CASE: 1
	Stag: 31 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: However, it is not trivial to apply their method to text summarization because no compression ratio is given to sentences. 
		Cause: [(0, 14), (0, 20)]
		Effect: [(0, 0), (0, 12)]

	CASE: 2
	Stag: 34 35 
		Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&ADV)'], ['(&THIS)', '&NP', '&R']]
		sentTXT: Although their method generated a well-organized summary, no optimality of information coverage was guaranteed and their method could not accept large texts because of the high computational cost. In addition, their method required large sets of data to calculate the accurate probability. 
		Cause: [(0, 0), (0, 22)]
		Effect: [(1, 2), (1, 14)]

Section 3:  3 Generating summary from nested tree has 11 CE cases
	CASE: 1
	Stag: 47 48 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: Each root EDU in a sentence has the parent EDU in another sentence. Hence, we can determine the parent-child relations between sentences. 
		Cause: [(0, 0), (0, 12)]
		Effect: [(1, 2), (1, 9)]

	CASE: 2
	Stag: 48 49 
		Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
		sentTXT: Hence, we can determine the parent-child relations between sentences. As a result, we obtain a tree that represents the parent-child relations of sentences, and we can use it as a document tree. 
		Cause: [(0, 0), (0, 9)]
		Effect: [(1, 4), (1, 24)]

	CASE: 3
	Stag: 52 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Our method generates a summary by trimming a nested tree. 
		Cause: [(0, 6), (0, 9)]
		Effect: [(0, 0), (0, 4)]

	CASE: 4
	Stag: 56 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Let us denote by w i u'\u2062' j the term weight of word i u'\u2062' j (word j in sentence i x i is a variable that is one if sentence i is selected as part of a summary, and z i u'\u2062' j is a variable that is one if word i u'\u2062' j is selected as part of a summary. 
		Cause: [(0, 44), (0, 78)]
		Effect: [(0, 7), (0, 42)]

	CASE: 5
	Stag: 55 56 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Our model is shown in Figure 3. Let us denote by w i u'\u2062' j the term weight of word i u'\u2062' j (word j in sentence i x i is a variable that is one if sentence i is selected as part of a summary, and z i u'\u2062' j is a variable that is one if word i u'\u2062' j is selected as part of a summary. 
		Cause: [(0, 0), (0, 34)]
		Effect: [(0, 0), (0, 30)]

	CASE: 6
	Stag: 56 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Let us denote by w i u'\u2062' j the term weight of word i u'\u2062' j (word j in sentence i x i is a variable that is one if sentence i is selected as part of a summary, and z i u'\u2062' j is a variable that is one if word i u'\u2062' j is selected as part of a summary. 
		Cause: [(0, 32), (0, 35)]
		Effect: [(0, 0), (0, 30)]

	CASE: 7
	Stag: 56 57 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Let us denote by w i u'\u2062' j the term weight of word i u'\u2062' j (word j in sentence i x i is a variable that is one if sentence i is selected as part of a summary, and z i u'\u2062' j is a variable that is one if word i u'\u2062' j is selected as part of a summary. According to the objective function, the score for the resulting summary is the sum of the term weights w i u'\u2062' j that are included in the summary. 
		Cause: [(0, 0), (1, 8)]
		Effect: [(1, 13), (1, 32)]

	CASE: 8
	Stag: 58 59 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We denote by r i u'\u2062' j the variable that is one if word i u'\u2062' j is selected as a root of an extracting sentence subtree. Constraint ( 1 ) guarantees that the summary length will be less than or equal to limit L. 
		Cause: [(0, 28), (1, 16)]
		Effect: [(0, 5), (0, 26)]

	CASE: 9
	Stag: 60 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Constraints ( 2 ) and ( 3 ) are tree constraints for a document tree and sentence trees r i u'\u2062' j in Constraint ( 3 ) allows the system to extract non-rooted sentence subtrees, as we previously mentioned. 
		Cause: [(0, 41), (0, 43)]
		Effect: [(0, 0), (0, 38)]

	CASE: 10
	Stag: 67 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We can set the candidate for the root node of the subtree by using constraint ( 7. 
		Cause: [(0, 13), (0, 14)]
		Effect: [(0, 0), (0, 11)]

	CASE: 11
	Stag: 74 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Constraints ( 11 ) and ( 12 ) guarantee that the selected sentence subtree has at least one subject and one object if it has any. 
		Cause: [(0, 23), (0, 25)]
		Effect: [(0, 4), (0, 21)]

Section 4:  4 Experiment has 17 CE cases
	CASE: 1
	Stag: 84 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: This dataset was first used by Marcu et al for evaluating a text summarization system [ 15 ]. 
		Cause: [(0, 10), (0, 17)]
		Effect: [(0, 0), (0, 8)]

	CASE: 2
	Stag: 85 86 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We used ROUGE [ 13 ] as an evaluation criterion. We compared our method ( sentence subtree ) with that of EDU selection [ 11 ]. 
		Cause: [(0, 7), (1, 14)]
		Effect: [(0, 0), (0, 5)]

	CASE: 3
	Stag: 89 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Rooted sentence subtree only selects rooted sentence subtrees 2 2 We achieved this by making R c u'\u2062' ( i ) only return the parser u'\u2019' s root node in Figure 7. 
		Cause: [(0, 14), (0, 39)]
		Effect: [(0, 1), (0, 12)]

	CASE: 4
	Stag: 91 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: It simply selects full sentences from a document tree 3 3 We achieved this by setting u'\u0398' to a very large number. 
		Cause: [(0, 15), (0, 25)]
		Effect: [(0, 0), (0, 13)]

	CASE: 5
	Stag: 100 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: We applied a multiple test by using Holm u'\u2019' s method and found that our method significantly outperformed EDU selection and sentence selection. 
		Cause: [(0, 6), (0, 14)]
		Effect: [(0, 15), (0, 26)]

	CASE: 6
	Stag: 101 102 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: The difference between the sentence subtree and the rooted sentence subtree methods was fairly small. We therefore qualitatively analyzed some actual examples that will be discussed in Section 4.2.2. 
		Cause: [(0, 1), (1, 0)]
		Effect: [(1, 2), (1, 13)]

	CASE: 7
	Stag: 107 108 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Figure 4 has two example sentences for which both methods selected a subtree as part of a summary. The { u'\u22c5' } indicates the parser u'\u2019' s root word. 
		Cause: [(0, 14), (1, 17)]
		Effect: [(0, 0), (0, 12)]

	CASE: 8
	Stag: 108 
		Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: The { u'\u22c5' } indicates the parser u'\u2019' s root word. 
		Cause: [(0, 0), (0, 7)]
		Effect: [(0, 9), (0, 18)]

	CASE: 9
	Stag: 109 
		Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: The [ u'\u22c5' ] indicates the word that the system selected as the root of the subtree. 
		Cause: [(0, 0), (0, 7)]
		Effect: [(0, 9), (0, 20)]

	CASE: 10
	Stag: 110 111 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Subtree selection selected a root in both examples that differed from the parser u'\u2019' s root. As we can see, subtree selection only selected important subtrees that did not include the parser u'\u2019' s root, e.g.,, purpose-clauses and that-clauses. 
		Cause: [(1, 1), (1, 30)]
		Effect: [(0, 0), (0, 19)]

	CASE: 11
	Stag: 112 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: This capability is very effective because we have to contain important content in summaries within given length limits, especially when the compression ratio is high (i.e.,, the method has to generate much shorter summaries than the source documents. 
		Cause: [(0, 6), (0, 17)]
		Effect: [(0, 19), (0, 41)]

	CASE: 12
	Stag: 113 114 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Many studies that have utilized RST have simply adopted EDUs as textual units [ 14 , 6 , 11 , 12 ]. While EDUs are textual units for RST, they are too fine grained as textual units for methods of extractive summarization. 
		Cause: [(0, 11), (1, 19)]
		Effect: [(0, 0), (0, 9)]

	CASE: 13
	Stag: 114 115 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: While EDUs are textual units for RST, they are too fine grained as textual units for methods of extractive summarization. Therefore, the models have tended to select small fragments from many sentences to maximize objective functions and have led to fragmented summaries being generated. 
		Cause: [(0, 14), (1, 23)]
		Effect: [(0, 0), (0, 12)]

	CASE: 14
	Stag: 114 115 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: While EDUs are textual units for RST, they are too fine grained as textual units for methods of extractive summarization. Therefore, the models have tended to select small fragments from many sentences to maximize objective functions and have led to fragmented summaries being generated. 
		Cause: [(0, 0), (0, 20)]
		Effect: [(1, 2), (1, 24)]

	CASE: 15
	Stag: 117 118 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: A fragmented summary is generated when small fragments are selected from many sentences. Hence, the number of sentences in the source document included in the resulting summary can be an indicator to measure the fragmentation of information. 
		Cause: [(0, 0), (0, 12)]
		Effect: [(1, 2), (1, 24)]

	CASE: 16
	Stag: 119 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: We counted the number of sentences in the source document that each method used to generate a summary 5 5 Note that the number for the EDU method is not equal to selected textual units because a sentence in the source document may contain multiple EDUs. 
		Cause: [(0, 36), (0, 45)]
		Effect: [(0, 0), (0, 34)]

	CASE: 17
	Stag: 126 127 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: It indicates that EDUs are shorter than the other textual units. Hence, the number of sentences tends to be large. 
		Cause: [(0, 0), (0, 10)]
		Effect: [(1, 2), (1, 9)]

Section 5:  5 Conclusion has 4 CE cases
	CASE: 1
	Stag: 133 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Although ROUGE scores are widely used as evaluation metrics for text summarization systems, they cannot take into consideration linguistic qualities such as human readability. 
		Cause: [(0, 7), (0, 25)]
		Effect: [(0, 1), (0, 5)]

	CASE: 2
	Stag: 133 134 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: Although ROUGE scores are widely used as evaluation metrics for text summarization systems, they cannot take into consideration linguistic qualities such as human readability. Hence, we plan to conduct evaluations with people 7 7 For example, the quality question metric from the Document Understanding Conference (DUC. 
		Cause: [(0, 0), (0, 25)]
		Effect: [(1, 2), (1, 24)]

	CASE: 3
	Stag: 136 137 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: However, there were also rhetorical structures between EDUs inside individual sentences. Hence, utilizing these for sentence compression has been left for future work. 
		Cause: [(0, 0), (0, 11)]
		Effect: [(1, 2), (1, 12)]

	CASE: 4
	Stag: 139 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: There have been related studies on building RST parsers [ 7 , 1 ] and by using such parsers, we should be able to apply our model to other corpora or to multi-document settings. 
		Cause: [(0, 16), (0, 18)]
		Effect: [(0, 19), (0, 34)]

#-------------------------------------------------

