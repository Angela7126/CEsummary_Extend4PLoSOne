Current File: P14-1097.xhtml_2 P14-1097.xhtml

Section 0:  Abstract
	SentNum: 5
	CENum: 5
	SentCovered: 4
	Covered_Rate: 80.0000%

Section 1:  1 Introduction
	SentNum: 17
	CENum: 6
	SentCovered: 6
	Covered_Rate: 35.2941%

Section 2:  2 Related Work
	SentNum: 45
	CENum: 15
	SentCovered: 16
	Covered_Rate: 35.5556%

Section 3:  3 Our Approach
	SentNum: 66
	CENum: 19
	SentCovered: 21
	Covered_Rate: 31.8182%

Section 4:  4 Experiments and Evaluations
	SentNum: 129
	CENum: 35
	SentCovered: 36
	Covered_Rate: 27.9070%

Section 5:  5 Conclusion
	SentNum: 11
	CENum: 7
	SentCovered: 7
	Covered_Rate: 63.6364%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-1097.xhtml_2's CE cases

Section 0:  Abstract has 5 CE cases
	CASE: 1
	Stag: 0 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: We present an unsupervised method for inducing verb classes from verb uses in giga-word corpora. 
		Cause: [(0, 6), (0, 14)]
		Effect: [(0, 0), (0, 4)]

	CASE: 2
	Stag: 1 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: Our method consists of two clustering steps verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames. 
		Cause: [(0, 14), (0, 19)]
		Effect: [(0, 20), (0, 29)]

	CASE: 3
	Stag: 1 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Our method consists of two clustering steps verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames. 
		Cause: [(0, 7), (0, 9)]
		Effect: [(0, 3), (0, 5)]

	CASE: 4
	Stag: 2 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: By taking this step-wise approach, we can not only generate verb classes based on a massive amount of verb uses in a scalable manner, but also deal with verb polysemy, which is bypassed by most of the previous studies on verb clustering. 
		Cause: [(0, 15), (0, 24)]
		Effect: [(0, 26), (0, 44)]

	CASE: 5
	Stag: 4 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: The effectiveness of our approach is verified through quantitative evaluations based on polysemy-aware gold-standard data. 
		Cause: [(0, 12), (0, 14)]
		Effect: [(0, 0), (0, 9)]

Section 1:  1 Introduction has 6 CE cases
	CASE: 1
	Stag: 6 7 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: Capturing the sense of a verb is essential for natural language processing (NLP), and thus lexical resources for verbs play an important role in NLP. Verb classes are one such lexical resource. 
		Cause: [(0, 0), (0, 14)]
		Effect: [(0, 18), (1, 5)]

	CASE: 2
	Stag: 12 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: This monosemous assumption, however, is not realistic because many frequent verbs actually have multiple senses. 
		Cause: [(0, 10), (0, 16)]
		Effect: [(0, 0), (0, 8)]

	CASE: 3
	Stag: 14 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: In this paper, we propose an unsupervised method for inducing verb classes that is aware of verb polysemy. 
		Cause: [(0, 10), (0, 18)]
		Effect: [(0, 0), (0, 8)]

	CASE: 4
	Stag: 15 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: Our method consists of two clustering steps verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames. 
		Cause: [(0, 14), (0, 19)]
		Effect: [(0, 20), (0, 29)]

	CASE: 5
	Stag: 15 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Our method consists of two clustering steps verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames. 
		Cause: [(0, 7), (0, 9)]
		Effect: [(0, 3), (0, 5)]

	CASE: 6
	Stag: 16 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: By taking this step-wise approach, we can not only induce verb classes with frequency information from a massive amount of verb uses in a scalable manner, but also deal with verb polysemy. 
		Cause: [(0, 1), (0, 4)]
		Effect: [(0, 5), (0, 33)]

Section 2:  2 Related Work has 15 CE cases
	CASE: 1
	Stag: 28 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: 2009 ) proposed a Dirichlet process mixture model (DPMM; Neal ( 2000 ) ) to cluster verbs based on subcategorization frame distributions. 
		Cause: [(0, 21), (0, 23)]
		Effect: [(0, 0), (0, 18)]

	CASE: 2
	Stag: 31 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: 2006 ) ) model to jointly learn argument structures (subcategorization frames) and verb classes by using syntactic features. 
		Cause: [(0, 17), (0, 19)]
		Effect: [(0, 0), (0, 15)]

	CASE: 3
	Stag: 32 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Parisien and Stevenson ( 2011 ) extended their model by adding semantic features. 
		Cause: [(0, 10), (0, 12)]
		Effect: [(0, 0), (0, 8)]

	CASE: 4
	Stag: 35 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: 2012 ) extended the model of Titov and Klementiev ( 2012 ) , which is an unsupervised model for inducing semantic roles, to jointly induce semantic roles and frames across verbs using the Chinese Restaurant Process [ 1 ]. 
		Cause: [(0, 19), (0, 21)]
		Effect: [(0, 0), (0, 17)]

	CASE: 5
	Stag: 46 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: In particular, they tried to consider verb polysemy by using the IB method, which is a soft clustering method [ 43 ]. 
		Cause: [(0, 10), (0, 23)]
		Effect: [(0, 0), (0, 8)]

	CASE: 6
	Stag: 47 48 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: However, the verb itself is still represented as a single data point. After performing soft clustering, they noted that most verbs fell into a single class, and they decided to assign a single class to each verb by hardening the clustering. 
		Cause: [(0, 9), (1, 13)]
		Effect: [(0, 0), (0, 7)]

	CASE: 7
	Stag: 48 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: After performing soft clustering, they noted that most verbs fell into a single class, and they decided to assign a single class to each verb by hardening the clustering. 
		Cause: [(0, 28), (0, 30)]
		Effect: [(0, 12), (0, 26)]

	CASE: 8
	Stag: 51 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: Lapata and Brew ( 2004 ) and Li and Brew ( 2007 ) proposed probabilistic models for calculating prior probabilities of verb classes for a verb. 
		Cause: [(0, 17), (0, 25)]
		Effect: [(0, 0), (0, 15)]

	CASE: 9
	Stag: 52 53 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: These models are approximated to condition not on verbs but on subcategorization frames. As mentioned in Li and Brew ( 2007 ) , it is desirable to extend the model to depend on verbs to further improve accuracy. 
		Cause: [(1, 1), (1, 24)]
		Effect: [(0, 0), (0, 12)]

	CASE: 10
	Stag: 56 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: 2008 ) also applied probabilistic soft clustering to verbs by incorporating subcategorization frames and selectional preferences based on WordNet. 
		Cause: [(0, 18), (0, 18)]
		Effect: [(0, 0), (0, 15)]

	CASE: 11
	Stag: 56 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: 2008 ) also applied probabilistic soft clustering to verbs by incorporating subcategorization frames and selectional preferences based on WordNet. 
		Cause: [(0, 10), (0, 12)]
		Effect: [(0, 13), (0, 15)]

	CASE: 12
	Stag: 57 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: This model is based on the Expectation-Maximization algorithm and the Minimum Description Length principle. 
		Cause: [(0, 5), (0, 13)]
		Effect: [(0, 0), (0, 1)]

	CASE: 13
	Stag: 58 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since they focused on the incorporation of selectional preferences, they did not evaluate verb classes but evaluated only selectional preferences using a language model-based measure. 
		Cause: [(0, 1), (0, 8)]
		Effect: [(0, 10), (0, 25)]

	CASE: 14
	Stag: 61 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: He used a model based on latent Dirichlet allocation (LDA; Blei et al. 
		Cause: [(0, 6), (0, 14)]
		Effect: [(0, 0), (0, 3)]

	CASE: 15
	Stag: 63 64 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Both of these are represented as a probabilistic distribution of words across verbs. He applied this method to the BNC and acquired 1,200 frames and 400 roles [ 21 ]. 
		Cause: [(0, 6), (1, 14)]
		Effect: [(0, 0), (0, 4)]

Section 3:  3 Our Approach has 19 CE cases
	CASE: 1
	Stag: 68 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Although Bayesian approaches are a possible solution to simultaneously induce frames and verb classes from a corpus as used in previous studies, it has prohibitive computational cost. 
		Cause: [(0, 18), (0, 27)]
		Effect: [(0, 1), (0, 16)]

	CASE: 2
	Stag: 75 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: In this paper, we propose a two-step approach for inducing semantic frames and verb classes. 
		Cause: [(0, 10), (0, 15)]
		Effect: [(0, 0), (0, 8)]

	CASE: 3
	Stag: 76 77 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: First, we make multiple data points for each verb to deal with verb polysemy (cf polysemy-aware previous studies still represented a verb as one data point [ 14 , 23 ]. To do that, we induce verb-specific semantic frames by clustering verb uses. 
		Cause: [(0, 25), (1, 12)]
		Effect: [(0, 0), (0, 23)]

	CASE: 4
	Stag: 78 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Then, we induce verb classes by clustering these verb-specific semantic frames across verbs. 
		Cause: [(0, 7), (0, 13)]
		Effect: [(0, 0), (0, 5)]

	CASE: 5
	Stag: 81 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: induce verb-specific semantic frames by clustering predicate-argument structures for each verb extracted from automatic parses as shown in the lower part of Figure 1 , and. 
		Cause: [(0, 5), (0, 14)]
		Effect: [(0, 15), (0, 25)]

	CASE: 6
	Stag: 82 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: induce verb classes by clustering the induced semantic frames across verbs as shown in the upper part of Figure 1. 
		Cause: [(0, 4), (0, 10)]
		Effect: [(0, 11), (0, 19)]

	CASE: 7
	Stag: 84 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: We induce verb-specific semantic frames from verb uses based on the method of Kawahara et al. 
		Cause: [(0, 10), (0, 15)]
		Effect: [(0, 0), (0, 7)]

	CASE: 8
	Stag: 89 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: merge the predicate-argument structures that have presumably the same meaning based on the assumption of one sense per collocation [ 46 ] to get a set of initial frames, and. 
		Cause: [(0, 12), (0, 30)]
		Effect: [(0, 0), (0, 9)]

	CASE: 9
	Stag: 90 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: apply clustering to the initial frames based on the Chinese Restaurant Process [ 1 ] to produce verb-specific semantic frames. 
		Cause: [(0, 8), (0, 19)]
		Effect: [(0, 0), (0, 5)]

	CASE: 10
	Stag: 104 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We select an argument in the following order by considering the degree of effect on the verb sense. 
		Cause: [(0, 9), (0, 17)]
		Effect: [(0, 0), (0, 7)]

	CASE: 11
	Stag: 105 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: 3 3 If a predicate-argument structure has multiple prepositional phrases, one of them is randomly selected. 
		Cause: [(0, 3), (0, 9)]
		Effect: [(0, 11), (0, 16)]

	CASE: 12
	Stag: 113 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: P ( f i c j ) is defined based on the Dirichlet-Multinomial distribution as follows. 
		Cause: [(0, 11), (0, 15)]
		Effect: [(0, 0), (0, 8)]

	CASE: 13
	Stag: 115 116 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The original method in Kawahara et al. 2014 ) defined w as pairs of slots and words, e.g.,, u'\u201c' nsubj:child u'\u201d' and u'\u201c' dobj:bird, u'\u201d' but does not consider slot-only features, e.g.,, u'\u201c' nsubj u'\u201d' and u'\u201c' dobj, u'\u201d' which ignore lexical information. 
		Cause: [(1, 5), (1, 79)]
		Effect: [(0, 4), (1, 3)]

	CASE: 14
	Stag: 122 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We regard each output cluster as a semantic frame, by merging the initial frames in a cluster into a semantic frame. 
		Cause: [(0, 11), (0, 21)]
		Effect: [(0, 0), (0, 9)]

	CASE: 15
	Stag: 126 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We can use exactly the same clustering method as described in Section 3.2.3 by using semantic frames for multiple verbs as an input instead of initial frames for a single verb. 
		Cause: [(0, 14), (0, 30)]
		Effect: [(0, 0), (0, 12)]

	CASE: 16
	Stag: 127 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: This is because an initial frame has the same structure as a semantic frame, which is produced by merging initial frames. 
		Cause: [(0, 3), (0, 13)]
		Effect: [(0, 15), (0, 21)]

	CASE: 17
	Stag: 128 129 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We regard each output cluster as a verb class this time. For the features, w , in equation ( 2 ), we try the two representations again slot-only features and slot-word pair features. 
		Cause: [(0, 6), (1, 22)]
		Effect: [(0, 0), (0, 4)]

	CASE: 18
	Stag: 131 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: The other representation using the slot-word pairs means that semantic similarity based on word overlap is naturally considered by looking at lexical information. 
		Cause: [(0, 13), (0, 22)]
		Effect: [(0, 0), (0, 10)]

	CASE: 19
	Stag: 131 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The other representation using the slot-word pairs means that semantic similarity based on word overlap is naturally considered by looking at lexical information. 
		Cause: [(0, 6), (0, 9)]
		Effect: [(0, 0), (0, 4)]

Section 4:  4 Experiments and Evaluations has 35 CE cases
	CASE: 1
	Stag: 135 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: These two levels of evaluations are performed by considering the work of Reichart et al. 
		Cause: [(0, 8), (0, 14)]
		Effect: [(0, 0), (0, 6)]

	CASE: 2
	Stag: 139 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: To prepare a web corpus, we extracted sentences from crawled web pages that are judged to be written in English based on the encoding information. 
		Cause: [(0, 23), (0, 25)]
		Effect: [(0, 0), (0, 20)]

	CASE: 3
	Stag: 153 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: However, since these measures are only applicable to a hard clustering, it is necessary to extend them to be applicable to a soft clustering, because in our task a verb can belong to multiple clusters or classes. 
		Cause: [(0, 3), (0, 11)]
		Effect: [(0, 13), (0, 39)]

	CASE: 4
	Stag: 153 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: However, since these measures are only applicable to a hard clustering, it is necessary to extend them to be applicable to a soft clustering, because in our task a verb can belong to multiple clusters or classes. 
		Cause: [(0, 15), (0, 26)]
		Effect: [(0, 0), (0, 12)]

	CASE: 5
	Stag: 155 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: 2003 ) evaluated hard clusterings based on a gold standard with multiple classes per verb. 
		Cause: [(0, 7), (0, 14)]
		Effect: [(0, 0), (0, 4)]

	CASE: 6
	Stag: 166 167 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In addition, to penalize clusters that consist of only one verb, such singleton clusters in K are considered as errors, as is usual with modified purity. The normalized modified purity (nmPU) can then be written as follows. 
		Cause: [(0, 21), (1, 11)]
		Effect: [(0, 0), (0, 19)]

	CASE: 7
	Stag: 169 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: K i denotes the number of positive components in K i , and c i u'\u2062' v denotes the v -th component of K i u'\u0394' K i u'\u2062' ( K i u'\u2229' G j ) means the total mass of the set of verbs in K i u'\u2229' G j , given by summing up the values in K i. 
		Cause: [(0, 75), (0, 81)]
		Effect: [(0, 3), (0, 73)]

	CASE: 8
	Stag: 171 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: K i u'\u2229' G j because all the values of c i u'\u2062' v are equal to 1. 
		Cause: [(0, 10), (0, 25)]
		Effect: [(0, 0), (0, 8)]

	CASE: 9
	Stag: 171 172 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: K i u'\u2229' G j because all the values of c i u'\u2062' v are equal to 1. As usual, the following normalized inverse purity (niPU) is used to measure the recall of a clustering. 
		Cause: [(1, 1), (1, 19)]
		Effect: [(0, 0), (0, 25)]

	CASE: 10
	Stag: 173 174 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Finally, we use the harmonic mean (F 1 ) of nmPU and niPU as a single measure of clustering quality. We first evaluate our induced verb classes on the test set created by Korhonen et al. 
		Cause: [(0, 16), (1, 14)]
		Effect: [(0, 0), (0, 14)]

	CASE: 11
	Stag: 175 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: 2003 ) (Table 1 of their paper) which was created by considering verb polysemy on the basis of Levin u'\u2019' s classes and the LCS database [ 6 ]. 
		Cause: [(0, 13), (0, 18)]
		Effect: [(0, 19), (0, 28)]

	CASE: 12
	Stag: 178 179 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: An excerpt from this data is shown in Table 1. As our baselines, we adopt two previously proposed methods. 
		Cause: [(1, 1), (1, 9)]
		Effect: [(0, 0), (0, 9)]

	CASE: 13
	Stag: 187 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: 2003 ) , prepositional phrases (pp) are parameterized for two frequent subcategorization frames (NP and NP_PP), and the unfiltered raw frequencies of subcategorization frames are used as features to represent a verb. 
		Cause: [(0, 32), (0, 34)]
		Effect: [(0, 10), (0, 30)]

	CASE: 14
	Stag: 188 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: It is necessary to specify the number of clusters, k , for the IB method beforehand, and we adopt 35 and 42 clusters according to their reported high accuracies. 
		Cause: [(0, 27), (0, 30)]
		Effect: [(0, 0), (0, 24)]

	CASE: 15
	Stag: 200 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The results of the IB baseline and our methods are obtained by averaging five runs. 
		Cause: [(0, 12), (0, 14)]
		Effect: [(0, 0), (0, 10)]

	CASE: 16
	Stag: 201 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: We can see that u'\u201c' web/SW-S u'\u201d' achieved the best performance and obtained a higher F 1 than the baselines by more than nine points u'\u201c' Web/SW-S u'\u201d' uses the combination of slot-word pair features for clustering verb-specific frames and slot-only features for clustering across verbs. 
		Cause: [(0, 52), (0, 54)]
		Effect: [(0, 0), (0, 50)]

	CASE: 17
	Stag: 201 202 
		Pattern: 0 [[['imply', 'implies', 'implied', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(that)', '&R@Complete@']]
		sentTXT: We can see that u'\u201c' web/SW-S u'\u201d' achieved the best performance and obtained a higher F 1 than the baselines by more than nine points u'\u201c' Web/SW-S u'\u201d' uses the combination of slot-word pair features for clustering verb-specific frames and slot-only features for clustering across verbs. Interestingly, this result indicates that slot distributions are more effective than lexical information in slot-word pairs for inducing verb classes similar to the gold standard. 
		Cause: [(0, 1), (1, 0)]
		Effect: [(1, 6), (1, 25)]

	CASE: 18
	Stag: 203 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: This result is consistent with expectations, given a gold standard based on Levin u'\u2019' s verb classes, which are organized according to the syntactic behavior of verbs. 
		Cause: [(0, 13), (0, 21)]
		Effect: [(0, 23), (0, 32)]

	CASE: 19
	Stag: 203 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: This result is consistent with expectations, given a gold standard based on Levin u'\u2019' s verb classes, which are organized according to the syntactic behavior of verbs. 
		Cause: [(0, 5), (0, 9)]
		Effect: [(0, 0), (0, 2)]

	CASE: 20
	Stag: 208 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since we focus on the handling of verb polysemy, predominant class induction for each verb is not our main objective. 
		Cause: [(0, 1), (0, 8)]
		Effect: [(0, 10), (0, 20)]

	CASE: 21
	Stag: 210 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: To output a single class for each verb by using our proposed method, we skip the induction of verb-specific semantic frames and instead create a single frame for each verb by merging all predicate-argument structures of the verb. 
		Cause: [(0, 9), (0, 12)]
		Effect: [(0, 13), (0, 38)]

	CASE: 22
	Stag: 213 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: We evaluate the single-class output for each verb based on the predominant gold-standard classes, which are defined for each verb in the test set of Korhonen et al. 
		Cause: [(0, 10), (0, 13)]
		Effect: [(0, 15), (0, 28)]

	CASE: 23
	Stag: 217 218 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: 2003 ) , using the gold standard with multiple classes, which we also use for our multi-class evaluations. As we did with the multi-class evaluations, we adopt modified purity (mPU), inverse purity (iPU) and their harmonic mean (F 1 ) as the metrics for the evaluation with predominant classes. 
		Cause: [(1, 1), (1, 37)]
		Effect: [(0, 12), (0, 18)]

	CASE: 24
	Stag: 219 220 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: It is not necessary to normalize these metrics when we treat verbs as monosemous, and evaluate against the predominant sense. When we evaluate against the multiple classes in the gold standard, we do normalize the inverse purity. 
		Cause: [(0, 13), (1, 17)]
		Effect: [(0, 0), (0, 11)]

	CASE: 25
	Stag: 223 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The clusterings with the NN and IB methods are obtained by using the VALEX subcategorization lexicon. 
		Cause: [(0, 11), (0, 15)]
		Effect: [(0, 0), (0, 9)]

	CASE: 26
	Stag: 227 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: Note that our results of the NN and IB methods are different from those reported in their paper since the data source is different. 
		Cause: [(0, 19), (0, 23)]
		Effect: [(0, 0), (0, 17)]

	CASE: 27
	Stag: 233 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: From the result, we can see that the induced verb classes based on slot-only features did not achieve a higher F 1 than those based on slot-word pair features in many cases. 
		Cause: [(0, 27), (0, 32)]
		Effect: [(0, 0), (0, 24)]

	CASE: 28
	Stag: 233 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: From the result, we can see that the induced verb classes based on slot-only features did not achieve a higher F 1 than those based on slot-word pair features in many cases. 
		Cause: [(0, 14), (0, 24)]
		Effect: [(0, 0), (0, 11)]

	CASE: 29
	Stag: 235 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: We speculate that slot distributions are not so different among verbs when all uses of a verb are merged into one frame, and thus their discrimination power is lower than that in the intermediate construction of semantic frames. 
		Cause: [(0, 0), (0, 21)]
		Effect: [(0, 25), (0, 38)]

	CASE: 30
	Stag: 235 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: We speculate that slot distributions are not so different among verbs when all uses of a verb are merged into one frame, and thus their discrimination power is lower than that in the intermediate construction of semantic frames. 
		Cause: [(0, 0), (0, 6)]
		Effect: [(0, 8), (0, 20)]

	CASE: 31
	Stag: 242 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: It is not necessary to normalize these metrics because the clustering of these instances is hard. 
		Cause: [(0, 9), (0, 15)]
		Effect: [(0, 0), (0, 7)]

	CASE: 32
	Stag: 244 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The results of these methods are obtained by averaging five runs. 
		Cause: [(0, 8), (0, 10)]
		Effect: [(0, 0), (0, 6)]

	CASE: 33
	Stag: 251 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: 9 9 Since FrameNet frames are not assigned to all verbs of SemLink, the number of verbs is different from the evaluations against VerbNet classes. 
		Cause: [(0, 3), (0, 12)]
		Effect: [(0, 14), (0, 25)]

	CASE: 34
	Stag: 255 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Based on the best results in the above evaluations, we induced semantic frames using slot-word pair features, and then induced verb classes using slot-only features. 
		Cause: [(0, 2), (0, 8)]
		Effect: [(0, 10), (0, 26)]

	CASE: 35
	Stag: 260 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: For instance, u'\u201c' Class 2 u'\u201d' consists of the semantic frames u'\u201c' need:2 u'\u201d' and u'\u201c' say:2 u'\u201d' These frames were merged due to the high syntactic similarity of constituting slot distributions, which are comprised of a subject and a sentential complement. 
		Cause: [(0, 51), (0, 58)]
		Effect: [(0, 60), (0, 69)]

Section 5:  5 Conclusion has 7 CE cases
	CASE: 1
	Stag: 262 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: We presented a step-wise unsupervised method for inducing verb classes from instances in giga-word corpora. 
		Cause: [(0, 7), (0, 14)]
		Effect: [(0, 0), (0, 5)]

	CASE: 2
	Stag: 264 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Both clustering steps are performed with exactly the same method, which is based on the Chinese Restaurant Process. 
		Cause: [(0, 15), (0, 18)]
		Effect: [(0, 0), (0, 12)]

	CASE: 3
	Stag: 267 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: From the results, we can see that the combination of the slot-word pair features for clustering verb-specific frames and the slot-only features for clustering across verbs is the most effective and outperforms the baselines by approximately 10 points. 
		Cause: [(0, 16), (0, 18)]
		Effect: [(0, 0), (0, 14)]

	CASE: 4
	Stag: 267 268 
		Pattern: 0 [[['imply', 'implies', 'implied', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(that)', '&R@Complete@']]
		sentTXT: From the results, we can see that the combination of the slot-word pair features for clustering verb-specific frames and the slot-only features for clustering across verbs is the most effective and outperforms the baselines by approximately 10 points. This indicates that slot distributions are more effective than lexical information in slot-word pairs for the induction of verb classes, when Levin-style classes are used for evaluation. 
		Cause: [(0, 0), (0, 38)]
		Effect: [(1, 3), (1, 27)]

	CASE: 5
	Stag: 269 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: This is consistent with Levin u'\u2019' s principle of organizing verb classes according to the syntactic behavior of verbs. 
		Cause: [(0, 18), (0, 22)]
		Effect: [(0, 0), (0, 15)]

	CASE: 6
	Stag: 269 270 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This is consistent with Levin u'\u2019' s principle of organizing verb classes according to the syntactic behavior of verbs. As applications of the resulting semantic frames and verb classes, we plan to integrate them into syntactic parsing, semantic role labeling and verb sense disambiguation. 
		Cause: [(1, 1), (1, 26)]
		Effect: [(0, 0), (0, 22)]

	CASE: 7
	Stag: 271 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: For instance, Kawahara and Kurohashi ( 2006 ) improved accuracy of dependency parsing based on Japanese semantic frames automatically induced from a raw corpus. 
		Cause: [(0, 16), (0, 24)]
		Effect: [(0, 0), (0, 13)]

#-------------------------------------------------

