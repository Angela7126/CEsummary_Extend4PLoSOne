Current File: P14-1144.xhtml_2 P14-1144.xhtml

Section 0:  Abstract
	SentNum: 4
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

Section 1:  1 Introduction
	SentNum: 19
	CENum: 7
	SentCovered: 6
	Covered_Rate: 31.5789%

Section 2:  2 Corpus Information
	SentNum: 5
	CENum: 1
	SentCovered: 2
	Covered_Rate: 40.0000%

Section 3:  3 Corpus Annotation
	SentNum: 12
	CENum: 1
	SentCovered: 1
	Covered_Rate: 8.3333%

Section 4:  4 Score Prediction
	SentNum: 115
	CENum: 55
	SentCovered: 54
	Covered_Rate: 46.9565%

Section 5:  5 Evaluation
	SentNum: 73
	CENum: 42
	SentCovered: 41
	Covered_Rate: 56.1644%

Section 6:  6 Conclusion
	SentNum: 3
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-1144.xhtml_2's CE cases

Section 0:  Abstract has 0 CE cases
Section 1:  1 Introduction has 7 CE cases
	CASE: 1
	Stag: 6 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: A major weakness of many existing scoring engines such as the Intelligent Essay Assessor u'\u2122' [ 13 ] is that they adopt a holistic scoring scheme, which summarizes the quality of an essay with a single score and thus provides very limited feedback to the writer. 
		Cause: [(0, 0), (0, 41)]
		Effect: [(0, 44), (0, 50)]

	CASE: 2
	Stag: 9 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Essay grading software that provides feedback along multiple dimensions of essay quality such as E- rater /Criterion [ 1 ] has also begun to emerge. 
		Cause: [(0, 0), (0, 18)]
		Effect: [(0, 19), (0, 26)]

	CASE: 3
	Stag: 10 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: Our goal in this paper is to develop a computational model for scoring an essay along an under-investigated dimension u'\u2014' prompt adherence. 
		Cause: [(0, 12), (0, 25)]
		Effect: [(0, 0), (0, 10)]

	CASE: 4
	Stag: 16 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Regarding task formulation, while Higgins et al. focus on classifying each sentence as having either good or bad adherence to the prompt, we focus on assigning a prompt adherence score to the entire essay , allowing the score to range from one to four points at half-point increments. 
		Cause: [(0, 14), (0, 49)]
		Effect: [(0, 5), (0, 12)]

	CASE: 5
	Stag: 16 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Regarding task formulation, while Higgins et al. focus on classifying each sentence as having either good or bad adherence to the prompt, we focus on assigning a prompt adherence score to the entire essay , allowing the score to range from one to four points at half-point increments. 
		Cause: [(0, 0), (0, 8)]
		Effect: [(0, 10), (0, 35)]

	CASE: 6
	Stag: 17 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: As far as the approach is concerned, Higgins et al. adopt a knowledge-lean approach to the task, where almost all of the features they employ are computed based on a word-based semantic similarity measure known as Random Indexing [ 10 ]. 
		Cause: [(0, 31), (0, 42)]
		Effect: [(0, 0), (0, 28)]

	CASE: 7
	Stag: 22 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since progress in prompt adherence modeling is hindered in part by the lack of a publicly annotated corpus, we believe that our data set will be a valuable resource to the NLP community. 
		Cause: [(0, 1), (0, 17)]
		Effect: [(0, 19), (0, 33)]

Section 2:  2 Corpus Information has 1 CE cases
	CASE: 1
	Stag: 23 24 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We use as our corpus the 4.5 million word International Corpus of Learner English (ICLE) [ 5 ] , which consists of more than 6000 essays written by university undergraduates from 16 countries and 16 native languages who are learners of English as a Foreign Language. 91% of the ICLE texts are argumentative. 
		Cause: [(0, 3), (1, 6)]
		Effect: [(0, 0), (0, 1)]

Section 3:  3 Corpus Annotation has 1 CE cases
	CASE: 1
	Stag: 38 
		Pattern: 2 [['for', 'the', 'sake', 'of'], [',']]---- [[], ['&V-ing/&NP@C@'], ['&R']]
		sentTXT: For the sake of our experiments, whenever annotators disagree on an essay u'\u2019' s prompt adherence score, we assign the essay the average of all annotations rounded to the nearest half point. 
		Cause: [(0, 4), (0, 5)]
		Effect: [(0, 7), (0, 37)]

Section 4:  4 Score Prediction has 55 CE cases
	CASE: 1
	Stag: 40 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: In this section, we describe in detail our system for predicting essays u'\u2019' prompt adherence scores. 
		Cause: [(0, 11), (0, 20)]
		Effect: [(0, 0), (0, 9)]

	CASE: 2
	Stag: 41 42 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We cast the problem of predicting an essay u'\u2019' s prompt adherence score as 13 regression problems, one for each prompt. Each essay is represented as an instance whose label is the essay u'\u2019' s true score (one of the values shown in Table 3 ) with up to seven types of features including baseline (Section 4.2) and six other feature types proposed by us (Section 4.3. 
		Cause: [(0, 18), (1, 52)]
		Effect: [(0, 0), (0, 16)]

	CASE: 3
	Stag: 42 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Each essay is represented as an instance whose label is the essay u'\u2019' s true score (one of the values shown in Table 3 ) with up to seven types of features including baseline (Section 4.2) and six other feature types proposed by us (Section 4.3. 
		Cause: [(0, 5), (0, 52)]
		Effect: [(0, 0), (0, 3)]

	CASE: 4
	Stag: 48 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If he was alive at the end of the 20th century, he would replace religion with television, u'\u201d' students sometimes write essays about all the evils of television, forgetting that their essay is only supposed to be about whether it is u'\u201c' the opium of the masses u'\u201d'. 
		Cause: [(0, 1), (0, 10)]
		Effect: [(0, 12), (0, 62)]

	CASE: 5
	Stag: 53 54 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The test instances are created in the same way as the training instances. Our baseline system for score prediction employs various features based on Random Indexing. 
		Cause: [(0, 10), (1, 11)]
		Effect: [(0, 0), (0, 8)]

	CASE: 6
	Stag: 54 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Our baseline system for score prediction employs various features based on Random Indexing. 
		Cause: [(0, 11), (0, 12)]
		Effect: [(0, 0), (0, 8)]

	CASE: 7
	Stag: 57 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: We expect that features based on RI will be useful for prompt adherence scoring because they may help us find text related to the prompt even if some of its concepts have have been rephrased (e.g.,, an essay may talk about u'\u201c' jail u'\u201d' rather than u'\u201c' prison u'\u201d' , which is mentioned in one of the prompts), and because they have already proven useful for the related task of determining which sentences in an essay are related to the prompt [ 7 ]. 
		Cause: [(0, 15), (0, 36)]
		Effect: [(0, 38), (0, 103)]

	CASE: 8
	Stag: 57 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: We expect that features based on RI will be useful for prompt adherence scoring because they may help us find text related to the prompt even if some of its concepts have have been rephrased (e.g.,, an essay may talk about u'\u201c' jail u'\u201d' rather than u'\u201c' prison u'\u201d' , which is mentioned in one of the prompts), and because they have already proven useful for the related task of determining which sentences in an essay are related to the prompt [ 7 ]. 
		Cause: [(0, 12), (0, 19)]
		Effect: [(0, 0), (0, 10)]

	CASE: 9
	Stag: 57 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: We expect that features based on RI will be useful for prompt adherence scoring because they may help us find text related to the prompt even if some of its concepts have have been rephrased (e.g.,, an essay may talk about u'\u201c' jail u'\u201d' rather than u'\u201c' prison u'\u201d' , which is mentioned in one of the prompts), and because they have already proven useful for the related task of determining which sentences in an essay are related to the prompt [ 7 ]. 
		Cause: [(0, 43), (0, 65)]
		Effect: [(0, 1), (0, 41)]

	CASE: 10
	Stag: 57 58 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: We expect that features based on RI will be useful for prompt adherence scoring because they may help us find text related to the prompt even if some of its concepts have have been rephrased (e.g.,, an essay may talk about u'\u201c' jail u'\u201d' rather than u'\u201c' prison u'\u201d' , which is mentioned in one of the prompts), and because they have already proven useful for the related task of determining which sentences in an essay are related to the prompt [ 7 ]. For each essay, we therefore attempt to adapt the RI features used by Higgins et al. 
		Cause: [(0, 1), (1, 4)]
		Effect: [(1, 6), (1, 16)]

	CASE: 11
	Stag: 60 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We do this by generating one feature encoding the entire essay u'\u2019' s similarity to the prompt, another encoding the essay u'\u2019' s highest individual sentence u'\u2019' s similarity to the prompt, a third encoding the highest entire essay similarity to one of the prompt sentences, another encoding the highest individual sentence similarity to an individual prompt sentence, and finally one encoding the entire essay u'\u2019' s similarity to a manually rewritten version of the prompt that excludes extraneous material (such as u'\u201c' In his novel Animal Farm, George Orwell wrote, u'\u201d' which is introductory material from the third prompt in Table 1. 
		Cause: [(0, 4), (0, 133)]
		Effect: [(0, 0), (0, 2)]

	CASE: 12
	Stag: 61 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: Our RI feature set necessarily excludes those features from Higgins et al. that are not easily translatable to our problem since we are concerned with an entire essay u'\u2019' s adherence to its prompt rather than with each of its sentences u'\u2019' relatedness to the prompt. 
		Cause: [(0, 21), (0, 53)]
		Effect: [(0, 0), (0, 19)]

	CASE: 13
	Stag: 62 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since RI does not provide a straightforward way to measure similarity between groups of words such as sentences or essays, we use Higgins and Burstein u'\u2019' s [ 8 ] method to generate these features. 
		Cause: [(0, 1), (0, 19)]
		Effect: [(0, 21), (0, 39)]

	CASE: 14
	Stag: 63 64 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Next, we introduce six types of novel features. As our first novel feature, we use the 10,000 most important lemmatized unigram, bigram, and trigram features that occur in the essay. 
		Cause: [(1, 1), (1, 24)]
		Effect: [(0, 0), (0, 8)]

	CASE: 15
	Stag: 65 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: N-grams can be useful for prompt adherence scoring because they can capture useful words and phrases related to a prompt. 
		Cause: [(0, 9), (0, 19)]
		Effect: [(0, 0), (0, 7)]

	CASE: 16
	Stag: 66 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: For example, words and phrases like u'\u201c' university degree u'\u201d' , u'\u201c' student u'\u201d' , and u'\u201c' real world u'\u201d' are relevant to the first prompt in Table 1 , so it is more likely that an essay adheres to the prompt if they appear in the essay. 
		Cause: [(0, 0), (0, 53)]
		Effect: [(0, 56), (0, 72)]

	CASE: 17
	Stag: 66 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: For example, words and phrases like u'\u201c' university degree u'\u201d' , u'\u201c' student u'\u201d' , and u'\u201c' real world u'\u201d' are relevant to the first prompt in Table 1 , so it is more likely that an essay adheres to the prompt if they appear in the essay. 
		Cause: [(0, 12), (0, 16)]
		Effect: [(0, 0), (0, 10)]

	CASE: 18
	Stag: 68 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since the essays vary greatly in length, we normalize each essay u'\u2019' s set of n-gram features to unit length. 
		Cause: [(0, 1), (0, 6)]
		Effect: [(0, 8), (0, 24)]

	CASE: 19
	Stag: 71 72 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The keyword features were formed by first examining the 13 essay prompts, splitting each into its component pieces. As an example of what is meant by a u'\u201c' component piece u'\u201d' , consider the first prompt in Table 1. 
		Cause: [(1, 1), (1, 28)]
		Effect: [(0, 0), (0, 18)]

	CASE: 20
	Stag: 74 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Then the most important (primary) and second most important (secondary) words were selected from each prompt component, where a word was considered u'\u201c' important u'\u201d' if it would be a good word for a student to use when stating her thesis about the prompt. 
		Cause: [(0, 39), (0, 56)]
		Effect: [(0, 0), (0, 37)]

	CASE: 21
	Stag: 75 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: So since the lemmatized version of the third component of the second prompt in Table 1 is u'\u201c' it should rehabilitate they u'\u201d' , u'\u201c' rehabilitate u'\u201d' was selected as a primary keyword and u'\u201c' society u'\u201d' as a secondary keyword. 
		Cause: [(0, 2), (0, 30)]
		Effect: [(0, 32), (0, 64)]

	CASE: 22
	Stag: 76 77 
		Pattern: 0 [['based', 'on']]---- [['&C', '(,/;/./--)', '(&AND)', '(&ADV)'], ['&this', '&NP', '(,)', '&R']]
		sentTXT: Features are then computed based on these keywords. For instance, one thesis clarity keyword feature is computed as follows. 
		Cause: [(0, 0), (0, 3)]
		Effect: [(1, 3), (1, 11)]

	CASE: 23
	Stag: 83 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: The greatest of the fractions generated in this way is encoded as a feature because if it has a low value, that indicates the essay u'\u2019' s thesis may not be very relevant to the prompt. 
		Cause: [(0, 15), (0, 20)]
		Effect: [(0, 22), (0, 40)]

	CASE: 24
	Stag: 86 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: The thesis clarity keyword features described above were intended for the task of determining how clear an essay u'\u2019' s thesis is, but since our goal is instead to determine how well an essay adheres to its prompt, it makes sense to adapt keyword features to our task rather than to adopt keyword features exactly as they have been used before. 
		Cause: [(0, 29), (0, 42)]
		Effect: [(0, 44), (0, 66)]

	CASE: 25
	Stag: 86 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The thesis clarity keyword features described above were intended for the task of determining how clear an essay u'\u2019' s thesis is, but since our goal is instead to determine how well an essay adheres to its prompt, it makes sense to adapt keyword features to our task rather than to adopt keyword features exactly as they have been used before. 
		Cause: [(0, 18), (0, 22)]
		Effect: [(0, 0), (0, 16)]

	CASE: 26
	Stag: 87 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: For this reason, we construct a new list of keywords for each prompt component, though since prompt adherence is more concerned with what the student says about the topics than it is with whether or not what she says about them is stated clearly, our keyword lists look a little different than the ones discussed above. 
		Cause: [(0, 18), (0, 45)]
		Effect: [(0, 47), (0, 58)]

	CASE: 27
	Stag: 89 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: If he was alive at the end of the 20th century, he would replace religion with television u'\u201d' Since the question suggests that students discuss whether television is analogous to religion in this way, our set of prompt adherence keywords for this prompt contains the word u'\u201c' religion u'\u201d' while the previously discussed keyword sets do not. 
		Cause: [(0, 24), (0, 38)]
		Effect: [(0, 40), (0, 70)]

	CASE: 28
	Stag: 90 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: This is because a thesis like u'\u201c' Television is bad u'\u201d' can be stated very clearly without making any reference to religion at all, and so an essay with a thesis like this can potentially have a very high thesis clarity score. 
		Cause: [(0, 0), (0, 31)]
		Effect: [(0, 35), (0, 50)]

	CASE: 29
	Stag: 90 
		Pattern: 1 [['because']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&C']]
		sentTXT: This is because a thesis like u'\u201c' Television is bad u'\u201d' can be stated very clearly without making any reference to religion at all, and so an essay with a thesis like this can potentially have a very high thesis clarity score. 
		Cause: [(0, 3), (0, 31)]
		Effect: [(0, 0), (0, 0)]

	CASE: 30
	Stag: 91 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: It should not, however, have a very high prompt adherence score, as the prompt asked the student to discuss whether television is like religion in a particular way, so religion should be at least briefly addressed for an essay to be awarded a high prompt adherence score. 
		Cause: [(0, 0), (0, 30)]
		Effect: [(0, 33), (0, 50)]

	CASE: 31
	Stag: 91 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: It should not, however, have a very high prompt adherence score, as the prompt asked the student to discuss whether television is like religion in a particular way, so religion should be at least briefly addressed for an essay to be awarded a high prompt adherence score. 
		Cause: [(0, 15), (0, 30)]
		Effect: [(0, 0), (0, 12)]

	CASE: 32
	Stag: 92 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: Additionally, our prompt adherence keyword sets do not adopt the notions of primary and secondary groups of keywords for each prompt component, instead collecting all the keywords for a component into one set because u'\u201c' secondary u'\u201d' keywords tend to be things that are important when we are concerned with what a student is saying about the topic rather than just how clearly she said it. 
		Cause: [(0, 36), (0, 74)]
		Effect: [(0, 0), (0, 34)]

	CASE: 33
	Stag: 95 96 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: To obtain feature values of the first type, we take the RI similarities between the whole essay and each set of prompt adherence keywords from the prompt u'\u2019' s components. This results in one to three features, as some prompts have one component while others have up to three. 
		Cause: [(1, 9), (1, 19)]
		Effect: [(0, 1), (1, 6)]

	CASE: 34
	Stag: 100 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: This results in one to three features since a prompt has one to three components. 
		Cause: [(0, 8), (0, 14)]
		Effect: [(0, 0), (0, 6)]

	CASE: 35
	Stag: 102 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: These topics should not diminish the essay u'\u2019' s prompt adherence score because they are at least related to prompt concepts. 
		Cause: [(0, 17), (0, 24)]
		Effect: [(0, 0), (0, 15)]

	CASE: 36
	Stag: 103 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: For example, consider the prompt u'\u201c' All armies should consist entirely of professional soldiers there is no value in a system of military service u'\u201d' An essay containing words like u'\u201c' peace u'\u201d' , u'\u201c' patriotism u'\u201d' , or u'\u201c' training u'\u201d' are probably not digressions from the prompt, and therefore should not be penalized for discussing these topics. 
		Cause: [(0, 0), (0, 81)]
		Effect: [(0, 85), (0, 92)]

	CASE: 37
	Stag: 103 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: For example, consider the prompt u'\u201c' All armies should consist entirely of professional soldiers there is no value in a system of military service u'\u201d' An essay containing words like u'\u201c' peace u'\u201d' , u'\u201c' patriotism u'\u201d' , or u'\u201c' training u'\u201d' are probably not digressions from the prompt, and therefore should not be penalized for discussing these topics. 
		Cause: [(0, 5), (0, 7)]
		Effect: [(0, 0), (0, 3)]

	CASE: 38
	Stag: 105 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: While n-gram features do not have exactly the same problem, they would still only notice that these example words are related to the prompt if multiple essays use the same words to discuss these concepts. 
		Cause: [(0, 26), (0, 35)]
		Effect: [(0, 0), (0, 24)]

	CASE: 39
	Stag: 105 106 
		Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
		sentTXT: While n-gram features do not have exactly the same problem, they would still only notice that these example words are related to the prompt if multiple essays use the same words to discuss these concepts. For this reason, we introduce Latent Dirichlet Allocation (LDA) [ 2 ] features. 
		Cause: [(0, 0), (0, 35)]
		Effect: [(1, 4), (1, 15)]

	CASE: 40
	Stag: 110 111 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This results in what we can think of as a soft clustering of words into 1,000 sets for each prompt, where each set of words represents one of the topics LDA identified being discussed in the essays for that prompt. So for example, the five most important words in the most frequently discussed topic for the military prompt we mentioned above are u'\u201c' man u'\u201d' , u'\u201c' military u'\u201d' , u'\u201c' service u'\u201d' , u'\u201c' pay u'\u201d' , and u'\u201c' war u'\u201d'. 
		Cause: [(0, 9), (1, 81)]
		Effect: [(0, 4), (0, 7)]

	CASE: 41
	Stag: 110 111 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: This results in what we can think of as a soft clustering of words into 1,000 sets for each prompt, where each set of words represents one of the topics LDA identified being discussed in the essays for that prompt. So for example, the five most important words in the most frequently discussed topic for the military prompt we mentioned above are u'\u201c' man u'\u201d' , u'\u201c' military u'\u201d' , u'\u201c' service u'\u201d' , u'\u201c' pay u'\u201d' , and u'\u201c' war u'\u201d'. 
		Cause: [(0, 5), (0, 40)]
		Effect: [(1, 1), (1, 82)]

	CASE: 42
	Stag: 114 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since the latter topic is discussed so much in the essay and does not appear to have much to do with the military prompt, this essay should probably get a bad prompt adherence score. 
		Cause: [(0, 1), (0, 23)]
		Effect: [(0, 25), (0, 34)]

	CASE: 43
	Stag: 114 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: Since the latter topic is discussed so much in the essay and does not appear to have much to do with the military prompt, this essay should probably get a bad prompt adherence score. 
		Cause: [(0, 0), (0, 4)]
		Effect: [(0, 6), (0, 22)]

	CASE: 44
	Stag: 116 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Each feature u'\u2019' s value is obtained by using the topic model to tell us how much of the essay was spent discussing the feature u'\u2019' s corresponding topic. 
		Cause: [(0, 12), (0, 36)]
		Effect: [(0, 0), (0, 10)]

	CASE: 45
	Stag: 118 119 
		Pattern: 8 [['because']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&ADV)'], ['&C']]
		sentTXT: A weakness of the LDA topics feature type is that it may result in a regressor that has trouble distinguishing between an infrequent topic that is adherent to the prompt and one that just represents an irrelevant digression. This is because an infrequent topic may not appear in the training set often enough for the regressor to make this judgment. 
		Cause: [(1, 3), (1, 21)]
		Effect: [(0, 0), (0, 37)]

	CASE: 46
	Stag: 121 122 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In order to construct manually annotated LDA topic features, we first build 13 topic models, one for each prompt, just as described in the section on LDA topic features. Rather than requesting models of 1,000 topics, however, we request models of only 100 topics 2 2 We use 100 topics for each prompt in the manually annotated version of LDA features rather than the 1,000 topics we use in the regular version of LDA features because 1,300 topics are not too costly to annotate, but manually annotating 13,000 topics would take too much time. 
		Cause: [(0, 24), (1, 67)]
		Effect: [(0, 2), (0, 22)]

	CASE: 47
	Stag: 122 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: Rather than requesting models of 1,000 topics, however, we request models of only 100 topics 2 2 We use 100 topics for each prompt in the manually annotated version of LDA features rather than the 1,000 topics we use in the regular version of LDA features because 1,300 topics are not too costly to annotate, but manually annotating 13,000 topics would take too much time. 
		Cause: [(0, 49), (0, 56)]
		Effect: [(0, 58), (0, 66)]

	CASE: 48
	Stag: 126 127 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: The first five features encode the sum of the contributions to an essay of topics annotated with a number u'\u2265' 1 , the sum of the contributions to an essay of topics annotated with a number u'\u2265' 2 , and so on up to 5. The next five features are similar to the last, with one feature taking on the sum of the contributions to an essay of topics annotated with the number 0, another feature taking on the sum of the contributions to an essay of topics annotated with the number 1, and so on up to 4. 
		Cause: [(0, 0), (0, 45)]
		Effect: [(0, 49), (1, 55)]

	CASE: 49
	Stag: 127 128 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: The next five features are similar to the last, with one feature taking on the sum of the contributions to an essay of topics annotated with the number 0, another feature taking on the sum of the contributions to an essay of topics annotated with the number 1, and so on up to 4. We do not include a feature for topics annotated with the number 5 because it would always have the same value as the feature for topics u'\u2265' 5. 
		Cause: [(0, 0), (0, 49)]
		Effect: [(0, 53), (1, 30)]

	CASE: 50
	Stag: 128 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: We do not include a feature for topics annotated with the number 5 because it would always have the same value as the feature for topics u'\u2265' 5. 
		Cause: [(0, 14), (0, 31)]
		Effect: [(0, 0), (0, 12)]

	CASE: 51
	Stag: 129 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Features like these should give the regressor a better idea how much of an essay is composed of prompt-related arguments and discussion and how much of it is irrelevant to the prompt, even if some of the topics occurring in it are too infrequent to judge just from training data. 
		Cause: [(0, 35), (0, 50)]
		Effect: [(0, 2), (0, 33)]

	CASE: 52
	Stag: 142 143 
		Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
		sentTXT: For instance, an essay that has a Relevance to Prompt error or an Incomplete Prompt Response error should intuitively receive a low prompt adherence score. For this reason, we introduce features based on these errors to our feature set for prompt adherence scoring 3 3 See our website at http://www.hlt.utdallas.edu/~persingq/ICLE/ for the complete list of error annotations. 
		Cause: [(0, 0), (0, 25)]
		Effect: [(1, 4), (1, 32)]

	CASE: 53
	Stag: 144 145 
		Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
		sentTXT: While each of the essays in our data set was previously annotated with these thesis clarity errors, in a realistic setting a prompt adherence scoring system will not have access to these manual error labels. As a result, we first need to predict which of these errors is present in each essay. 
		Cause: [(0, 0), (0, 35)]
		Effect: [(1, 4), (1, 17)]

	CASE: 54
	Stag: 148 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If a training essay is written in response to p , it will be used to generate a training instance whose label is 1 if e was annotated for it or 0 otherwise. 
		Cause: [(0, 1), (0, 9)]
		Effect: [(0, 11), (0, 32)]

	CASE: 55
	Stag: 149 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since error prediction and prompt adherence scoring are related problems, the features we associate with this instance are features 1 - 6 which we have described earlier in this section. 
		Cause: [(0, 1), (0, 9)]
		Effect: [(0, 11), (0, 29)]

Section 5:  5 Evaluation has 42 CE cases
	CASE: 1
	Stag: 159 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: As we will see below, S u'\u2062' 1 , S u'\u2062' 2 , and S u'\u2062' 3 are error metrics, so lower scores imply better performance. 
		Cause: [(0, 2), (0, 32)]
		Effect: [(0, 35), (0, 39)]

	CASE: 2
	Stag: 159 
		Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: As we will see below, S u'\u2062' 1 , S u'\u2062' 2 , and S u'\u2062' 3 are error metrics, so lower scores imply better performance. 
		Cause: [(0, 1), (0, 1)]
		Effect: [(0, 3), (0, 4)]

	CASE: 3
	Stag: 160 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: In contrast, P u'\u2062' C is a correlation metric, so higher correlation implies better performance. 
		Cause: [(0, 0), (0, 13)]
		Effect: [(0, 16), (0, 20)]

	CASE: 4
	Stag: 160 
		Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: In contrast, P u'\u2062' C is a correlation metric, so higher correlation implies better performance. 
		Cause: [(0, 0), (0, 1)]
		Effect: [(0, 3), (0, 4)]

	CASE: 5
	Stag: 161 162 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: The simplest metric, S u'\u2062' 1 , measures the frequency at which a system predicts the wrong score out of the seven possible scores. Hence, a system that predicts the right score only 25% of the time would receive an S u'\u2062' 1 score of 0.75. 
		Cause: [(0, 0), (0, 28)]
		Effect: [(1, 2), (1, 27)]

	CASE: 6
	Stag: 164 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: This metric reflects the idea that a system that predicts scores close to the annotator-assigned scores should be preferred over a system whose predictions are further off, even if both systems estimate the correct score at the same frequency. 
		Cause: [(0, 30), (0, 39)]
		Effect: [(0, 0), (0, 28)]

	CASE: 7
	Stag: 168 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: where A j , E j , and E j u'\u2032' are the annotator assigned, system predicted, and rounded system predicted scores 4 4 Since our regressor assigns each essay a real value rather than an actual valid score, it would be difficult to obtain a reasonable S u'\u2062' 1 score without rounding the system estimated score to one of the possible values. 
		Cause: [(0, 31), (0, 44)]
		Effect: [(0, 46), (0, 53)]

	CASE: 8
	Stag: 168 169 
		Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
		sentTXT: where A j , E j , and E j u'\u2032' are the annotator assigned, system predicted, and rounded system predicted scores 4 4 Since our regressor assigns each essay a real value rather than an actual valid score, it would be difficult to obtain a reasonable S u'\u2062' 1 score without rounding the system estimated score to one of the possible values. For that reason, we round the estimated score to the nearest of the seven scores the human annotators were permitted to assign (1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0) only when calculating S u'\u2062' 1. 
		Cause: [(0, 0), (0, 73)]
		Effect: [(1, 4), (1, 47)]

	CASE: 9
	Stag: 170 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: For other scoring metrics, we only round the predictions to 1.0 or 4.0 if they fall outside the 1.0 - 4.0 range respectively for essay j , and N is the number of essays. 
		Cause: [(0, 15), (0, 22)]
		Effect: [(0, 0), (0, 13)]

	CASE: 10
	Stag: 173 174 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: A positive (negative) P u'\u2062' C implies that the two sets of predictions are positively (negatively) correlated. As mentioned earlier, for each prompt p i , we train a linear regressor r i using LIBSVM with regularization parameter c i. 
		Cause: [(1, 1), (1, 23)]
		Effect: [(0, 0), (0, 24)]

	CASE: 11
	Stag: 176 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: Note that each of the c i values can be tuned independently because a c i value that is optimal for predicting scores for p i essays with respect to any of the error performance measures is necessarily also the optimal c i when measuring that error on essays from all prompts. 
		Cause: [(0, 13), (0, 50)]
		Effect: [(0, 0), (0, 11)]

	CASE: 12
	Stag: 177 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: However, this is not case with Pearson u'\u2019' s correlation coefficient, as the P u'\u2062' C value for essays from all 13 prompts cannot be simplified as a weighted sum of the P u'\u2062' C values obtained on each individual prompt. 
		Cause: [(0, 18), (0, 55)]
		Effect: [(0, 0), (0, 15)]

	CASE: 13
	Stag: 177 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: However, this is not case with Pearson u'\u2019' s correlation coefficient, as the P u'\u2062' C value for essays from all 13 prompts cannot be simplified as a weighted sum of the P u'\u2062' C values obtained on each individual prompt. 
		Cause: [(0, 20), (0, 36)]
		Effect: [(0, 0), (0, 18)]

	CASE: 14
	Stag: 177 178 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: However, this is not case with Pearson u'\u2019' s correlation coefficient, as the P u'\u2062' C value for essays from all 13 prompts cannot be simplified as a weighted sum of the P u'\u2062' C values obtained on each individual prompt. In order to obtain an optimal result as measured by P u'\u2062' C , we jointly tune the c i parameters to optimize the P u'\u2062' C value achieved by our system on the same held-out validation data. 
		Cause: [(1, 8), (1, 45)]
		Effect: [(0, 0), (1, 6)]

	CASE: 15
	Stag: 179 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: However, an exact solution to this optimization problem is computationally expensive, as there are too many ( 7 13 ) possible combinations of c values to exhaustively search. 
		Cause: [(0, 14), (0, 29)]
		Effect: [(0, 0), (0, 11)]

	CASE: 16
	Stag: 179 180 
		Pattern: 9 [['consequently']]---- [['&C', '(,/;/./--)'], ['(,)', '&R']]
		sentTXT: However, an exact solution to this optimization problem is computationally expensive, as there are too many ( 7 13 ) possible combinations of c values to exhaustively search. Consequently, we find a local maximum by employing the simulated annealing algorithm [ 11 ] , altering one c i value at a time to optimize P u'\u2062' C while holding the remaining parameters fixed. 
		Cause: [(0, 0), (0, 29)]
		Effect: [(1, 2), (1, 39)]

	CASE: 17
	Stag: 188 189 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: These results mean that the greatest improvements our system makes are that it ensures that our score predictions are not too often very far away from an essay u'\u2019' s actual score, as making such predictions would tend to drive up S u'\u2062' 3 , yielding a relative error reduction in S u'\u2062' 3 of 15.8%, and it also ensures a better correlation between predicted and actual scores, thus yielding the 16.6% improvement in P u'\u2062' C. 7 7 These numbers are calculated B - O B - P where B is the baseline system u'\u2019' s score, O is our system u'\u2019' s score, and P is a perfect score. 
		Cause: [(0, 0), (0, 82)]
		Effect: [(0, 85), (1, 43)]

	CASE: 18
	Stag: 194 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: The top line of each subtable shows what our system u'\u2019' s score would be if we removed just one of the feature types from our system. 
		Cause: [(0, 20), (0, 30)]
		Effect: [(0, 0), (0, 18)]

	CASE: 19
	Stag: 195 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: So to see how our system performs by the S u'\u2062' 1 metric if we remove only predicted thesis clarity error features, we would look at the first row of results of Table d (a) under the column headed by the number 7 since predicted thesis clarity errors are the seventh feature type introduced in Section 4. 
		Cause: [(0, 51), (0, 63)]
		Effect: [(0, 10), (0, 49)]

	CASE: 20
	Stag: 195 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: So to see how our system performs by the S u'\u2062' 1 metric if we remove only predicted thesis clarity error features, we would look at the first row of results of Table d (a) under the column headed by the number 7 since predicted thesis clarity errors are the seventh feature type introduced in Section 4. 
		Cause: [(0, 8), (0, 11)]
		Effect: [(0, 17), (0, 39)]

	CASE: 21
	Stag: 197 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: Since Table 4 shows that when our system includes this feature type (along with all the other feature types), it obtains an S u'\u2062' 1 score of .488, this feature type u'\u2019' s removal costs our system .014 S u'\u2062' 1 points, and thus its inclusion has a beneficial effect on the S u'\u2062' 1 score. 
		Cause: [(0, 0), (0, 57)]
		Effect: [(0, 61), (0, 74)]

	CASE: 22
	Stag: 197 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since Table 4 shows that when our system includes this feature type (along with all the other feature types), it obtains an S u'\u2062' 1 score of .488, this feature type u'\u2019' s removal costs our system .014 S u'\u2062' 1 points, and thus its inclusion has a beneficial effect on the S u'\u2062' 1 score. 
		Cause: [(0, 1), (0, 20)]
		Effect: [(0, 22), (0, 24)]

	CASE: 23
	Stag: 198 199 
		Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
		sentTXT: From row 1 of Table d (a), we can see that removing feature 4 yields a system with the best S u'\u2062' 1 score in the presence of the other feature types in this row. For this reason, we permanently remove feature 4 from the system before we generate the results on line 2. 
		Cause: [(0, 0), (0, 41)]
		Effect: [(1, 4), (1, 19)]

	CASE: 24
	Stag: 199 200 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: For this reason, we permanently remove feature 4 from the system before we generate the results on line 2. Thus, we can see what happens when we remove both feature 4 and feature 5 by looking at the second entry in row 2. 
		Cause: [(0, 0), (0, 19)]
		Effect: [(1, 1), (1, 24)]

	CASE: 25
	Stag: 201 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: And since removing feature 6 harms performance least in the presence of row 2 u'\u2019' s other feature types, we permanently remove both 4 and 6 from our feature set when we generate the third row of results. 
		Cause: [(0, 2), (0, 21)]
		Effect: [(0, 24), (0, 42)]

	CASE: 26
	Stag: 203 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since the feature type whose removal yields the best system is always the rightmost entry in a line, the order of column headings indicates the relative importance of the feature types, with the leftmost feature types being most important to performance and the rightmost feature types being least important in the presence of the other feature types. 
		Cause: [(0, 1), (0, 17)]
		Effect: [(0, 19), (0, 58)]

	CASE: 27
	Stag: 203 
		Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Since the feature type whose removal yields the best system is always the rightmost entry in a line, the order of column headings indicates the relative importance of the feature types, with the leftmost feature types being most important to performance and the rightmost feature types being least important in the presence of the other feature types. 
		Cause: [(0, 0), (0, 4)]
		Effect: [(0, 6), (0, 39)]

	CASE: 28
	Stag: 204 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: This being the case, it is interesting to note that while the relative importance of different feature types does not remain exactly the same if we measure performance in different ways, we can see that some feature types tend to be more important than others in a majority of the four scoring metrics. 
		Cause: [(0, 26), (0, 54)]
		Effect: [(0, 0), (0, 24)]

	CASE: 29
	Stag: 205 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Features 2 (n-grams), 3 (thesis clarity keywords), and 6 (manually annotated LDA topics) tend to be the most important feature types, as they tend to be the last feature types removed in the ablation subtables. 
		Cause: [(0, 31), (0, 43)]
		Effect: [(0, 0), (0, 28)]

	CASE: 30
	Stag: 207 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Finally, while features 4 (prompt adherence keywords) and 7 (predicted thesis clarity errors) may by themselves provide useful information to our system, in the presence of the other feature types they tend to be the least important to performance as they are often the first feature types removed. 
		Cause: [(0, 46), (0, 53)]
		Effect: [(0, 3), (0, 44)]

	CASE: 31
	Stag: 209 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: For example, while we identified feature 3 (thesis clarity keywords) as one of the most important feature types generally due to its tendency to have a large beneficial impact on performance, when we are measuring performance using S u'\u2062' 3 , it is the least useful feature type. 
		Cause: [(0, 14), (0, 55)]
		Effect: [(0, 4), (0, 12)]

	CASE: 32
	Stag: 209 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: For example, while we identified feature 3 (thesis clarity keywords) as one of the most important feature types generally due to its tendency to have a large beneficial impact on performance, when we are measuring performance using S u'\u2062' 3 , it is the least useful feature type. 
		Cause: [(0, 10), (0, 33)]
		Effect: [(0, 35), (0, 41)]

	CASE: 33
	Stag: 211 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Though feature 3 is an extreme example, all feature types fluctuate in importance, as we see when we compare their orders of removal among the four ablation subtables. 
		Cause: [(0, 16), (0, 29)]
		Effect: [(0, 0), (0, 13)]

	CASE: 34
	Stag: 211 212 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: Though feature 3 is an extreme example, all feature types fluctuate in importance, as we see when we compare their orders of removal among the four ablation subtables. Hence, it is important to know how performance is measured when building a system for scoring prompt adherence. 
		Cause: [(0, 0), (0, 29)]
		Effect: [(1, 2), (1, 18)]

	CASE: 35
	Stag: 213 214 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Feature 3 is not the only feature type whose removal sometimes has a beneficial impact on performance. As we can see in Table d (b), the removal of features 4, 5, and 7 improves our system u'\u2019' s S u'\u2062' 2 score by .001 points. 
		Cause: [(1, 1), (1, 40)]
		Effect: [(0, 0), (0, 16)]

	CASE: 36
	Stag: 217 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Fortunately, this effect does not occur in any other cases than the two listed above, as most feature types usually have a beneficial or at least neutral impact on our system u'\u2019' s performance. 
		Cause: [(0, 18), (0, 39)]
		Effect: [(0, 0), (0, 15)]

	CASE: 37
	Stag: 220 221 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We can see this is the case by noting that they are not all the least important feature types in their respective subtables as indicated by column order. For example, by the time feature 1 gets permanently removed in Table d (c), its removal harms performance by .002 S u'\u2062' 3 points. 
		Cause: [(0, 24), (1, 29)]
		Effect: [(0, 0), (0, 22)]

	CASE: 38
	Stag: 222 223 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: To more closely examine the behavior of our system, in Table 6 we chart the distributions of scores it predicts for essays having each gold standard score. As an example of how to read this table, consider the number 3.06 appearing in row 2.0 in the .25 column of the S u'\u2062' 3 region. 
		Cause: [(1, 1), (1, 30)]
		Effect: [(0, 13), (0, 27)]

	CASE: 39
	Stag: 224 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: This means that 25% of the time, when our system with parameters tuned for optimizing S u'\u2062' 3 is presented with a test essay having a gold standard score of 2.0, it predicts that the essay has a score less than or equal to 3.06. 
		Cause: [(0, 16), (0, 23)]
		Effect: [(0, 0), (0, 14)]

	CASE: 40
	Stag: 225 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: From this table, we see that our system has a strong bias toward predicting more frequent scores as there are no numbers less than 3.0 in the table, and about 93.7% of all essays have gold standard scores of 3.0 or above. 
		Cause: [(0, 19), (0, 43)]
		Effect: [(0, 0), (0, 17)]

	CASE: 41
	Stag: 227 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Another interesting point to note about this table is that the difference in error weighting between the S u'\u2062' 2 and S u'\u2062' 3 scoring metrics appears to be having its desired effect, as every entry in the S u'\u2062' 3 subtable is less than its corresponding entry in the S u'\u2062' 2 subtable due to the greater penalty the S u'\u2062' 3 metric imposes for predictions that are very far away from the gold standard scores. 
		Cause: [(0, 43), (0, 97)]
		Effect: [(0, 0), (0, 40)]

	CASE: 42
	Stag: 227 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: Another interesting point to note about this table is that the difference in error weighting between the S u'\u2062' 2 and S u'\u2062' 3 scoring metrics appears to be having its desired effect, as every entry in the S u'\u2062' 3 subtable is less than its corresponding entry in the S u'\u2062' 2 subtable due to the greater penalty the S u'\u2062' 3 metric imposes for predictions that are very far away from the gold standard scores. 
		Cause: [(0, 30), (0, 44)]
		Effect: [(0, 45), (0, 54)]

Section 6:  6 Conclusion has 0 CE cases
#-------------------------------------------------

