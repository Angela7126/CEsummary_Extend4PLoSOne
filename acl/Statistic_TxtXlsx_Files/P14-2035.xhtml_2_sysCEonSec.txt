Current File: P14-2035.xhtml_2 P14-2035.xhtml

Section 0:  Abstract
	SentNum: 3
	CENum: 2
	SentCovered: 3
	Covered_Rate: 100.0000%

Section 1:  1 Introduction
	SentNum: 23
	CENum: 7
	SentCovered: 9
	Covered_Rate: 39.1304%

Section 2:  2 Composition in distributional models
	SentNum: 12
	CENum: 4
	SentCovered: 5
	Covered_Rate: 41.6667%

Section 3:  3 Disambiguation and composition
	SentNum: 13
	CENum: 1
	SentCovered: 2
	Covered_Rate: 15.3846%

Section 4:  4 Creating tensors for verbs
	SentNum: 9
	CENum: 6
	SentCovered: 5
	Covered_Rate: 55.5556%

Section 5:  5 Experimental setting
	SentNum: 13
	CENum: 1
	SentCovered: 1
	Covered_Rate: 7.6923%

Section 6:  6 Supervised disambiguation
	SentNum: 30
	CENum: 10
	SentCovered: 8
	Covered_Rate: 26.6667%

Section 7:  7 Unsupervised disambiguation
	SentNum: 28
	CENum: 15
	SentCovered: 12
	Covered_Rate: 42.8571%

Section 8:  8 Conclusion and future work
	SentNum: 3
	CENum: 1
	SentCovered: 2
	Covered_Rate: 66.6667%

Section 9:  Acknowledgements
	SentNum: 4
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-2035.xhtml_2's CE cases

Section 0:  Abstract has 2 CE cases
	CASE: 1
	Stag: 0 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: This paper provides a method for improving tensor-based compositional distributional models of meaning by the addition of an explicit disambiguation step prior to composition. 
		Cause: [(0, 6), (0, 23)]
		Effect: [(0, 0), (0, 4)]

	CASE: 2
	Stag: 1 2 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: In contrast with previous research where this hypothesis has been successfully tested against relatively simple compositional models, in our work we use a robust model trained with linear regression. The results we get in two experiments show the superiority of the prior disambiguation method and suggest that the effectiveness of this approach is model-independent. 
		Cause: [(0, 5), (0, 29)]
		Effect: [(1, 22), (1, 24)]

Section 1:  1 Introduction has 7 CE cases
	CASE: 1
	Stag: 3 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The provision of compositionality in distributional models of meaning, where a word is represented as a vector of co-occurrence counts with every other word in the vocabulary, offers a solution to the fact that no text corpus, regardless of its size, is capable of providing reliable co-occurrence statistics for anything but very short text constituents. 
		Cause: [(0, 16), (0, 58)]
		Effect: [(0, 11), (0, 14)]

	CASE: 2
	Stag: 4 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: By composing the vectors for the words within a sentence, we are still able to create a vectorial representation for that sentence that is very useful in a variety of natural language processing tasks, such as paraphrase detection, sentiment analysis or machine translation. 
		Cause: [(0, 1), (0, 9)]
		Effect: [(0, 10), (0, 45)]

	CASE: 3
	Stag: 4 5 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: By composing the vectors for the words within a sentence, we are still able to create a vectorial representation for that sentence that is very useful in a variety of natural language processing tasks, such as paraphrase detection, sentiment analysis or machine translation. Hence, given a sentence w 1 u'\u2062' w 2 u'\u2062' u'\u2026' u'\u2062' w n , a compositional distributional model provides a function f such that. 
		Cause: [(0, 0), (0, 45)]
		Effect: [(1, 2), (1, 41)]

	CASE: 4
	Stag: 17 18 
		Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
		sentTXT: What makes the models of the above work u'\u2018' partial u'\u2019' is that the authors used simplified versions of the linear maps, projected onto spaces of order lower than that required by the theoretical framework. As a result, a certain amount of transformational power was traded off for efficiency. 
		Cause: [(0, 0), (0, 43)]
		Effect: [(1, 4), (1, 14)]

	CASE: 5
	Stag: 19 20 
		Pattern: 1 [[[',', '.', ';', 'and']], ['as', 'a'], ['consequence']]---- [['&C'], ['&R'], ['(&ADJ)']]
		sentTXT: A potential explanation then for the effectiveness of the proposed prior disambiguation method can be sought on the limitations imposed by the compositional models under test. After all, the idea of having disambiguation emerge as a direct consequence of the compositional process, without the introduction of any explicit step, seems more natural and closer to the way the human mind resolves lexical ambiguities. 
		Cause: [(0, 1), (1, 1)]
		Effect: [(1, 3), (1, 8)]

	CASE: 6
	Stag: 22 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: We create such a model by using linear regression, and we explain how an explicit disambiguation step can be introduced to this model prior to composition. 
		Cause: [(0, 6), (0, 8)]
		Effect: [(0, 9), (0, 26)]

	CASE: 7
	Stag: 23 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We then proceed by comparing the composite vectors produced by this approach with those produced by the model alone in a number of experiments. 
		Cause: [(0, 4), (0, 23)]
		Effect: [(0, 0), (0, 2)]

Section 2:  2 Composition in distributional models has 4 CE cases
	CASE: 1
	Stag: 26 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Compositional distributional models of meaning vary in sophistication, from simple element-wise operations between vectors such as addition and multiplication [] to deep learning techniques based on neural networks []. 
		Cause: [(0, 28), (0, 31)]
		Effect: [(0, 0), (0, 25)]

	CASE: 2
	Stag: 31 32 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: N u'\u2192' N (where N is our basic vector space for nouns), which takes as input a noun and returns a modified version of it. Since every map of this sort can be represented by a matrix living in the tensor product space N u'\u2297' N , we now see that the meaning of a phrase such as u'\u2018' red car u'\u2019' is given by r u'\u2062' e u'\u2062' d ¯ × c u'\u2062' a u'\u2062' r u'\u2192' , where r u'\u2062' e u'\u2062' d ¯ is an adjective matrix and × indicates matrix multiplication. 
		Cause: [(0, 22), (1, 45)]
		Effect: [(0, 0), (0, 20)]

	CASE: 3
	Stag: 32 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since every map of this sort can be represented by a matrix living in the tensor product space N u'\u2297' N , we now see that the meaning of a phrase such as u'\u2018' red car u'\u2019' is given by r u'\u2062' e u'\u2062' d ¯ × c u'\u2062' a u'\u2062' r u'\u2192' , where r u'\u2062' e u'\u2062' d ¯ is an adjective matrix and × indicates matrix multiplication. 
		Cause: [(0, 1), (0, 16)]
		Effect: [(0, 26), (0, 105)]

	CASE: 4
	Stag: 33 34 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: The same concept applies for functions of higher order, such as a transitive verb (a function of two arguments, so a tensor of order 3. For these cases, matrix multiplication generalizes to the more generic notion of tensor contraction. 
		Cause: [(0, 0), (0, 20)]
		Effect: [(0, 23), (1, 13)]

Section 3:  3 Disambiguation and composition has 1 CE cases
	CASE: 1
	Stag: 49 50 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: Here, the model does not fully exploit the space provided by the theoretical framework (i.e., an order-3 tensor), which has two disadvantages firstly, we lose space that could hold valuable information about the verb in this case and relational words in general; secondly, the generally non-commutative tensor contraction operation is now partly relying on element-wise multiplication, which is commutative, thus forgets (part of the) order of composition. In the next section we will see how to apply linear regression in order to create full tensors for verbs and use them for a compositional model that avoids these pitfalls. 
		Cause: [(0, 0), (0, 67)]
		Effect: [(0, 70), (1, 29)]

Section 4:  4 Creating tensors for verbs has 6 CE cases
	CASE: 1
	Stag: 53 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: In order to create a matrix for, say, the intransitive verb u'\u2018' play u'\u2019' , we first collect all instances of the verb occurring with some subject in the training corpus, and then we create non-compositional holistic vectors for these elementary sentences following exactly the same methodology as if they were words. 
		Cause: [(0, 60), (0, 62)]
		Effect: [(0, 14), (0, 58)]

	CASE: 2
	Stag: 54 
		Pattern: 47 [['so'], ['that']]---- [['&C'], ['&adj/&adv@C@'], ['&R']]
		sentTXT: We now have a dataset with instances of the form u'\u27e8' s u'\u2062' u u'\u2062' b u'\u2062' j i u'\u2192' , s u'\u2062' u u'\u2062' b u'\u2062' j i u'\u2062' p u'\u2062' l u'\u2062' a u'\u2062' y u'\u2192' u'\u27e9' (e.g., the vector of u'\u2018' kids u'\u2019' paired with the holistic vector of u'\u2018' kids play u'\u2019' , and so on), that can be used to train a linear regression model in order to produce an appropriate matrix for verb u'\u2018' play u'\u2019'. 
		Cause: [(0, 0), (0, 133)]
		Effect: [(0, 137), (0, 165)]

	CASE: 3
	Stag: 55 
		Pattern: 1 [['with', 'the'], ['result', 'that']]---- [['&C', '(,)'], ['(&ADJ)'], ['&R']]
		sentTXT: The premise of a model like this is that the multiplication of the verb matrix with the vector of a new subject will produce a result that approximates the distributional behaviour of all these elementary two-word exemplars used in training. 
		Cause: [(0, 0), (0, 14)]
		Effect: [(0, 27), (0, 39)]

	CASE: 4
	Stag: 56 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: We present examples and experiments based on this method, constructing ambiguous and disambiguated tensors of order 2 (that is, matrices) for verbs taking one argument. 
		Cause: [(0, 7), (0, 8)]
		Effect: [(0, 10), (0, 28)]

	CASE: 5
	Stag: 59 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: Instead of using subject-verb constructs as above we concentrate on elementary verb phrases of the form verb-object (e.g., u'\u2018' play football u'\u2019' , u'\u2018' admit student u'\u2019' ), since in general objects comprise stronger contexts for disambiguating the usage of a verb. 
		Cause: [(0, 48), (0, 60)]
		Effect: [(0, 0), (0, 45)]

	CASE: 6
	Stag: 59 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: Instead of using subject-verb constructs as above we concentrate on elementary verb phrases of the form verb-object (e.g., u'\u2018' play football u'\u2019' , u'\u2018' admit student u'\u2019' ), since in general objects comprise stronger contexts for disambiguating the usage of a verb. 
		Cause: [(0, 7), (0, 12)]
		Effect: [(0, 0), (0, 5)]

Section 5:  5 Experimental setting has 1 CE cases
	CASE: 1
	Stag: 60 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: Our basic vector space is trained from the ukWaC corpus [] , originally using as a basis the 2,000 content words with the highest frequency (but excluding a list of stop words as well as the 50 most frequent content words since they exhibit low information content. 
		Cause: [(0, 44), (0, 48)]
		Effect: [(0, 4), (0, 42)]

Section 6:  6 Supervised disambiguation has 10 CE cases
	CASE: 1
	Stag: 75 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: The verb phrases of our dataset are based on the 5 ambiguous verbs of Table 1. 
		Cause: [(0, 9), (0, 15)]
		Effect: [(0, 0), (0, 5)]

	CASE: 2
	Stag: 78 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: As an example, in the verb u'\u2018' play u'\u2019' we impose the two distinct meanings of using a musical instrument and participating in a sport; so the first set of objects contains nouns such as u'\u2018' oboe u'\u2019' , u'\u2018' piano u'\u2019' , u'\u2018' guitar u'\u2019' , and so on, while in the second set we see nouns such as u'\u2018' football u'\u2019' , u'\u2019' baseball u'\u201d' etc. 
		Cause: [(0, 0), (0, 33)]
		Effect: [(0, 36), (0, 118)]

	CASE: 3
	Stag: 78 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: As an example, in the verb u'\u2018' play u'\u2019' we impose the two distinct meanings of using a musical instrument and participating in a sport; so the first set of objects contains nouns such as u'\u2018' oboe u'\u2019' , u'\u2018' piano u'\u2019' , u'\u2018' guitar u'\u2019' , and so on, while in the second set we see nouns such as u'\u2018' football u'\u2019' , u'\u2019' baseball u'\u201d' etc. 
		Cause: [(0, 0), (0, 43)]
		Effect: [(0, 47), (0, 82)]

	CASE: 4
	Stag: 84 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: Then, each object in the list was manually annotated as exclusively belonging to one of the two senses; so, an object could be selected only if it was related to a single sense, but not both. 
		Cause: [(0, 0), (0, 18)]
		Effect: [(0, 22), (0, 39)]

	CASE: 5
	Stag: 84 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Then, each object in the list was manually annotated as exclusively belonging to one of the two senses; so, an object could be selected only if it was related to a single sense, but not both. 
		Cause: [(0, 7), (0, 17)]
		Effect: [(0, 0), (0, 5)]

	CASE: 6
	Stag: 85 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: For example, u'\u2018' attention u'\u2019' was a valid object for the attract sense of verb u'\u2018' draw u'\u2019' , since it is unrelated to the sketch sense of that verb. 
		Cause: [(0, 37), (0, 46)]
		Effect: [(0, 0), (0, 34)]

	CASE: 7
	Stag: 86 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: On the other hand, u'\u2018' car u'\u2019' is not an appropriate object for either sense of u'\u2018' draw u'\u2019' , since it could actually appear under both of them in different contexts. 
		Cause: [(0, 38), (0, 48)]
		Effect: [(0, 0), (0, 35)]

	CASE: 8
	Stag: 89 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: We apply linear regression in order to train verb matrices using jointly the object sets for both meanings of each verb, as well as separately u'\u2014' so in this latter case we get two matrices for each verb, one for each sense. 
		Cause: [(0, 0), (0, 30)]
		Effect: [(0, 32), (0, 47)]

	CASE: 9
	Stag: 90 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: For each verb phrase, we create a composite vector by matrix-multiplying the verb matrix with the vector of the specific object. 
		Cause: [(0, 11), (0, 21)]
		Effect: [(0, 0), (0, 9)]

	CASE: 10
	Stag: 92 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: This is done by comparing each holistic vector with all the composite ones, and then evaluating the rank of the correct composite vector within the list of results. 
		Cause: [(0, 4), (0, 28)]
		Effect: [(0, 0), (0, 2)]

Section 7:  7 Unsupervised disambiguation has 15 CE cases
	CASE: 1
	Stag: 106 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: For every occurrence of the verb, we create a vector representing the surrounding context by averaging the vectors of every other word in the same sentence. 
		Cause: [(0, 16), (0, 26)]
		Effect: [(0, 0), (0, 14)]

	CASE: 2
	Stag: 108 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: The clustering algorithm uses Ward u'\u2019' s method as inter-cluster measure, and Pearson correlation for measuring the distance of vectors within a cluster. 
		Cause: [(0, 20), (0, 27)]
		Effect: [(0, 0), (0, 18)]

	CASE: 3
	Stag: 109 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since HAC returns a dendrogram embedding all possible groupings, we measure the quality of each partitioning by using the variance ratio criterion [] and we select the partitioning that achieves the best score (so the number of senses varies from verb to verb. 
		Cause: [(0, 1), (0, 8)]
		Effect: [(0, 10), (0, 45)]

	CASE: 4
	Stag: 109 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: Since HAC returns a dendrogram embedding all possible groupings, we measure the quality of each partitioning by using the variance ratio criterion [] and we select the partitioning that achieves the best score (so the number of senses varies from verb to verb. 
		Cause: [(0, 1), (0, 25)]
		Effect: [(0, 27), (0, 35)]

	CASE: 5
	Stag: 109 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: Since HAC returns a dendrogram embedding all possible groupings, we measure the quality of each partitioning by using the variance ratio criterion [] and we select the partitioning that achieves the best score (so the number of senses varies from verb to verb. 
		Cause: [(0, 7), (0, 11)]
		Effect: [(0, 12), (0, 22)]

	CASE: 6
	Stag: 110 111 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The next step is to classify every noun that has been used as an object with that verb to the most probable verb sense, and then use these sets of nouns as before for training tensors for the various verb senses. Being equipped with a number of sense clusters created as above for every verb, the classification of each object to a relevant sense is based on the cosine distance of the object vector from the centroids of the clusters. 
		Cause: [(0, 13), (1, 39)]
		Effect: [(0, 0), (0, 11)]

	CASE: 7
	Stag: 111 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Being equipped with a number of sense clusters created as above for every verb, the classification of each object to a relevant sense is based on the cosine distance of the object vector from the centroids of the clusters. 
		Cause: [(0, 10), (0, 39)]
		Effect: [(0, 3), (0, 8)]

	CASE: 8
	Stag: 111 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: Being equipped with a number of sense clusters created as above for every verb, the classification of each object to a relevant sense is based on the cosine distance of the object vector from the centroids of the clusters. 
		Cause: [(0, 17), (0, 29)]
		Effect: [(0, 2), (0, 13)]

	CASE: 9
	Stag: 114 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: The union of all object sets is used for training a single unambiguous tensor for the verb. 
		Cause: [(0, 9), (0, 16)]
		Effect: [(0, 0), (0, 7)]

	CASE: 10
	Stag: 114 115 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The union of all object sets is used for training a single unambiguous tensor for the verb. As usual, data points are presented to learning algorithm in random order. 
		Cause: [(1, 1), (1, 12)]
		Effect: [(0, 0), (0, 16)]

	CASE: 11
	Stag: 122 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: For the ambiguous regression model, the composition is done by matrix-multiplying the ambiguous verb matrix (learned by the union of all object sets) with the vector of the noun. 
		Cause: [(0, 11), (0, 31)]
		Effect: [(0, 0), (0, 9)]

	CASE: 12
	Stag: 123 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: For the disambiguated version, we first detect the most probable sense of the verb given the noun, again by comparing the vector of the noun with the centroids of the verb clusters; then, we matrix-multiply the corresponding unambiguous tensor created exclusively from objects that have been classified as closer to this specific sense of the verb with the noun. 
		Cause: [(0, 21), (0, 33)]
		Effect: [(0, 34), (0, 62)]

	CASE: 13
	Stag: 124 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We also test a number of baselines the u'\u2018' verbs-only u'\u2019' model is a non-compositional baseline where only the two verbs are compared; u'\u2018' additive u'\u2019' and u'\u2018' multiplicative u'\u2019' compose the word vectors of each phrase by applying simple element-wise operations. 
		Cause: [(0, 63), (0, 66)]
		Effect: [(0, 7), (0, 61)]

	CASE: 14
	Stag: 127 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: First of all, the regression model is based on the assumption that the holistic vectors of the exemplar verb phrases follow an ideal distributional behaviour that the model aims to approximate as close as possible. 
		Cause: [(0, 10), (0, 35)]
		Effect: [(0, 0), (0, 6)]

	CASE: 15
	Stag: 130 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: This is very important, since a regression model can only perform as well as its training dataset allows it; and in our case this is achieved to a very satisfactory level. 
		Cause: [(0, 6), (0, 32)]
		Effect: [(0, 0), (0, 3)]

Section 8:  8 Conclusion and future work has 1 CE cases
	CASE: 1
	Stag: 132 133 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The use of a robust regression model rejects the hypothesis that the proposed methodology is helpful only for relatively u'\u201c' weak u'\u201d' compositional approaches. As for future work, an interesting direction would be to see how a prior disambiguation step can affect deep learning compositional settings similar to [] and []. 
		Cause: [(1, 1), (1, 29)]
		Effect: [(0, 0), (0, 31)]

Section 9:  Acknowledgements has 0 CE cases
#-------------------------------------------------

