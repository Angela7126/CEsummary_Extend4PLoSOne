Current File: P14-2058.xhtml_2 P14-2058.xhtml

Section 0:  Abstract
	SentNum: 5
	CENum: 1
	SentCovered: 1
	Covered_Rate: 20.0000%

Section 1:  1 Introduction
	SentNum: 17
	CENum: 7
	SentCovered: 6
	Covered_Rate: 35.2941%

Section 2:  2 Related work
	SentNum: 10
	CENum: 3
	SentCovered: 3
	Covered_Rate: 30.0000%

Section 3:  3 Memory tip generation
	SentNum: 40
	CENum: 13
	SentCovered: 17
	Covered_Rate: 42.5000%

Section 4:  4 Experiment setup
	SentNum: 19
	CENum: 2
	SentCovered: 3
	Covered_Rate: 15.7895%

Section 5:  5 Experiment results
	SentNum: 21
	CENum: 6
	SentCovered: 9
	Covered_Rate: 42.8571%

Section 6:  6 Conclusion and Future Work
	SentNum: 6
	CENum: 2
	SentCovered: 3
	Covered_Rate: 50.0000%

Section 7:  Acknowledgements
	SentNum: 1
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-2058.xhtml_2's CE cases

Section 0:  Abstract has 1 CE cases
	CASE: 1
	Stag: 0 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: In this paper, we combine existing NLP techniques with minimal supervision to build memory tips according to the keyword method, a well established mnemonic device for second language learning. 
		Cause: [(0, 18), (0, 30)]
		Effect: [(0, 0), (0, 15)]

Section 1:  1 Introduction has 7 CE cases
	CASE: 1
	Stag: 7 
		Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
		sentTXT: 1) one or more L1 words, possibly referring to a concrete entity, are chosen based on orthographic or phonetic similarity with the target word; 2) an L1 sentence is constructed in which an association between the translation of the target word and the keyword(s) is established, so that the learner, when seeing or hearing the word, immediately recalls the keyword(s. 
		Cause: [(0, 0), (0, 54)]
		Effect: [(0, 57), (0, 72)]

	CASE: 2
	Stag: 7 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: 1) one or more L1 words, possibly referring to a concrete entity, are chosen based on orthographic or phonetic similarity with the target word; 2) an L1 sentence is constructed in which an association between the translation of the target word and the keyword(s) is established, so that the learner, when seeing or hearing the word, immediately recalls the keyword(s. 
		Cause: [(0, 19), (0, 54)]
		Effect: [(0, 0), (0, 16)]

	CASE: 3
	Stag: 8 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: To illustrate, for teaching the Italian word cuore which means heart in English, the learner might be asked to imagine u'\u201c' a lonely heart with a hard core u'\u201d'. 
		Cause: [(0, 4), (0, 13)]
		Effect: [(0, 0), (0, 2)]

	CASE: 4
	Stag: 10 
		Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
		sentTXT: However, the preparation of the memorization tips for each new word is an activity that requires considerable time, linguistic competence and creativity. 
		Cause: [(0, 17), (0, 23)]
		Effect: [(0, 0), (0, 14)]

	CASE: 5
	Stag: 12 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: In [] , we proposed to automate the keyword method by retrieving sentences from the Web. 
		Cause: [(0, 12), (0, 16)]
		Effect: [(0, 0), (0, 10)]

	CASE: 6
	Stag: 15 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: In this paper, we overcome these limitations by introducing a semi-automatic system implementing the keyword method that builds upon the keyword selection mechanism of and combines it with a state-of-the-art creative sentence generation framework []. 
		Cause: [(0, 9), (0, 36)]
		Effect: [(0, 0), (0, 7)]

	CASE: 7
	Stag: 17 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: According to our scenario, the teacher relies on automatic techniques to generate relatively few, high quality mnemonics in English to teach Italian vocabulary. 
		Cause: [(0, 2), (0, 3)]
		Effect: [(0, 5), (0, 24)]

Section 2:  2 Related work has 3 CE cases
	CASE: 1
	Stag: 23 
		Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Their results show that using KM leads to better learning of second language vocabulary for beginners. 
		Cause: [(0, 4), (0, 5)]
		Effect: [(0, 8), (0, 15)]

	CASE: 2
	Stag: 30 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: While we had discussed the potentiality of creative sentence generation as a useful teaching device, we had not validated our claim experimentally yet. 
		Cause: [(0, 11), (0, 23)]
		Effect: [(0, 1), (0, 9)]

	CASE: 3
	Stag: 30 31 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: While we had discussed the potentiality of creative sentence generation as a useful teaching device, we had not validated our claim experimentally yet. As a previous attempt at using NLP for education, employ a riddle generator to create a language playground for children with complex communication needs. 
		Cause: [(1, 1), (1, 24)]
		Effect: [(0, 0), (0, 23)]

Section 3:  3 Memory tip generation has 13 CE cases
	CASE: 1
	Stag: 34 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: We started by compiling a collection of Italian nouns consisting of three syllables from various resources for vocabulary teaching including http://didattica.org/italiano.htm and http://ielanguages.com , and produced a list of 185 target L2 words. 
		Cause: [(0, 3), (0, 22)]
		Effect: [(0, 23), (0, 32)]

	CASE: 2
	Stag: 43 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: Unlike in [] , where we did not enforce any constraints for selecting the keywords, in this case we applied a more sophisticated filtering and ranking strategy. 
		Cause: [(0, 13), (0, 15)]
		Effect: [(0, 0), (0, 11)]

	CASE: 3
	Stag: 45 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: We allowed the keyword generation module to consider all the entries in the CMU dictionary, and rank the keyword pairs based on the following criteria in decreasing order of precedence. 
		Cause: [(0, 23), (0, 30)]
		Effect: [(0, 0), (0, 20)]

	CASE: 4
	Stag: 46 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: 1) Keywords with a smaller orthographic/phonetic distance are preferred; 2) Keywords consisting of a single word are preferred over two words (e.g.,, for the target word lavagna , which means blackboard , lasagna takes precedence over love and onion ); 3) Keywords that do not contain stop words are preferred (e.g.,, for the target word pettine , which means comb , the keyword pair pet and inn is ranked higher than pet and in , since in is a stop word); 4) Keyword pairs obtained with orthographic similarity are preferred over those obtained with phonetic similarity, as learners might be unfamiliar with the phonetic rules of the target language. 
		Cause: [(0, 87), (0, 109)]
		Effect: [(0, 111), (0, 123)]

	CASE: 5
	Stag: 48 49 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We selected up to three of the highest ranked keyword pairs for each target word, obtaining 407 keyword combinations for the initial 185 Italian words, which we used as the input for the sentence generator. In this step, our goal was to generate, for each Italian word, sentences containing its L1 translation and the set of orthographically (or phonetically) similar keywords that we previously selected. 
		Cause: [(0, 31), (1, 33)]
		Effect: [(0, 0), (0, 29)]

	CASE: 6
	Stag: 50 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: For each keyword combination, starting from the top-ranked ones, we generated up to 10 sentences by allowing any known part-of-speech for the keywords. 
		Cause: [(0, 18), (0, 24)]
		Effect: [(0, 0), (0, 16)]

	CASE: 7
	Stag: 52 53 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The system relies on two corpora of automatic parses as a repository of sentence templates and lexical statistics. As for the former, we combined two resources a corpus of 16,000 proverbs [] and a collection of 5,000 image captions 2 2 http://vision.cs.uiuc.edu/pascal-sentences/ collected by. 
		Cause: [(1, 1), (1, 27)]
		Effect: [(0, 0), (0, 17)]

	CASE: 8
	Stag: 54 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: We chose these two collections since they offer a combination of catchy or simple sentences that we expect to be especially suitable for second language learning. 
		Cause: [(0, 6), (0, 25)]
		Effect: [(0, 0), (0, 4)]

	CASE: 9
	Stag: 54 55 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We chose these two collections since they offer a combination of catchy or simple sentences that we expect to be especially suitable for second language learning. As for the second corpus, we used LDC u'\u2019' s English GigaWord 5th Edition 3 3 http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC2011T07. 
		Cause: [(1, 1), (1, 21)]
		Effect: [(0, 0), (0, 25)]

	CASE: 10
	Stag: 59 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: For comparison, when we attempted to retrieve sentences from the Web as suggested in , we could collect an output for less than 10% of the input configurations. 
		Cause: [(0, 13), (0, 29)]
		Effect: [(0, 4), (0, 11)]

	CASE: 11
	Stag: 65 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: Among the sentences u'\u201c' The girl received a call in the bathroom u'\u201d' and u'\u201c' Call the blond girl in case you need u'\u201d' , the first one is preferred, since the keywords are closer to each other. 
		Cause: [(0, 48), (0, 54)]
		Effect: [(0, 0), (0, 45)]

	CASE: 12
	Stag: 67 68 
		Pattern: 2 [['accordingly']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: To illustrate, for the same keywords and the target words, we would prefer the sentence u'\u201c' I called him in the morning yesterday u'\u201d' over u'\u201c' You talk a lot in a call u'\u201d'. Accordingly, for each target word in random order, we sequentially scanned the outputs generated for each keyword pair. 
		Cause: [(0, 0), (0, 51)]
		Effect: [(1, 2), (1, 19)]

	CASE: 13
	Stag: 70 71 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We continued this process until we selected a sentence for 40 distinct target words, which we set as the target size of the experiment. We had to inspect the outputs generated for 48 target words before we were able to select 40 good examples, meaning that for 17% of the target words the sentence generator could not produce a sentence of acceptable quality. 
		Cause: [(0, 19), (1, 39)]
		Effect: [(0, 0), (0, 17)]

Section 4:  4 Experiment setup has 2 CE cases
	CASE: 1
	Stag: 75 76 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: 4 4 We preferred to select the experiment subjects in person as opposed to crowdsourcing the evaluation to be able to verify the proficiency of the subjects in the two languages and to ensure the reliability of the outcome of the evaluation. After obtaining the sentences as explained in Section 3 , we shuffled and then divided the whole set including 40 target words together with their translation, the generated keywords and sentences into 2 batches (A, B) and further divided each batch into 2 groups consisting of 10 elements (A1, A2, B1 and B2. 
		Cause: [(0, 12), (1, 17)]
		Effect: [(0, 2), (0, 10)]

	CASE: 2
	Stag: 89 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: 5 5 Otherwise, they could easily filter out the wrong answers just because they were not exposed to them recently. 
		Cause: [(0, 14), (0, 20)]
		Effect: [(0, 0), (0, 11)]

Section 5:  5 Experiment results has 6 CE cases
	CASE: 1
	Stag: 93 94 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: Due to the presence of the u'\u201c' I already knew this word u'\u201d' option in the learning-assessment questionnaire, the number of the actual answers provided by each subject can be slightly different, hence the difference between macro- and micro-average. The error rate for each memorization technique t (where t = R for u'\u201c' Rote memorization u'\u201d' and t = K for u'\u201c' keyword-aided memorization u'\u201d' ) is calculated as e t = i t c t + i t , where c t and i t are the number of correct and incorrect answers provided by the subjects, respectively. 
		Cause: [(0, 0), (0, 40)]
		Effect: [(0, 43), (1, 76)]

	CASE: 2
	Stag: 94 95 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The error rate for each memorization technique t (where t = R for u'\u201c' Rote memorization u'\u201d' and t = K for u'\u201c' keyword-aided memorization u'\u201d' ) is calculated as e t = i t c t + i t , where c t and i t are the number of correct and incorrect answers provided by the subjects, respectively. The absolute error rate reduction u'\u0394' u'\u2062' e is calculated as the absolute difference in error rate between rote and keyword-aided memorization, i.e u'\u0394' e = e R - e K. 
		Cause: [(0, 47), (1, 41)]
		Effect: [(0, 0), (0, 45)]

	CASE: 3
	Stag: 95 96 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The absolute error rate reduction u'\u0394' u'\u2062' e is calculated as the absolute difference in error rate between rote and keyword-aided memorization, i.e u'\u0394' e = e R - e K. Finally, the relative error rate reduction % e is calculated as the the ratio between the absolute error rate reduction u'\u0394' u'\u2062' e and the error rate of rote memorization e R , i.e. 
		Cause: [(0, 19), (1, 25)]
		Effect: [(0, 0), (0, 17)]

	CASE: 4
	Stag: 100 101 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The results clearly indicate that one group (A1) by chance contained easier words to memorize as shown by the low error rate (between 3% and 4%) obtained with both methods. Similarly, groups A2 and B1 are of average difficulty, whereas group B2 appears to be the most difficult, with an error rate higher than 22% when using only rote memorization. 
		Cause: [(0, 18), (1, 33)]
		Effect: [(0, 0), (0, 16)]

	CASE: 5
	Stag: 102 103 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Interestingly, there is a strong correlation (Pearson u'\u2019' s r = 0.85 ) between the difficulty of the words in each group (measured as the error rate on rote memorization) and the positive contribution of the generated sentences to the learning process. In fact, we can see how the relative error rate reduction % e increases from u'\u223c' 17% (group A1) to almost 45% (group B2. 
		Cause: [(0, 31), (1, 23)]
		Effect: [(0, 0), (0, 29)]

	CASE: 6
	Stag: 104 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Based on the results obtained by , who showed that the keyword method results in better long-term word retention than rote memorization, we would expect the error rate reduction to be even higher in a delayed post-test. 
		Cause: [(0, 2), (0, 5)]
		Effect: [(0, 7), (0, 37)]

Section 6:  6 Conclusion and Future Work has 2 CE cases
	CASE: 1
	Stag: 115 116 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The significant reduction in retention error rate (between 17% and 45% on different word groups) for the words learned with the aid of the automatically generated sentences shows that they are a viable low-effort alternative to human-constructed examples for vocabulary teaching. As future work, it would be interesting to involve learners in an interactive evaluation to understand the extent to which learners can benefit from ad-hoc personalization. 
		Cause: [(1, 1), (1, 26)]
		Effect: [(0, 0), (0, 44)]

	CASE: 2
	Stag: 117 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Furthermore, it should be possible to use frameworks similar to the one that we presented to automate other teaching devices based on sentences conforming to specific requirements [] , such as verbal chaining and acrostic. 
		Cause: [(0, 23), (0, 36)]
		Effect: [(0, 0), (0, 20)]

Section 7:  Acknowledgements has 0 CE cases
#-------------------------------------------------

