Current File: P14-2114.xhtml_2 P14-2114.xhtml

Section 0:  Abstract
	SentNum: 8
	CENum: 2
	SentCovered: 3
	Covered_Rate: 37.5000%

Section 1:  1 Introduction
	SentNum: 27
	CENum: 8
	SentCovered: 9
	Covered_Rate: 33.3333%

Section 2:  2 Methodology
	SentNum: 48
	CENum: 13
	SentCovered: 15
	Covered_Rate: 31.2500%

Section 3:  3 Experiments
	SentNum: 44
	CENum: 11
	SentCovered: 10
	Covered_Rate: 22.7273%

Section 4:  4 Conclusions and Future Work
	SentNum: 7
	CENum: 1
	SentCovered: 1
	Covered_Rate: 14.2857%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-2114.xhtml_2's CE cases

Section 0:  Abstract has 2 CE cases
	CASE: 1
	Stag: 0 1 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: With the proliferation of social media sites, social streams have proven to contain the most up-to-date information on current events. Therefore, it is crucial to extract events from the social streams such as tweets. 
		Cause: [(0, 0), (0, 20)]
		Effect: [(1, 2), (1, 14)]

	CASE: 2
	Stag: 2 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: However, it is not straightforward to adapt the existing event extraction systems since texts in social media are fragmented and noisy. 
		Cause: [(0, 14), (0, 21)]
		Effect: [(0, 0), (0, 12)]

Section 1:  1 Introduction has 8 CE cases
	CASE: 1
	Stag: 9 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Previous work in event extraction has focused largely on news articles, as the newswire texts have been the best source of information on current events [ 6 ]. 
		Cause: [(0, 13), (0, 27)]
		Effect: [(0, 0), (0, 10)]

	CASE: 2
	Stag: 12 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: They lack the flexibility of porting to new domains since extraction patterns often need to be re-defined. 
		Cause: [(0, 10), (0, 16)]
		Effect: [(0, 0), (0, 8)]

	CASE: 3
	Stag: 18 19 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Social media messages are often short and evolve rapidly over time. As such, it is not possible to know the event types a priori and hence violates the use of existing event extraction approaches. 
		Cause: [(1, 1), (1, 23)]
		Effect: [(0, 0), (0, 10)]

	CASE: 4
	Stag: 20 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Approaches to event extraction from Twitter make use of a graphical model to extract canonical entertainment events from tweets by aggregating information across multiple messages [ 1 ]. 
		Cause: [(0, 20), (0, 27)]
		Effect: [(0, 0), (0, 18)]

	CASE: 5
	Stag: 21 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: In [ 7 ] , social events involving two persons are extracted from multiple similar tweets using a factor graph by harvesting the redundancy in tweets. 
		Cause: [(0, 21), (0, 25)]
		Effect: [(0, 0), (0, 19)]

	CASE: 6
	Stag: 25 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: This property allows us resort to statistical models that can group similar events based on the co-occurrence patterns of their event elements. 
		Cause: [(0, 15), (0, 21)]
		Effect: [(0, 0), (0, 12)]

	CASE: 7
	Stag: 27 28 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We can treat an event as a latent variable and model the generation of an event as a joint distribution of its individual event elements. We thus propose a Latent Event Model (LEM) which can automatically detect events from social media without the use of labeled data. 
		Cause: [(0, 6), (1, 9)]
		Effect: [(0, 0), (0, 4)]

	CASE: 8
	Stag: 27 28 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: We can treat an event as a latent variable and model the generation of an event as a joint distribution of its individual event elements. We thus propose a Latent Event Model (LEM) which can automatically detect events from social media without the use of labeled data. 
		Cause: [(0, 1), (1, 0)]
		Effect: [(1, 2), (1, 23)]

Section 2:  2 Methodology has 13 CE cases
	CASE: 1
	Stag: 35 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Events extracted in our proposed framework are represented as a 4-tuple u'\u27e8' y , d , l , k u'\u27e9' , where y stands for a non-location named entity, d for a date, l for a location, and k for an event-related keyword. 
		Cause: [(0, 9), (0, 52)]
		Effect: [(0, 0), (0, 7)]

	CASE: 2
	Stag: 37 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: It should be noted that for some events, one or more elements in their corresponding tuples might be absent as their related information is not available in tweets. 
		Cause: [(0, 21), (0, 28)]
		Effect: [(0, 0), (0, 19)]

	CASE: 3
	Stag: 37 38 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: It should be noted that for some events, one or more elements in their corresponding tuples might be absent as their related information is not available in tweets. As illustrated in Figure 1 , our proposed framework consists of three main steps, pre-processing, event extraction based on the LEM model and post-processing. 
		Cause: [(1, 1), (1, 16)]
		Effect: [(0, 0), (0, 28)]

	CASE: 4
	Stag: 43 44 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: To resolve the ambiguity of the time expressions, SUTime 1 1 http://nlp.stanford.edu/software/sutime.shtml [ 2 ] is employed, which takes text and a reference date as input and outputs a more accurate date which the time expression refers to. Named entity recognition (NER) is a crucial step since the results would directly impact the final extracted 4-tuple u'\u27e8' y , d , l , k u'\u27e9'. 
		Cause: [(0, 27), (1, 36)]
		Effect: [(0, 2), (0, 25)]

	CASE: 5
	Stag: 44 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: Named entity recognition (NER) is a crucial step since the results would directly impact the final extracted 4-tuple u'\u27e8' y , d , l , k u'\u27e9'. 
		Cause: [(0, 11), (0, 36)]
		Effect: [(0, 0), (0, 9)]

	CASE: 6
	Stag: 45 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: It is not easy to accurately identify named entities in the Twitter data since tweets contain a lot of misspellings and abbreviations. 
		Cause: [(0, 14), (0, 21)]
		Effect: [(0, 0), (0, 12)]

	CASE: 7
	Stag: 46 47 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: However, it is often observed that events mentioned in tweets are also reported in news articles in the same period [ 10 ]. Therefore, named entities mentioned in tweets are likely to appear in news articles as well. 
		Cause: [(0, 0), (0, 23)]
		Effect: [(1, 2), (1, 15)]

	CASE: 8
	Stag: 47 48 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: Therefore, named entities mentioned in tweets are likely to appear in news articles as well. We thus perform named entity recognition in the following way. 
		Cause: [(0, 1), (1, 0)]
		Effect: [(1, 2), (1, 9)]

	CASE: 9
	Stag: 51 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Named entities from tweets are extracted by looking up the dictionary through fuzzy matching. 
		Cause: [(0, 7), (0, 13)]
		Effect: [(0, 0), (0, 5)]

	CASE: 10
	Stag: 57 58 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: After the pre-processing step, non-location entities y , locations l , dates d and candidate keywords of the tweets are collected as the input to the LEM model for event extraction. We propose an unsupervised latent variable model, called the Latent Event Model (LEM), to extract events from tweets. 
		Cause: [(0, 23), (1, 20)]
		Effect: [(0, 0), (0, 21)]

	CASE: 11
	Stag: 60 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In this model, we assume that each tweet message m u'\u2208' { 1 u'\u2062' M } is assigned to one event instance e , while e is modeled as a joint distribution over the named entities y , the date/time d when the event occurred, the location l where the event occurred and the event-related keywords k. 
		Cause: [(0, 38), (0, 57)]
		Effect: [(0, 0), (0, 36)]

	CASE: 12
	Stag: 78 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: Once the class assignments for all events are known, we can easily estimate the model parameters { u'\ud835' u'\udf45' , u'\ud835' u'\udf3d' , u'\ud835' u'\udf4b' , u'\ud835' u'\udf4d' , u'\ud835' u'\udf4e' }. 
		Cause: [(0, 1), (0, 8)]
		Effect: [(0, 10), (0, 72)]

	CASE: 13
	Stag: 82 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If P ( element) is less than 1 u'\u039e' u'\u2062' P u'\u2062' ( S ) , where P u'\u2062' ( S ) is the sum of probabilities of the other three elements and u'\u039e' is a threshold value and is set to 5 empirically, the element will be removed from the extracted results. 
		Cause: [(0, 1), (0, 27)]
		Effect: [(0, 29), (0, 74)]

Section 3:  3 Experiments has 11 CE cases
	CASE: 1
	Stag: 83 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: In this section, we first describe the Twitter corpus used in our experiments and then present how we build a baseline based on the previously proposed TwiCal system [ 14 ] , the state-of-the-art open event extraction system on tweets. 
		Cause: [(0, 24), (0, 40)]
		Effect: [(0, 0), (0, 21)]

	CASE: 2
	Stag: 93 94 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: We believe that in reality, events which are mentioned in very few tweets are less likely to be significant. Therefore, the dataset was filtered by removing the events which are mentioned in less than 10 tweets. 
		Cause: [(0, 0), (0, 19)]
		Effect: [(1, 2), (1, 17)]

	CASE: 3
	Stag: 97 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The events extracted in the baseline are represented as a 3-tuple u'\u27e8' y , d , k u'\u27e9' 5 5 TwiCal also groups event instances into event types such as u'\u201d' Sport u'\u201d' or u'\u201d' Politics u'\u201d' using LinkLDA which is not considered here where y stands for a non-location named entity, d for a date and k for an event phrase. 
		Cause: [(0, 9), (0, 85)]
		Effect: [(0, 0), (0, 7)]

	CASE: 4
	Stag: 104 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: Due to the difficulties of re-implementing the sequence labeler without knowing the actual features set and the annotated training data, we assume all the event-related phrases are identified correctly and simply use the event trigger words annotated in the FSD corpus as k to form the event 3-tuples. 
		Cause: [(0, 2), (0, 19)]
		Effect: [(0, 21), (0, 48)]

	CASE: 5
	Stag: 107 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: For the 4-tuple u'\u27e8' y , d , l , k u'\u27e9' , the precision is calculated based on the following criteria. 
		Cause: [(0, 27), (0, 29)]
		Effect: [(0, 0), (0, 24)]

	CASE: 6
	Stag: 110 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If the extracted representation does not contain keywords, its precision is calculated by checking the criteria 1. 
		Cause: [(0, 1), (0, 7)]
		Effect: [(0, 9), (0, 17)]

	CASE: 7
	Stag: 110 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: If the extracted representation does not contain keywords, its precision is calculated by checking the criteria 1. 
		Cause: [(0, 5), (0, 8)]
		Effect: [(0, 0), (0, 3)]

	CASE: 8
	Stag: 111 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If the extracted representation contains keywords, its precision is calculated by checking both criteria 1 and 2. 
		Cause: [(0, 1), (0, 5)]
		Effect: [(0, 7), (0, 17)]

	CASE: 9
	Stag: 111 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: If the extracted representation contains keywords, its precision is calculated by checking both criteria 1 and 2. 
		Cause: [(0, 5), (0, 10)]
		Effect: [(0, 0), (0, 3)]

	CASE: 10
	Stag: 121 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: It can be observed from Table 2 that by using NW-NER, the performance of event extraction system is improved significantly by 7.5% and 3% respectively on F-measure when evaluated on 3-tuples (without keywords) or 4-tuples (with keywords. 
		Cause: [(0, 9), (0, 10)]
		Effect: [(0, 11), (0, 42)]

	CASE: 11
	Stag: 126 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: This shows that our LEM model is less sensitive to the number of events E so long as E is set to a relatively larger value. 
		Cause: [(0, 0), (0, 14)]
		Effect: [(0, 16), (0, 24)]

Section 4:  4 Conclusions and Future Work has 1 CE cases
	CASE: 1
	Stag: 129 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: After that, the model can automatically extract events which involving a named entity at certain time, location, and with event-related keywords based on the co-occurrence patterns of the event elements. 
		Cause: [(0, 26), (0, 32)]
		Effect: [(0, 0), (0, 23)]

#-------------------------------------------------

