Current File: P14-1087.xhtml_2 P14-1087.xhtml

Section 0:  Abstract
	SentNum: 6
	CENum: 1
	SentCovered: 1
	Covered_Rate: 16.6667%

Section 1:  1 Introduction
	SentNum: 30
	CENum: 8
	SentCovered: 13
	Covered_Rate: 43.3333%

Section 2:  2 Related Work
	SentNum: 34
	CENum: 6
	SentCovered: 7
	Covered_Rate: 20.5882%

Section 3:  3 Methodology
	SentNum: 108
	CENum: 26
	SentCovered: 28
	Covered_Rate: 25.9259%

Section 4:  4 Experiments and Results
	SentNum: 35
	CENum: 8
	SentCovered: 12
	Covered_Rate: 34.2857%

Section 5:  5 Discussion
	SentNum: 48
	CENum: 13
	SentCovered: 15
	Covered_Rate: 31.2500%

Section 6:  6 Conclusion
	SentNum: 9
	CENum: 3
	SentCovered: 5
	Covered_Rate: 55.5556%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-1087.xhtml_2's CE cases

Section 0:  Abstract has 1 CE cases
	CASE: 1
	Stag: 2 
		Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: We derive three features from these timelines, and show that their use in supervised summarization lead to a significant 4.1% improvement in ROUGE performance over a state-of-the-art baseline. 
		Cause: [(0, 11), (0, 15)]
		Effect: [(0, 18), (0, 29)]

Section 1:  1 Introduction has 8 CE cases
	CASE: 1
	Stag: 7 8 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Besides the increasing availability of annotation standards (e.g.,, TimeML [ 21 ] ) and corpora (e.g.,, TIDES [ 9 ] , TimeBank [ 22 ] ), the community has also organized three successful evaluation workshops u'\u2014' TempEval-1 [ 25 ] , -2 [ 26 ] , and -3 [ 24 ]. As the state-of-the-art improves, these workshops have moved away from the piecemeal evaluation of individual temporal processing tasks and towards the evaluation of complete end-to-end systems in TempEval-3. 
		Cause: [(1, 1), (1, 28)]
		Effect: [(0, 0), (0, 61)]

	CASE: 2
	Stag: 12 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We hope to improve the quality of the summaries that are generated by considering temporal information found in the input text. 
		Cause: [(0, 13), (0, 20)]
		Effect: [(0, 0), (0, 11)]

	CASE: 3
	Stag: 15 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Recognizing that sentence (3) is about a storm that had happened in the past is important when writing a summary about the recent storm, as it is not relevant and can likely be excluded. 
		Cause: [(0, 28), (0, 36)]
		Effect: [(0, 2), (0, 25)]

	CASE: 4
	Stag: 16 17 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: 1) A fierce cyclone packing extreme winds and torrential rain smashed into Bangladesh u'\u2019' s southwestern coast Thursday, wiping out homes and trees in what officials described as the worst storm in years. 2) More than 100,000 coastal villagers have been evacuated before the cyclone made landfall. 
		Cause: [(0, 34), (1, 13)]
		Effect: [(0, 2), (0, 32)]

	CASE: 5
	Stag: 24 25 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: There are fewer events which talk about the previous storm. Thus, temporal information does assist in identifying which sentences are more relevant to the final summary. 
		Cause: [(0, 0), (0, 9)]
		Effect: [(1, 1), (1, 16)]

	CASE: 6
	Stag: 26 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Our work is significant as it addresses an important gap in the exploitation of temporal information. 
		Cause: [(0, 5), (0, 15)]
		Effect: [(0, 0), (0, 3)]

	CASE: 7
	Stag: 28 29 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In this work we construct timelines (as a representation of temporal information) automatically and incorporate them into a state-of-the-art multi-document summarization system. This is achieved with 1) three novel features derived from timelines to help measure the saliency of sentences, as well as 2) TimeMMR , a modification to the traditional Maximal Marginal Relevance (MMR) [ 3 ]. 
		Cause: [(0, 8), (1, 38)]
		Effect: [(0, 1), (0, 6)]

	CASE: 8
	Stag: 34 35 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This work additionally proposes the use of the lengths of timelines as a metric to gauge the usefulness of timelines. Together with the earlier described contributions, this metric further improves summarization, yielding an overall 5.9% performance increase. 
		Cause: [(0, 12), (1, 18)]
		Effect: [(0, 0), (0, 10)]

Section 2:  2 Related Work has 6 CE cases
	CASE: 1
	Stag: 53 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: After laying out these events onto a timeline by making use of these timestamps, the number of events that happen within the same day is used to influence sentence scoring. 
		Cause: [(0, 9), (0, 13)]
		Effect: [(0, 14), (0, 30)]

	CASE: 2
	Stag: 56 
		Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
		sentTXT: In sentence re-ordering, final summaries are re-arranged so that the extracted sentences that form the summary are in a chronological order. 
		Cause: [(0, 0), (0, 7)]
		Effect: [(0, 10), (0, 21)]

	CASE: 3
	Stag: 58 59 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Depending on the style of writing or journalistic guidelines, a summary can arguably be written in a number of ways. The use of recency as an indicator of saliency is useful, yet disregards other accessible temporal information. 
		Cause: [(1, 5), (1, 17)]
		Effect: [(0, 1), (1, 3)]

	CASE: 4
	Stag: 60 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If a summary of a whole sequence of events is desired, recency becomes less useful. 
		Cause: [(0, 1), (0, 10)]
		Effect: [(0, 12), (0, 15)]

	CASE: 5
	Stag: 64 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: In this work, we have simplified this idea by dropping the need for event co-referencing (removing a source of propagated error), and augmented it with two additional features derived from timelines. 
		Cause: [(0, 10), (0, 23)]
		Effect: [(0, 24), (0, 34)]

	CASE: 6
	Stag: 64 65 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: In this work, we have simplified this idea by dropping the need for event co-referencing (removing a source of propagated error), and augmented it with two additional features derived from timelines. By doing so, we are able to make better use of the available temporal information, taking into account all known events and the time in which they occur. 
		Cause: [(0, 1), (1, 1)]
		Effect: [(1, 4), (1, 29)]

Section 3:  3 Methodology has 26 CE cases
	CASE: 1
	Stag: 74 
		Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: They indicate the temporal relationships between two basic temporal units. 
		Cause: [(0, 0), (0, 0)]
		Effect: [(0, 2), (0, 9)]

	CASE: 2
	Stag: 84 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: SWING is a supervised, extractive summarization system which ranks sentences based on scores computed using a set of features in the Sentence Scoring phase. 
		Cause: [(0, 13), (0, 24)]
		Effect: [(0, 0), (0, 10)]

	CASE: 3
	Stag: 86 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The timelines built in the earlier temporal processing can be incorporated into this pipeline by deriving a set of features used to score sentences in Sentence Scoring , and as input to the MMR algorithm when computing similarity in Sentence Re-ordering. 
		Cause: [(0, 15), (0, 40)]
		Effect: [(0, 0), (0, 13)]

	CASE: 4
	Stag: 93 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Generalizing, we refer to the time period an event takes place in as its time span (vertical dotted lines. 
		Cause: [(0, 0), (0, 0)]
		Effect: [(0, 2), (0, 20)]

	CASE: 5
	Stag: 93 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Generalizing, we refer to the time period an event takes place in as its time span (vertical dotted lines. 
		Cause: [(0, 12), (0, 18)]
		Effect: [(0, 0), (0, 10)]

	CASE: 6
	Stag: 93 94 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Generalizing, we refer to the time period an event takes place in as its time span (vertical dotted lines. As a simplifying assumption, events are laid out on the timeline based on the starting time of their time span. 
		Cause: [(1, 1), (1, 20)]
		Effect: [(0, 0), (0, 20)]

	CASE: 7
	Stag: 103 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Referring to Figure 1 , whose timeline is shown in Figure 2 , we see that the time span with the most number of events is when the latest cyclone made landfall. 
		Cause: [(0, 0), (0, 11)]
		Effect: [(0, 13), (0, 31)]

	CASE: 8
	Stag: 104 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Assigning higher scores for sentences which contain events in this time span will help us to select more relevant sentences if we want a summary about the cyclone. 
		Cause: [(0, 21), (0, 27)]
		Effect: [(0, 1), (0, 19)]

	CASE: 9
	Stag: 106 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The importance of a time span T u'\u2062' S i is computed by normalizing the number of events in T u'\u2062' S i against the number of events in T u'\u2062' S L. 
		Cause: [(0, 17), (0, 44)]
		Effect: [(0, 0), (0, 15)]

	CASE: 10
	Stag: 135 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Then the temporal coverage of a sentence is defined as the number of time spans between the earliest time span T u'\u2062' S a and the latest time span T u'\u2062' S c. 
		Cause: [(0, 10), (0, 39)]
		Effect: [(0, 0), (0, 8)]

	CASE: 11
	Stag: 138 139 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The constraint on the number of sentences that can be included in a summary requires us to select compact sentences which contain as many relevant facts as possible. Traditional lexical measures may attempt to achieve this by computing the ratio of keyphrases to the number of words in a sentence [ 11 ]. 
		Cause: [(0, 23), (1, 23)]
		Effect: [(0, 0), (0, 21)]

	CASE: 12
	Stag: 139 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Traditional lexical measures may attempt to achieve this by computing the ratio of keyphrases to the number of words in a sentence [ 11 ]. 
		Cause: [(0, 9), (0, 24)]
		Effect: [(0, 0), (0, 7)]

	CASE: 13
	Stag: 140 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: Stated equivalently, when two sentences are of the same length, if one contains more keyphrases, it should contain more useful facts. 
		Cause: [(0, 13), (0, 16)]
		Effect: [(0, 18), (0, 23)]

	CASE: 14
	Stag: 141 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: TCD parallels this idea with the use of temporal information, i.e., if two sentences are of the same temporal coverage, then the one with more events should carry more useful facts. 
		Cause: [(0, 14), (0, 21)]
		Effect: [(0, 23), (0, 32)]

	CASE: 15
	Stag: 142 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: Formally, if a sentence s contains events u'\ud835' u'\udd3c' s = { e 1 , u'\u2026' , e n } , where each event is associated with a time span T u'\u2062' S i , then T u'\u2062' C u'\u2062' D is computed using. 
		Cause: [(0, 3), (0, 22)]
		Effect: [(0, 24), (0, 68)]

	CASE: 16
	Stag: 145 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: 1) An official in Barisal, 120 kilometres south of Dhaka, spoke of severe destruction as the 500 kilometre-wide mass of cloud passed overhead. 
		Cause: [(0, 18), (0, 25)]
		Effect: [(0, 0), (0, 16)]

	CASE: 17
	Stag: 149 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: In each iteration, s is penalized if it is lexically similar to other sentences that have already been selected to form the eventual summary S = { s 1 , s 2 , u'\u2026' }. 
		Cause: [(0, 8), (0, 39)]
		Effect: [(0, 0), (0, 6)]

	CASE: 18
	Stag: 150 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The motivating idea is to reduce repeated information by preferring sentences which bring in new facts. 
		Cause: [(0, 9), (0, 15)]
		Effect: [(0, 0), (0, 7)]

	CASE: 19
	Stag: 154 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: A summary about the hurricane need not contain all of these sentences as they are all describing the same thing. 
		Cause: [(0, 13), (0, 19)]
		Effect: [(0, 0), (0, 11)]

	CASE: 20
	Stag: 155 156 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: However it is not trivial for the lexically-motivated MMR algorithm to detect that events like u'\u201c' passed u'\u201d' , u'\u201c' uprooted u'\u201d' or u'\u201c' damaged u'\u201d' are in fact repetitive. Thus, we propose further penalizing the score of s if it contains events that happen in similar time spans as those contained in sentences within S. 
		Cause: [(0, 0), (0, 53)]
		Effect: [(1, 1), (1, 26)]

	CASE: 21
	Stag: 160 161 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: where S u'\u2062' c u'\u2062' o u'\u2062' r u'\u2062' e u'\u2062' ( s ) is the score of s , S is the set of sentences already selected to be in the summary from previous iterations, and R u'\u2062' 2 is the predicted ROUGE-2 score of s with respect to the already selected sentences ( S u'\u0393' is a weighting parameter which is empirically set to 0.9 after tuning over a development dataset u'\ud835' u'\udcaf' is the proportion of events in s which happen in the same time span as another event in any other sentence in S. Two events are said to be in the same time span if one happens within the time period the other happens in. 
		Cause: [(0, 127), (1, 20)]
		Effect: [(0, 2), (0, 125)]

	CASE: 22
	Stag: 161 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Two events are said to be in the same time span if one happens within the time period the other happens in. 
		Cause: [(0, 12), (0, 21)]
		Effect: [(0, 0), (0, 10)]

	CASE: 23
	Stag: 163 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: While TimeMMR is proposed here as an improvement over MMR, the premise is that incorporating temporal information can be helpful to minimize redundancy in summaries. 
		Cause: [(0, 6), (0, 25)]
		Effect: [(0, 1), (0, 4)]

	CASE: 24
	Stag: 167 168 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We chose to use MMR here as a proof-of-concept to demonstrate the viability of such a technique, and to easily integrate our work into SWING. Temporal processing is imperfect. 
		Cause: [(0, 7), (1, 2)]
		Effect: [(0, 0), (0, 5)]

	CASE: 25
	Stag: 171 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: This can be done by computing a metric which can be used to decide whether or not timelines should be used for a particular input document collection. 
		Cause: [(0, 5), (0, 26)]
		Effect: [(0, 0), (0, 3)]

	CASE: 26
	Stag: 173 174 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We postulate that the length of a timeline can serve as a simple reliability filtering metric. The intuition for this is that for longer timelines (which contain more events), possible errors are spread over the entire timeline, and do not overpower any useful signal that can be obtained from the timeline features outlined earlier. 
		Cause: [(0, 11), (1, 40)]
		Effect: [(0, 0), (0, 9)]

Section 4:  4 Experiments and Results has 8 CE cases
	CASE: 1
	Stag: 180 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since the focus of this paper is on multi-document summarization, we employ only the three generic features, i.e.,, 1) sentence position, 2) sentence length, and 3) interpolated n-gram document frequency in our experiments below. 
		Cause: [(0, 1), (0, 9)]
		Effect: [(0, 11), (0, 42)]

	CASE: 2
	Stag: 181 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Summarization evaluation is done using ROUGE-2 (R-2) [ 13 ] , as it has previously been shown to correlate well with human assessment [ 14 ] and is often used to evaluate automatic text summarization. 
		Cause: [(0, 14), (0, 36)]
		Effect: [(0, 0), (0, 11)]

	CASE: 3
	Stag: 184 185 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We also show the results of two reference systems, CLASSY [ 5 ] and POLYCOM [ 30 ] , as benchmarks. CLASSY and POLYCOM are top performing systems at TAC-2011 (ranked 2nd and 3rd by R-2 in TAC 2011, respectively; the full version of SWING was ranked 1st with a R-2 score of 0.1380. 
		Cause: [(0, 21), (1, 19)]
		Effect: [(0, 0), (0, 18)]

	CASE: 4
	Stag: 188 189 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: We assume that the various input document sets to be summarized are available at the time of processing. Hence in these experiments, the threshold for filtering is set to be the average of all the timeline sizes over the whole input dataset. 
		Cause: [(0, 0), (0, 17)]
		Effect: [(1, 1), (1, 24)]

	CASE: 5
	Stag: 196 197 
		Pattern: 0 [[['imply', 'implies', 'implied', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(that)', '&R@Complete@']]
		sentTXT: The same drop occurs even when reliability filtering is used (Rows 9 to 12. These indicate that all the proposed features are important and need to be used together to be effective. 
		Cause: [(0, 0), (0, 14)]
		Effect: [(1, 3), (1, 17)]

	CASE: 6
	Stag: 200 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Looking at Rows 1 to 8, and Rows 9 to 16, we see the importance of reliability filtering. 
		Cause: [(0, 0), (0, 11)]
		Effect: [(0, 13), (0, 19)]

	CASE: 7
	Stag: 202 
		Pattern: 0 [[['imply', 'implies', 'implied', 'mean', 'means', 'indicate', 'indicates', 'indicated']]]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
		sentTXT: To help visualize what the differences in these ROUGE scores mean, Figure 7 shows two summaries 1 1 The produced summaries are truncated to fit within a 100-word limit imposed by the TAC-2011 guidelines generated for document set D1117C of the TAC-2011 dataset. 
		Cause: [(0, 0), (0, 6)]
		Effect: [(0, 12), (0, 13)]

	CASE: 8
	Stag: 204 205 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: u'\u211d' 2) A top Army general vowed to personally oversee the upgrading of Walter Reed Army Medical Center u'\u2019' s Building 18, a dilapidated former hotel that houses wounded soldiers as outpatients. [2]. 
		Cause: [(0, 41), (1, 1)]
		Effect: [(0, 0), (0, 39)]

Section 5:  5 Discussion has 13 CE cases
	CASE: 1
	Stag: 214 
		Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
		sentTXT: For the analysis on timeline features, we only present an analysis for TSI and CTSI due to space constraints. 
		Cause: [(0, 18), (0, 19)]
		Effect: [(0, 0), (0, 15)]

	CASE: 2
	Stag: 218 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: It is easy to see why ( u'\ud835' u'\udd43' 1) scores higher for R-2 u'\u2014' it describes the cause of the accident just as it occurred u'\u211d' 1) however talks about events which happened before the accident itself (e.g.,, how much of the tower had already been erected. 
		Cause: [(0, 37), (0, 67)]
		Effect: [(0, 0), (0, 35)]

	CASE: 3
	Stag: 219 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: In this case time span importance is able to correctly guide summary generation by favoring time spans containing events related to the actual toppling. 
		Cause: [(0, 14), (0, 23)]
		Effect: [(0, 0), (0, 12)]

	CASE: 4
	Stag: 233 
		Pattern: 8 [['because']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&ADV)'], ['&C']]
		sentTXT: However we believe it is because the ROUGE measures that are used for evaluation are not suited for this purpose. 
		Cause: [(0, 6), (0, 19)]
		Effect: [(0, 0), (0, 2)]

	CASE: 5
	Stag: 234 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Recall that TimeMMR seeks to eliminate redundancy based on time span similarities and not lexical likeness. 
		Cause: [(0, 9), (0, 15)]
		Effect: [(0, 0), (0, 6)]

	CASE: 6
	Stag: 240 241 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: TimeMMR penalizes ( u'\u211d' 3 u'\u211d' 3) reports that the shoe-throwing incident happened as the U.S. President Bush appeared together with the Iraqi Prime Minister Nouri al-Maliki. 
		Cause: [(0, 23), (1, 9)]
		Effect: [(0, 0), (0, 21)]

	CASE: 7
	Stag: 243 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since ( u'\u211d' 1) and ( u'\u211d' 3) talk about the same time span, TimeMMR down-weights ( u'\u211d' 3. 
		Cause: [(0, 1), (0, 17)]
		Effect: [(0, 25), (0, 33)]

	CASE: 8
	Stag: 246 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: u'\u211d' 3) The incident occurred as Bush was appearing with Iraqi Prime Minister Nouri al-Maliki. 
		Cause: [(0, 11), (0, 19)]
		Effect: [(0, 7), (0, 9)]

	CASE: 9
	Stag: 253 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: T =0 means that timelines are used for all input document sets, whereas T =100 means that no timelines are used, as the length of the longest timeline is less than 100. 
		Cause: [(0, 26), (0, 35)]
		Effect: [(0, 0), (0, 23)]

	CASE: 10
	Stag: 253 254 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: T =0 means that timelines are used for all input document sets, whereas T =100 means that no timelines are used, as the length of the longest timeline is less than 100. As the threshold increases from 0 to 40 u'\u2013' 50, summarization performance improves while the number of document sets where temporal information is used is reduced. 
		Cause: [(1, 1), (1, 30)]
		Effect: [(0, 0), (0, 35)]

	CASE: 11
	Stag: 257 258 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This affirms our use of the average length of timelines as the threshold value in our earlier experiments. Beyond 60, the R-2 scores are still higher than that obtained by SWING , but no longer significantly different. 
		Cause: [(0, 11), (1, 18)]
		Effect: [(0, 0), (0, 9)]

	CASE: 12
	Stag: 258 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: Beyond 60, the R-2 scores are still higher than that obtained by SWING , but no longer significantly different. 
		Cause: [(0, 13), (0, 13)]
		Effect: [(0, 14), (0, 15)]

	CASE: 13
	Stag: 259 260 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: At these higher thresholds, temporal information is still able to help get an improvement in R-2. However as this affects only very few out of the 44 document sets, statistical variances mean that these R-2 scores are no longer significant from that produced by SWING. 
		Cause: [(1, 2), (1, 29)]
		Effect: [(0, 1), (1, 0)]

Section 6:  6 Conclusion has 3 CE cases
	CASE: 1
	Stag: 264 265 
		Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
		sentTXT: To overcome errors propagated from the underlying temporal processing systems, we proposed a reliability filtering metric which can be used to help decide when temporal information should be used for summarization. The use of this metric leads to an overall 5.9% gain in R-2 over the competitive SWING baseline. 
		Cause: [(0, 1), (1, 2)]
		Effect: [(1, 7), (1, 18)]

	CASE: 2
	Stag: 267 268 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This can help us better understand their value in improving content selection. As noted earlier, it will be also be useful to repeat our experiments with less lexicon-influenced measures like the Pyramid method [ 20 ]. 
		Cause: [(1, 1), (1, 22)]
		Effect: [(0, 0), (0, 11)]

	CASE: 3
	Stag: 269 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Manual assessment of the generated summaries can also be done to give a better picture of the quality of the summaries generated with the use of timelines.Â  Finally, given the importance of reliability filtering, a natural question is if there are other metrics that can be used to get better results. 
		Cause: [(0, 42), (0, 53)]
		Effect: [(0, 28), (0, 40)]

#-------------------------------------------------

