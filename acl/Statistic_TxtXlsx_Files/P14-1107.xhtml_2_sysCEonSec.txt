Current File: P14-1107.xhtml_2 P14-1107.xhtml

Section 0:  Abstract
	SentNum: 6
	CENum: 2
	SentCovered: 2
	Covered_Rate: 33.3333%

Section 1:  1 Introduction
	SentNum: 23
	CENum: 4
	SentCovered: 6
	Covered_Rate: 26.0870%

Section 2:  2 Related work
	SentNum: 40
	CENum: 1
	SentCovered: 1
	Covered_Rate: 2.5000%

Section 3:  3 Crowdsourcing Translation
	SentNum: 33
	CENum: 5
	SentCovered: 5
	Covered_Rate: 15.1515%

Section 4:  4 Problem Formulation
	SentNum: 70
	CENum: 9
	SentCovered: 10
	Covered_Rate: 14.2857%

Section 5:  5 Evaluation
	SentNum: 49
	CENum: 12
	SentCovered: 14
	Covered_Rate: 28.5714%

Section 6:  6 Conclusion
	SentNum: 5
	CENum: 3
	SentCovered: 3
	Covered_Rate: 60.0000%

Section 7:  Acknowledgements
	SentNum: 4
	CENum: 1
	SentCovered: 1
	Covered_Rate: 25.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-1107.xhtml_2's CE cases

Section 0:  Abstract has 2 CE cases
	CASE: 1
	Stag: 0 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: Crowdsourcing is a viable mechanism for creating training data for machine translation. 
		Cause: [(0, 6), (0, 11)]
		Effect: [(0, 0), (0, 4)]

	CASE: 2
	Stag: 3 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: Careful quality control is necessary for crowdsourcing to work well. 
		Cause: [(0, 6), (0, 9)]
		Effect: [(0, 0), (0, 4)]

Section 1:  1 Introduction has 4 CE cases
	CASE: 1
	Stag: 9 10 
		Pattern: 1 [['because', 'of']]---- [['&C', '(,/;/./--)', '(&AND)', '(&ADV)'], ['&THIS', '(,)', '&R']]
		sentTXT: This drastically limits which languages SMT can be successfully applied to. Because of this, collecting parallel corpora for minor languages has become an interesting research challenge. 
		Cause: [(0, 0), (0, 10)]
		Effect: [(1, 4), (1, 15)]

	CASE: 2
	Stag: 11 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: There are various options for creating training data for new language pairs. 
		Cause: [(0, 5), (0, 11)]
		Effect: [(0, 0), (0, 3)]

	CASE: 3
	Stag: 13 14 
		Pattern: 8 [['because']]---- [['&R', '(,/./;/--)', '(&AND)', '&THIS', '&BE', '(&ADV)'], ['&C']]
		sentTXT: Until relatively recently, little consideration has been given to creating parallel data from scratch. This is because the cost of hiring professional translators is prohibitively high. 
		Cause: [(1, 3), (1, 11)]
		Effect: [(0, 0), (0, 14)]

	CASE: 4
	Stag: 20 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: This setup presents unique challenges, since it typically involves non-professional translators whose language skills are varied, and since it sometimes involves participants who try to cheat to get the small financial reward [ 43 ]. 
		Cause: [(0, 7), (0, 16)]
		Effect: [(0, 18), (0, 36)]

Section 2:  2 Related work has 1 CE cases
	CASE: 1
	Stag: 65 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: They also hired US-based Turkers to edit the translations, since the translators were largely based in Pakistan and exhibited errors that are characteristic of speakers of English as a language. 
		Cause: [(0, 11), (0, 30)]
		Effect: [(0, 0), (0, 8)]

Section 3:  3 Crowdsourcing Translation has 5 CE cases
	CASE: 1
	Stag: 84 85 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We use translation edit rate (TER) as a measure of translation similarity. TER represents the amount of change necessary to transform one sentence into another, so a low TER means the two sentences are very similar. 
		Cause: [(0, 9), (1, 23)]
		Effect: [(0, 0), (0, 7)]

	CASE: 2
	Stag: 85 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: TER represents the amount of change necessary to transform one sentence into another, so a low TER means the two sentences are very similar. 
		Cause: [(0, 0), (0, 12)]
		Effect: [(0, 15), (0, 24)]

	CASE: 3
	Stag: 91 
		Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: We measure aggressiveness by looking at the TER between the pre- and post-edited versions of each editor u'\u2019' s translations; higher TER implies more aggressive editing. 
		Cause: [(0, 0), (0, 27)]
		Effect: [(0, 29), (0, 31)]

	CASE: 4
	Stag: 96 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: To address this question, we split our translations into 5 bins, based on their TER g u'\u2062' o u'\u2062' l u'\u2062' d. 
		Cause: [(0, 15), (0, 35)]
		Effect: [(0, 0), (0, 11)]

	CASE: 5
	Stag: 97 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: We also split our editors into 5 bins, based on their effectiveness (i.e., the average amount by which their editing reduces TER g u'\u2062' o u'\u2062' l u'\u2062' d. 
		Cause: [(0, 11), (0, 12)]
		Effect: [(0, 16), (0, 43)]

Section 4:  4 Problem Formulation has 9 CE cases
	CASE: 1
	Stag: 103 
		Pattern: 6 [[['result', 'consequence'], 'of']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '&ONE'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: This output translation is the result of the combined translation and editing stages. 
		Cause: [(0, 7), (0, 12)]
		Effect: [(0, 0), (0, 2)]

	CASE: 2
	Stag: 103 104 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: This output translation is the result of the combined translation and editing stages. Therefore, our method operates over a heterogeneous network that includes translators and post-editors as well as the translated sentences that they produce. 
		Cause: [(0, 0), (0, 12)]
		Effect: [(1, 2), (1, 22)]

	CASE: 3
	Stag: 107 108 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: These two graphs, G T and G C are combined as subgraphs of a third graph ( G T u'\u2062' C. Edges in G T u'\u2062' C connect author pairs (nodes in G T ) to the candidate that they produced (nodes in G C. 
		Cause: [(0, 12), (1, 29)]
		Effect: [(0, 0), (0, 10)]

	CASE: 4
	Stag: 126 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The ranking method allows us to obtain a global ranking by taking into account the intra-/inter-component dependencies. 
		Cause: [(0, 11), (0, 19)]
		Effect: [(0, 0), (0, 9)]

	CASE: 5
	Stag: 129 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: A candidate is important if 1) it is similar to many of the other proposed candidates and 2) it is authored by better qualified translators and/or post-editors. 
		Cause: [(0, 5), (0, 15)]
		Effect: [(0, 0), (0, 3)]

	CASE: 6
	Stag: 149 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: By fusing the above equations, we can have the following iterative calculation in matrix forms. 
		Cause: [(0, 1), (0, 4)]
		Effect: [(0, 5), (0, 15)]

	CASE: 7
	Stag: 155 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: To this end, we must make the c and t column stochastic [ 20 ] c and t are therefore normalized after each iteration of Equation (4) and (5. 
		Cause: [(0, 0), (0, 19)]
		Effect: [(0, 21), (0, 32)]

	CASE: 8
	Stag: 166 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We treat a candidate as a short document and weight each term with tf.idf [ 23 ] , where tf is the term frequency and idf is the inverse document frequency. 
		Cause: [(0, 5), (0, 30)]
		Effect: [(0, 0), (0, 3)]

	CASE: 9
	Stag: 167 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: The Turker graph, G T , is an undirected graph whose edges represent u'\u201c' collaboration u'\u201d' Formally, let t i and t j be two translator/editor pairs; we say that pair t i u'\u201c' collaborates with u'\u201d' pair t j (and therefore, there is an edge between t i and t j ) if t i and t j share either a translator or an editor (or share both a translator and an editor. 
		Cause: [(0, 0), (0, 59)]
		Effect: [(0, 63), (0, 95)]

Section 5:  5 Evaluation has 12 CE cases
	CASE: 1
	Stag: 174 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: 1) based on the unedited translations only and 2) based on the edited sentences after translator/editor collaborations. 
		Cause: [(0, 13), (0, 18)]
		Effect: [(0, 5), (0, 10)]

	CASE: 2
	Stag: 175 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since we have four professional translation sets, we can calculate the Bilingual Evaluation Understudy (BLEU) score [ 27 ] for one professional translator (P1) using the other three (P2,3,4) as a reference set. 
		Cause: [(0, 1), (0, 6)]
		Effect: [(0, 8), (0, 40)]

	CASE: 3
	Stag: 177 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: In the following sections, we evaluate each of our methods by calculating BLEU scores against the same four sets of three reference translations. 
		Cause: [(0, 12), (0, 23)]
		Effect: [(0, 0), (0, 10)]

	CASE: 4
	Stag: 177 178 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: In the following sections, we evaluate each of our methods by calculating BLEU scores against the same four sets of three reference translations. Therefore, each number reported in our experimental results is an average of four numbers, corresponding to the four possible ways of choosing 3 of the 4 reference sets. 
		Cause: [(0, 0), (0, 23)]
		Effect: [(1, 2), (1, 29)]

	CASE: 5
	Stag: 179 180 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This allows us to compare the BLEU score achieved by our methods against the BLEU scores achievable by professional translators. As a naive baseline, we choose one candidate translation at random for each input Urdu sentence. 
		Cause: [(1, 1), (1, 16)]
		Effect: [(0, 0), (0, 19)]

	CASE: 6
	Stag: 181 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: To establish an upper bound for our methods, and to determine if there exist high-quality Turker translations at all, we compute four oracle scores. 
		Cause: [(0, 13), (0, 19)]
		Effect: [(0, 21), (0, 25)]

	CASE: 7
	Stag: 193 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since the oracles select from a small group of only 4 translations per source segment, they are not overly optimistic, and rather reflect the true potential of the collected translations. 
		Cause: [(0, 1), (0, 14)]
		Effect: [(0, 16), (0, 31)]

	CASE: 8
	Stag: 197 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Using the raw translations without post-editing, our graph-based ranking method achieves a BLEU score of 38.89, compared to Zaidan and Callison-Burch ( 2011 ) u'\u2019' s reported score of 28.13, which they achieved using a linear feature-based classification. 
		Cause: [(0, 0), (0, 5)]
		Effect: [(0, 7), (0, 44)]

	CASE: 9
	Stag: 198 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Their linear classifier achieved a reported score of 39.06 2 2 Note that the data we used in our experiments are slightly different, by discarding nearly 100 NULL sentences in the raw data. 
		Cause: [(0, 25), (0, 33)]
		Effect: [(0, 0), (0, 23)]

	CASE: 10
	Stag: 200 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: According to our experiments, most of the results generated by baselines and oracles are very close to the previously reported values when combining information from both translators and editors. 
		Cause: [(0, 2), (0, 3)]
		Effect: [(0, 5), (0, 29)]

	CASE: 11
	Stag: 212 213 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We first examine the centroid-based ranking on the candidate sub-graph ( G C ) alone to see the effect of voting among translated sentences; we denote this strategy as plain ranking. Then we incorporate the standard random walk on the Turker graph ( G T ) to include the structural information but without yet including any collaboration information; that is, we incorporate information from G T and G C without including edges linking the two together. 
		Cause: [(0, 30), (1, 27)]
		Effect: [(0, 25), (0, 28)]

	CASE: 12
	Stag: 220 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: This result supports the intuition that a denser collaboration matrix will help propagate saliency to good translators/post-editors and hence provides better predictions for candidate quality. 
		Cause: [(0, 0), (0, 16)]
		Effect: [(0, 19), (0, 24)]

Section 6:  6 Conclusion has 3 CE cases
	CASE: 1
	Stag: 221 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: We have proposed an algorithm for using a two-step collaboration between non-professional translators and post-editors to obtain professional-quality translations. 
		Cause: [(0, 6), (0, 18)]
		Effect: [(0, 0), (0, 4)]

	CASE: 2
	Stag: 222 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Our method, based on a co-ranking model, selects the best crowdsourced translation from a set of candidates, and is capable of selecting translations which near professional quality. 
		Cause: [(0, 5), (0, 7)]
		Effect: [(0, 9), (0, 29)]

	CASE: 3
	Stag: 225 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: In future work on crowdsourced translation, further benefits in quality improvement and cost reduction could stem from 1) building ground truth data sets based on high-quality Turkers u'\u2019' translations and 2) identifying when sufficient data has been collected for a given input, to avoid soliciting unnecessary redundant translations. 
		Cause: [(0, 27), (0, 47)]
		Effect: [(0, 50), (0, 55)]

Section 7:  Acknowledgements has 1 CE cases
	CASE: 1
	Stag: 226 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: This material is based on research sponsored by a DARPA Computer Science Study Panel phase 3 award entitled u'\u201c' Crowdsourcing Translation u'\u201d' (contract D12PC00368. 
		Cause: [(0, 5), (0, 32)]
		Effect: [(0, 0), (0, 1)]

#-------------------------------------------------

