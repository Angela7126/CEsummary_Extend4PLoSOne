Current File: P14-1024.xhtml_2 P14-1024.xhtml

Section 0:  Abstract
	SentNum: 5
	CENum: 2
	SentCovered: 3
	Covered_Rate: 60.0000%

Section 1:  1 Introduction
	SentNum: 14
	CENum: 3
	SentCovered: 3
	Covered_Rate: 21.4286%

Section 2:  2 Methodology
	SentNum: 42
	CENum: 6
	SentCovered: 6
	Covered_Rate: 14.2857%

Section 3:  3 Model and Feature Extraction
	SentNum: 46
	CENum: 5
	SentCovered: 7
	Covered_Rate: 15.2174%

Section 4:  4 Datasets
	SentNum: 29
	CENum: 5
	SentCovered: 8
	Covered_Rate: 27.5862%

Section 5:  5 Experiments
	SentNum: 92
	CENum: 16
	SentCovered: 22
	Covered_Rate: 23.9130%

Section 6:  6 Related Work
	SentNum: 34
	CENum: 4
	SentCovered: 5
	Covered_Rate: 14.7059%

Section 7:  7 Conclusion
	SentNum: 8
	CENum: 3
	SentCovered: 2
	Covered_Rate: 25.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-1024.xhtml_2's CE cases

Section 0:  Abstract has 2 CE cases
	CASE: 1
	Stag: 2 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Using a model transfer approach by pivoting through a bilingual dictionary, we show our model can identify metaphoric expressions in other languages. 
		Cause: [(0, 0), (0, 10)]
		Effect: [(0, 12), (0, 22)]

	CASE: 2
	Stag: 3 4 
		Pattern: 4 [['result'], ['is', 'that']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&R']]
		sentTXT: We provide results on three new test sets in Spanish, Farsi, and Russian. The results support the hypothesis that metaphors are conceptual, rather than lexical, in nature. 
		Cause: [(0, 0), (0, 14)]
		Effect: [(1, 6), (1, 15)]

Section 1:  1 Introduction has 3 CE cases
	CASE: 1
	Stag: 5 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Lakoff and Johnson ( 1980 ) characterize metaphor as reasoning about one thing in terms of another, i.e.,, a metaphor is a type of conceptual mapping , where words or phrases are applied to objects and actions in ways that do not permit a literal interpretation. 
		Cause: [(0, 9), (0, 47)]
		Effect: [(0, 0), (0, 7)]

	CASE: 2
	Stag: 12 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: On one hand, there is a subjective component humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language [ 32 ]. 
		Cause: [(0, 23), (0, 35)]
		Effect: [(0, 0), (0, 20)]

	CASE: 3
	Stag: 18 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: 1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses; 2 2 https://github.com/ytsvetko/metaphor (2) we create new metaphor-annotated corpora for Russian and English; 3 3 http://www.cs.cmu.edu/~ytsvetko/metaphor/datasets.zip (3) using a paradigm of model transfer [ 21 , 41 , 15 ] , we provide support for the hypothesis that metaphors are conceptual (rather than lexical) in nature by showing that our English-trained model can detect metaphors in Spanish, Farsi, and Russian. 
		Cause: [(0, 81), (0, 95)]
		Effect: [(0, 1), (0, 79)]

Section 2:  2 Methodology has 6 CE cases
	CASE: 1
	Stag: 24 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: According to Wilks [ 42 ] , this metaphor represents a violation of selectional preferences for the verb drink , which is normally associated with animate subjects (the car is inanimate and, hence, cannot drink in the literal sense of the verb. 
		Cause: [(0, 0), (0, 32)]
		Effect: [(0, 36), (0, 45)]

	CASE: 2
	Stag: 24 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: According to Wilks [ 42 ] , this metaphor represents a violation of selectional preferences for the verb drink , which is normally associated with animate subjects (the car is inanimate and, hence, cannot drink in the literal sense of the verb. 
		Cause: [(0, 2), (0, 5)]
		Effect: [(0, 7), (0, 32)]

	CASE: 3
	Stag: 36 
		Pattern: 0 [['if'], ['then']]---- [[], ['&C', '(,)'], ['&R']]
		sentTXT: 6 6 If word one is represented by features u'\ud835' u'\udc2e' u'\u2208' u'\u211d' n and word two by features u'\ud835' u'\udc2f' u'\u2208' u'\u211d' m then the conjunction feature vector is the vectorization of the outer product u'\ud835' u'\udc2e' u'\ud835' u'\udc2f' u'\u22a4'. 
		Cause: [(0, 3), (0, 55)]
		Effect: [(0, 57), (0, 92)]

	CASE: 4
	Stag: 50 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: English adjectives do not, as yet, have a similar high-level semantic partitioning in WordNet, thus we use a 13-class taxonomy of adjective supersenses constructed by Tsvetkov et al. 
		Cause: [(0, 0), (0, 15)]
		Effect: [(0, 18), (0, 30)]

	CASE: 5
	Stag: 52 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Supersenses are particularly attractive features for metaphor detection coarse sense taxonomies can be viewed as semantic concepts, and since concept mapping is a process in which metaphors are born, we expect different supersense co-occurrences in metaphoric and literal combinations. 
		Cause: [(0, 20), (0, 29)]
		Effect: [(0, 31), (0, 40)]

	CASE: 6
	Stag: 59 60 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: 2013 ) reveal an interesting cross-lingual property of distributed word representations there is a strong similarity between the vector spaces across languages that can be easily captured by linear mapping. Thus, vector space models can also be seen as vectors of (latent) semantic concepts, that preserve their u'\u201c' meaning u'\u201d' across languages. 
		Cause: [(0, 0), (0, 29)]
		Effect: [(1, 1), (1, 33)]

Section 3:  3 Model and Feature Extraction has 5 CE cases
	CASE: 1
	Stag: 64 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Random forest ensembles are particularly suitable for our resource-scarce scenario rather than overfitting, they produce a limiting value of the generalization error as the number of trees increases, 8 8 See Theorem 1.2 in [ 3 ] for details and no hyperparameter tuning is required. 
		Cause: [(0, 24), (0, 45)]
		Effect: [(0, 0), (0, 22)]

	CASE: 2
	Stag: 68 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If this probability is above a threshold, the relation is classified as metaphoric, otherwise it is literal. 
		Cause: [(0, 1), (0, 6)]
		Effect: [(0, 8), (0, 18)]

	CASE: 3
	Stag: 79 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: They were chosen empirically based on accuracy during cross-validation. 
		Cause: [(0, 6), (0, 8)]
		Effect: [(0, 0), (0, 3)]

	CASE: 4
	Stag: 102 103 
		Pattern: 7 [['hence']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: A Russian word u'\u0413' u'\u041e' u'\u041b' u'\u041e' u'\u0412' u'\u0410' is translated as head and brain. Hence, we select all the synsets of the nouns head and brain. 
		Cause: [(0, 0), (0, 38)]
		Effect: [(1, 2), (1, 12)]

	CASE: 5
	Stag: 105 106 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: Four of these synsets are associated with the supersense noun.body. Therefore, the value of the feature noun.body is 4 / 38 u'\u2248' 0.11. 
		Cause: [(0, 0), (0, 9)]
		Effect: [(1, 2), (1, 17)]

Section 4:  4 Datasets has 5 CE cases
	CASE: 1
	Stag: 113 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: After filtering, there are 953 metaphorical and 656 literal SVO relations which we use as a training set. 
		Cause: [(0, 16), (0, 18)]
		Effect: [(0, 0), (0, 14)]

	CASE: 2
	Stag: 116 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: At least one additional person carefully examined and culled the collected metaphors, by removing duplicates, weak metaphors, and metaphorical phrases (such as drowning students ) whose interpretation depends on the context. 
		Cause: [(0, 14), (0, 34)]
		Effect: [(0, 1), (0, 12)]

	CASE: 3
	Stag: 117 118 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: We collect and annotate metaphoric and literal test sentences in four languages. Thus, we compile eight test datasets, four for SVO relations, and four for AN relations. 
		Cause: [(0, 0), (0, 11)]
		Effect: [(1, 1), (1, 17)]

	CASE: 4
	Stag: 126 127 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: Our test sentence domains are, therefore, diverse economic, political, sports, etc. Then she used the SketchEngine, which provides searching capability for the TenTen Web corpus, 19 19 http://trac.sketchengine.co.uk/wiki/Corpora/enTenTen to extract sentences with words that frequently co-occurred with words from the seed lists. 
		Cause: [(0, 0), (0, 4)]
		Effect: [(0, 8), (1, 31)]

	CASE: 5
	Stag: 134 135 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: No English annotators of the test set, and only one Russian annotator out of 6 participated in the selection of the training samples. Thus, we trust that annotator judgments were not biased towards the cases that the system is trained to process. 
		Cause: [(0, 0), (0, 23)]
		Effect: [(1, 1), (1, 19)]

Section 5:  5 Experiments has 16 CE cases
	CASE: 1
	Stag: 139 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: This is done by computing an accuracy in the 10-fold cross validation. 
		Cause: [(0, 4), (0, 11)]
		Effect: [(0, 0), (0, 2)]

	CASE: 2
	Stag: 149 
		Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Yet, combining all features leads to even higher accuracy during cross-validation. 
		Cause: [(0, 2), (0, 4)]
		Effect: [(0, 7), (0, 11)]

	CASE: 3
	Stag: 151 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: Although the first experiment shows very high scores, the 10-fold cross-validation cannot fully reflect the generality of the model, because all folds are parts of the same corpus. 
		Cause: [(0, 23), (0, 30)]
		Effect: [(0, 0), (0, 20)]

	CASE: 4
	Stag: 152 153 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: They are collected by the same human judges and belong to the same domain. Therefore, experiments on out-of-domain data are crucial. 
		Cause: [(0, 0), (0, 13)]
		Effect: [(1, 2), (1, 7)]

	CASE: 5
	Stag: 160 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: It is possible to trade precision for recall by choosing a different threshold. 
		Cause: [(0, 9), (0, 12)]
		Effect: [(0, 0), (0, 7)]

	CASE: 6
	Stag: 160 161 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: It is possible to trade precision for recall by choosing a different threshold. Thus, in addition to giving a single f -score value for balanced thresholds, we present a Receiver Operator Characteristic (ROC) curve, where we plot a fraction of true positives against the fraction of false positives for 100 threshold values in the range from zero to one. 
		Cause: [(0, 0), (0, 12)]
		Effect: [(1, 1), (1, 51)]

	CASE: 7
	Stag: 162 163 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The area under the ROC curve (AUC) can be interpreted as the probability that a classifier will assign a higher score to a randomly chosen positive example than to a randomly chosen negative example. 20 20 Assuming that positive examples are labeled by ones, and negative examples are labeled by zeros. 
		Cause: [(0, 13), (1, 16)]
		Effect: [(0, 0), (0, 11)]

	CASE: 8
	Stag: 166 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: According to ROC plots in Figure 3 , all three feature sets are effective, both for SVO and for AN tasks. 
		Cause: [(0, 2), (0, 6)]
		Effect: [(0, 8), (0, 21)]

	CASE: 9
	Stag: 183 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: According to Table 3 , we obtain higher performance scores for both Russian and English. 
		Cause: [(0, 2), (0, 3)]
		Effect: [(0, 5), (0, 14)]

	CASE: 10
	Stag: 195 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: According to results in Table 4 , almost all of the judge-specific f -scores are slightly higher for our system, as well as the overall average f -score. 
		Cause: [(0, 2), (0, 5)]
		Effect: [(0, 7), (0, 27)]

	CASE: 11
	Stag: 207 
		Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
		sentTXT: We hypothesize that this happens due to a higher-quality translation dictionary (which allows a more accurate model transfer. 
		Cause: [(0, 7), (0, 18)]
		Effect: [(0, 0), (0, 4)]

	CASE: 12
	Stag: 208 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: Relatively lower (yet reasonable) results for Farsi can be explained by a smaller size of the bilingual dictionary (thus, fewer feature projections can be obtained. 
		Cause: [(0, 0), (0, 20)]
		Effect: [(0, 22), (0, 28)]

	CASE: 13
	Stag: 209 210 
		Pattern: 10 [['why']]---- [['&C', '(,/./;/--)', '(&AND)', '&THIS', '&BE'], ['&R']]
		sentTXT: Also note that, in our experience, most of Farsi metaphors are adjective-noun constructions. This is why the AN fa dataset in Table 1 is significantly larger than SVO fa. 
		Cause: [(0, 0), (0, 14)]
		Effect: [(1, 3), (1, 15)]

	CASE: 14
	Stag: 213 214 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We view this result as a strong evidence of language-independent nature of our metaphor detection method. In particular, this shows that proposed conceptual features can be used to detect selectional preferences violation across languages. 
		Cause: [(0, 5), (1, 17)]
		Effect: [(0, 0), (0, 3)]

	CASE: 15
	Stag: 217 218 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: For example, in English we classify as metaphoric dirty word and cloudy future. Word pairs dirty diaper and cloudy weather have same adjectives. 
		Cause: [(0, 8), (1, 8)]
		Effect: [(0, 0), (0, 6)]

	CASE: 16
	Stag: 219 220 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Yet they are classified as literal. Indeed, diaper is a more concrete term than word and weather is more concrete than future. 
		Cause: [(0, 5), (1, 15)]
		Effect: [(0, 0), (0, 3)]

Section 6:  6 Related Work has 4 CE cases
	CASE: 1
	Stag: 238 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If this adjective modifies a noun with the supersense noun.feeling , we conclude that a metaphor is found. 
		Cause: [(0, 1), (0, 9)]
		Effect: [(0, 11), (0, 17)]

	CASE: 2
	Stag: 247 
		Pattern: 18 [['because'], [',']]---- [[], ['&C'], ['&R']]
		sentTXT: Because they heavily rely on WordNet and availability of imageability scores, their approach may not be applicable to low-resource languages. 
		Cause: [(0, 1), (0, 10)]
		Effect: [(0, 12), (0, 20)]

	CASE: 3
	Stag: 251 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: We cannot compare directly our model with this work because our classifier is restricted to detection of only SVO and AN metaphors. 
		Cause: [(0, 11), (0, 22)]
		Effect: [(0, 0), (0, 9)]

	CASE: 4
	Stag: 257 258 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Current work builds on this study, and incorporates new syntactic relations as metaphor candidates, adds several new feature sets and different, more reliable datasets for evaluating results. We demonstrate results on two new languages, Spanish and Farsi, to emphasize the generality of the method. 
		Cause: [(0, 13), (1, 18)]
		Effect: [(0, 0), (0, 11)]

Section 7:  7 Conclusion has 3 CE cases
	CASE: 1
	Stag: 262 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The key contribution of our work is that we show how to identify metaphors across languages by building a model in English and applying it u'\u2014' without adaptation u'\u2014' to other languages. 
		Cause: [(0, 17), (0, 39)]
		Effect: [(0, 0), (0, 15)]

	CASE: 2
	Stag: 268 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: Future work will expand the scope of metaphor identification by including nominal metaphoric relations as well as explore techniques for incorporating contextual features, which can play a key role in identifying certain kinds of metaphors. 
		Cause: [(0, 20), (0, 35)]
		Effect: [(0, 0), (0, 18)]

	CASE: 3
	Stag: 268 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: Future work will expand the scope of metaphor identification by including nominal metaphoric relations as well as explore techniques for incorporating contextual features, which can play a key role in identifying certain kinds of metaphors. 
		Cause: [(0, 10), (0, 13)]
		Effect: [(0, 14), (0, 18)]

#-------------------------------------------------

