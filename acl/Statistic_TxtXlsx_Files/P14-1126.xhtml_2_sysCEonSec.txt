Current File: P14-1126.xhtml_2 P14-1126.xhtml

Section 0:  Abstract
	SentNum: 5
	CENum: 3
	SentCovered: 4
	Covered_Rate: 80.0000%

Section 1:  1 Introduction
	SentNum: 29
	CENum: 11
	SentCovered: 11
	Covered_Rate: 37.9310%

Section 2:  2 Our Approach
	SentNum: 60
	CENum: 17
	SentCovered: 16
	Covered_Rate: 26.6667%

Section 3:  3 Data and Tools
	SentNum: 34
	CENum: 7
	SentCovered: 10
	Covered_Rate: 29.4118%

Section 4:  4 Experiments
	SentNum: 75
	CENum: 10
	SentCovered: 14
	Covered_Rate: 18.6667%

Section 5:  5 Conclusion
	SentNum: 3
	CENum: 1
	SentCovered: 2
	Covered_Rate: 66.6667%

Section 6:  Acknowledgements
	SentNum: 3
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-1126.xhtml_2's CE cases

Section 0:  Abstract has 3 CE cases
	CASE: 1
	Stag: 0 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: We present a novel approach for inducing unsupervised dependency parsers for languages that have no labeled training data, but have translated text in a resource-rich language. 
		Cause: [(0, 6), (0, 26)]
		Effect: [(0, 0), (0, 4)]

	CASE: 2
	Stag: 1 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We train probabilistic parsing models for resource-poor languages by transferring cross-lingual knowledge from resource-rich language with entropy regularization. 
		Cause: [(0, 9), (0, 17)]
		Effect: [(0, 0), (0, 7)]

	CASE: 3
	Stag: 2 3 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: Our method can be used as a purely monolingual dependency parser, requiring no human translations for the test data, thus making it applicable to a wide range of resource-poor languages. We perform experiments on three Data sets u'\u2014' Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages. 
		Cause: [(0, 0), (0, 19)]
		Effect: [(0, 22), (1, 30)]

Section 1:  1 Introduction has 11 CE cases
	CASE: 1
	Stag: 5 
		Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
		sentTXT: In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation [ 43 ] , relation extraction [ 37 ] and machine translation [ 21 , 51 ]. 
		Cause: [(0, 12), (0, 39)]
		Effect: [(0, 0), (0, 9)]

	CASE: 2
	Stag: 7 8 
		Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&C', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['&NP@R@']]
		sentTXT: However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction [ 9 , 22 , 47 , 12 , 48 , 4 , 29 , 49 ] , which appears to be a natural solution to this problem, as unsupervised methods require only unannotated text for training parsers. 
		Cause: [(0, 0), (0, 27)]
		Effect: [(1, 3), (1, 50)]

	CASE: 3
	Stag: 12 
		Pattern: 2 [['for', 'the', 'sake', 'of'], [',']]---- [[], ['&V-ing/&NP@C@'], ['&R']]
		sentTXT: 1 1 For the sake of simplicity, we refer to the resource-poor language as the u'\u201c' target language u'\u201d' , and resource-rich language as the u'\u201c' source language u'\u201d'. 
		Cause: [(0, 6), (0, 6)]
		Effect: [(0, 8), (0, 45)]

	CASE: 4
	Stag: 12 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: 1 1 For the sake of simplicity, we refer to the resource-poor language as the u'\u201c' target language u'\u201d' , and resource-rich language as the u'\u201c' source language u'\u201d'. 
		Cause: [(0, 7), (0, 18)]
		Effect: [(0, 0), (0, 5)]

	CASE: 5
	Stag: 13 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In addition, in this study we use English as the source resource-rich language, but our methodology can be applied to any resource-rich languages. 
		Cause: [(0, 10), (0, 23)]
		Effect: [(0, 0), (0, 8)]

	CASE: 6
	Stag: 17 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: Obviously, bilingual treebanks are much more difficult to acquire than the resources required in our scenario, since the labeled training data and the parallel text in our case are completely separated. 
		Cause: [(0, 19), (0, 32)]
		Effect: [(0, 0), (0, 16)]

	CASE: 7
	Stag: 28 
		Pattern: 25 [['for']]---- [['&R'], ['&V-ing@C@']]
		sentTXT: In this work, we propose a learning framework for transferring dependency grammars from a resource-rich language to resource-poor languages via parallel text. 
		Cause: [(0, 10), (0, 22)]
		Effect: [(0, 0), (0, 8)]

	CASE: 8
	Stag: 29 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: We train probabilistic parsing models for resource-poor languages by maximizing a combination of likelihood on parallel data and confidence on unlabeled data. 
		Cause: [(0, 9), (0, 21)]
		Effect: [(0, 0), (0, 7)]

	CASE: 9
	Stag: 30 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Our work is based on the learning framework used in Smith and Eisner [ 44 ] , which is originally designed for parser bootstrapping. 
		Cause: [(0, 5), (0, 15)]
		Effect: [(0, 17), (0, 23)]

	CASE: 10
	Stag: 31 
		Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
		sentTXT: We extend this learning framework so that it can be used to transfer cross-lingual knowledge between different languages. 
		Cause: [(0, 0), (0, 4)]
		Effect: [(0, 7), (0, 17)]

	CASE: 11
	Stag: 32 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Throughout this paper, English is used as the source language and we evaluate our approach on ten target languages u'\u2014' Danish (da), Dutch (nl), French (fr), German (de), Greek (el), Italian (it), Korean (ko), Portuguese (pt), Spanish (es) and Swedish (sv. 
		Cause: [(0, 8), (0, 71)]
		Effect: [(0, 0), (0, 6)]

Section 2:  2 Our Approach has 17 CE cases
	CASE: 1
	Stag: 35 36 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: For example, Figure 1 shows a dependency tree for the sentence, Economic news had little effect on financial markets , with the sentence u'\u2019' s root-symbol as its root. The focus of this work is on building dependency parsers for target languages, assuming that an accurate English dependency parser and some parallel text between the two languages are available. 
		Cause: [(0, 33), (1, 13)]
		Effect: [(0, 0), (0, 31)]

	CASE: 2
	Stag: 38 
		Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
		sentTXT: Another advantage of the learning framework is that it combines both the likelihood on parallel data and confidence on unlabeled data, so that both parallel text and unlabeled data can be utilized in our approach. 
		Cause: [(0, 0), (0, 21)]
		Effect: [(0, 24), (0, 35)]

	CASE: 3
	Stag: 42 43 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: where F j are feature functions, u'\u039b' = ( u'\u039b' 1 , u'\u039b' 2 , u'\u2026' ) are parameters of the model, and Z u'\u2062' ( u'\ud835' u'\udc99' ) is a normalization factor, which is commonly referred to as the partition function. A common strategy to make this parsing model efficiently computable is to factor dependency trees into sets of edges. 
		Cause: [(0, 70), (1, 17)]
		Effect: [(0, 8), (0, 68)]

	CASE: 4
	Stag: 44 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: That is, dependency tree y is treated as a set of edges e and each feature function F j u'\u2062' ( u'\ud835' u'\udc9a' , u'\ud835' u'\udc99' ) is equal to the sum of all the features f j u'\u2062' ( e , u'\ud835' u'\udc99' ). 
		Cause: [(0, 9), (0, 76)]
		Effect: [(0, 0), (0, 7)]

	CASE: 5
	Stag: 66 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: First, by transferring the weight function to the corresponding weight in the well-developed English parsing model, we can project syntactic information across language boundaries. 
		Cause: [(0, 3), (0, 16)]
		Effect: [(0, 17), (0, 25)]

	CASE: 6
	Stag: 69 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: By reducing unaligned edges to their delexicalized forms, we can still use those delexicalized features, such as part-of-speech tags, for those unaligned edges, and can address problem that automatically generated word alignments include errors. 
		Cause: [(0, 1), (0, 7)]
		Effect: [(0, 8), (0, 37)]

	CASE: 7
	Stag: 72 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: Due to the normalizing factor Z ~ u'\u2062' ( u'\ud835' u'\udc99' ) , the transferring distribution is a valid one. 
		Cause: [(0, 2), (0, 23)]
		Effect: [(0, 25), (0, 31)]

	CASE: 8
	Stag: 72 73 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Due to the normalizing factor Z ~ u'\u2062' ( u'\ud835' u'\udc99' ) , the transferring distribution is a valid one. We introduce a multiplier u'\u0393' as a trade-off between the two contributions (parallel and unsupervised) of the objective function K , and the final objective function K u'\u2032' has the following form. 
		Cause: [(1, 10), (1, 41)]
		Effect: [(0, 0), (1, 8)]

	CASE: 9
	Stag: 75 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: One may regard u'\u0393' as a Lagrange multiplier that is used to constrain the parser u'\u2019' s uncertainty H to be low, as presented in several studies on entropy regularization [ 5 , 17 , 20 ]. 
		Cause: [(0, 9), (0, 43)]
		Effect: [(0, 0), (0, 7)]

	CASE: 10
	Stag: 80 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: According to equation ( 9 ), p ~ ( u'\ud835' u'\udc9a' u'\ud835' u'\udc99' ) can also be factored into the multiplication of the weight of each edge, so both K P and its gradient can be calculated by running the O u'\u2062' ( n 3 ) inside-outside algorithm [ 2 , 41 ] for projective parsing. 
		Cause: [(0, 0), (0, 43)]
		Effect: [(0, 46), (0, 77)]

	CASE: 11
	Stag: 80 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: According to equation ( 9 ), p ~ ( u'\ud835' u'\udc9a' u'\ud835' u'\udc99' ) can also be factored into the multiplication of the weight of each edge, so both K P and its gradient can be calculated by running the O u'\u2062' ( n 3 ) inside-outside algorithm [ 2 , 41 ] for projective parsing. 
		Cause: [(0, 2), (0, 5)]
		Effect: [(0, 7), (0, 43)]

	CASE: 12
	Stag: 80 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: According to equation ( 9 ), p ~ ( u'\ud835' u'\udc9a' u'\ud835' u'\udc99' ) can also be factored into the multiplication of the weight of each edge, so both K P and its gradient can be calculated by running the O u'\u2062' ( n 3 ) inside-outside algorithm [ 2 , 41 ] for projective parsing. 
		Cause: [(0, 10), (0, 31)]
		Effect: [(0, 0), (0, 8)]

	CASE: 13
	Stag: 81 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: For non-projective parsing, the analogy to the inside algorithm is the O u'\u2062' ( n 3 ) matrix-tree algorithm based on Kirchhoff u'\u2019' s Matrix-Tree Theorem, which is dominated asymptotically by a matrix determinant [ 25 , 46 ]. 
		Cause: [(0, 26), (0, 34)]
		Effect: [(0, 36), (0, 48)]

	CASE: 14
	Stag: 82 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: The gradient of a determinant may be computed by matrix inversion, so evaluating the gradient again has the same O u'\u2062' ( n 3 ) complexity as evaluating the function. 
		Cause: [(0, 0), (0, 10)]
		Effect: [(0, 13), (0, 33)]

	CASE: 15
	Stag: 85 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Similar with the calculation of K P , K U can also be computed by running the inside-outside algorithm [ 2 , 41 ] for projective parsing. 
		Cause: [(0, 0), (0, 6)]
		Effect: [(0, 8), (0, 26)]

	CASE: 16
	Stag: 85 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Similar with the calculation of K P , K U can also be computed by running the inside-outside algorithm [ 2 , 41 ] for projective parsing. 
		Cause: [(0, 7), (0, 18)]
		Effect: [(0, 0), (0, 5)]

	CASE: 17
	Stag: 92 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: Prepare parallel text by running word alignment method to obtain word alignments, 3 3 The word alignment methods do not require additional resources besides parallel text and prepare the unlabeled data. 
		Cause: [(0, 4), (0, 26)]
		Effect: [(0, 27), (0, 31)]

Section 3:  3 Data and Tools has 7 CE cases
	CASE: 1
	Stag: 96 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: We select target languages based on the availability of these resources. 
		Cause: [(0, 6), (0, 10)]
		Effect: [(0, 0), (0, 3)]

	CASE: 2
	Stag: 97 
		Pattern: 2 [['for', 'the'], ['reason']]---- [['&R', '(,)', '(&ADV)'], ['(&ADJ)'], ['(that)', '&C']]
		sentTXT: The monolingual treebanks in our experiments are from the Google Universal Dependency Treebanks [ 31 ] , for the reason that the treebanks of different languages in Google Universal Dependency Treebanks have consistent syntactic representations. 
		Cause: [(0, 21), (0, 34)]
		Effect: [(0, 0), (0, 15)]

	CASE: 3
	Stag: 102 
		Pattern: 0 [[['concern', 'concerns', 'concerned', 'require', 'requires', 'required', 'request', 'requests', 'requested']]]---- [['&R', '(,/./;/--)', '&this', '(&adj)', '(&N)', '(&CAN/have/has/had)', '(&ADV)'], ['(about)', '&V-ing/&NP@C@']]
		sentTXT: However, previous studies [ 34 , 31 ] have demonstrated that a homogeneous representation is critical for multilingual language technologies that require consistent cross-lingual analysis for downstream components, and the heterogenous representations used in CoNLL shared-tasks treebanks weaken any conclusion that can be drawn. 
		Cause: [(0, 23), (0, 28)]
		Effect: [(0, 0), (0, 20)]

	CASE: 4
	Stag: 105 106 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: The three languages are Danish, Dutch and Greek. So totally we have ten target languages. 
		Cause: [(0, 0), (0, 8)]
		Effect: [(1, 1), (1, 6)]

	CASE: 5
	Stag: 114 115 
		Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
		sentTXT: The set of POS tags needs to be consistent across languages and treebanks. For this reason we use the universal POS tag set of Petrov et al. 
		Cause: [(0, 0), (0, 12)]
		Effect: [(1, 3), (1, 13)]

	CASE: 6
	Stag: 119 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: POS tags are not available for parallel data in the Europarl and Kaist corpus, so we need to provide the POS tags for these data. 
		Cause: [(0, 0), (0, 13)]
		Effect: [(0, 16), (0, 25)]

	CASE: 7
	Stag: 124 125 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: For the purpose of evaluation of our approach and comparison with previous work, we need to exploit the gold POS tags to train the POS taggers. As part-of-speech tags are also a form of syntactic analysis, this assumption weakens the applicability of our approach. 
		Cause: [(1, 1), (1, 18)]
		Effect: [(0, 0), (0, 26)]

Section 4:  4 Experiments has 10 CE cases
	CASE: 1
	Stag: 128 129 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In this section, we will describe the details of our experiments and compare our results with previous methods. As presented in Section 3.1 , we evaluate our parsing approach on both version 1.0 and version 2.0 of Google Univereal Treebanks for seven languages 6 6 Japanese and Indonesia are excluded as no practicable parallel data are available. 
		Cause: [(1, 1), (1, 38)]
		Effect: [(0, 0), (0, 18)]

	CASE: 2
	Stag: 140 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: It is based on the transition-based dependency parsing paradigm [ 40 ]. 
		Cause: [(0, 4), (0, 11)]
		Effect: [(0, 0), (0, 0)]

	CASE: 3
	Stag: 143 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: In addition to their original results, we also report results by re-implementing the direct transfer parser based on the first-order projective dependency parsing model [ 30 ] (DTP u'\u2020'. 
		Cause: [(0, 19), (0, 33)]
		Effect: [(0, 0), (0, 16)]

	CASE: 4
	Stag: 152 153 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: One may regard this system as an oracle of transfer parsing. Parsing accuracy is measured with unlabeled attachment score (UAS the percentage of words with the correct head. 
		Cause: [(0, 6), (1, 16)]
		Effect: [(0, 0), (0, 4)]

	CASE: 5
	Stag: 155 156 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Our approaches significantly outperform all the baseline systems across all the seven target languages. For the results on Google Universal Treebanks version 1.0, the improvement on average over the projected transfer paper (PTP u'\u2020' ) is 3.96% and up to 6.22% for Korean and 4.80% for German. 
		Cause: [(0, 1), (1, 0)]
		Effect: [(1, 28), (1, 41)]

	CASE: 6
	Stag: 158 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: By adding entropy regularization from unlabeled data, our full model achieves average improvement of 0.29% over the u'\u201c' -U u'\u201d' setting. 
		Cause: [(0, 1), (0, 6)]
		Effect: [(0, 7), (0, 31)]

	CASE: 7
	Stag: 175 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Table 6 gives the results comparing the model without unlabeled data (-U) presented in this work to those five baseline systems and the oracle (OR. 
		Cause: [(0, 0), (0, 2)]
		Effect: [(0, 18), (0, 28)]

	CASE: 8
	Stag: 180 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: Table 7 shows the results of our system and the results of baseline systems u'\u201c' USR u'\u2020' u'\u201d' is the weakly supervised system of Naseem et al. 
		Cause: [(0, 0), (0, 8)]
		Effect: [(0, 31), (0, 38)]

	CASE: 9
	Stag: 190 191 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: It should be noted that the u'\u201c' NMG u'\u201d' system utilizes more than one helper languages. So it is not directly comparable to our work. 
		Cause: [(0, 0), (0, 23)]
		Effect: [(1, 1), (1, 8)]

	CASE: 10
	Stag: 198 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: For example, if we want to make our model capable of utilizing more contextual information, we can extend our transferring weight to higher-order parts. 
		Cause: [(0, 4), (0, 15)]
		Effect: [(0, 17), (0, 25)]

Section 5:  5 Conclusion has 1 CE cases
	CASE: 1
	Stag: 204 205 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: By presenting a model training framework, our approach can utilize parallel text to estimate transferring distribution with the help of a well-developed resource-rich language dependency parser, and use unlabeled data as entropy regularization. The experimental results on three data sets across ten target languages show that our approach achieves significant improvement over previous studies. 
		Cause: [(0, 33), (1, 19)]
		Effect: [(0, 0), (0, 31)]

Section 6:  Acknowledgements has 0 CE cases
#-------------------------------------------------

