Current File: P14-2031.xhtml_2 P14-2031.xhtml

Section 0:  Abstract
	SentNum: 6
	CENum: 1
	SentCovered: 1
	Covered_Rate: 16.6667%

Section 1:  1 Introduction
	SentNum: 24
	CENum: 4
	SentCovered: 5
	Covered_Rate: 20.8333%

Section 2:  2 Edit-Turn-Pairs
	SentNum: 23
	CENum: 6
	SentCovered: 6
	Covered_Rate: 26.0870%

Section 3:  3 Corpus
	SentNum: 42
	CENum: 17
	SentCovered: 23
	Covered_Rate: 54.7619%

Section 4:  4 Machine Learning with Edit-Turn-Pairs
	SentNum: 41
	CENum: 11
	SentCovered: 14
	Covered_Rate: 34.1463%

Section 5:  5 Related Work
	SentNum: 18
	CENum: 2
	SentCovered: 2
	Covered_Rate: 11.1111%

Section 6:  6 Conclusion
	SentNum: 9
	CENum: 1
	SentCovered: 1
	Covered_Rate: 11.1111%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-2031.xhtml_2's CE cases

Section 0:  Abstract has 1 CE cases
	CASE: 1
	Stag: 2 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Based on properties of the involved edit and turn, we have defined constraints for corresponding edit-turn-pairs. 
		Cause: [(0, 2), (0, 8)]
		Effect: [(0, 10), (0, 16)]

Section 1:  1 Introduction has 4 CE cases
	CASE: 1
	Stag: 7 
		Pattern: 45 [['so', 'that']]---- [['&C'], ['&R']]
		sentTXT: Most of the resources used for collaborative writing do not explicitly allow their users to interact directly, so that the implicit effort of coordination behind the actual writing is not documented. 
		Cause: [(0, 0), (0, 17)]
		Effect: [(0, 20), (0, 31)]

	CASE: 2
	Stag: 8 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: Wikipedia, as one of the most prominent collaboratively created resources, offers its users a platform to coordinate their writing, the so called talk or discussion pages [ 18 ]. 
		Cause: [(0, 0), (0, 22)]
		Effect: [(0, 24), (0, 31)]

	CASE: 3
	Stag: 15 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Roughly five hours after that turn was issued on the discussion page, user Sbharris added a wikilink to the u'\u201c' History and etymology u'\u201d' section of the article by performing the following edit. 
		Cause: [(0, 38), (0, 41)]
		Effect: [(0, 0), (0, 36)]

	CASE: 4
	Stag: 16 17 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: {mdframed} [backgroundcolor=gray!30, linewidth=0pt, leftmargin=0, rightmargin=0, skipabove=4pt, skipbelow=3pt, innertopmargin=3pt, innerbottommargin=3pt] '' borax '' u'\u2192' [[borax]] This is what we define as a corresponding edit-turn-pair. More details follow in Section 2. 
		Cause: [(0, 57), (1, 4)]
		Effect: [(0, 0), (0, 55)]

Section 2:  2 Edit-Turn-Pairs has 6 CE cases
	CASE: 1
	Stag: 33 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Edits are coherent modifications based on a pair of adjacent revisions from Wikipedia article pages. 
		Cause: [(0, 6), (0, 14)]
		Effect: [(0, 0), (0, 3)]

	CASE: 2
	Stag: 42 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: Individual turns are retrieved from topics by considering the revision history of the discussion page. 
		Cause: [(0, 7), (0, 14)]
		Effect: [(0, 0), (0, 5)]

	CASE: 3
	Stag: 45 46 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: An edit-turn-pair is defined as a pair of an edit from a Wikipedia article u'\u2019' s revision history and a turn from the discussion page bound to the same article. If an article has no discussion page, there are no edit-turn-pairs for this article. 
		Cause: [(0, 5), (1, 5)]
		Effect: [(0, 0), (0, 3)]

	CASE: 4
	Stag: 46 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: If an article has no discussion page, there are no edit-turn-pairs for this article. 
		Cause: [(0, 1), (0, 6)]
		Effect: [(0, 8), (0, 14)]

	CASE: 5
	Stag: 50 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: Due to their performative nature, we assume that these dialog acts make the turn they belong to a good candidate for a corresponding edit-turn-pair. 
		Cause: [(0, 2), (0, 4)]
		Effect: [(0, 6), (0, 24)]

	CASE: 6
	Stag: 50 51 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: Due to their performative nature, we assume that these dialog acts make the turn they belong to a good candidate for a corresponding edit-turn-pair. We therefore define an edit-turn-pair as corresponding, if i) The turn is an explicit suggestion, recommendation or request and the edit performs this suggestion, recommendation or request, ii) the turn is an explicit reference or pointer and the edit adds or modifies this reference or pointer, iii) the turn is a commitment to an action in the future and the edit performs this action, and iv) the turn is a report of a performed action and the edit performs this action. 
		Cause: [(0, 1), (1, 0)]
		Effect: [(1, 2), (1, 90)]

Section 3:  3 Corpus has 17 CE cases
	CASE: 1
	Stag: 54 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The search space for corresponding edit-turn-pairs is quite big, as any edit to an article may correspond to any turn from the article u'\u2019' s discussion page. 
		Cause: [(0, 11), (0, 31)]
		Effect: [(0, 0), (0, 8)]

	CASE: 2
	Stag: 55 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Assuming that most edit-turn-pairs are non-corresponding, we expect a heavy imbalance in the class distribution. 
		Cause: [(0, 0), (0, 5)]
		Effect: [(0, 7), (0, 15)]

	CASE: 3
	Stag: 56 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: It was important to find a reasonable amount of corresponding edit-turn-pairs before the actual annotation could take place, as we needed a certain amount of positive seeds to keep turkers from simply labeling pairs as non-corresponding all the time. 
		Cause: [(0, 20), (0, 39)]
		Effect: [(0, 0), (0, 17)]

	CASE: 4
	Stag: 59 60 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Based on an automatic classification using the model presented in our previous work [ 7 ] , we excluded edits classified as Vandalism, Revert or Other. Furthermore, we removed all edits which are part of a revision created by bots, based on the Wikimedia user group 2 2 http://meta.wikimedia.org/wiki/User_classes scheme. 
		Cause: [(0, 22), (1, 15)]
		Effect: [(0, 2), (0, 20)]

	CASE: 5
	Stag: 60 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Furthermore, we removed all edits which are part of a revision created by bots, based on the Wikimedia user group 2 2 http://meta.wikimedia.org/wiki/User_classes scheme. 
		Cause: [(0, 18), (0, 25)]
		Effect: [(0, 0), (0, 14)]

	CASE: 6
	Stag: 61 62 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: To keep the class imbalance within reasonable margins, we limited the time span between edits and turns to 86,000 seconds (about 24 hours. The result is a set of 13,331 edit-turn-pairs, referred to as ETP-all. 
		Cause: [(0, 0), (0, 24)]
		Effect: [(1, 3), (1, 12)]

	CASE: 7
	Stag: 63 64 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: From ETP-all, a set of 262 edit-turn-pairs have been annotated as corresponding as part of a preliminary annotation study with one human annotator. This step is intended to make sure that we have a substantial number of corresponding pairs in the data for the final annotation study. 
		Cause: [(0, 12), (1, 22)]
		Effect: [(0, 0), (0, 10)]

	CASE: 8
	Stag: 65 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: However, we still expect a certain amount of non-corresponding edit-turn-pairs in this data, as the annotator judged the correspondence based on the entire revision and not the individual edit. 
		Cause: [(0, 16), (0, 29)]
		Effect: [(0, 0), (0, 13)]

	CASE: 9
	Stag: 65 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: However, we still expect a certain amount of non-corresponding edit-turn-pairs in this data, as the annotator judged the correspondence based on the entire revision and not the individual edit. 
		Cause: [(0, 7), (0, 9)]
		Effect: [(0, 0), (0, 4)]

	CASE: 10
	Stag: 66 67 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We refer to this 262 edit-turn-pairs as ETP-unconfirmed. Finally, for the Mechanical Turk annotation study, we selected 500 random edit-turn-pairs from ETP-all excluding ETP-unconfirmed. 
		Cause: [(0, 7), (1, 16)]
		Effect: [(0, 0), (0, 5)]

	CASE: 11
	Stag: 72 73 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The context of an edit is defined as one preceding and one following paragraph of the edited paragraph. Each edit-turn-pair could be labeled as u'\u201c' corresponding u'\u201d' , u'\u201c' non-corresponding u'\u201d' or u'\u201c' can u'\u2019' t tell u'\u201d'. 
		Cause: [(0, 8), (1, 46)]
		Effect: [(0, 0), (0, 6)]

	CASE: 12
	Stag: 73 74 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Each edit-turn-pair could be labeled as u'\u201c' corresponding u'\u201d' , u'\u201c' non-corresponding u'\u201d' or u'\u201c' can u'\u2019' t tell u'\u201d'. To select good turkers and to block spammers, we carried out a pilot study on a small portion of manually confirmed corresponding and non-corresponding pairs, and required turkers to pass a qualification test. 
		Cause: [(0, 6), (1, 26)]
		Effect: [(0, 0), (0, 4)]

	CASE: 13
	Stag: 76 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This was calculated as 1 N u'\u2062' u'\u2211' i = 1 N u'\u2211' c = 1 C v i c C , where N = 750 is the overall number of annotated edit-turn-pairs, C = R 2 - R 2 is the number of pairwise comparisons, R = 5 is the number of raters per edit-turn-pair, and v i c = 1 if a pair of raters c labeled edit-turn-pair i equally, and 0 otherwise. 
		Cause: [(0, 4), (0, 77)]
		Effect: [(0, 0), (0, 2)]

	CASE: 14
	Stag: 79 80 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We counted an edit-turn-pair as corresponding, if it was annotated as u'\u201c' corresponding u'\u201d' by least three out of five annotators, and likewise for non-corresponding pairs. Furthermore, we deleted 21 pairs for which the turn segmentation algorithm clearly failed (e.g., when the turn text was empty. 
		Cause: [(0, 5), (1, 21)]
		Effect: [(0, 0), (0, 3)]

	CASE: 15
	Stag: 83 84 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: To assess the reliability of these annotations, one of the co-authors manually annotated a random subset of 100 edit-turn-pairs contained in ETP-gold as corresponding or non-corresponding. The inter-rater agreement between ETP-gold (majority votes over Mechanical Turk annotations) and our expert annotations on this subset is Cohen u'\u2019' s u'\u039a' = .72. 
		Cause: [(0, 24), (1, 33)]
		Effect: [(0, 0), (0, 22)]

	CASE: 16
	Stag: 87 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: However, given the high price for a new corresponding edit-turn-pair (due to the high class imbalance in random data), we consider it as a useful starting point for research on edit-turn-pairs in Wikipedia. 
		Cause: [(0, 14), (0, 20)]
		Effect: [(0, 21), (0, 36)]

	CASE: 17
	Stag: 91 92 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: In our 24 hours search space, the probability to find a corresponding edit-turn-pair drops steeply for time spans of more than 6 hours. We therefore expect to cover the vast majority of corresponding edit-turn-pairs within a search space of 24 hours. 
		Cause: [(0, 1), (1, 0)]
		Effect: [(1, 2), (1, 17)]

Section 4:  4 Machine Learning with Edit-Turn-Pairs has 11 CE cases
	CASE: 1
	Stag: 104 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: We propose a number of features which are purely based on the textual similarity between the text of the turn, and the edited text and context. 
		Cause: [(0, 11), (0, 26)]
		Effect: [(0, 0), (0, 8)]

	CASE: 2
	Stag: 109 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: Several of our features are based on metadata from both the edit and the turn. 
		Cause: [(0, 7), (0, 14)]
		Effect: [(0, 0), (0, 3)]

	CASE: 3
	Stag: 112 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: Some features are based on the edit or the turn alone and do not take into account the pair itself. 
		Cause: [(0, 5), (0, 19)]
		Effect: [(0, 0), (0, 1)]

	CASE: 4
	Stag: 115 116 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The 1,000 most frequent uni-, bi- and trigrams from the turn text are represented as binary features. We treat the automatic classification of edit-turn-pairs as a binary classification problem. 
		Cause: [(0, 18), (1, 4)]
		Effect: [(0, 1), (0, 16)]

	CASE: 5
	Stag: 116 117 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We treat the automatic classification of edit-turn-pairs as a binary classification problem. Given the small size of ETP-gold, we did not assign a fixed train/test split to the data. 
		Cause: [(0, 8), (1, 0)]
		Effect: [(0, 0), (0, 6)]

	CASE: 6
	Stag: 117 118 
		Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
		sentTXT: Given the small size of ETP-gold, we did not assign a fixed train/test split to the data. For the same reason, we did not further divide the data into train/test and development data. 
		Cause: [(0, 0), (0, 17)]
		Effect: [(1, 5), (1, 16)]

	CASE: 7
	Stag: 122 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: A reduction of the feature set as judged by a u'\u03a7' 2 ranker improved the results for both Random Forest as well as the SVM, so we limited our feature set to the 100 best features. 
		Cause: [(0, 0), (0, 28)]
		Effect: [(0, 31), (0, 40)]

	CASE: 8
	Stag: 124 125 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Previous work [ 11 , 4 ] has shown that these algorithms work well for edit and turn classification. As baseline, we defined a majority class classifier, which labels all edit-turn-pairs as non-corresponding. 
		Cause: [(1, 1), (1, 15)]
		Effect: [(0, 0), (0, 18)]

	CASE: 9
	Stag: 127 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: Due to the high class imbalance in the data, the majority class baseline sets a challenging accuracy score of .80. 
		Cause: [(0, 2), (0, 8)]
		Effect: [(0, 10), (0, 20)]

	CASE: 10
	Stag: 130 
		Pattern: 0 [['due', 'to']]---- [['&R'], ['&NP@C@']]
		sentTXT: The low F1 on corresponding pairs is likely due to the small number of training examples. 
		Cause: [(0, 10), (0, 15)]
		Effect: [(0, 0), (0, 7)]

	CASE: 11
	Stag: 131 132 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: To understand the mistakes of the classifier, we manually assessed error patterns within the model of the Random Forest classifier. Some of the false positives (i.e., non-corresponding pairs classified as corresponding) were caused by pairs where the revision (as judged by its comment or the edit context) is related to the turn text, however the specific edit in this pair is not. 
		Cause: [(1, 12), (1, 21)]
		Effect: [(0, 1), (1, 10)]

Section 5:  5 Related Work has 2 CE cases
	CASE: 1
	Stag: 141 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: Both of these may be part of a corresponding edit-turn-pair, according to our definition in Section 2. 
		Cause: [(0, 13), (0, 17)]
		Effect: [(0, 0), (0, 9)]

	CASE: 2
	Stag: 146 
		Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: In the present study, we have analyzed cases where explicit coordination lead to implicit coordination and vice versa. 
		Cause: [(0, 10), (0, 11)]
		Effect: [(0, 14), (0, 18)]

Section 6:  6 Conclusion has 1 CE cases
	CASE: 1
	Stag: 156 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Based on the types of turn and edit in an edit-turn-pair, we have operationalized the notion of corresponding and non-corresponding edit-turn-pairs. 
		Cause: [(0, 2), (0, 10)]
		Effect: [(0, 12), (0, 21)]

#-------------------------------------------------

