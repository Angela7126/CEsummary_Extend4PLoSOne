Current File: P14-1123.xhtml_2 P14-1123.xhtml

Section 0:  Abstract
	SentNum: 5
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

Section 1:  1 Introduction
	SentNum: 23
	CENum: 2
	SentCovered: 3
	Covered_Rate: 13.0435%

Section 2:  2 Related Work
	SentNum: 24
	CENum: 5
	SentCovered: 7
	Covered_Rate: 29.1667%

Section 3:  3 Shallow-analysis approach to measuring syntactic complexity
	SentNum: 26
	CENum: 5
	SentCovered: 6
	Covered_Rate: 23.0769%

Section 4:  4 Models for Measuring Grammatical Competence
	SentNum: 40
	CENum: 12
	SentCovered: 17
	Covered_Rate: 42.5000%

Section 5:  5 Experimental Setup
	SentNum: 69
	CENum: 14
	SentCovered: 19
	Covered_Rate: 27.5362%

Section 6:  6 Experimental Results
	SentNum: 20
	CENum: 5
	SentCovered: 6
	Covered_Rate: 30.0000%

Section 7:  7 Discussions
	SentNum: 26
	CENum: 4
	SentCovered: 5
	Covered_Rate: 19.2308%

Section 8:  8 Conclusions
	SentNum: 6
	CENum: 3
	SentCovered: 3
	Covered_Rate: 50.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-1123.xhtml_2's CE cases

Section 0:  Abstract has 0 CE cases
Section 1:  1 Introduction has 2 CE cases
	CASE: 1
	Stag: 15 16 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Instead of focusing on grammatical errors that are found to be highly representative of language proficiency, our interest is in capturing the range of forms that surface in language production and the degree of sophistication of such forms, collectively referred to as syntactic complexity in [ 24 ]. The choice and design of objective measures of language proficiency is governed by two crucial constraints. 
		Cause: [(0, 44), (1, 14)]
		Effect: [(0, 0), (0, 42)]

	CASE: 2
	Stag: 26 
		Pattern: 0 [[['indicate', 'indicates', 'indicated', 'realize', 'realizes', 'realized', 'ensure', 'ensures', 'ensured', 'imply', 'implies', 'implied']]]---- [['&NP@C@', '(&Clause@C@)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: In the domain of native language acquisition, the presence or absence of a grammatical structure indicates grammatical development. 
		Cause: [(0, 8), (0, 15)]
		Effect: [(0, 17), (0, 18)]

Section 2:  2 Related Work has 5 CE cases
	CASE: 1
	Stag: 28 29 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Speaking in a non-native language requires diverse abilities, including fluency, pronunciation, intonation, grammar, vocabulary, and discourse. Informed by studies in second language acquisition and language testing that regard these factors as key determiners of spoken language proficiency, some researchers have focused on the objective measurement of these aspects of spoken language in the context of automatic assessment of language ability. 
		Cause: [(1, 15), (1, 44)]
		Effect: [(0, 2), (1, 13)]

	CASE: 2
	Stag: 42 43 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Automatic recognition of non-native speakers u'\u2019' spontaneous speech is a challenging task as evidenced by the error rate of the state-of-the-art speech recognizer. For instance, Chen and Zechner ( 2011 ) reported a 50.5% word error rate (WER) and Yoon and Bhat ( 2012 ) reported a 30% WER in the recognition of ESL students u'\u2019' spoken responses. 
		Cause: [(0, 17), (1, 41)]
		Effect: [(0, 0), (0, 15)]

	CASE: 3
	Stag: 44 45 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: These high error rates at the recognition stage negatively affect the subsequent stages of the speech scoring system in general, and in particular, during a deep syntactic analysis, which operates on a long sequence of words as its context. As a result, measures of grammatical complexity that are closely tied to a correct syntactic analysis are rendered unreliable. 
		Cause: [(0, 40), (1, 18)]
		Effect: [(0, 0), (0, 38)]

	CASE: 4
	Stag: 44 45 
		Pattern: 3 [['as', 'a'], ['result']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&ADJ)'], ['(,)', '&R']]
		sentTXT: These high error rates at the recognition stage negatively affect the subsequent stages of the speech scoring system in general, and in particular, during a deep syntactic analysis, which operates on a long sequence of words as its context. As a result, measures of grammatical complexity that are closely tied to a correct syntactic analysis are rendered unreliable. 
		Cause: [(0, 0), (0, 41)]
		Effect: [(1, 4), (1, 19)]

	CASE: 5
	Stag: 48 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: In order to avoid the problems encountered with deep analysis-based measures, Yoon and Bhat ( 2012 ) explored a shallow analysis-based approach, based on the assumption that the level of grammar sophistication at each proficiency level is reflected in the distribution of part-of-speech (POS) tag bigrams. 
		Cause: [(0, 26), (0, 49)]
		Effect: [(0, 0), (0, 22)]

Section 3:  3 Shallow-analysis approach to measuring syntactic complexity has 5 CE cases
	CASE: 1
	Stag: 53 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Hence we will refer to this approach as u'\u2018' shallow analysis u'\u2019'. 
		Cause: [(0, 8), (0, 19)]
		Effect: [(0, 1), (0, 6)]

	CASE: 2
	Stag: 64 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: The idea that the level of syntactic complexity (in terms of its range and sophistication) can be assessed based on the distribution of POS-tags is informed by prior studies in second language acquisition. 
		Cause: [(0, 22), (0, 34)]
		Effect: [(0, 0), (0, 19)]

	CASE: 3
	Stag: 67 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Based on this idea, Yoon and Bhat ( 2012 ) developed a set of features of syntactic complexity based on POS sequences extracted from a large corpus of ESL learners u'\u2019' spoken responses, grouped by human-assigned scores of proficiency level. 
		Cause: [(0, 21), (0, 37)]
		Effect: [(0, 39), (0, 45)]

	CASE: 4
	Stag: 71 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: The syntactic complexity of a test spoken response was estimated based on its similarity to the proficiency groups in the reference corpus with respect to the score-specific constructions. 
		Cause: [(0, 12), (0, 27)]
		Effect: [(0, 0), (0, 9)]

	CASE: 5
	Stag: 76 77 
		Pattern: 4 [['result'], ['is']]---- [['&C', '(,/./;/--)', '&ONE', '(&adj)'], ['(of &THIS (&NP))'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: We first analyze the limitations of the model studied in [ 37 ] and then describe how our model can address those limitations. The result is a new measure based on POS bigrams to assess ESL learners u'\u2019' mastery of syntactic complexity. 
		Cause: [(0, 0), (0, 22)]
		Effect: [(1, 3), (1, 22)]

Section 4:  4 Models for Measuring Grammatical Competence has 12 CE cases
	CASE: 1
	Stag: 78 79 
		Pattern: 2 [['accordingly']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: We mentioned that the measure proposed in this study is derived from assumptions similar to those studied in [ 37 ]. Accordingly, we will summarize the previously studied model, outline its limitations, show how our proposed measure addresses those limitations and compare the two measures for the task of automatic scoring of speech. 
		Cause: [(0, 0), (0, 20)]
		Effect: [(1, 2), (1, 34)]

	CASE: 2
	Stag: 81 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: They treat the concatenated collection of responses from a particular score-class as a u'\u2018' super u'\u2019' document. 
		Cause: [(0, 12), (0, 24)]
		Effect: [(0, 0), (0, 10)]

	CASE: 3
	Stag: 82 83 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: Then, regarding POS bigrams as terms, they construct POS-based vector space models for each score-class (there are four score classes denoting levels of proficiency as will be explained in Section 5.2 ), thus yielding four score-specific vector-space models (VSMs. The terms of the VSM are weighted by the term frequency-inverse document frequency ( t u'\u2062' f - i u'\u2062' d u'\u2062' f ) weighting scheme [ 29 ]. 
		Cause: [(0, 0), (0, 34)]
		Effect: [(0, 37), (1, 40)]

	CASE: 4
	Stag: 89 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Of these, c u'\u2062' o u'\u2062' s 4 was selected based on its empirical performance (it showed the strongest correlation with human-assigned scores of proficiency among the distance-based measures. 
		Cause: [(0, 21), (0, 38)]
		Effect: [(0, 0), (0, 18)]

	CASE: 5
	Stag: 94 95 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: First, the VSM-based method is likely to over-estimate the contribution of the POS bigrams when highly correlated bigrams occur as terms in the VSM. Consider the presence of a grammar pattern represented by more than one POS bigram. 
		Cause: [(0, 21), (1, 12)]
		Effect: [(0, 0), (0, 19)]

	CASE: 6
	Stag: 100 101 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: Grammatical expressions that occur frequently in one score level but rarely in other levels can be assumed to be characteristic of a specific score level. Therefore, the more uneven the distribution of a grammatical expression across score classes, the more important that grammatical expression should be as an indicator of a particular score class. 
		Cause: [(0, 0), (0, 24)]
		Effect: [(1, 2), (1, 28)]

	CASE: 7
	Stag: 103 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: A pattern that occurs rarely but uniformly across different score groups can get the same weight as a pattern which is unevenly distributed to one score group. 
		Cause: [(0, 17), (0, 25)]
		Effect: [(0, 5), (0, 15)]

	CASE: 8
	Stag: 105 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: When using t u'\u2062' f - i u'\u2062' d u'\u2062' f weighting to extract words that were strongly associated with positive sentiment in a movie review corpus (they considered each review as a document and a word as a term), it was found that a substantial proportion of words with the highest t u'\u2062' f - i u'\u2062' d u'\u2062' f were rare words (e.g.,, proper nouns) which were not directly associated with the sentiment. 
		Cause: [(0, 45), (0, 105)]
		Effect: [(0, 4), (0, 43)]

	CASE: 9
	Stag: 107 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: This is done by resorting to a maximum entropy model based approach, to which we turn next. 
		Cause: [(0, 4), (0, 17)]
		Effect: [(0, 0), (0, 2)]

	CASE: 10
	Stag: 109 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Taking an approach different from previous studies, we formulate the task of assigning a score of syntactic complexity to a spoken response as a classification problem given a spoken response, assign the response to a proficiency class. 
		Cause: [(0, 24), (0, 38)]
		Effect: [(0, 4), (0, 22)]

	CASE: 11
	Stag: 111 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: A distinguishing feature of the current study is that the measure is based on a comparison of characteristics of the test response to models trained on large amounts of data from each score point, as opposed to measures that are simply characteristics of the responses themselves (which is how measures have been considered in prior studies. 
		Cause: [(0, 14), (0, 33)]
		Effect: [(0, 35), (0, 56)]

	CASE: 12
	Stag: 115 116 
		Pattern: 62 [['therefore']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(,)', '&R']]
		sentTXT: The second limitation, related to the ineffective weighting of terms via the the t u'\u2062' f - i u'\u2062' d u'\u2062' f scheme, seems to be addressed by the fact that the MaxEnt model assigns a weight to each feature (in our case, POS bigrams) on a per-class basis (in our case, score group), by taking every instance into consideration. Therefore, a MaxEnt model has an advantage over the model described in 4.1 in that it uses four different weight schemes (one per score level) and each scheme is optimized for each score level. 
		Cause: [(0, 0), (0, 80)]
		Effect: [(1, 2), (1, 36)]

Section 5:  5 Experimental Setup has 14 CE cases
	CASE: 1
	Stag: 128 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: Test takers read and/or listened to stimulus materials and then responded to questions based on the stimuli. 
		Cause: [(0, 15), (0, 16)]
		Effect: [(0, 0), (0, 12)]

	CASE: 2
	Stag: 136 137 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The distribution of proficiency scores, along with other details of the data sets, are presented in Table 1. As seen in Table 1 , there is a strong bias towards the middle scores (score 2 and 3) with approximately 84-85% of the responses belonging to these two score levels. 
		Cause: [(1, 1), (1, 33)]
		Effect: [(0, 0), (0, 19)]

	CASE: 3
	Stag: 138 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: Although the skewed distribution limits the number of score-specific instances for the highest and lowest scores available for model training, we used the data without modifying the distribution since it is representative of responses in a large-scale language assessment scenario. 
		Cause: [(0, 30), (0, 40)]
		Effect: [(0, 0), (0, 28)]

	CASE: 4
	Stag: 144 145 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: The first stage, ASR, yields an automatic transcription, which is followed by the POS tagging stage. Subsequently, the feature extraction stage (a VSM or a MaxEnt model as the case may be) generates the syntactic complexity feature which is then incorporated in a multiple linear regression model to generate a score. 
		Cause: [(1, 14), (1, 37)]
		Effect: [(0, 1), (1, 12)]

	CASE: 5
	Stag: 156 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: However, due to substantial amount of speech recognition errors in our data, the POS error rate (resulting from the combined errors of ASR and automated POS tagger) is expected to be higher. 
		Cause: [(0, 4), (0, 12)]
		Effect: [(0, 14), (0, 35)]

	CASE: 6
	Stag: 162 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: The results that follow are based on MaxEnt classifier u'\u2019' s parameter settings initialized to zero. 
		Cause: [(0, 7), (0, 19)]
		Effect: [(0, 0), (0, 3)]

	CASE: 7
	Stag: 163 
		Pattern: 15 [['since'], [',']]---- [[], ['&C@NCTime@'], ['&R@NCTime@']]
		sentTXT: Since a preliminary analysis of the effect of varying the feature (binary or frequency) revealed that the binary-valued feature was optimal (in terms of yielding the best agreement between human and machine scores), we only report our results for this case. 
		Cause: [(0, 1), (0, 24)]
		Effect: [(0, 38), (0, 45)]

	CASE: 8
	Stag: 167 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: To illustrate this, consider a scenario where the classifier assigns two responses A and B to score level 2 (based on the maximum a posteriori condition. 
		Cause: [(0, 23), (0, 27)]
		Effect: [(0, 0), (0, 20)]

	CASE: 9
	Stag: 169 170 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: It is apparent that the classifier has an overall tendency to assign a higher score to B, but looking at its top preference alone (2 for both responses), masks this tendency. We thus capture the classifier u'\u2019' s finer-grained scoring tendency by calculating the expected value of the classifier output. 
		Cause: [(0, 1), (1, 0)]
		Effect: [(1, 2), (1, 22)]

	CASE: 10
	Stag: 173 174 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This permits us to better represent the score assigned by the MaxEnt classifier as a relative preference over score assignments. We consider a multiple regression automatic scoring model as studied in Zechner et al. 
		Cause: [(0, 14), (1, 12)]
		Effect: [(0, 0), (0, 12)]

	CASE: 11
	Stag: 180 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: A measure u'\u2019' s utility has been evaluated according to its ability to discriminate between levels of proficiency assigned by human raters. 
		Cause: [(0, 14), (0, 25)]
		Effect: [(0, 0), (0, 11)]

	CASE: 12
	Stag: 181 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: This is done by considering the Pearson correlation coefficient between the feature and the human scores. 
		Cause: [(0, 4), (0, 15)]
		Effect: [(0, 0), (0, 2)]

	CASE: 13
	Stag: 183 184 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: In our case, however, with only access to the overall proficiency scores, we use scores of language proficiency as those of grammatical skill. A criterion for evaluating the performance of the scoring model is the extent to which the automatic scores of overall proficiency agree with the human scores. 
		Cause: [(0, 22), (1, 24)]
		Effect: [(0, 0), (0, 20)]

	CASE: 14
	Stag: 184 185 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: A criterion for evaluating the performance of the scoring model is the extent to which the automatic scores of overall proficiency agree with the human scores. As in prior studies, here too the level of agreement is evaluated by means of the weighted kappa measure as well as unrounded and rounded Pearson u'\u2019' s correlations between machine and human scores (since the output of the regression model can either be rounded or regarded as is. 
		Cause: [(1, 1), (1, 33)]
		Effect: [(0, 0), (0, 25)]

Section 6:  6 Experimental Results has 5 CE cases
	CASE: 1
	Stag: 191 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Seeking to study the robustness of the measures derived using a shallow analysis, we next compare the two measures studied here, with respect to the impact of speech recognition errors on their correlation with scores of syntactic complexity. 
		Cause: [(0, 0), (0, 12)]
		Effect: [(0, 14), (0, 39)]

	CASE: 2
	Stag: 195 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: Chen and Zechner ( 2011 ) found that while using measures of syntactic complexity obtained from transcriptions, errors in ASR transcripts caused over 0.40 drop in correlation from that found with manual transcriptions 5 5 Due to differences in the dataset and ASR system, a direct comparison between the current study and the cited prior study was not possible. 
		Cause: [(0, 38), (0, 44)]
		Effect: [(0, 46), (0, 60)]

	CASE: 3
	Stag: 197 
		Pattern: 0 [[['by', 'through']]]---- [['&R@Complete@'], ['&V-ing@C@']]
		sentTXT: The effect of the measure of syntactic complexity is best studied by including it in an automatic scoring model of overall proficiency. 
		Cause: [(0, 12), (0, 21)]
		Effect: [(0, 0), (0, 10)]

	CASE: 4
	Stag: 201 
		Pattern: 0 [[['lead', 'leads', 'led'], 'to']]---- [['&V-ing/&NP@C@', '(&CAN/have/has/had)'], ['&NP@R@', '(&Clause@R@)']]
		sentTXT: As seen in Table 3 , using the proposed measure, m u'\u2062' e u'\u2062' s u'\u2062' c u'\u2062' o u'\u2062' r u'\u2062' e , leads to an improved agreement between human and machine scores of proficiency. 
		Cause: [(0, 38), (0, 47)]
		Effect: [(0, 51), (0, 60)]

	CASE: 5
	Stag: 205 206 
		Pattern: 35 [['thus']]---- [['&C', '(,/;/./--)', '(&AND)'], ['&R']]
		sentTXT: The performance gain of Base+cos4 over Base , however, is not statistically significant at level = 0.01. Thus, the inclusion of the MaxEnt-based measure of syntactic complexity results in improved agreement between machine and human scores compared to the state-of-the-art model (here, Base. 
		Cause: [(0, 0), (0, 19)]
		Effect: [(1, 1), (1, 28)]

Section 7:  7 Discussions has 4 CE cases
	CASE: 1
	Stag: 226 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: The D-Level Scale categorizes grammatical development into 8 levels according to the presence of a set of diverse grammatical expressions varying in difficulty (for example, level 0 consists of simple sentences, while level 5 consists of sentences joined by a subordinating conjunction. 
		Cause: [(0, 11), (0, 19)]
		Effect: [(0, 27), (0, 44)]

	CASE: 2
	Stag: 227 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: Similarly, Scarborough ( 1990 ) proposed the Index of Productive Syntax (IPSyn), according to which, the presence of particular grammatical structures, from a list of 60 structures (ranging from simple ones such as including only subjects and verbs, to more complex constructions such as conjoined sentences) is evidence of language acquisition milestones. 
		Cause: [(0, 18), (0, 18)]
		Effect: [(0, 20), (0, 60)]

	CASE: 3
	Stag: 228 229 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Despite the functional differences between the indices, there is a fundamental operational similarity - that they both use the presence or absence of grammatical structures, rather than their occurrence count, as evidence of acquisition of certain grammatical levels. The assumption that a presence-based view of grammatical level acquisition is also applicable to second language assessment helps validate our observation that binary-valued features yield a better performance when compared with frequency-valued features. 
		Cause: [(0, 34), (1, 31)]
		Effect: [(0, 0), (0, 31)]

	CASE: 4
	Stag: 232 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Looking ahead, an important question is the extent to which our measure is sensitive to a mismatch between training and test data. 
		Cause: [(0, 0), (0, 1)]
		Effect: [(0, 3), (0, 22)]

Section 8:  8 Conclusions has 3 CE cases
	CASE: 1
	Stag: 233 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: Seeking alternatives to measuring syntactic complexity of spoken responses via syntactic parsers, we study a shallow-analysis based approach for use in automatic scoring. 
		Cause: [(0, 0), (0, 11)]
		Effect: [(0, 13), (0, 23)]

	CASE: 2
	Stag: 234 
		Pattern: 0 [['based', 'on'], [',']]---- [[], ['&V-ing/&NP@C@', '(&Clause@C@)'], ['&R']]
		sentTXT: Empirically, we show that the proposed measure, based on a maximum entropy classification, satisfied the constraints of the design of an objective measure to a high degree. 
		Cause: [(0, 11), (0, 14)]
		Effect: [(0, 16), (0, 29)]

	CASE: 3
	Stag: 236 
		Pattern: 0 [['based', 'on']]---- [['&R', '(,)', '(&ADV)'], ['&V-ing/&NP@C@', '(&Clause@C@)']]
		sentTXT: The measure outperformed a related measure of syntactic complexity (also based on shallow-analysis of spoken response) previously found to be well-suited for automatic scoring. 
		Cause: [(0, 13), (0, 25)]
		Effect: [(0, 0), (0, 9)]

#-------------------------------------------------

