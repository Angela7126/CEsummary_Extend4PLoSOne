Current File: P14-2047.xhtml_2 P14-2047.xhtml

Section 0:  Abstract
	SentNum: 5
	CENum: 2
	SentCovered: 2
	Covered_Rate: 40.0000%

Section 1:  1 Introduction
	SentNum: 10
	CENum: 3
	SentCovered: 2
	Covered_Rate: 20.0000%

Section 2:  2 Data and experiment settings
	SentNum: 13
	CENum: 4
	SentCovered: 4
	Covered_Rate: 30.7692%

Section 3:  3 Sentence length and HTER
	SentNum: 6
	CENum: 3
	SentCovered: 5
	Covered_Rate: 83.3333%

Section 4:  4 When a sentence becomes discourse
	SentNum: 20
	CENum: 4
	SentCovered: 5
	Covered_Rate: 25.0000%

Section 5:  5 Explicit discourse relations
	SentNum: 34
	CENum: 5
	SentCovered: 6
	Covered_Rate: 17.6471%

Section 6:  6 Human edits of discourse connectives
	SentNum: 21
	CENum: 7
	SentCovered: 7
	Covered_Rate: 33.3333%

Section 7:  7 Conclusion
	SentNum: 6
	CENum: 0
	SentCovered: 0
	Covered_Rate: 0.0000%

#-------------------------------------------------

####################### CE links on each Section #########################

P14-2047.xhtml_2's CE cases

Section 0:  Abstract has 2 CE cases
	CASE: 1
	Stag: 1 
		Pattern: 0 [['based', 'on']]---- [['&V-ing/&NP@R@', '(&Clause@R@)', '&BE', '(&ADV)'], ['&NP@C@', '(&Clause@C@)']]
		sentTXT: Our analysis is based on manual evaluations of translations of news from Chinese and Arabic to English. 
		Cause: [(0, 5), (0, 16)]
		Effect: [(0, 0), (0, 1)]

	CASE: 2
	Stag: 3 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: Also related to lower translation quality is the need to employ multiple explicit discourse connectives ( because, but , etc.), as well as the presence of ambiguous discourse connectives in the English translation. 
		Cause: [(0, 17), (0, 20)]
		Effect: [(0, 0), (0, 15)]

Section 1:  1 Introduction has 3 CE cases
	CASE: 1
	Stag: 8 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: Discourse structure has largely been considered irrelevant to MT, mostly due to the assumption that discourse analysis is needed to interpret multi-sentential text while statistical MT systems are trained to translate a single sentence in one language into a single sentence in another. 
		Cause: [(0, 13), (0, 17)]
		Effect: [(0, 18), (0, 43)]

	CASE: 2
	Stag: 12 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: Similarly discourse connectives like because, but, since and while often relate information expressed in simple sentential clauses. 
		Cause: [(0, 9), (0, 17)]
		Effect: [(0, 0), (0, 6)]

	CASE: 3
	Stag: 12 
		Pattern: 407 [['because']]---- [['&R', '(,)', '(&ADV)'], ['&C']]
		sentTXT: Similarly discourse connectives like because, but, since and while often relate information expressed in simple sentential clauses. 
		Cause: [(0, 5), (0, 6)]
		Effect: [(0, 0), (0, 3)]

Section 2:  2 Data and experiment settings has 4 CE cases
	CASE: 1
	Stag: 16 
		Pattern: 0 [[['by', 'through']]]---- [[], ['&V-ing@C@', '&R']]
		sentTXT: By comparing MT output with post-edited references, HTER provides more reliable estimates of translation quality than using translated references, especially at the segment level. 
		Cause: [(0, 1), (0, 6)]
		Effect: [(0, 7), (0, 25)]

	CASE: 2
	Stag: 25 
		Pattern: 0 [['according', 'to'], [',']]---- [[], ['&NP@C@'], ['&R']]
		sentTXT: For discourse factors that are significant at the 95% confidence level or higher according to the ANOVA analysis, we provide detailed breakdown of the system HTER for each value of the discourse factor. 
		Cause: [(0, 16), (0, 18)]
		Effect: [(0, 20), (0, 34)]

	CASE: 3
	Stag: 26 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: In this paper we do not compare the performance of individual systems, but instead seek to understand if a discourse phenomena is problematic across systems. 
		Cause: [(0, 19), (0, 25)]
		Effect: [(0, 0), (0, 17)]

	CASE: 4
	Stag: 27 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: 2 2 For the readers with keen interest in system comparison, we note that according to ANOVA none of the differences in system performance on this data is statistically significant. 
		Cause: [(0, 17), (0, 27)]
		Effect: [(0, 0), (0, 14)]

Section 3:  3 Sentence length and HTER has 3 CE cases
	CASE: 1
	Stag: 29 30 
		Pattern: 265 [['so']]---- [['&C', '(,/;/./--)', '(&AND)'], ['(-far)', '(,)', '&R']]
		sentTXT: It stands to reason that long sentences will be harder to process automatically and this reasoning has motivated the first approaches to text simplification [ 3 ]. So before turning to the analysis of discourse phenomena, we examine the correlation between translation quality and sentence length. 
		Cause: [(0, 0), (0, 26)]
		Effect: [(1, 1), (1, 19)]

	CASE: 2
	Stag: 31 32 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: A strong correlation between the two would call for revival of interest in text simplification where syntactically complex sentences are transformed into several shorter sentences as a preprocessing step. We find however that no strong relationship exists between the two, as shown by the correlation coefficients between HTER values and the number of words in each segment in Table 1. 
		Cause: [(0, 26), (1, 30)]
		Effect: [(0, 0), (0, 24)]

	CASE: 3
	Stag: 33 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Next we examine if sentence u'\u2013' discourse divergence between languages and the presence of (ambiguous) discourse connectives would be more indicative of the expected translation quality. 
		Cause: [(0, 4), (0, 30)]
		Effect: [(0, 1), (0, 2)]

Section 4:  4 When a sentence becomes discourse has 4 CE cases
	CASE: 1
	Stag: 35 36 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: Chinese is known for sentences of this kind; for example, the usage of punctuation is very different in Chinese in the sense that a comma can sometimes function as a full stop in English, motivating a series of disambiguation tasks [ 7 , 20 , 19 ]. Special handling of long Chinese sentences were also shown to improve machine translation [ 8 , 21 ]. 
		Cause: [(0, 31), (1, 17)]
		Effect: [(0, 4), (0, 29)]

	CASE: 2
	Stag: 37 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: To investigate the prevalence of sentences in the source language (Chinese and Arabic in our case) that do not confirm to the notion of sentence in the target language (English for the purposes of this study), we separate the translation segments in the source language into two classes a source sentence is considered 1-1 if the reference translation consists of exactly one sentence, and 1-many if the reference contains more than one sentence. 
		Cause: [(0, 60), (0, 78)]
		Effect: [(0, 0), (0, 58)]

	CASE: 3
	Stag: 46 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: We conducted ANOVA on HTER, separately for each language, with type of segment (1-1 or 1-many) as the independent variable and systems treated as subjects. 
		Cause: [(0, 21), (0, 27)]
		Effect: [(0, 0), (0, 19)]

	CASE: 4
	Stag: 53 
		Pattern: 0 [[['if', 'once']], [',']]---- [[], ['&C@Complete@'], ['&R@Complete@']]
		sentTXT: Once 1-many segments are identified, source-side text simplification techniques may be developed [ 17 ] to improve translation quality. 
		Cause: [(0, 1), (0, 4)]
		Effect: [(0, 6), (0, 19)]

Section 5:  5 Explicit discourse relations has 5 CE cases
	CASE: 1
	Stag: 66 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: For example, while can signal either comparison or temporal relations and since can signal either contingency or temporal. 
		Cause: [(0, 13), (0, 18)]
		Effect: [(0, 2), (0, 11)]

	CASE: 2
	Stag: 70 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: This analysis gives lower bound on the translation quality degradation associated with discourse phenomena as it does not capture problems arising from connective ambiguity on the source side. 
		Cause: [(0, 15), (0, 27)]
		Effect: [(0, 0), (0, 13)]

	CASE: 3
	Stag: 71 
		Pattern: 0 [['according', 'to']]---- [['&R', '(,)'], ['&NP@C@']]
		sentTXT: We base our classification of discourse connectives into ambiguous or not according to the distribution of their senses in the PDTB. 
		Cause: [(0, 13), (0, 20)]
		Effect: [(0, 1), (0, 10)]

	CASE: 4
	Stag: 72 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: We call a connective ambiguous if its most frequent sense among comparison, contingency, expansion, temporal accounts for less than 80% of occurrence of that connective in the PDTB. 
		Cause: [(0, 6), (0, 31)]
		Effect: [(0, 0), (0, 4)]

	CASE: 5
	Stag: 74 75 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: 4 4 The ambiguous connectives are as, as if, as long as, as though, finally, if and when, in the end, in turn, lest, meanwhile, much as, neither u'\u2026' nor, now that, rather, since, ultimately, when, when and if, while. In the ANOVA tests for each language, we compared the quality of segments which contained an ambiguous connective in the reference with those that do not, with systems treated as subjects. 
		Cause: [(0, 52), (1, 31)]
		Effect: [(0, 27), (0, 49)]

Section 6:  6 Human edits of discourse connectives has 7 CE cases
	CASE: 1
	Stag: 93 94 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: [ ref ] Still some others can receive further professional game training in universities and later ( Temporal ) be employed as technical consultants by large game manufacturers, etc. [ sys ] Some people may go to the university games professional education, which is appointed as the big game manufacturers such as technical advisers. 
		Cause: [(0, 22), (1, 24)]
		Effect: [(0, 0), (0, 20)]

	CASE: 2
	Stag: 94 
		Pattern: 30 []---- [['&V-ing@C@', '(,)', '&R@Complete@']]
		sentTXT: [ sys ] Some people may go to the university games professional education, which is appointed as the big game manufacturers such as technical advisers. 
		Cause: [(0, 0), (0, 1)]
		Effect: [(0, 2), (0, 13)]

	CASE: 3
	Stag: 95 96 
		Pattern: 26 [['as']]---- [['&R@Complete@', '(,)', '(-such/-same/-seem/-regard/-regards/-regarded/-view/-views/-viewed/-denote/-denoted/-denotes)'], ['(-if/-follow/-follows/-&adv)', '&C@Complete@']]
		sentTXT: [ edited ] Some people may go to university to receive professional game education, and later ( Temporal ) be appointed by the big game manufacturers as technical advisers. The system fails to translate the discourse connective {CJK*} UTF8gbsn u'\u201c' èå u'\u201d' (later), leading to a probable misinterpretation between receiving education and being appointed as technical advisors. 
		Cause: [(0, 28), (1, 35)]
		Effect: [(0, 1), (0, 26)]

	CASE: 4
	Stag: 97 
		Pattern: 0 [['due', 'to']]---- [[], ['&NP@C@', '(,)', '&R']]
		sentTXT: Due to the lack of reliable tools and resources, we approximate mismatches between discourse expressions in the source and MT output using discourse-related edits. 
		Cause: [(0, 2), (0, 8)]
		Effect: [(0, 10), (0, 24)]

	CASE: 5
	Stag: 104 
		Pattern: 23 [['since']]---- [['&R@NCTime@', '(,)'], ['&C@NCTime@']]
		sentTXT: Obviously, the mismatch in implicit/explicit expression of discourse relation is related to the first problem we studied, i.e.,, if the source segment is translated into one or multiple sentences in English, since discourse relations between adjacent sentences are more often implicit (than intra-sentence ones. 
		Cause: [(0, 37), (0, 49)]
		Effect: [(0, 0), (0, 34)]

	CASE: 6
	Stag: 104 
		Pattern: 0 [['if']]---- [['&R@Complete@'], ['&C@Complete@']]
		sentTXT: Obviously, the mismatch in implicit/explicit expression of discourse relation is related to the first problem we studied, i.e.,, if the source segment is translated into one or multiple sentences in English, since discourse relations between adjacent sentences are more often implicit (than intra-sentence ones. 
		Cause: [(0, 23), (0, 34)]
		Effect: [(0, 0), (0, 21)]

	CASE: 7
	Stag: 104 105 
		Pattern: 7 [['for'], [['reason', 'reasons']]]---- [['&C', '(,/;/./--)', '(&AND)'], ['(&this)'], ['(,/that)', '&R']]
		sentTXT: Obviously, the mismatch in implicit/explicit expression of discourse relation is related to the first problem we studied, i.e.,, if the source segment is translated into one or multiple sentences in English, since discourse relations between adjacent sentences are more often implicit (than intra-sentence ones. For this reason we performed a Wilcoxon rank sum test for the translation quality of segments with discourse mismatch conditioned on whether the segment was 1-1 or 1-many. 
		Cause: [(0, 0), (0, 49)]
		Effect: [(1, 3), (1, 27)]

Section 7:  7 Conclusion has 0 CE cases
#-------------------------------------------------

