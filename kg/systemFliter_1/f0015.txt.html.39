<html>
<head>
<title>f0015.txt</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Searle says that since the person in the example doesn't understand Chinese -- even though he can produce intelligent Chinese conversation by following rules -- a computer cannot be said to 'understand' things.</a>
<a name="1">[1]</a> <a href="#1" id=1>In this we try to understand the behavior of a system by ascribing to it beliefs, goals, intentions, likes and dislikes, and other mental qualities.</a>
<a name="2">[2]</a> <a href="#2" id=2>I would argue that the set of rules understands Chinese, and, analogously, a computer program may be said to understand things, even if the computer does not.</a>
<a name="3">[3]</a> <a href="#3" id=3>The reason for ascribing mental qualities and mental processes to machines is the same as for ascribing them to other people.</a>
<a name="4">[4]</a> <a href="#4" id=4>A person who doesn't know Chinese memorizes a book of rules for manipulating Chinese characters.</a>
<a name="5">[5]</a> <a href="#5" id=5>We suppose that the rules result in a Chinese conversation so intelligent that the person giving and receiving the sentences can't tell him from an intelligent Chinese.</a>
<a name="6">[6]</a> <a href="#6" id=6>The third is called the intentional stance, and this is what we'll often need for understanding computer programs.</a>
<a name="7">[7]</a> <a href="#7" id=7>Researchers in artificial intelligence (AI) are interested in the use of mental terms to describe machines for two reasons.</a>
<a name="8">[8]</a> <a href="#8" id=8>He is repeatedly given Chinese sentences, to which he applies the rules, and gives back what turn out, because of the clever rules, to be Chinese sentences that are appropriate replies.</a>
<a name="9">[9]</a> <a href="#9" id=9>Adopting this principle of rationality, we see that different machines have intellectual qualities to differing extents.</a>
<a name="10">[10]</a> <a href="#10" id=10>Our object is to account for as much behavior as possible by saying the machine or person or animal does what it thinks will achieve its goals.</a>
</body>
</html>