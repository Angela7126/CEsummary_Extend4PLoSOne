<html>
<head>
<title>f0037.txt</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>So, shared disk systems have morphed to partitioned served-disk systems to improve locality.</a>
<a name="1">[1]</a> <a href="#1" id=1>So, paradoxically, shared memory systems have been successful by adopting a shared-nothing software architecture.</a>
<a name="2">[2]</a> <a href="#2" id=2>So, paradoxically, shared-memory and shared-disk systems are becoming shared-nothing systems as they aim for better data locality.</a>
<a name="3">[3]</a> <a href="#3" id=3>Persistent data is stored in a database partitioned among several servers, and these servers are packed, so that if one server fails, another member of the pack can provide access to the failed server's database.</a>
<a name="4">[4]</a> <a href="#4" id=4>In retrospect this was due to a bus rather than switched memory interconnect, unsophisticated cache management, and ignorant software.</a>
<a name="5">[5]</a> <a href="#5" id=5>Interestingly they achieve this scaling by recognizing that cache locality is critical, so sharing of memory is used very sparingly:</a>
<a name="6">[6]</a> <a href="#6" id=6>Ideally, each of the 64 processors executes in its own cache and on its own partition of the shared memory, only occasionally reading and writing memory shared with other processors.</a>
<a name="7">[7]</a> <a href="#7" id=7>RAM is cheap and so the popular data is in RAM not on disk.</a>
<a name="8">[8]</a> <a href="#8" id=8>It is generally faster to RPC to the cached version of the data than it is to read it off shared disk.</a>
<a name="9">[9]</a> <a href="#9" id=9>In part this is due to Moore's law, in part it is due to our finally bringing the software base to a modular and partitionable architecture that maps well to shared-nothing arrays (and hence to shared memory and shared disk arrays).</a>
<a name="10">[10]</a> <a href="#10" id=10>The next step is to have redundant servers and a load balancing system that can redistribute the load as servers fail.</a>
<a name="11">[11]</a> <a href="#11" id=11>hardware, software, operations mistakes, and environmental problems (power failures, storms,..</a>
<a name="12">[12]</a> <a href="#12" id=12>Systems fail for prosaic reasons:</a>
<a name="13">[13]</a> <a href="#13" id=13>Clones, packs, load balancing, failover, and fallback all improve availability -- and they are all automatic.</a>
</body>
</html>