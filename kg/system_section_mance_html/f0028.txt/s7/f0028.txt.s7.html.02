<html>
<head>
<title>f0028.txt.s7</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>One approach to this is to use the MPI (Message Passing Interface) parallel programming environment to write procedural programs that stream files across a processor array -- each node of the array exploring one part of the hierarchy.</a>
<a name="1">[1]</a> <a href="#1" id=1>The scientific file-formats of HDF, NetCDF, and FITS can represent tabular data but they provide minimal tools for searching and analyzing tabular data.</a>
<a name="2">[2]</a> <a href="#2" id=2>Performing this filter-then-analyze, data analysis on large datasets with conventional procedural tools runs slower and slower as data volumes increase.</a>
<a name="3">[3]</a> <a href="#3" id=3>Often, these arrays are accompanied by tabular data describing the experimental setup, simulation parameters, or environmental conditions.</a>
<a name="4">[4]</a> <a href="#4" id=4>From our perspective, the key aspect of Google Map-Reduce is that it applies thousands of processors and disks to explore large datasets in parallel.</a>
<a name="5">[5]</a> <a href="#5" id=5>Scientists need a way (1) to use intelligent indices and data organizations to subset the search, (2) to use parallel processing and data access to search huge datasets within seconds, and (3) to have powerful analysis tools that they can apply to the subset of data being analyzed.</a>
</body>
</html>