<html>
<head>
<title>f0028.txt.s7</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In this model, data analysis proceeds by searching all the relevant files -- opening each file, extracting the relevant data and then moving onto the next file.</a>
<a name="1">[1]</a> <a href="#1" id=1>Performing this filter-then-analyze, data analysis on large datasets with conventional procedural tools runs slower and slower as data volumes increase.</a>
<a name="2">[2]</a> <a href="#2" id=2>The scientific file-formats of HDF, NetCDF, and FITS can represent tabular data but they provide minimal tools for searching and analyzing tabular data.</a>
<a name="3">[3]</a> <a href="#3" id=3>Most scientific studies involve exploring and data mining these object-oriented tabular datasets.</a>
<a name="4">[4]</a> <a href="#4" id=4>The data avalanche is creating billions of files and trillions of events.</a>
<a name="5">[5]</a> <a href="#5" id=5>Set-oriented file processing will make file names increasingly irrelevant -- analysis will be applied to "all data with these attributes" rather than working on a list of file/directory names or name patterns.</a>
<a name="6">[6]</a> <a href="#6" id=6>As file systems grow to petabyte-scale archives with billions of files, the science community must create a synthesis of database systems and file systems.</a>
</body>
</html>