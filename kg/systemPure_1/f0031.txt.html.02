<html>
<head>
<title>f0031.txt</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The raw astronomy data from a telescope runs through a substantial "software pipeline" that extracts objects (stars, galaxies, clouds, planets, asteroids) from the data and assigns attributes (luminosity, morphology, classification) to them.</a>
<a name="1">[1]</a> <a href="#1" id=1>a unified search engine, to collect and aggregate data from several large archives simultaneously, and a huge distributed computing resource, to perform the analyses close to the data, in order to avoid moving petabytes of data across the networks.</a>
<a name="2">[2]</a> <a href="#2" id=2>It can be in the form of fluxes measured in finite size pixels on the sky, spectra (flux as a function of wavelength), individual photon events, or even phase information from the interference of radio waves.</a>
<a name="3">[3]</a> <a href="#3" id=3>The European Union also sponsors research in pipeline processing technology to handle the anticipated terabyte data streams from future large survey telescopes.</a>
</body>
</html>