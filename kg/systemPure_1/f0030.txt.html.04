<html>
<head>
<title>f0030.txt</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The data pipeline processing that analyses the raw detector data and the data storage is linearly proportional to the amount of data.</a>
<a name="1">[1]</a> <a href="#1" id=1>Some of these Web services are OGSA services to run long-running analysis jobs on the archive's data and to produce derived datasets -- but most are interactive tasks that extract data on demand for portals and for interactive client tools.</a>
<a name="2">[2]</a> <a href="#2" id=2>The vast majority of the data and almost all the "current" data will be decentralized among the data sources -- the new publishers.</a>
<a name="3">[3]</a> <a href="#3" id=3>therefore, it makes sense to move as much of the data processing as near the data as possible, because in many cases after the first few steps of processing the output volume is dramatically smaller (e.g., extracting object catalogs).</a>
<a name="4">[4]</a> <a href="#4" id=4>Therefore, while every instrument produces a steady data stream, there is an ever more complex worldwide network of facilities with large output data sets.</a>
<a name="5">[5]</a> <a href="#5" id=5>The Virtual Observatory -- sometimes also called the World Wide Telescope -- is under construction in many countries [1, 2, 5, 7, 10] It seeks to provide portals, protocols, and standards that unify the world's astronomy archives into a giant database containing all astronomy literature, images, raw data, derived datasets, and simulation data -- integrated as a single intelligent telescope [25].</a>
<a name="6">[6]</a> <a href="#6" id=6>They provide data mining tools that allow easy search and subsetting of the data objects at each archive.</a>
<a name="7">[7]</a> <a href="#7" id=7>The exponential growth in both the number of data sources and individual data set sizes puts a particular burden on the projects that generate the data:</a>
<a name="8">[8]</a> <a href="#8" id=8>Thus, the archives have only 12% of the total data and less than 25% of the public data (data is typically made public after a year).</a>
<a name="9">[9]</a> <a href="#9" id=9>This software is constantly being refined and improved, so all the old data needs to be reprocessed about once a year to produce a new dataset that includes all the data processed in the new and better way.</a>
<a name="10">[10]</a> <a href="#10" id=10>The archives each store text, image, and raw data in blobs or files, and store their schematized data in relational databases.</a>
<a name="11">[11]</a> <a href="#11" id=11>As more and more data access is through automated facilities, it is increasingly important to capture the details of how the data was derived and calibrated.</a>
<a name="12">[12]</a> <a href="#12" id=12>The transformation of raw instrument data into calibrated and cataloged data is a demanding computational task.</a>
<a name="13">[13]</a> <a href="#13" id=13>The data and derived products were collected at great expense, so the data should be safely stored at two or more locations.</a>
<a name="14">[14]</a> <a href="#14" id=14>the rate at which it produces data stays constant, while the cost of the computers required to analyze the data decreases by Moore's law.</a>
<a name="15">[15]</a> <a href="#15" id=15>As the amount of data is doubling every year, in three years the data grows by eightfold.</a>
<a name="16">[16]</a> <a href="#16" id=16>They have the additional roles of data publisher and data curator.</a>
<a name="17">[17]</a> <a href="#17" id=17>The archives provide Web service interfaces for on-demand queries and a file-transfer service for answers that involve substantial computation or data transfer.</a>
</body>
</html>