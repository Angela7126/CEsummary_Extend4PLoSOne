<html>
<head>
<title>f0028.txt</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Data classes encapsulated with methods provide data independence and make it much easier to evolve the data without perturbing programs.</a>
<a name="1">[1]</a> <a href="#1" id=1>The separation of data and programs is artificial -- one cannot see the data without using a program and most programs are data driven.</a>
<a name="2">[2]</a> <a href="#2" id=2>So, it is paradoxical that the data management community has worked for 40 years to achieve something called data independence -- a clear separation of programs from data.</a>
<a name="3">[3]</a> <a href="#3" id=3>By allowing such techniques, physical data independence allows performance improvements by reorganizing data for parallelism -- at little or no extra effort on the part of scientists.</a>
<a name="4">[4]</a> <a href="#4" id=4>As file systems grow to petabyte-scale archives with billions of files, the science community must create a synthesis of database systems and file systems.</a>
<a name="5">[5]</a> <a href="#5" id=5>In this model, data analysis proceeds by searching all the relevant files -- opening each file, extracting the relevant data and then moving onto the next file.</a>
<a name="6">[6]</a> <a href="#6" id=6>Performing this filter-then-analyze, data analysis on large datasets with conventional procedural tools runs slower and slower as data volumes increase.</a>
<a name="7">[7]</a> <a href="#7" id=7>Once you can put your types and your programs inside the database you get the parallelism, non-procedural query, and data independence advantages of traditional database systems.</a>
<a name="8">[8]</a> <a href="#8" id=8>If the data is to be analyzed by generic tools, the tools need to "understand" the data.</a>
<a name="9">[9]</a> <a href="#9" id=9>All these tools are aimed at making it easy to analyze commercial data, but they are equally applicable to scientific data analysis.</a>
<a name="10">[10]</a> <a href="#10" id=10>And, they have a collection of tools to create, access, search, and visualize the data.</a>
<a name="11">[11]</a> <a href="#11" id=11>Set-oriented file processing will make file names increasingly irrelevant -- analysis will be applied to "all data with these attributes" rather than working on a list of file/directory names or name patterns.</a>
<a name="12">[12]</a> <a href="#12" id=12>Increasingly, the datasets are so large, and the application programs are so complex, that it is much more economical to move the end-user's programs to the data and only communicate questions and answers rather than moving the source data and its applications to the user's local system.</a>
<a name="13">[13]</a> <a href="#13" id=13>So our focus here is on data exploration, interactive data analysis, and integration of Level 2 datasets.</a>
<a name="14">[14]</a> <a href="#14" id=14>If scientists are to read data collected by others, then the data must be carefully documented and must be published in forms that allow easy access and automated manipulation.</a>
<a name="15">[15]</a> <a href="#15" id=15>The cost of learning the tools (data definition and data loading, and query) doesn't seem worth it.</a>
<a name="16">[16]</a> <a href="#16" id=16>In addition, data analysis using data cubes has made huge advances, and now efforts are focused on integrating machine learning algorithms that infer trends, do data clustering, and detect anomalies.</a>
<a name="17">[17]</a> <a href="#17" id=17>If this is common, the two data centers will likely federate with one another to provide mutual data backup since the data traffic will justify making the copy.</a>
<a name="18">[18]</a> <a href="#18" id=18>When a scientist wants to correlate data from two different data centers, then there is no option but to move part of the data from one place to another.</a>
<a name="19">[19]</a> <a href="#19" id=19>it enables generic tools to understand the data, and it enables people to understand the data.</a>
</body>
</html>