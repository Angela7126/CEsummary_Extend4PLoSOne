<html>
<head>
<title>f0030.txt</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The data pipeline processing that analyses the raw detector data and the data storage is linearly proportional to the amount of data.</a>
<a name="1">[1]</a> <a href="#1" id=1>If the query is small, it can just be sent to one of the archive servers.</a>
<a name="2">[2]</a> <a href="#2" id=2>In the Virtual Observatory, most the data will be remote.</a>
<a name="3">[3]</a> <a href="#3" id=3>The data is published to the collaborations (and the world) through Web-based archives.</a>
<a name="4">[4]</a> <a href="#4" id=4>As more and more data access is through automated facilities, it is increasingly important to capture the details of how the data was derived and calibrated.</a>
<a name="5">[5]</a> <a href="#5" id=5>Much of the work was invested in building the processing pipeline, special data access methods, and Web services.</a>
<a name="6">[6]</a> <a href="#6" id=6>IRAF and AIPS++ are prototypes, but the concept needs to be extended to handle remote and virtual data sources.</a>
<a name="7">[7]</a> <a href="#7" id=7>The core will be set of simple, low-level services that are easy to implement even by small projects.</a>
<a name="8">[8]</a> <a href="#8" id=8>Thus, the archives have only 12% of the total data and less than 25% of the public data (data is typically made public after a year).</a>
<a name="9">[9]</a> <a href="#9" id=9>Each of these services, given a point in the sky and a radius (a cone), returns the archives' objects that fall within that cone.</a>
<a name="10">[10]</a> <a href="#10" id=10>As the amount of data is doubling every year, in three years the data grows by eightfold.</a>
<a name="11">[11]</a> <a href="#11" id=11>These new roles are making many projects spend large software on the software to document, publish, and provide access to the data.</a>
<a name="12">[12]</a> <a href="#12" id=12>The VO need only provide clear standards, interfaces, documentation, and reference implementations in order to have most data providers adopt a set of core services.</a>
<a name="13">[13]</a> <a href="#13" id=13>While much of the pipeline processing of the data into catalogs stored in archives is linear, and has the cost of a few thousand instructions per byte, there are also complex statistical analysis that needs to be performed on the archives subsequently.</a>
<a name="14">[14]</a> <a href="#14" id=14>see Chapter LIVNY) and to create a proper workflow for the data reduction.</a>
<a name="15">[15]</a> <a href="#15" id=15>a standardized way to invoke remote resources on the Web and to exchange complex data.</a>
<a name="16">[16]</a> <a href="#16" id=16>Traditionally, authors have written papers that contain the data and explained it.</a>
<a name="17">[17]</a> <a href="#17" id=17>The transformation of raw instrument data into calibrated and cataloged data is a demanding computational task.</a>
</body>
</html>