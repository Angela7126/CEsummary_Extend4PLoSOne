<html>
<head>
<title>f0024.txt</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The result of a production system pattern match is a substitution of constants for variables in the pattern part of the rule.</a>
<a name="1">[1]</a> <a href="#1" id=1>For example, consider the definition that a container is sterile if it is sealed against entry by bacteria, and all the bacteria in it are dead.</a>
<a name="2">[2]</a> <a href="#2" id=2>In my opinion, GPS was unsuccessful as a general problem solver, because problems don't take this form in general and because most of the knowledge about the common sense needed for problem solving and achieving goals is not simply representable in the form of rules for transforming expressions.</a>
<a name="3">[3]</a> <a href="#3" id=3>It seemed to me in 1958 that small modifications in behavior are most often representable as small modifications in beliefs about the world, and this requires a system that represents beliefs explicitly.</a>
<a name="4">[4]</a> <a href="#4" id=4>A small conceptual modification to a behavior is usually not represented by a small modification to the program, especially if machine language programs are used and any one small modification to the text of a program is considered as likely as any other.</a>
<a name="5">[5]</a> <a href="#5" id=5>Thus it cannot reason that heating a sealed container will sterilize it given that a heated bacterium dies, because it cannot reason about the unenumerated set of bacteria in the container.</a>
<a name="6">[6]</a> <a href="#6" id=6>However, a Prolog program incorporating this fragment directly can sterilize a container only by killing each bacterium individually and would require that some other part of the program successively generate the names of the bacteria.</a>
<a name="7">[7]</a> <a href="#7" id=7>For example, MYCIN (Buchanan and Shortliffe 1974) has many rules about how to infer which bacterium is causing an illness based on symptoms and the result of laboratory tests.</a>
<a name="8">[8]</a> <a href="#8" id=8>Newell's current candidate for general problem representation is SOAR (Laird, Newell and Rosenbloom 1987), which, as I understand it, is concerned with transforming one state to another, where the states need not be represented by expressions.</a>
<a name="9">[9]</a> <a href="#9" id=9>In fact MYCIN has no way of representing processes occuring in time, although other production systems can represent processes at about the level of the situation calculus to be described in the next section.</a>
<a name="10">[10]</a> <a href="#10" id=10>We say that a container is sterile if it is sealed and all the bacteria in it are dead.</a>
<a name="11">[11]</a> <a href="#11" id=11>Some contexts are very specific, so that Watson is a doctor in the context of Sherlock Holmes stories and a baritone psychologist in a tragic opera about the history of psychology.</a>
<a name="12">[12]</a> <a href="#12" id=12>This resembles the usual logical natural deduction systems, but for reasons beyond the scope of this lecture, it is probably not correct to regard contexts as equivalent to sets of assumptions -- not even infinite sets of assumptions.</a>
<a name="13">[13]</a> <a href="#13" id=13>The Friedberg approach was successful in learning only how to move a single bit from one memory cell to another, and its scheme of rewarding instructions involved in successful runs by reducing their probability of modification was shown by Herbert Simon (a now substantiated rumor froma 1987 personal communication) to be inferior to testing each program thoroughly and completely scrapping any program that wasn't perfect.</a>
<a name="14">[14]</a> <a href="#14" id=14>However, if we imagine that additional features of situations and additional actions may be added to the database, we face the problem that the axiomatization of an action is never completed.</a>
<a name="15">[15]</a> <a href="#15" id=15>It seemed then and still seems that humans communicate mainly in declarative sentences rather than in programming languages for good objective reasons that will apply whether the communicator is a human, a creature from Alpha Centauri or a computer program.</a>
<a name="16">[16]</a> <a href="#16" id=16>Conversely, if we axiomatize at a fairly high level of generality, the axioms are often longer than is convenient in special situations.</a>
<a name="17">[17]</a> <a href="#17" id=17>"If one wants a machine to be able to discover an abstraction, it seems most likely that the machine must be able to represent this abstraction in some relatively simple way" (McCarthy 1959).</a>
</body>
</html>