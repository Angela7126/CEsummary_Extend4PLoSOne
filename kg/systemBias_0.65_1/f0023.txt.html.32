<html>
<head>
<title>f0023.txt</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We have maintained that the basic notion of free will is the same for humans, animals and robots.</a>
<a name="1">[1]</a> <a href="#1" id=1>intentional behavior, because full generality is beyond the state of the art.</a>
<a name="2">[2]</a> <a href="#2" id=2>If asked to tell what it is doing, humans or some machine will tell about their choices for action and say that they intend to determine which action leads to the best consequence.</a>
<a name="3">[3]</a> <a href="#3" id=3>It seems to me that formulas (1) and (2) expressing the use of the branching time Result(e,s) function in determining what events occur make the philosophical ideas definite.</a>
<a name="4">[4]</a> <a href="#4" id=4>Since there may be many different events that can occur in s, and the theory of the function Result does not say which occurs, the theory is nondeterministic.</a>
<a name="5">[5]</a> <a href="#5" id=5>The older McNachten criterion, "unable to understand the nature and consequences of his acts", uses essentially the criteria of the present article for assessing the presence or absence of free will.</a>
<a name="6">[6]</a> <a href="#6" id=6>If a training set of (say) 32 combinations permits the ape to do the remaining 32 without further trial and error, it would be reasonable to conclude that the ape can predict the effects of the successive bounces.</a>
<a name="7">[7]</a> <a href="#7" id=7>Burning one's bridges, nailing the flag to the mast, and promising to love until death do us part are examples of actions that reduce choices.</a>
<a name="8">[8]</a> <a href="#8" id=8>If we wanted robots susceptible to schizophrenia, we would have to program in something like schizophrenia, and it would be a complicated and unmotivated undertaking -- unmotivated by anything but the goal of imitating human schizophrenia.</a>
<a name="9">[9]</a> <a href="#9" id=9>According to Dennett (phone conversation), some recent experiments suggest that apes sometimes consider the consequences of alternate actions.</a>
<a name="10">[10]</a> <a href="#10" id=10>Chess programs do compare the consequences of various moves, and so have free will in the sense of this article.</a>
<a name="11">[11]</a> <a href="#11" id=11>I am doubtful about the generalization, because I don't see how to represent commonsense preferences between actions except in terms of preferring one resulting situation to another.</a>
<a name="12">[12]</a> <a href="#12" id=12>However, the number of possible tic-tac-toe positions is small enough so that one could make a program with the same external behavior that just looked up each position in a table to determine its move.</a>
<a name="13">[13]</a> <a href="#13" id=13>He considers that freedom evolves in such a way as to make more and more events evitable, especially events that are bad for the organism.</a>
<a name="14">[14]</a> <a href="#14" id=14>The whole apparatus is visible to the ape, so it can see the consequences of each choice.</a>
<a name="15">[15]</a> <a href="#15" id=15>If the ape can mentally follow the prize as it would bounce from baffle to baffle, it will succeed.</a>
<a name="16">[16]</a> <a href="#16" id=16>It may be based on a more basic ability to predict something about what future will result from the occurrence of certain events including actions.</a>
<a name="17">[17]</a> <a href="#17" id=17>Thus "If I make this move, my opponent (or nature regarded as an opponent) will have the following choices, each of which will give me further choices.</a>
<a name="18">[18]</a> <a href="#18" id=18>Thus we can see which modifications of the notions are compatible with (1) and (2), and which require different axioms.</a>
</body>
</html>