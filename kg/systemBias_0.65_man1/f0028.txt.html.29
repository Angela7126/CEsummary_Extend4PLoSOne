<html>
<head>
<title>f0028.txt</title>
</head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The demand for tools and computational resources to perform scientific data-analysis is rising even faster than data volumes.</a>
<a name="1">[1]</a> <a href="#1" id=1>The separation of data and programs is artificial -- one cannot see the data without using a program and most programs are data driven.</a>
<a name="2">[2]</a> <a href="#2" id=2>it enables generic tools to understand the data, and it enables people to understand the data.</a>
<a name="3">[3]</a> <a href="#3" id=3>Data classes encapsulated with methods provide data independence and make it much easier to evolve the data without perturbing programs.</a>
<a name="4">[4]</a> <a href="#4" id=4>So, it is paradoxical that the data management community has worked for 40 years to achieve something called data independence -- a clear separation of programs from data.</a>
<a name="5">[5]</a> <a href="#5" id=5>Indeed, there is an emerging trend to store a personal workspace (a MyDB) at the data center and deposit answers there.</a>
<a name="6">[6]</a> <a href="#6" id=6>If the data is to be analyzed by generic tools, the tools need to "understand" the data.</a>
<a name="7">[7]</a> <a href="#7" id=7>The cost of learning the tools (data definition and data loading, and query) doesn't seem worth it.</a>
<a name="8">[8]</a> <a href="#8" id=8>As file systems grow to petabyte-scale archives with billions of files, the science community must create a synthesis of database systems and file systems.</a>
<a name="9">[9]</a> <a href="#9" id=9>The new work style in these scientific domains is to send questions to applications running at a data center and get back answers, rather than to bulk-copy raw data from the archive to your local server for further analysis.</a>
<a name="10">[10]</a> <a href="#10" id=10>And, they have a collection of tools to create, access, search, and visualize the data.</a>
<a name="11">[11]</a> <a href="#11" id=11>So our focus here is on data exploration, interactive data analysis, and integration of Level 2 datasets.</a>
<a name="12">[12]</a> <a href="#12" id=12>(2) Many analysis algorithms are super-linear, often needing N2 or N3 time to process N data points.</a>
<a name="13">[13]</a> <a href="#13" id=13>In this model, data analysis proceeds by searching all the relevant files -- opening each file, extracting the relevant data and then moving onto the next file.</a>
<a name="14">[14]</a> <a href="#14" id=14>All these tools are aimed at making it easy to analyze commercial data, but they are equally applicable to scientific data analysis.</a>
<a name="15">[15]</a> <a href="#15" id=15>Once you can put your types and your programs inside the database you get the parallelism, non-procedural query, and data independence advantages of traditional database systems.</a>
<a name="16">[16]</a> <a href="#16" id=16>These personal workspaces are also a vehicle for data analysis groups to collaborate.</a>
<a name="17">[17]</a> <a href="#17" id=17>If scientists are to read data collected by others, then the data must be carefully documented and must be published in forms that allow easy access and automated manipulation.</a>
<a name="18">[18]</a> <a href="#18" id=18>Performing this filter-then-analyze, data analysis on large datasets with conventional procedural tools runs slower and slower as data volumes increase.</a>
<a name="19">[19]</a> <a href="#19" id=19>one could focus on the science rather than needing to be an information-technology-professional with expertise in arcane computer data analysis tools.</a>
</body>
</html>